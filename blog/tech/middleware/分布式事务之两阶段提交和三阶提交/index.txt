1:"$Sreact.fragment"
2:I[10616,["874","static/chunks/874-f2e46e41114bd221.js","177","static/chunks/app/layout-c432974c723daafe.js"],"default"]
3:I[87555,[],""]
4:I[31295,[],""]
5:I[6874,["874","static/chunks/874-f2e46e41114bd221.js","968","static/chunks/968-bf93abe4de13a5fc.js","909","static/chunks/app/blog/%5B...slug%5D/page-26cc6d1a0064a78b.js"],""]
7:I[59665,[],"OutletBoundary"]
a:I[74911,[],"AsyncMetadataOutlet"]
c:I[59665,[],"ViewportBoundary"]
e:I[59665,[],"MetadataBoundary"]
10:I[26614,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/0a7d53676a1eb136.css","style"]
0:{"P":null,"b":"2sdYANRfbiQBiP_K2cNX6","p":"","c":["","blog","tech","middleware","%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%92%8C%E4%B8%89%E9%98%B6%E6%8F%90%E4%BA%A4",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","tech/middleware/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%92%8C%E4%B8%89%E9%98%B6%E6%8F%90%E4%BA%A4","c"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/0a7d53676a1eb136.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"zh-CN","children":["$","body",null,{"className":"__className_f367f3","children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"bg-[var(--background)]","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 py-12 md:flex md:items-center md:justify-between lg:px-8","children":[["$","div",null,{"className":"flex justify-center space-x-6 md:order-2","children":[["$","$L5",null,{"href":"/about","className":"text-gray-600 hover:text-gray-800","children":"关于"}],["$","$L5",null,{"href":"/blog","className":"text-gray-600 hover:text-gray-800","children":"博客"}],["$","$L5",null,{"href":"/contact","className":"text-gray-600 hover:text-gray-800","children":"联系"}]]}],["$","div",null,{"className":"mt-8 md:order-1 md:mt-0","children":["$","p",null,{"className":"text-center text-xs leading-5 text-gray-600","children":"© 2024 Skyfalling Blog. All rights reserved."}]}]]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","tech/middleware/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%92%8C%E4%B8%89%E9%98%B6%E6%8F%90%E4%BA%A4","c"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",null,["$","$L7",null,{"children":["$L8","$L9",["$","$La",null,{"promise":"$@b"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","_NYlNlhNS95OXmVtQrul7v",{"children":[["$","$Lc",null,{"children":"$Ld"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Le",null,{"children":"$Lf"}]]}],false]],"m":"$undefined","G":["$10","$undefined"],"s":false,"S":true}
11:"$Sreact.suspense"
12:I[74911,[],"AsyncMetadata"]
14:I[32923,["874","static/chunks/874-f2e46e41114bd221.js","968","static/chunks/968-bf93abe4de13a5fc.js","909","static/chunks/app/blog/%5B...slug%5D/page-26cc6d1a0064a78b.js"],"default"]
16:I[40780,["874","static/chunks/874-f2e46e41114bd221.js","968","static/chunks/968-bf93abe4de13a5fc.js","909","static/chunks/app/blog/%5B...slug%5D/page-26cc6d1a0064a78b.js"],"default"]
19:I[85300,["874","static/chunks/874-f2e46e41114bd221.js","968","static/chunks/968-bf93abe4de13a5fc.js","909","static/chunks/app/blog/%5B...slug%5D/page-26cc6d1a0064a78b.js"],"default"]
f:["$","div",null,{"hidden":true,"children":["$","$11",null,{"fallback":null,"children":["$","$L12",null,{"promise":"$@13"}]}]}]
15:T3dd1,<blockquote>
<p>在分布式一致性一文中主要介绍了分布式系统中存在的一致性问题。本文将简单介绍如何有效的解决分布式的一致性问题,其中包括什么是分布式事务，二阶段提交和三阶段提交。</p>
</blockquote>
<h3>分布式一致性回顾</h3>
<p>在分布式系统中，为了保证数据的高可用，通常，我们会将数据保留多个副本(replica)，这些副本会放置在不同的物理的机器上。为了对用户提供正确的增\删\改\差等语义，我们需要保证这些放置在不同物理机器上的副本是一致的。为了解决这种分布式一致性问题，前人在性能和数据一致性的反反复复权衡过程中总结了许多典型的协议和算法。其中比较著名的有二阶提交协议（Two Phase Commitment Protocol）、三阶提交协议（Three Phase Commitment Protocol）和Paxos算法。</p>
<h3>分布式事务</h3>
<blockquote>
<p>分布式事务是指会涉及到操作多个数据库的事务。其实就是将对同一库事务的概念扩大到了对多个库的事务。目的是为了保证分布式系统中的数据一致性。分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚）</p>
</blockquote>
<p>在分布式系统中，各个节点之间在物理上相互独立，通过网络进行沟通和协调。由于存在事务机制，可以保证每个独立节点上的数据操作可以满足ACID。但是，相互独立的节点之间无法准确的知道其他节点中的事务执行情况。所以从理论上讲，两台机器理论上无法达到一致的状态。如果想让分布式部署的多台机器中的数据保持一致性，那么就要保证在所有节点的数据写操作，要不全部都执行，要么全部的都不执行。但是，一台机器在执行本地事务的时候无法知道其他机器中的本地事务的执行结果。所以他也就不知道本次事务到底应该commit还是 roolback。所以，常规的解决办法就是引入一个“协调者”的组件来统一调度所有分布式节点的执行。</p>
<h3>XA规范</h3>
<p>X/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。    通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。   所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。     一般情况下，某一数据库无法知道其它数据库在做什么，因此，在一个 DTP 环境中，交易中间件是必需的，由它通知和协调相关数据库的提交或回滚。而一个数据库只将其自己所做的操作（可恢复）影射到全局事务中。   </p>
<blockquote>
<p>XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。</p>
</blockquote>
<p>二阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说二阶段提交其实就是实现XA分布式事务的关键(确切地说：两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做)</p>
<h3>2PC</h3>
<blockquote>
<p>二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。</p>
</blockquote>
<p>所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。</p>
<h4>准备阶段</h4>
<p>事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。可以进一步将准备阶段分为以下三个步骤：</p>
<blockquote>
<p>1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。</p>
</blockquote>
<h4>提交阶段</h4>
<p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)接下来分两种情况分别讨论提交阶段的过程。当协调者节点从所有参与者节点获得的相应消息都为”同意”时:</p>
<p><img src="/images/blog/tech/middleware/img_20250723_01.png" alt=""></p>
<blockquote>
<p>1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求。2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源。3）参与者节点向协调者节点发送”完成”消息。4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。</p>
</blockquote>
<p>如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：</p>
<p><img src="/images/blog/tech/middleware/img_20250723_02.png" alt=""></p>
<blockquote>
<p>1）协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。2）参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。3）参与者节点向协调者节点发送”回滚完成”消息。4）协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。</p>
</blockquote>
<p>　　不管最后结果如何，第二阶段都会结束当前事务。二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个缺点的：</p>
<blockquote>
<p>1、同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。2、单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）3、数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。4、二阶段无法解决的问题：协调者在发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。</p>
</blockquote>
<p>由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。</p>
<h3>3PC</h3>
<blockquote>
<p>三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。</p>
</blockquote>
<p><img src="/images/blog/tech/middleware/img_20250723_03.png" alt="图片"></p>
<p>与两阶段提交不同的是，三阶段提交有两个改动点。1、引入超时机制。同时在协调者和参与者中都引入超时机制。2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。</p>
<h4>CanCommit阶段</h4>
<p>3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。</p>
<blockquote>
<p>1.事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。2.响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No</p>
</blockquote>
<h4>PreCommit阶段</h4>
<p>协调者根据参与者的反应情况来决定是否可以进行事务的PreCommit操作。根据响应情况，有以下两种可能。假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。</p>
<blockquote>
<p>1.发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。2.事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。3.响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。</p>
</blockquote>
<p>假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。</p>
<blockquote>
<p>1.发送中断请求 协调者向所有参与者发送abort请求。2.中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</p>
</blockquote>
<h4>doCommit阶段</h4>
<p>该阶段进行真正的事务提交，也可以分为以下两种情况。执行提交</p>
<blockquote>
<p>1.发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。2.事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。3.响应反馈 事务提交完之后，向协调者发送Ack响应。4.完成事务 协调者接收到所有参与者的ack响应之后，完成事务。</p>
</blockquote>
<p>中断事务 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。</p>
<blockquote>
<p>1.发送中断请求 协调者向所有参与者发送abort请求2.事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。3.反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息4.中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。</p>
</blockquote>
<p>在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。）</p>
<h3>2PC与3PC的区别</h3>
<p>相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</p>
<hr>
<p>了解了2PC和3PC之后，我们可以发现，无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos. 意即<strong>世上只有一种一致性算法，那就是Paxos</strong>，所有其他一致性算法都是Paxos算法的不完整版。后面的文章会介绍这个公认为难于理解但是行之有效的Paxos算法。</p>
<h3>参考资料：</h3>
<p><a href="http://www.mamicode.com/info-detail-890945.html">分布式协议之两阶段提交协议（2PC）和改进三阶段提交协议（3PC）</a> <a href="http://blog.csdn.net/bluishglc/article/details/7612811">关于分布式事务、两阶段提交、一阶段提交、Best Efforts 1PC模式和事务补偿机制的研究</a> <a href="http://www.tuicool.com/articles/mARV3u">两阶段提交协议与三阶段提交协议</a></p>
17:T1f2f,<blockquote>
<p>在初识分布式系统一文中简单介绍了分布式的基本概念，本文将在上篇文章的基础上继续学习分布式的一致性问题。主要介绍分布式一致性的基本概念、重要性、一致性模型等。</p>
</blockquote>
<h3>一致性的重要性</h3>
<p>分布式领域CAP理论告诉我们，任何一个分布式系统都无法同时满足Consistency(一致性),Availability(可用性), Partition tolerance(分区容错性) 这三个基本需求。最多只能满足其中两项。 但是，一个分布式系统无论在CAP三者之间如何权衡，都无法彻底放弃一致性（Consistency），如果真的放弃一致性，那么就说明这个系统中的数据根本不可信，数据也就没有意义，那么这个系统也就没有任何价值可言。所以，无论如何，分布式系统的一致性问题都需要重点关注。(分布式系统的CAP理论、分布式系统的BASE理论)</p>
<p>这里先简单提一下，由于一个分布式系统不可能放弃一致性，那么为什么有的架构师还说在某些场景中可以牺牲一致性呢？通常这里说的放弃一致性指的是放弃数据的强一致性（后文介绍什么是强一致性）。</p>
<p>通常情况下，我们所说的分布式一致性问题通常指的是数据一致性问题。那么我们就先来了解一下什么是数据一致性。</p>
<h3>数据一致性</h3>
<p>数据一致性其实是数据库系统中的概念。我们可以简单的把一致性理解为正确性或者完整性，那么数据一致性通常指关联数据之间的逻辑关系是否正确和完整。我们知道，在数据库系统中通常用事务（访问并可能更新数据库中各种数据项的一个程序执行单元）来保证数据的一致性和完整性。而在分布式系统中，数据一致性往往指的是由于数据的复制，不同数据节点中的数据内容是否完整并且相同。</p>
<p>比如在集中式系统中，有一些关键的配置信息，可以直接保存在服务器的内存中，但是在分布式系统中，如何保存这些配置信息，又如何保证所有机器上的配置信息都保持一致，又如何保证修改一个配置能够把这次修改同步到所有机器中呢？</p>
<p>再比如，在集中式系统中，进行一个同步操作要写同一个数据的时候，可以直接使用事务+锁来管理保证数据的ACID。但是，在分布式系统中如何保证多台机器不会同时写同一条数据呢？</p>
<p>除了上面提到的同一个数据的一致性，还有一种情况也可以叫做数据的一致性：比如我们在电商网站下单，需要经历扣减库存、扣减红包、扣减折扣券等一系列操作。如果库存库存扣减成功，但是红包和折扣券扣减失败的话，也可以说是数据没有保证一致性。</p>
<p>如何保证数据的一致性，是分布式系统中必须面对的问题。</p>
<h3>为什么会有数据一致性问题</h3>
<p>在初识分布式系统中我们介绍过，虽然分布式系统有着诸多优点，但是由于采用多机器进行分布式部署的方式提供服务，必然存在着数据的复制（如数据库的异地容灾，多地部署）。分布式系统的数据复制需求主要来源于以下两个原因：</p>
<p>可用性。将数据复制到分布式部署的多台机器中，可以消除单点故障。防止系统由于某台（些）机器宕机导致的不可用。</p>
<p>性能。通过负载均衡技术，能够让分布在不同地方的数据副本全都对外提供服务。有效提高系统性能。</p>
<p>分布式系统为了提升可用性和性能，会通过复制技术来进行数据同步。复制机制的目的是为了保证数据的一致性。但是数据复制面临的主要难题也是如何保证多个副本之间的数据一致性。在分布式系统引入复制机制后，不同的数据节点之间由于网络延时等原因很容易产生数据不一致的情况。</p>
<p>如果上面提到的数据复制场景你不是很熟悉的话，下面这个例子你肯定遇到过。就是现在很多网站都是微服务化的，一个网站被垂直拆分成多个功能模块。各模块之间独立部署。模块间通过RPC或者HTTP交互。由于这种RPC或者HTTP的交互可能存在网络延迟导致超时的情况。甚至被调用方也有可能执行出错等情况，这时候就可能导致数据不一致。</p>
<p>比如下单操作要依次扣减红包、扣减折扣券、扣减库存。在下单应用的执行过程中，调用红包系统扣减红包成功了，但是再调用折扣券系统扣减折扣券的时候网络超时了。这时候下单应用根本不知道折扣券系统到底有没有执行成功。这时候他就需要一些机制来决定是要回滚红包的扣减，还是继续执行库存的扣减。这种机制，其实就是数据一致性的解决方案了。</p>
<p>由于应用分布式部署，就无法通过数据库事务保证多个写操作的原子性。一旦某个操作失败，其他操作如果不回滚的话就会发生数据不一致问题。</p>
<p>因此，如何能既保证数据一致性，又保证系统的性能，是每一个分布式系统都需要重点考虑和权衡的。一致性模型可以在做这些权衡的时候给我们很多借鉴和思考。</p>
<h3>一致性模型</h3>
<h4>强一致性</h4>
<p>当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。</p>
<p>但是这种实现对性能影响较大，因为这意味着，只要上次的操作没有处理完，就不能让用户读取数据。</p>
<h4>弱一致性</h4>
<p>系统并不保证进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。</p>
<h4>最终一致性</h4>
<p>弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS是一个典型的最终一致性系统。</p>
<p>最终一致性模型的变种</p>
<ul>
<li><p>因果一致性：如果A进程在更新之后向B进程通知更新的完成，那么B的访问操作将会返回更新的值。如果没有因果关系的C进程将会遵循最终一致性的规则。</p>
</li>
<li><p>读己所写一致性：因果一致性的特定形式。一个进程总可以读到自己更新的数据。</p>
</li>
<li><p>会话一致性：读己所写一致性的特定形式。进程在访问存储系统同一个会话内，系统保证该进程读己之所写。</p>
</li>
<li><p>单调读一致性：如果一个进程已经读取到一个特定值，那么该进程不会读取到该值以前的任何值。</p>
</li>
<li><p>单调写一致性：系统保证对同一个进程的写操作串行化。</p>
</li>
</ul>
<p>上述最终一致性的不同方式可以进行组合，例如单调读一致性和读己之所写一致性就可以组合实现。并且从实践的角度来看，这两者的组合，读取自己更新的数据，和一旦读取到最新的版本不会再读取旧版本，对于此架构上的程序开发来说，会少很多额外的烦恼。</p>
<p>为了解决分布式的一致性问题，在长期的研究探索过程中，涌现出了一大批经典的一致性协议和算法，其中比较著名的有二阶段提交协议，三阶段提交协议和Paxos算法。 下一篇文章将介绍这些和分布式一致性相关的协议和算法。</p>
18:T4029,<h2>1. Background</h2>
<p>Protocol Buffers (Protobuf) is a language-neutral, platform-neutral, extensible mechanism for serializing structured data. It was developed by Google to efficiently serialize data for use in a variety of applications, including network communication, data storage, and inter-process communication (IPC).  Protobuf messages are smaller and more efficient than text-based formats like JSON and XML ,and provides fast serialization and deserialization, which is crucial for high-performance systems. </p>
<h2>2. Protobuf compiler</h2>
<p>Protobuf allows you to define the structure of your data (messages) in a .proto file, and then use the Protobuf compiler (protoc) to generate source code in selected programming language that can serialize and deserialize data in the Protobuf format.  Protobuf adds overhead to the development process compared to formats like JSON, where you can directly parse or serialize data without needing code generation. Additionally, any changes to the schema may require re-compiling the code to handle new or modified message types.</p>
<h2>3. Dynamic compilation(Dynamic Schema)</h2>
<p>Typically, Protobuf schemas are compiled using the protoc compiler ahead of time, which generates source code in various programming languages (such as C++, Java, Python, etc.) for serialization and deserialization. However, in some scenarios, you might need to work with Protobuf messages dynamically without relying on pre-generated codes. </p>
<p>This is especially useful when:</p>
<ul>
<li>You want to work with Protobuf messages dynamically at runtime, where the schema is not known in advance.</li>
<li>You need to handle multiple or evolving Protobuf schemas at runtime without recompiling your code.</li>
<li>You want to dynamically serialize or deserialize Protobuf messages in a generic way, perhaps for applications like plugins, dynamic API handling, or protocol-based communication where the schema might change often.</li>
</ul>
<h3>Key Concepts for Dynamic Compilation in Protobuf</h3>
<ul>
<li>Dynamic Message (Dynamic Parsing)</li>
<li>Reflection API in Protobuf</li>
<li>Dynamic Code Generation</li>
</ul>
<h3>3.1 Dynamic Message (Dynamic Parsing)</h3>
<p>In Protobuf, a Dynamic Message is an object where you can manipulate the message’s fields dynamically, without needing a pre-generated class for the specific message type. This is enabled through Protobuf&#39;s Reflection API.<br>You can use dynamic messages when:</p>
<ul>
<li>The Protobuf schema is available at runtime, but you don&#39;t know the message types ahead of time.</li>
<li>You want to work with messages whose types are determined dynamically (e.g., reading from a file or network stream that specifies the message type).<br>To use dynamic messages, you typically:</li>
<li>Load the schema definition (e.g., .proto file) at runtime.</li>
<li>Use the Protobuf Reflection API to create message types and set/get fields.</li>
</ul>
<h3>3.2 Reflection API</h3>
<p>The Protobuf Reflection API allows you to inspect the structure of Protobuf messages at runtime, and dynamically access their fields. This is the core tool for implementing dynamic compilation because it lets you:</p>
<ul>
<li>Discover available fields.</li>
<li>Inspect field types (e.g., int32, string, nested messages).</li>
<li>Set and get field values dynamically.<br>The key components of the Reflection API in Protobuf are:</li>
<li>Descriptors: These are metadata objects that describe the fields, types, and structure of messages.</li>
<li>Dynamic Messages: These are messages created dynamically using descriptors, where you can set/get fields without needing a pre-compiled class.</li>
</ul>
<h3>3.3 Dynamic Code Generation with Protobuf Compiler</h3>
<p>In some use cases, you may need to generate Protobuf code dynamically based on new or unknown schemas. This would involve invoking the Protobuf compiler (protoc) programmatically to generate the code at runtime, either directly from .proto files or from a descriptor or a set of schema definitions.<br>This process typically involves the following steps:</p>
<ol>
<li>Obtain the .proto files or schema descriptors.</li>
<li>Run protoc programmatically to generate source code.</li>
<li>Use the generated code within the application to work with dynamic messages.</li>
</ol>
<h2>4. Code Implementation</h2>
<h3>4.1 Code Analysis</h3>
<p>The above method is valid for languages that support dynamic loading such as java, but not for golang. Since golang doesn&#39;t support dynamic loading, we can&#39;t use the generated source code. However, through technical analysis, we know that the conversion path from a text file to a binary message is: file.proto --&gt; FileDescriptor --&gt; proto.message, and there are two key points: </p>
<ol>
<li>how to get FileDescriptor from a proto file at runtime?</li>
<li>how to create a proto.message using FileDescriptor?</li>
</ol>
<p>For the second point, the solution is not complicated. We can use dynamicpb.message mentioned before. The following code demonstrates how to create a proto.message by dynamicpb.message:</p>
<pre><code class="language-golang">func NeweMessages(fd protoreflect.FileDescriptor, msgName string)proto.Message{
  fm := fd.Messages()
  md = fm.ByName(protoreflect.Name(msgName))
  return dynamicpb.NewMessage(md)
}
</code></pre>
<p>Now let&#39;s look at the second question, how to get FileFescriptor from a proto file at runtime? To get the FileFescriptor dynamically in golang, we first need to know how the FileFescriptor is generated. Typically, we can not get FileFescriptor directly from proto file. But we analyzed the source code in google.golang.org/protobuf , and found that FileDescriptor is created from FileDescriptorProto as follows:</p>
<pre><code class="language-golang">fdp := new(descriptorpb.FileDescriptorProto)
//Unmarshal([]byte,fdp)
fd, err := protodesc.NewFile(fdp, nil)
</code></pre>
<p>Thus, the conversion path from a text file to a binary message is changed to:  file.proto --&gt; FileDescriptorProto --&gt; FileDescriptor --&gt; proto.message,So the final question is, how do we get the FileDescriptorProto object?<br>FileDescriptorProto is a proto.message object, so it can be serialized to binary and deserialized from binary. In fact, we can use protoc to generate the binary data of FileDescriptorProto at the same time as the source code with option: --descriptor_set_out=your_file_descriptord_proto.pb.<br>Further analyzing the source code of protoc , there are plugins that receive the compiled binary streams from proto file for data processing, including code generation. </p>
<p>The following is the source code analysis, and the highlighted part is the key code:</p>
<pre><code class="language-golang">func main() {
  //...
  protogen.Options{
     ParamFunc: flags.Set,
  }.Run(func(gen *protogen.Plugin) error {
     //...
     for _, f := range gen.Files {
        if f.Generate {
           gengo.GenerateFile(gen, f)
        }
     }
     //...
     return nil
  })
}
//It reads a [pluginpb.CodeGeneratorRequest] message from [os.Stdin], invokes the plugin function, and writes a [pluginpb.CodeGeneratorResponse] message to [os.Stdout].
func (opts Options) Run(f func(*Plugin) error) {
    if err := run(opts, f); err != nil {
       fmt.Fprintf(os.Stderr, &quot;%s: %v\n&quot;, filepath.Base(os.Args[0]), err)
       os.Exit(1)
    }
}

func run(opts Options, f func(*Plugin) error) error {
    if len(os.Args) &gt; 1 {
       return fmt.Errorf(&quot;unknown argument %q (this program should be run by protoc, not directly)&quot;, os.Args[1])
    }
    //Here is the compiled binary stream from protoc
    in, err := io.ReadAll(os.Stdin)
    if err != nil {
       return err
    }
    
    req := &amp;pluginpb.CodeGeneratorRequest{}
    if err := proto.Unmarshal(in, req); err != nil {
       return err
    }
    gen, err := opts.New(req)
    if err != nil {
       return err
    }
    //This is the plugin&#39;s custom processing logic
    if err := f(gen); err != nil {
       gen.Error(err)
    }
    resp := gen.Response()
    out, err := proto.Marshal(resp)
    if err != nil {
       return err
    }
    //Write the source code to a file
    if _, err := os.Stdout.Write(out); err != nil {
       return err
    }
    return nil
}

//CodeGeneratorRequest defines a FileDescriptorProto field
type CodeGeneratorRequest struct {
    state         protoimpl.MessageState
    sizeCache     protoimpl.SizeCache
    unknownFields protoimpl.UnknownFields

    FileToGenerate []string 
    Parameter *string 
    ProtoFile []*desriptorpb.FileDescriptorProto
    SourceFileDescriptors []*descriptorpb.FileDescriptorProto 
    CompilerVersion *Version
}
</code></pre>
<p>By analyzing the source code of protoc, we can also implement a custom plugin to output the text-format serialized data of FileDescriptorProto.<br>Actually, there are two text-format serialization schemes for FileDescriptorProto: json/proto-text.</p>
<ul>
<li>JSON</li>
</ul>
<p>For json format, we can serialize/deserialize FileDescriptorProto via protojson.Marshal/Unmarshal.<br>Example of json-format:</p>
<pre><code class="language-json">{
  &quot;name&quot;:  &quot;protobuf/tns_demo.proto&quot;,
  &quot;package&quot;:  &quot;tns.search.proto&quot;,
  &quot;messageType&quot;:  [
    {
      &quot;name&quot;:  &quot;TnsDemo&quot;,
      &quot;field&quot;:  [
        {
          &quot;name&quot;:  &quot;id&quot;,
          &quot;number&quot;:  1,
          &quot;label&quot;:  &quot;LABEL_OPTIONAL&quot;,
          &quot;type&quot;:  &quot;TYPE_INT64&quot;,
          &quot;jsonName&quot;:  &quot;id&quot;
        },
        {
          &quot;name&quot;:  &quot;status&quot;,
          &quot;number&quot;:  2,
          &quot;label&quot;:  &quot;LABEL_OPTIONAL&quot;,
          &quot;type&quot;:  &quot;TYPE_INT32&quot;,
          &quot;jsonName&quot;:  &quot;status&quot;
        },
        {
          &quot;name&quot;:  &quot;result&quot;,
          &quot;number&quot;:  3,
          &quot;label&quot;:  &quot;LABEL_REPEATED&quot;,
          &quot;type&quot;:  &quot;TYPE_MESSAGE&quot;,
          &quot;typeName&quot;:  &quot;.tns.search.proto.TnsDemo.ResultEntry&quot;,
          &quot;jsonName&quot;:  &quot;result&quot;
        },
        {
          &quot;name&quot;:  &quot;reasons&quot;,
          &quot;number&quot;:  4,
          &quot;label&quot;:  &quot;LABEL_REPEATED&quot;,
          &quot;type&quot;:  &quot;TYPE_INT32&quot;,
          &quot;jsonName&quot;:  &quot;reasons&quot;
        }
      ],
      &quot;nestedType&quot;:  [
        {
          &quot;name&quot;:  &quot;ResultEntry&quot;,
          &quot;field&quot;:  [
            {
              &quot;name&quot;:  &quot;key&quot;,
              &quot;number&quot;:  1,
              &quot;label&quot;:  &quot;LABEL_OPTIONAL&quot;,
              &quot;type&quot;:  &quot;TYPE_STRING&quot;,
              &quot;jsonName&quot;:  &quot;key&quot;
            },
            {
              &quot;name&quot;:  &quot;value&quot;,
              &quot;number&quot;:  2,
              &quot;label&quot;:  &quot;LABEL_OPTIONAL&quot;,
              &quot;type&quot;:  &quot;TYPE_STRING&quot;,
              &quot;jsonName&quot;:  &quot;value&quot;
            }
          ],
          &quot;options&quot;:  {
            &quot;mapEntry&quot;:  true
          }
        }
      ]
    }
  ],
  &quot;options&quot;:  {
    &quot;goPackage&quot;:  &quot;./gen;protobuf&quot;
  },
  &quot;syntax&quot;:  &quot;proto3&quot;
}
</code></pre>
<ul>
<li>Proto-Text</li>
</ul>
<p>The Text Format  is a human-readable format used for serializing and displaying protobuf messages in text form. It is often used for debugging or configuration purposes when you want to quickly inspect the contents of a protobuf message.<br>In the text format, protobuf messages are represented in a straightforward key-value style, where each field in the message is written in a human-readable way, with the field name followed by the value. This format is defined in the Protocol Buffers specification.<br>For text-format, we can serialize/deserialize FileDescriptorProto via prototext.Marshal/Unmarshal<br>Example of text-format:</p>
<pre><code class="language-protobuf">name:  &quot;protobuf/tns_demo.proto&quot;
package:  &quot;tns.search.proto&quot;
message_type:  {
  name:  &quot;TnsDemo&quot;
  field:  {
    name:  &quot;id&quot;
    number:  1
    label:  LABEL_OPTIONAL
    type:  TYPE_INT64
    json_name:  &quot;id&quot;
  }
  field:  {
    name:  &quot;status&quot;
    number:  2
    label:  LABEL_OPTIONAL
    type:  TYPE_INT32
    json_name:  &quot;status&quot;
  }
  field:  {
    name:  &quot;result&quot;
    number:  3
    label:  LABEL_REPEATED
    type:  TYPE_MESSAGE
    type_name:  &quot;.tns.search.proto.TnsDemo.ResultEntry&quot;
    json_name:  &quot;result&quot;
  }
  field:  {
    name:  &quot;reasons&quot;
    number:  4
    label:  LABEL_REPEATED
    type:  TYPE_INT32
    json_name:  &quot;reasons&quot;
  }
  nested_type:  {
    name:  &quot;ResultEntry&quot;
    field:  {
      name:  &quot;key&quot;
      number:  1
      label:  LABEL_OPTIONAL
      type:  TYPE_STRING
      json_name:  &quot;key&quot;
    }
    field:  {
      name:  &quot;value&quot;
      number:  2
      label:  LABEL_OPTIONAL
      type:  TYPE_STRING
      json_name:  &quot;value&quot;
    }
    options:  {
      map_entry:  true
    }
  }
}
options:  {
  go_package:  &quot;./gen;protobuf&quot;
}
syntax:  &quot;proto3&quot;
</code></pre>
<h3>4.2 protoc-plugin</h3>
<p>In order to keep the generality, we choose the json-format as the serialization solution. </p>
<pre><code class="language-golang">func main() {
    protogen.Options{}.Run(func(gen *protogen.Plugin) error {
       gen.SupportedFeatures = SupportedFeatures
       for _, file := range gen.Files {
          // Skip files that are not part of the plugin&#39;s current output.
          if !file.Generate {
             continue
          }
          genJsonFile(file, gen)
          genExtFile(file, gen)
       }
       return nil
    })
}
func genJsonFile(file *protogen.File, gen *protogen.Plugin) {
    fd := file.Proto
    sci := fd.SourceCodeInfo
    fd.SourceCodeInfo = nil
    jsonFile := gen.NewGeneratedFile(file.GeneratedFilenamePrefix+&quot;.json&quot;, &quot;.&quot;)
    jsonFile.P(protojson.Format(fd))
    fd.SourceCodeInfo = sci
}
</code></pre>
<p>Once we get serialized content in json format, the rest is easy. We can save the json to tcc and load it later at runtime to marshal/unmarshal proto.Message. If the proto file changes, we can manually compile it offline and then update the new json data in tcc to realize the hot update. </p>
<h3>4.3 How to use dynamic schema</h3>
<ul>
<li>generate json schema with plugin</li>
</ul>
<pre><code class="language-shell">SRC_DIR=$(pwd)
go build -o $SRC_DIR/protoc-gen-ext
protoc --proto_path=$SRC_DIR \
--plugin=protoc-gen-go=$(which protoc-gen-go) \
--go_out=$SRC_DIR/protobuf \
--fastpb_out=$SRC_DIR/protobuf \
--plugin=protoc-gen-ext=$SRC_DIR/protoc-gen-ext \
--ext_out=$SRC_DIR/protobuf \
$SRC_DIR/protobuf/*.proto
</code></pre>
<ul>
<li>manipulate dynamic schema</li>
</ul>
<pre><code class="language-golang">    //jsonData:=getJsonFromTcc(...)
    fdp := new(descriptorpb.FileDescriptorProto)
    //load schema from json
    if err := protojson.Unmarshal([]byte(jsonData), fdp); err != nil {
       panic(err)
    }
    //create FileDescriptorfrom FileDescriptorProto
    fd, err := protodesc.NewFile(fdp, nil)
    if err != nil {
       panic(err)
    }
   // find the MessageDescriptor by name
    md = fd.Messages().ByName(protoreflect.Name(msg))
   // create dynamicpb message
    dynamicpb.NewMessage(md)
</code></pre>
<h2>5. Conlusion</h2>
<p>Dynamic compilation of Protobuf is a powerful technique for situations where the schema cannot be known ahead of time or needs to be handled at runtime. By using Protobuf’s Reflection API, Dynamic Messages, and Any fields, you can create, manipulate, and serialize Protobuf messages dynamically. This allows for greater flexibility in scenarios such as plugin-based architectures, evolving APIs, or systems that need to work with arbitrary message types at runtime. However, dynamic compilation is more complex than static compilation and may introduce performance overhead due to reflection and dynamic handling of schema data.</p>
6:["$","article",null,{"className":"min-h-screen","children":["$","div",null,{"className":"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12","children":[["$","header",null,{"className":"mb-8","children":[["$","div",null,{"className":"flex items-center mb-6","children":["$","div",null,{"className":"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal","children":[["$","svg",null,{"className":"w-4 h-4 mr-2 text-gray-400","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"}]}],["$","time",null,{"dateTime":"2025-07-23","children":"2025年07月23日"}]]}]}],["$","h1",null,{"className":"text-4xl font-bold text-gray-900 mb-6 text-center","children":"分布式事务之两阶段提交和三阶提交"}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-6 justify-center","children":[["$","$L5","分布式事务",{"href":"/blog/tag/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"分布式事务"}],["$","$L5","技术专题",{"href":"/blog/tag/%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"技术专题"}]]}]]}],["$","div",null,{"className":"max-w-5xl mx-auto","children":["$","$L14",null,{"content":"$15"}]}],["$","$11",null,{"fallback":["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":"加载导航中..."}],"children":["$","$L16",null,{"globalNav":{"prev":{"slug":"tech/middleware/分布式一致性的探究","title":"分布式一致性的探究","description":"在初识分布式系统一文中简单介绍了分布式的基本概念，本文将在上篇文章的基础上继续学习分布式的一致性问题。主要介绍分布式一致性的基本概念、重要性、一致性模型等","pubDate":"2025-07-22","tags":["分布式事务","技术专题"],"heroImage":"$undefined","content":"$17"},"next":{"slug":"tech/practice/How to implement dynamic protobuf in Golang","title":"How to implement dynamic protobuf in Golang?","description":"Protocol Buffers (Protobuf) is a language-neutral, platform-neutral, extensible mechanism for serializing structured data. It was developed by Google to efficiently serialize data for use in a variety of applications, including network communication, data storage, and inter-process communication (IPC).  Protobuf messages are smaller and more efficient than text-based formats like JSON and XML, and provides fast serialization and deserialization, which is crucial for high-performance systems.","pubDate":"2025-07-29","tags":["技术实战","Protobuf","Dynamic"],"heroImage":"$undefined","content":"$18"}},"tagNav":{"分布式事务":{"prev":"$6:props:children:props:children:props:children:2:props:children:props:globalNav:prev","next":null},"技术专题":{"prev":"$6:props:children:props:children:props:children:2:props:children:props:globalNav:prev","next":null}}}]}],["$","$L19",null,{}]]}]}]}]
9:null
d:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
b:{"metadata":[["$","title","0",{"children":"分布式事务之两阶段提交和三阶提交 - Skyfalling Blog"}],["$","meta","1",{"name":"description","content":"在分布式一致性一文中主要介绍了分布式系统中存在的一致性问题。本文将简单介绍如何有效的解决分布式的一致性问题,其中包括什么是分布式事务，二阶段提交和三阶段提交。"}],["$","meta","2",{"property":"og:title","content":"分布式事务之两阶段提交和三阶提交"}],["$","meta","3",{"property":"og:description","content":"在分布式一致性一文中主要介绍了分布式系统中存在的一致性问题。本文将简单介绍如何有效的解决分布式的一致性问题,其中包括什么是分布式事务，二阶段提交和三阶段提交。"}],["$","meta","4",{"property":"og:type","content":"article"}],["$","meta","5",{"property":"article:published_time","content":"2025-07-23"}],["$","meta","6",{"property":"article:author","content":"Skyfalling"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"分布式事务之两阶段提交和三阶提交"}],["$","meta","9",{"name":"twitter:description","content":"在分布式一致性一文中主要介绍了分布式系统中存在的一致性问题。本文将简单介绍如何有效的解决分布式的一致性问题,其中包括什么是分布式事务，二阶段提交和三阶段提交。"}],["$","link","10",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","link","11",{"rel":"icon","href":"/favicon.svg"}]],"error":null,"digest":"$undefined"}
13:{"metadata":"$b:metadata","error":null,"digest":"$undefined"}
