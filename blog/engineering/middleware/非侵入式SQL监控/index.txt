1:"$Sreact.fragment"
2:I[10616,["6874","static/chunks/6874-7791217feaf05c17.js","7177","static/chunks/app/layout-142e67ac4336647c.js"],"default"]
3:I[87555,[],""]
4:I[31295,[],""]
6:I[59665,[],"OutletBoundary"]
9:I[74911,[],"AsyncMetadataOutlet"]
b:I[59665,[],"ViewportBoundary"]
d:I[59665,[],"MetadataBoundary"]
f:I[26614,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/ab9f9bc568942ddd.css","style"]
0:{"P":null,"b":"CEV2RmJ4qYe381pMG-_gT","p":"","c":["","blog","engineering","middleware","%E9%9D%9E%E4%BE%B5%E5%85%A5%E5%BC%8FSQL%E7%9B%91%E6%8E%A7",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","engineering/middleware/%E9%9D%9E%E4%BE%B5%E5%85%A5%E5%BC%8FSQL%E7%9B%91%E6%8E%A7","c"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ab9f9bc568942ddd.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"zh-CN","children":["$","body",null,{"className":"__className_f367f3","children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"bg-[var(--background)]","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 py-12 lg:px-8","children":["$","p",null,{"className":"text-center text-xs leading-5 text-gray-400","children":["© ",2026," Skyfalling"]}]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","engineering/middleware/%E9%9D%9E%E4%BE%B5%E5%85%A5%E5%BC%8FSQL%E7%9B%91%E6%8E%A7","c"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5",null,["$","$L6",null,{"children":["$L7","$L8",["$","$L9",null,{"promise":"$@a"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","JUOzwJqIQpx62eO3NwX9Bv",{"children":[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Ld",null,{"children":"$Le"}]]}],false]],"m":"$undefined","G":["$f","$undefined"],"s":false,"S":true}
10:"$Sreact.suspense"
11:I[74911,[],"AsyncMetadata"]
13:I[6874,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],""]
14:I[32923,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
16:I[40780,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
1b:I[85300,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
e:["$","div",null,{"hidden":true,"children":["$","$10",null,{"fallback":null,"children":["$","$L11",null,{"promise":"$@12"}]}]}]
15:T4fc0,<p>你有没有遇到过因为没有打印SQL导致问题排查困难？如果你使用了成熟ORM框架，那么很容易支撑SQL的拦截和监控，例如Mybatis的Interceptor或JOOQ的Listener都支持SQL执行过程的跟踪监控，但是，如果你的ORM框架不支持SQL监控，那么很不幸，你就只能在代码中手动打印日志了。然而，为了防SQL注入，应用中的SQL语句都是参数化的，直接打印的话，SQL语句未绑定参数，ORM框架一般都提供了SQL参数绑定的功能，原生的JDBC这样就失去了一定的监控价值。</p>
<p>另外，在TOB的业务中，有些场景SQL参数超长，如大IN查询，SQL语句会长达到几万甚至十几万，此时，我们又需要对SQL语句进行缩略打印。注意，这里的SQL缩略打印不是简单的对SQL语句进行截断，而是对SQL语句中的参数列表进行截断，例如下面的SQL</p>
<pre><code class="language-sql">select * from user 
where id in (1001,1001, 1002, 1003, 1004, 1005, 1006, 1007) 
and name in(sql
select name from whitelist 
where name in(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;,&#39;h&#39;,&#39;i&#39;,&#39;j&#39;,&#39;k&#39;,&#39;l&#39;,&#39;m&#39;)
)
</code></pre>
<p>缩略下印如下：</p>
<pre><code class="language-sql">select * from user 
where id in (1001,1001, 1002, 1003, 1004,...) 
and name in(
select name from whitelist 
where name in(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,...)
)
</code></pre>
<p>既然SQL 监控很重要，那么对于应用层的SQL监控都有哪些手段呢？一个SQL请求的执行链路，一般从DAO层开始：DAO -&gt; ORM -&gt; DataSource  -&gt; Connection -&gt; Driver -&gt; DB，那么在这个链路上有哪些环节可以切入监控呢？ DAO层是数据访问层的入口，而我们的目标是应用层监控，因此，能够实现SQL监控的环节只有：ORM -&gt; DataSource  -&gt; Connection -&gt; Driver，而要实现通用的非侵入式监控，则应该独立于ORM，因此我们可以从<strong>DataSource  -&gt; Connection -&gt; Driver</strong>三个环节进行入手：</p>
<h3><strong>一、SQL Profile监控</strong></h3>
<h4><strong>1、驱动层监控</strong></h4>
<p>如果Driver层支持日志监控，则最方便，例如MySQL，可以在jdbc url中添加logger：</p>
<pre><code class="language-properties">jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC&amp;logger=Slf4JLogger&amp;profileSQL=true
</code></pre>
<p>基于Driver监控的问题在于：一方面强依赖于DB，和ORM层面临一样的问题，不具有通用性上述的问题，且需要厂商的支持，例如Oracle Driver就不支持日志监控；另一方面SQL格式固定，无法进行定制化输出。</p>
<h4><strong>2、连接层监控</strong></h4>
<p>如果厂商驱动不支持SQL日志，可以Driver进行代理实现SQL监控功能，常用的开源组件如<a href="https://p6spy.readthedocs.io/en/latest/">P6Spy</a>、<a href="https://github.com/arthurblake/log4jdbc">log4jdbc</a> 等，其原理都是代理了厂商的驱动，因此只需要修改jdbc url：</p>
<ul>
<li>pyspy</li>
</ul>
<pre><code class="language-properties">jdbc:p6spy:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC
</code></pre>
<ul>
<li>log4jdbc</li>
</ul>
<pre><code class="language-properties">jdbc:log4jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC
</code></pre>
<h4><strong>3、数据源层监控</strong></h4>
<p>可以通过对DataSource进行代理实现SQL监控</p>
<ul>
<li>P6Spy：</li>
</ul>
<pre><code class="language-java">@Bean
@Primary
public DataSource spyDataSource(@Autowired DataSource dataSource) {
  // wrap a datasource using P6SpyDataSource
  return new P6DataSource(dataSource);
}
</code></pre>
<ul>
<li>log4jdbc</li>
</ul>
<pre><code class="language-java">public DataSource spyDataSource(DataSource dataSource) {
    // wrap the provided dataSource
  return new DataSource() {
    @Override
    public Connection getConnection() throws SQLException {
      // wrap the connection with log4jdbc
      return new ConnectionSpy(dataSource.getConnection());
    }
      
    @Override
    public Connection getConnection(String username, String password) throws SQLException {
       // wrap the connection with log4jdbc
      return new ConnectionSpy(dataSource.getConnection(username, password));
     }
      //...
  };
}
</code></pre>
<p>上述三种方案都可以实现SQL监控，那么在实际应用场景中选择哪种方式更好呢？这和实际的生产方式有关。在我手，数据库是基于KDB的，Java应用是基于KsBoot，其中，数据库连接是在KDB平台配置的，底层的数据源是使用ShardingSphere+HikariDataSource进行魔改的。</p>
<p>第一种方案，由于数据库连接是由DBA维护的，升级需求修改数据库连接，因此不建议。</p>
<p>第二种方案，同理需要修改数据库连接，且比第一种更容易配错，因此也不建议。</p>
<p>排除上述两种方式，剩下的只有第三种方案了，但是第三种方案有很大的挑战，原因在于需要兼容快手kuaishou-framework奇葩的JdbcTemplate使用方式。确切地说，在于使用了DataSourceConfig。</p>
<pre><code class="language-java">public interface DataSourceConfig extends HasBizDef {

    /**
     * 数据源名称，必须与KDB申请时填写的一致
     */String bizName();

    /**
     * 获取当前可用区单库只读的JdbcTemplate
     */
    default NamedParameterJdbcTemplate read() {
        return InternalDatasourceConfig.readForceAz(this, currentAz(), currentPaz(), &quot;read&quot;);
    }   

    /**
     * 获取当前可用区单库读写的JdbcTemplate
     */
    default NamedParameterJdbcTemplate write() {
        return InternalDatasourceConfig.writeForceAz(this, currentAz(), currentPaz(), &quot;write&quot;);
    }	
  //....
}
</code></pre>
<p>DefaultDataSourceConfig是一个接口类，默认封装了NamedParameterJdbcTemplate的创建，业务方通过继承该接口来定义数据源:</p>
<pre><code class="language-kotlin">enum class AdDataSources(
    private val bizDef: BizDef,
    private val forTest: AdDataSources? = null,
    private val usingNewZk: Boolean = false
) : DataSourceConfig{
    adFansTopProfileDashboardTest,
    adFansTopProfileDashboard,
    adChargeTest,
    adCharge,
    adChargeReadOnly,
    adDspReadOnlyTest,
    adDspReadOnly;
    public open fun bizName(): String {
        return bizDef.bizName
    }
}
</code></pre>
<p>如果在业务中直接使用了DataSourceConfig创建的NamedParameterJdbcTemplate，那么我们就需要修改过程中创建的DataSource对象。那么，这里的DataSource究竟是怎么创建的呢？</p>
<p>具体扒代码的过程就不赘述了，直接说结果吧，kuaishou-framework的数据源最终是通过DataSourceFactory进行创建的，具体代码如下：</p>
<pre><code class="language-java">public static ListenableDataSource&lt;Failover&lt;Instance&gt;&gt; create(Instance i) {
   //...
   try {
       return supplyWithRetry(
        DATA_SOURCE_BUILD_RETRY,
        DATA_SOURCE_BUILD_RETRY_DELAY,
        () -&gt; new ListenableDataSource&lt;&gt;(
              bizName, 
              new HikariDataSource(config), ds -&gt; i.toString(), i),
              DataSourceFactory::needRetry);
                               
  } catch (Throwable e) {/**/}
}
</code></pre>
<p>由代码可以看到，这里的数据源实际上是通过new HikariDataSource(config)手动创建的，而DataSourceConfig又没有对外暴露创建的数据源，所以，我们该如何对DataSource代理呢?</p>
<h3><strong>二、动态修改加载类</strong></h3>
<p>成本最低的方式就是直接修改这段代码，将其中&#x7684;<em>&#x6E;ew HikariDataSource(config)</em>&#x4FEE;改&#x6210;<em>&#x6E;ew P6DataSource(new HikariDataSource(config))，</em>&#x90A3;么问题来了，这段代码属于基础组件包中的代码，基础架构组没有动力去修改，而我们又没有修改的权限，要想动这块代码，只能使用黑科技了。黑科技的手段有很多，那么问题又来了，哪种手段更合适呢？</p>
<p>首先我们来分析一下，有哪些手段可以修改Java字节码？</p>
<ul>
<li>方案一、编译时修改，需要开发maven插件</li>
</ul>
<p>（不使用maven插件的同学咋办？）</p>
<ul>
<li>方案二、加载时修改，重写类加载器</li>
</ul>
<p>需要在代码中指定特定的类加载器，用有一定的侵入式</p>
<ul>
<li>方案三、运行时修改，使用JavaAgent</li>
</ul>
<p>需要修改应用启动参数，运维成本有点高</p>
<p>首先要说明的是，这里不是对类方法进行增强，所以想使用cglib动态代理的想法是不可行的。前面三种方案都有一定的局限性：方案一比较麻烦，方案二侵入性强，方案三则需要使用JavaAgent技术，那有没有方案不使用Agent就可以动态修改已经加载的字节码呢？答案是没有，至少理论上没有。不过，好在天无绝人之路，JDK9之后，可以动态启动JavaAgent，这样就不用修改启动参数了。这里，我们选择使用byte-buddy进行字节码重写。</p>
<p><em>下面是对动态启动Java Agent技术的解释</em></p>
<blockquote>
<p>Note that starting with Java 9, there is the Launcher-Agent-Class manifest attribute for jar files that can specify the class of a Java Agent to start before the class specified with the Main-Class is launched. That way, you can easily have your Agent collaborating with your application code in your JVM, without the need for any additional command line options. The Agent can be as simple as having an agentmain method in your main class storing the Instrumentation reference in a static variable.</p>
</blockquote>
<blockquote>
<p>See <a href="https://docs.oracle.com/en/java/javase/15/docs/api/java.instrument/java/lang/instrument/package-summary.html#package.description">the java.lang.instrument package documentation</a>…</p>
</blockquote>
<blockquote>
<p>Getting hands on an Instrumentation instance when the JVM has not been started with Agents is trickier. It must support launching Agents after startup in general, e.g. via the Attach API. <a href="https://stackoverflow.com/a/19912148/2711488">This answer</a> demonstrates at its end such a self-attach to get hands on the Instrumentation. When you have the necessary manifest attribute in your application jar file, you could even use that as agent jar and omit the creation of a temporary stub file.</p>
</blockquote>
<blockquote>
<p>However, recent JVMs forbid self-attaching unless -Djdk.attach.allowAttachSelf=true has been specified at startup, but I suppose, taking additional steps at startup time, is precisely what you don’t want to do. One way to circumvent this, is to use another process. All this process has to to, is to attach to your original process and tell the JVM to start the Agent. Then, it may already terminate and everything else works the same way as before the introduction of this restriction.</p>
</blockquote>
<blockquote>
<p>As mentioned in <a href="https://stackoverflow.com/questions/56787777/?noredirect=1&lq=1#comment100160373_56787777">this comment</a>, Byte-Buddy has already implemented those necessary steps and the stripped-down Byte-Buddy-Agent contains that logic only, so you can use it to build your own logic atop it.</p>
</blockquote>
<ul>
<li>字节码工具对比</li>
</ul>
<p><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/4223630ea14c6367968188fd52cafa26.png" alt="图片"></p>
<ul>
<li>使用bytebuddy修改字节码</li>
</ul>
<p>在实现代码之前，我们回过头来再看一下快手的数据源生成：</p>
<pre><code class="language-java">new ListenableDataSource&lt;&gt;(bizName, new HikariDataSource(config), ds -&gt; i.toString());
</code></pre>
<p>这里实际生成的数据源类型是ListenableDataSource，而ListenableDataSource刚好继承了DelegatingDataSource类，而DelegatingDataSource的构造方法如下：</p>
<pre><code class="language-java">public class DelegatingDataSource implements DataSource {
   //...
  public DelegatingDataSource(DataSource targetDataSource) {
    this.setTargetDataSource(targetDataSource);
   }

  public void setTargetDataSource(@Nullable DataSource targetDataSource) {
      this.targetDataSource = targetDataSource;
  }
  //...
}
</code></pre>
<p>因此，我们可以通过改写DelegatingDataSource#setTargetDataSource方法，实现同样的效果，修改后的方法应该如下：</p>
<pre><code class="language-java">public void setTargetDataSource(@Nullable DataSource targetDataSource) {
        this.targetDataSource = new P6DataSource(targetDataSource;
}
</code></pre>
<p>那么具体如何修改字节码呢？这里是<a href="https://bytebuddy.net/#/tutorial">官方文档</a>，原理我们不做赘述，直接介绍实现了。实现方式有三种：</p>
<h4><strong>1、类文件替换</strong></h4>
<p>假设你已经通过Java代码编译了新的类，现在要替换JVM中类的定义，代码如下：</p>
<pre><code class="language-java">new ByteBuddy()
  .redefine(NewDelegatingDataSource.class)
  .name(DelegatingDataSource.class.getName())
  .make()
  .load(Thread.currentThread().getContextClassLoader(), 
        ClassReloadingStrategy.fromInstalledAgent());
</code></pre>
<h4><strong>2、操作字节码：</strong></h4>
<pre><code class="language-java">new ByteBuddy()
    .redefine(DelegatingDataSource.class)
    //重写DelegatingDataSource#setTargetDataSource方法
    .method(named(&quot;setTargetDataSource&quot;))
    .intercept(MyImplementation.INSTANCE)
    .make()
    .load(Thread.currentThread().getContextClassLoader(),
          ClassReloadingStrategy.fromInstalledAgent());

enum MyImplementation implements Implementation {

INSTANCE; // singleton

  @Override
  public InstrumentedType prepare(InstrumentedType instrumentedType) {
  return instrumentedType;
  }
  
  @Override
  public ByteCodeAppender appender(Target implementationTarget) {
  return MyAppender.INSTANCE;
  }
  
}
//字节码定义
enum MyAppender implements ByteCodeAppender {

INSTANCE; // singleton

@Override
public Size apply(MethodVisitor methodVisitor,
        Implementation.Context implementationContext,
        MethodDescription instrumentedMethod) {
  Label label0 = new Label();
  methodVisitor.visitLabel(label0);
  methodVisitor.visitLineNumber(70, label0);
  methodVisitor.visitVarInsn(ALOAD, 0);
  methodVisitor.visitTypeInsn(NEW, &quot;com/p6spy/engine/spy/P6DataSource&quot;);
  methodVisitor.visitInsn(DUP);
  methodVisitor.visitVarInsn(ALOAD, 1);
  methodVisitor.visitMethodInsn(INVOKESPECIAL, &quot;com/p6spy/engine/spy/P6DataSource&quot;, &quot;&lt;init&gt;&quot;, &quot;(Ljavax/sql/DataSource;)V&quot;, false);
  methodVisitor.visitFieldInsn(PUTFIELD, &quot;org/springframework/jdbc/datasource/DelegatingDataSource&quot;, &quot;targetDataSource&quot;, &quot;Ljavax/sql/DataSource;&quot;);
  Label label1 = new Label();
  methodVisitor.visitLabel(label1);
  methodVisitor.visitLineNumber(71, label1);
  methodVisitor.visitInsn(RETURN);
  Label label2 = new Label();
  methodVisitor.visitLabel(label2);
  methodVisitor.visitLocalVariable(&quot;this&quot;, &quot;Lorg/springframework/jdbc/datasource/DelegatingDataSource;&quot;, null, label0, label2, 0);
  methodVisitor.visitLocalVariable(&quot;targetDataSource&quot;, &quot;Ljavax/sql/DataSource;&quot;, null, label0, label2, 1);
  methodVisitor.visitMaxs(4, 2);
  return new Size(4, 2);
  }
}
</code></pre>
<p>上述代码的核心思想是字节操作字节码，操作字节码是非常复杂和繁重的事情，且无法debug，那么有没有比较方便的方式呢？</p>
<p>我们可以手动改写Java代码，然后利用插件生成对应的字节码，然后在其基础上进行修改，研发成本会低很多。这里推荐IDEA的一个插件：Byte-Code-Analyzer，使用该插件可以查看类对应的ASM字节码:</p>
<p><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/e31962a90f6598880e78d8254d6c74d9" alt="图片"></p>
<h4><strong>3、利用byte-buddy的Advice</strong></h4>
<pre><code class="language-java"> public static void redefine() {
   new ByteBuddy()
     .redefine(DelegatingDataSource.class)
     .visit(Advice.to(Decorator.class)
            .on(ElementMatchers.named(&quot;setTargetDataSource&quot;)))
     .make()
     .load(Thread.currentThread().getContextClassLoader(),
           ClassReloadingStrategy.fromInstalledAgent()).getLoaded();
 }

static class Decorator {

  //在方法开始插入代码
  @Advice.OnMethodEnter
    public static void enter(@Advice.Argument(value = 0, readOnly = false) DataSource dataSource) {
    dataSource = new P6DataSource(dataSource);
  }
}
</code></pre>
<p>byte-buddy的Advisor和动态代理的原理不一样，他是直接修改方法体的字节码，上面的方法就是表示在方法开始插入一行，其效果如下：</p>
<pre><code class="language-java">public void setTargetDataSource(@Nullable DataSource targetDataSource) {
  //插入的代码
  targetDataSource = new P6DataSource(targetDataSource);
  this.targetDataSource = targetDataSource;
}
</code></pre>
<p>注：</p>
<ol>
<li>动态修改已加载的类，是有限制条件的，不能添加方法或者字段，因此通过byte-buddy的Methoddelegation方法修改字节码是不可行的。</li>
<li>使用byte-buddy的Advice，可以对非Spring托管的类进行动态增强，因为是直接修改字节码，性能更好。</li>
</ol>
<h3><strong>三、自动生效</strong></h3>
<p>前面我们讲了如何修改字节码，以提供SQL监控功能，那么如何让SQL监控自动生效呢？我们的目标是非侵入式解决方案：既不能修改业务代码，也不能更改系统配置。鉴于Java世界的事实标准，我们利用了SpringBoot-Starter功能，只需增加一个maven依赖，就自动提供了SQL监控能力。</p>
<pre><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;com.kuaishou.ad&lt;/groupId&gt;
  &lt;artifactId&gt;sqllog-spring-boot-starter&lt;/artifactId&gt;
  &lt;version&gt;制品库查询最新版&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>至于SpringBoot-Starter的实现原理，网上资料很多，核心思想就是提供默认配置，开箱即用。需要注意的是，Spring6.0自动配置的方案有了调整，原来基于spring.factories的配置改成了org.springframework.boot.autoconfigure.AutoConfiguration.imports，原有的方式还支持，这对应普通应用没有影响，但是在实现Spring多容器隔离的方案上有一定的影响，后面有时间会展开讲一下。</p>
<pre><code class="language-java">private static String[] getConfigurations(File file) {
  @EnableAutoConfiguration
  class NoScan {
    //用于扫描META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports,该类定义在方法中,是为了避免扫描当前类时被加载
  }
  FileClassLoader classLoader = new FileClassLoader(file);
  AutoConfigurationImportSelector selector = new AutoConfigurationImportSelector();
  selector.setBeanClassLoader(classLoader);
  selector.setResourceLoader(new ClassLoaderResourcePatternResolver(classLoader));
  selector.setEnvironment(new StandardEnvironment());
  String[] configurations = selector.selectImports(new StandardAnnotationMetadata(NoScan.class));
  return configurations;
}
</code></pre>
<h3><strong>四、SQL打印效果</strong></h3>
<p>sqllog-spring-boot-starter默认基于p6spy，并对SQL输出提供了扩展，打印SQL日志如下：</p>
<p><img src="https://static.yximgs.com/udata/pkg/EE-KSTACK/28cd44d1451c960cfb982773aab6ec44" alt=""></p>
<p>SQL的打印内容分为三部分：</p>
<p>第一行，显示执行时间、耗时、SQL操作、数据库连接等信息</p>
<p>第二行，显示参数化SQL</p>
<p>第三行，显示绑定参数后的实际执行的SQL</p>
<p>通过日志看到，当SQL语句超长时，系统会对参数化SQL进行个性化缩略，而对实际执行的SQL，则保持原样输出，这样可以检索关键信息。</p>
17:T59f6,<h1>Git 常用命令速查手册</h1>
<blockquote>
<p>本文按使用场景组织，覆盖日常开发中最常用的 Git 操作。每条命令附带简要说明，部分附有使用示例。</p>
</blockquote>
<hr>
<h2>1. 配置</h2>
<pre><code class="language-bash"># 查看当前配置
git config --list

# 设置用户信息（全局）
git config --global user.name &quot;Your Name&quot;
git config --global user.email &quot;your@email.com&quot;

# 仅对当前仓库设置（去掉 --global）
git config user.name &quot;Your Name&quot;

# 设置默认编辑器
git config --global core.editor &quot;vim&quot;

# 设置默认分支名
git config --global init.defaultBranch main

# 配置命令别名
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
git config --global alias.lg &quot;log --oneline --graph --all&quot;
</code></pre>
<hr>
<h2>2. 仓库初始化与克隆</h2>
<pre><code class="language-bash"># 初始化新仓库
git init

# 克隆远程仓库
git clone &lt;url&gt;

# 克隆指定分支
git clone -b &lt;branch&gt; &lt;url&gt;

# 浅克隆（只拉最近 1 次提交，适合大仓库）
git clone --depth 1 &lt;url&gt;

# 克隆并指定本地目录名
git clone &lt;url&gt; my-project
</code></pre>
<hr>
<h2>3. 文件追踪与暂存</h2>
<pre><code class="language-bash"># 查看工作区状态
git status

# 简洁模式
git status -s

# 添加文件到暂存区
git add &lt;file&gt;
git add .                    # 当前目录所有变更
git add -A                   # 整个仓库所有变更
git add -p                   # 交互式选择要暂存的代码块

# 取消暂存（保留工作区修改）
git restore --staged &lt;file&gt;
git reset HEAD &lt;file&gt;        # 旧写法，效果相同

# 丢弃工作区修改（危险操作，不可恢复）
git restore &lt;file&gt;
git checkout -- &lt;file&gt;       # 旧写法
</code></pre>
<h3>取消跟踪已版本控制的文件</h3>
<pre><code class="language-bash"># 不再追踪文件改动（文件保留在仓库中，但本地修改不再显示为 dirty）
git update-index --assume-unchanged &lt;filePath&gt;

# 恢复追踪
git update-index --no-assume-unchanged &lt;filePath&gt;

# 查看所有被 assume-unchanged 的文件
git ls-files -v | grep &#39;^h&#39;

# 从版本控制中删除文件（但保留本地文件）
git rm --cached &lt;filePath&gt;

# 从版本控制中删除文件夹
git rm -r -f --cached &lt;dirPath&gt;
</code></pre>
<blockquote>
<p><strong><code>--assume-unchanged</code> vs <code>--skip-worktree</code></strong>：两者都能让 Git 忽略本地修改，但语义不同。<code>--assume-unchanged</code> 是性能优化提示（告诉 Git &quot;这个文件不会变&quot;），<code>--skip-worktree</code> 是明确的意图声明（&quot;我故意修改了这个文件，但不想提交&quot;）。对于本地配置文件的修改，推荐使用 <code>--skip-worktree</code>。</p>
</blockquote>
<pre><code class="language-bash">git update-index --skip-worktree &lt;filePath&gt;
git update-index --no-skip-worktree &lt;filePath&gt;
git ls-files -v | grep &#39;^S&#39;    # 查看所有 skip-worktree 文件
</code></pre>
<hr>
<h2>4. 提交</h2>
<pre><code class="language-bash"># 提交暂存区内容
git commit -m &quot;commit message&quot;

# 添加并提交所有已跟踪文件的修改（不含新文件）
git commit -am &quot;commit message&quot;

# 修改最近一次提交的信息（未推送到远程时使用）
git commit --amend -m &quot;new message&quot;

# 修改最近一次提交，追加文件但不改消息
git commit --amend --no-edit

# 创建空提交（可用于触发 CI）
git commit --allow-empty -m &quot;trigger build&quot;
</code></pre>
<hr>
<h2>5. 分支管理</h2>
<pre><code class="language-bash"># 查看本地分支
git branch

# 查看所有分支（含远程）
git branch -a

# 查看分支及最后一次提交
git branch -v

# 创建分支
git branch &lt;name&gt;

# 创建并切换
git checkout -b &lt;name&gt;
git switch -c &lt;name&gt;         # 推荐新写法

# 切换分支
git checkout &lt;name&gt;
git switch &lt;name&gt;            # 推荐新写法

# 重命名当前分支
git branch -m &lt;new-name&gt;

# 删除本地分支（已合并）
git branch -d &lt;name&gt;

# 强制删除本地分支（未合并也删）
git branch -D &lt;name&gt;

# 删除远程分支
git push origin --delete &lt;name&gt;

# 查看已合并到当前分支的分支
git branch --merged

# 查看未合并到当前分支的分支
git branch --no-merged
</code></pre>
<hr>
<h2>6. 合并与变基</h2>
<pre><code class="language-bash"># 合并指定分支到当前分支
git merge &lt;branch&gt;

# 合并时不使用 fast-forward（保留合并提交记录）
git merge --no-ff &lt;branch&gt;

# 只生成一个合并提交（压缩对方所有提交）
git merge --squash &lt;branch&gt;

# 变基（将当前分支的提交移到目标分支的最新提交之后）
git rebase &lt;branch&gt;

# 交互式变基（修改/合并/删除/排序最近 N 次提交）
git rebase -i HEAD~N

# 变基冲突后继续 / 跳过 / 终止
git rebase --continue
git rebase --skip
git rebase --abort

# 合并冲突后终止合并
git merge --abort
</code></pre>
<h3>Cherry-pick</h3>
<pre><code class="language-bash"># 将某个提交应用到当前分支
git cherry-pick &lt;commit-hash&gt;

# 连续多个提交
git cherry-pick &lt;hash1&gt; &lt;hash2&gt;

# 只暂存不提交
git cherry-pick &lt;hash&gt; --no-commit
</code></pre>
<hr>
<h2>7. 远程协作</h2>
<pre><code class="language-bash"># 查看远程仓库
git remote -v

# 添加远程仓库
git remote add origin &lt;url&gt;

# 修改远程仓库地址
git remote set-url origin &lt;new-url&gt;

# 拉取远程更新（不合并）
git fetch
git fetch --all              # 拉取所有远程
git fetch --prune            # 同时清理已删除的远程分支引用

# 拉取并合并（= fetch + merge）
git pull

# 拉取并变基（= fetch + rebase，保持线性历史）
git pull --rebase

# 推送
git push
git push origin &lt;branch&gt;

# 首次推送并建立追踪关系
git push -u origin &lt;branch&gt;

# 强制推送（覆盖远程历史，团队协作慎用）
git push --force

# 安全的强制推送（远程有新提交时会拒绝）
git push --force-with-lease

# 推送所有分支
git push --all

# 推送所有标签
git push --tags
</code></pre>
<hr>
<h2>8. 暂存工作区（Stash）</h2>
<pre><code class="language-bash"># 暂存当前工作区和暂存区的修改
git stash

# 带描述信息
git stash save &quot;work in progress: feature X&quot;
git stash push -m &quot;description&quot;   # 推荐新写法

# 暂存时包含未跟踪的文件
git stash -u

# 暂存时包含所有文件（含 .gitignore 忽略的）
git stash -a

# 查看 stash 列表
git stash list

# 恢复最近的 stash（保留 stash 记录）
git stash apply

# 恢复并删除最近的 stash
git stash pop

# 恢复指定的 stash
git stash apply stash@{2}

# 删除指定 stash
git stash drop stash@{0}

# 清空所有 stash
git stash clear

# 查看某个 stash 的内容
git stash show -p stash@{0}
</code></pre>
<hr>
<h2>9. 日志与差异</h2>
<pre><code class="language-bash"># 查看提交日志
git log

# 简洁单行显示
git log --oneline

# 图形化显示分支合并历史
git log --oneline --graph --all

# 显示每次提交的文件变更统计
git log --stat

# 显示每次提交的具体修改
git log -p

# 最近 N 次提交
git log -n 5

# 按作者过滤
git log --author=&quot;name&quot;

# 按时间范围过滤
git log --since=&quot;2024-01-01&quot; --until=&quot;2024-06-30&quot;

# 按提交信息关键字搜索
git log --grep=&quot;fix bug&quot;

# 搜索某段代码的变更历史
git log -S &quot;functionName&quot;

# 查看某个文件的提交历史
git log -- &lt;file&gt;
git log --follow -- &lt;file&gt;   # 包含重命名前的历史
</code></pre>
<h3>差异对比</h3>
<pre><code class="language-bash"># 工作区 vs 暂存区
git diff

# 暂存区 vs 最新提交
git diff --staged
git diff --cached            # 同义

# 两个分支之间的差异
git diff &lt;branch1&gt;..&lt;branch2&gt;

# 两个提交之间的差异
git diff &lt;commit1&gt;..&lt;commit2&gt;

# 只看文件名列表
git diff --name-only

# 查看文件改动统计
git diff --stat
</code></pre>
<hr>
<h2>10. 撤销与回退</h2>
<pre><code class="language-bash"># 撤销工作区修改（未暂存）
git restore &lt;file&gt;

# 撤销暂存（保留工作区修改）
git restore --staged &lt;file&gt;

# 回退到某个提交（保留修改在工作区）
git reset --soft &lt;commit&gt;

# 回退到某个提交（保留修改在暂存区）
git reset --mixed &lt;commit&gt;     # 默认模式

# 回退到某个提交（丢弃所有修改，危险操作）
git reset --hard &lt;commit&gt;

# 回退最近 N 次提交
git reset --soft HEAD~N

# 创建一个新提交来撤销指定提交（安全的回退方式，不改写历史）
git revert &lt;commit&gt;

# 撤销多个连续提交
git revert &lt;older-commit&gt;..&lt;newer-commit&gt;

# 只修改工作区不自动提交
git revert --no-commit &lt;commit&gt;
</code></pre>
<blockquote>
<p><strong><code>reset</code> vs <code>revert</code></strong>：<code>reset</code> 改写提交历史（适合未推送的本地提交），<code>revert</code> 创建新提交来撤销（适合已推送的公共分支）。在多人协作的分支上，永远优先使用 <code>revert</code>。</p>
</blockquote>
<hr>
<h2>11. 标签</h2>
<pre><code class="language-bash"># 查看所有标签
git tag

# 按模式过滤
git tag -l &quot;v1.*&quot;

# 创建轻量标签
git tag &lt;tag-name&gt;

# 创建附注标签（推荐）
git tag -a &lt;tag-name&gt; -m &quot;description&quot;

# 给历史提交打标签
git tag -a &lt;tag-name&gt; &lt;commit-hash&gt;

# 查看标签详情
git show &lt;tag-name&gt;

# 推送单个标签到远程
git push origin &lt;tag-name&gt;

# 推送所有标签
git push origin --tags

# 删除本地标签
git tag -d &lt;tag-name&gt;

# 删除远程标签
git push origin --delete &lt;tag-name&gt;
</code></pre>
<hr>
<h2>12. 子模块</h2>
<pre><code class="language-bash"># 添加子模块
git submodule add &lt;url&gt; &lt;path&gt;

# 克隆含子模块的仓库
git clone --recurse-submodules &lt;url&gt;

# 已克隆后初始化子模块
git submodule init
git submodule update

# 一步到位
git submodule update --init --recursive

# 更新所有子模块到最新
git submodule update --remote

# 删除子模块
git submodule deinit &lt;path&gt;
git rm &lt;path&gt;
rm -rf .git/modules/&lt;path&gt;
</code></pre>
<hr>
<h2>13. Worktree（多工作目录）</h2>
<pre><code class="language-bash"># 为指定分支创建一个独立的工作目录（无需 stash 即可同时处理多个分支）
git worktree add &lt;path&gt; &lt;branch&gt;

# 创建新分支并建立 worktree
git worktree add -b &lt;new-branch&gt; &lt;path&gt;

# 查看所有 worktree
git worktree list

# 删除 worktree
git worktree remove &lt;path&gt;

# 清理无效的 worktree 引用
git worktree prune
</code></pre>
<hr>
<h2>14. 查找与定位</h2>
<pre><code class="language-bash"># 查找引入 bug 的提交（二分法）
git bisect start
git bisect bad                # 当前版本有 bug
git bisect good &lt;commit&gt;      # 某个已知正常的版本
# Git 自动切换到中间版本，测试后标记 good/bad，直到定位到具体提交
git bisect reset              # 结束 bisect

# 查看某行代码的最后修改人和提交
git blame &lt;file&gt;
git blame -L 10,20 &lt;file&gt;    # 只看第 10-20 行

# 在所有提交中搜索内容
git grep &quot;pattern&quot;
git grep &quot;pattern&quot; &lt;branch&gt;
</code></pre>
<hr>
<h2>15. 清理</h2>
<pre><code class="language-bash"># 预览将被清理的未跟踪文件
git clean -n

# 删除未跟踪的文件
git clean -f

# 删除未跟踪的文件和目录
git clean -fd

# 删除未跟踪的文件（含 .gitignore 忽略的文件）
git clean -fdx

# 垃圾回收（压缩历史，清理悬空对象）
git gc

# 清理远程已删除的分支引用
git remote prune origin
git fetch --prune             # 等价
</code></pre>
<hr>
<h2>16. 常见场景速查</h2>
<h3>撤销最近一次提交但保留代码</h3>
<pre><code class="language-bash">git reset --soft HEAD~1
</code></pre>
<h3>合并多次提交为一个</h3>
<pre><code class="language-bash">git rebase -i HEAD~3
# 编辑器中将后两个 pick 改为 squash (或 s)，保存退出
</code></pre>
<h3>从其他分支拿一个文件</h3>
<pre><code class="language-bash">git checkout &lt;branch&gt; -- &lt;file&gt;
git restore --source &lt;branch&gt; -- &lt;file&gt;   # 推荐新写法
</code></pre>
<h3>找回误删的分支或提交</h3>
<pre><code class="language-bash"># 查看所有引用变更记录（包括已删除的）
git reflog

# 基于 reflog 中的哈希恢复
git checkout -b recovered-branch &lt;hash&gt;
</code></pre>
<h3>修改历史提交的作者信息</h3>
<pre><code class="language-bash">git rebase -i &lt;commit&gt;^
# 将目标提交标记为 edit，保存退出
git commit --amend --author=&quot;Name &lt;email&gt;&quot; --no-edit
git rebase --continue
</code></pre>
<h3>统计代码贡献</h3>
<pre><code class="language-bash"># 按作者统计提交数
git shortlog -sn

# 统计某人的代码行数增删
git log --author=&quot;name&quot; --numstat --pretty=&quot;%H&quot; | awk &#39;NF==3 {add+=$1; del+=$2} END {print &quot;+&quot;add, &quot;-&quot;del}&#39;
</code></pre>
<h3>临时切到其他分支修 bug，不想 stash</h3>
<pre><code class="language-bash"># 用 worktree 在另一个目录打开 hotfix 分支，互不干扰
git worktree add ../hotfix-dir hotfix/issue-123

# 修完后删除
git worktree remove ../hotfix-dir
</code></pre>
<h3>只克隆仓库的某个子目录（Sparse Checkout）</h3>
<pre><code class="language-bash">git clone --filter=blob:none --sparse &lt;url&gt;
cd &lt;repo&gt;
git sparse-checkout set path/to/subdir
</code></pre>
<h3>把未提交的修改生成补丁发给别人</h3>
<pre><code class="language-bash"># 生成补丁文件
git diff &gt; my-changes.patch

# 对方应用补丁
git apply my-changes.patch
</code></pre>
<h3>把已提交的 commit 生成补丁</h3>
<pre><code class="language-bash"># 生成最近 3 次提交的补丁文件（每个提交一个 .patch 文件）
git format-patch -3

# 对方应用
git am *.patch
</code></pre>
<hr>
<h2>17. .gitignore</h2>
<pre><code class="language-bash"># .gitignore 文件常用模式

# 忽略所有 .log 文件
*.log

# 但保留 important.log
!important.log

# 忽略根目录下的 build 文件夹（不影响子目录中的 build）
/build/

# 忽略所有目录下的 node_modules
node_modules/

# 忽略所有 .env 文件（防止泄露密钥）
.env
.env.*

# 忽略 IDE 配置
.idea/
.vscode/
*.swp
*.swo
*~

# 忽略操作系统文件
.DS_Store
Thumbs.db
</code></pre>
<pre><code class="language-bash"># .gitignore 已经添加规则，但文件之前已被跟踪？需要先从缓存中移除
git rm --cached &lt;file&gt;
git commit -m &quot;stop tracking &lt;file&gt;&quot;

# 检查某个文件为什么被忽略
git check-ignore -v &lt;file&gt;

# 列出所有被忽略的文件
git status --ignored

# 全局 gitignore（对所有仓库生效）
git config --global core.excludesfile ~/.gitignore_global
</code></pre>
<hr>
<h2>18. Git Hooks</h2>
<p>Git Hooks 是在特定事件（提交、推送等）发生时自动执行的脚本，存放在 <code>.git/hooks/</code> 目录下。</p>
<h3>常用 Hook 类型</h3>
<table>
<thead>
<tr>
<th>Hook</th>
<th>触发时机</th>
<th>典型用途</th>
</tr>
</thead>
<tbody><tr>
<td><code>pre-commit</code></td>
<td><code>git commit</code> 执行前</td>
<td>代码格式检查、lint、单元测试</td>
</tr>
<tr>
<td><code>commit-msg</code></td>
<td>提交信息写入后</td>
<td>校验 commit message 格式</td>
</tr>
<tr>
<td><code>pre-push</code></td>
<td><code>git push</code> 执行前</td>
<td>运行测试、阻止推送到 main</td>
</tr>
<tr>
<td><code>post-merge</code></td>
<td><code>git merge</code> 完成后</td>
<td>自动安装依赖</td>
</tr>
<tr>
<td><code>pre-rebase</code></td>
<td><code>git rebase</code> 执行前</td>
<td>阻止对公共分支变基</td>
</tr>
<tr>
<td><code>post-checkout</code></td>
<td><code>git checkout</code> 完成后</td>
<td>环境初始化</td>
</tr>
</tbody></table>
<h3>示例：pre-commit 检查是否有 console.log</h3>
<pre><code class="language-bash">#!/bin/sh
# .git/hooks/pre-commit

if git diff --cached --name-only | grep -E &#39;\.(js|ts|tsx)$&#39; | xargs grep -l &#39;console\.log&#39; 2&gt;/dev/null; then
    echo &quot;Error: console.log found in staged files&quot;
    exit 1
fi
</code></pre>
<h3>使用 Husky 管理 Hooks（推荐）</h3>
<p><code>.git/hooks/</code> 不会被提交到仓库，团队共享不方便。<a href="https://typicode.github.io/husky/">Husky</a> 解决了这个问题：</p>
<pre><code class="language-bash"># 安装
npm install husky -D
npx husky init

# 添加 pre-commit hook
echo &quot;npm run lint&quot; &gt; .husky/pre-commit
</code></pre>
<hr>
<h2>19. Git LFS（大文件存储）</h2>
<p>Git 不擅长处理大文件（二进制、模型文件、设计稿等），Git LFS 用指针文件替代大文件，实际内容存储在单独的 LFS 服务器上。</p>
<pre><code class="language-bash"># 安装（macOS）
brew install git-lfs

# 在仓库中启用
git lfs install

# 追踪特定类型的大文件
git lfs track &quot;*.psd&quot;
git lfs track &quot;*.zip&quot;
git lfs track &quot;models/**&quot;

# 追踪规则保存在 .gitattributes 中，需要提交
git add .gitattributes
git commit -m &quot;track large files with LFS&quot;

# 后续正常 add/commit/push，LFS 文件会自动走 LFS 通道
git add large-file.psd
git commit -m &quot;add design file&quot;
git push

# 查看当前 LFS 追踪的文件模式
git lfs track

# 查看 LFS 管理的文件列表
git lfs ls-files

# 拉取所有 LFS 文件（克隆后可能需要）
git lfs pull
</code></pre>
<hr>
<h2>20. Git Archive（导出代码）</h2>
<pre><code class="language-bash"># 导出当前 HEAD 为 zip
git archive --format=zip HEAD -o project.zip

# 导出指定分支
git archive --format=tar.gz release/v1.0 -o release-v1.0.tar.gz

# 只导出某个子目录
git archive HEAD --prefix=src/ -- src/ -o src-only.zip

# 导出两个版本之间的差异文件
git diff --name-only v1.0 v2.0 | xargs git archive HEAD -o diff-files.zip --
</code></pre>
<hr>
<h2>21. 交互式变基详解</h2>
<p><code>git rebase -i</code> 是最强大的提交历史编辑工具，编辑器中每行一个提交，支持以下操作：</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>缩写</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>pick</code></td>
<td><code>p</code></td>
<td>保留该提交（默认）</td>
</tr>
<tr>
<td><code>reword</code></td>
<td><code>r</code></td>
<td>保留提交但修改提交信息</td>
</tr>
<tr>
<td><code>edit</code></td>
<td><code>e</code></td>
<td>暂停在该提交，允许修改内容</td>
</tr>
<tr>
<td><code>squash</code></td>
<td><code>s</code></td>
<td>合并到上一个提交，合并提交信息</td>
</tr>
<tr>
<td><code>fixup</code></td>
<td><code>f</code></td>
<td>合并到上一个提交，丢弃本条提交信息</td>
</tr>
<tr>
<td><code>drop</code></td>
<td><code>d</code></td>
<td>删除该提交</td>
</tr>
</tbody></table>
<h3>典型场景</h3>
<pre><code class="language-bash"># 合并最近 4 次提交为 1 个
git rebase -i HEAD~4
# 编辑器中：第一个保持 pick，其余改为 squash 或 fixup

# 调整提交顺序：直接在编辑器中拖动行的位置

# 拆分一个提交为多个
git rebase -i HEAD~3
# 将目标提交标记为 edit，保存退出
git reset HEAD~1              # 撤回提交但保留文件修改
git add file1 &amp;&amp; git commit -m &quot;part 1&quot;
git add file2 &amp;&amp; git commit -m &quot;part 2&quot;
git rebase --continue
</code></pre>
<hr>
<h2>22. 签名与验证</h2>
<pre><code class="language-bash"># 配置 GPG 签名
git config --global user.signingkey &lt;GPG-KEY-ID&gt;
git config --global commit.gpgsign true    # 默认对所有提交签名

# 签名提交
git commit -S -m &quot;signed commit&quot;

# 签名标签
git tag -s v1.0 -m &quot;signed release&quot;

# 验证提交签名
git log --show-signature

# 验证标签签名
git tag -v v1.0
</code></pre>
<hr>
<h2>23. 高级配置技巧</h2>
<pre><code class="language-bash"># 自动纠正拼写错误的命令（如 git stauts → git status）
git config --global help.autocorrect 10   # 1 秒后自动执行

# 启用 rerere（记住冲突解决方式，下次自动应用）
git config --global rerere.enabled true

# diff 时使用更好的算法（对函数移动更友好）
git config --global diff.algorithm histogram

# 全局忽略文件权限变更（在 macOS/Windows 上避免无意义的 diff）
git config --global core.fileMode false

# 设置 pull 默认使用 rebase（保持线性历史）
git config --global pull.rebase true

# 推送时自动设置上游分支
git config --global push.autoSetupRemote true

# 多行 commit message 使用 heredoc
git commit -m &quot;$(cat &lt;&lt;&#39;EOF&#39;
feat: add user authentication

- Add JWT token generation
- Add login/logout endpoints
- Add middleware for protected routes
EOF
)&quot;
</code></pre>
<hr>
<h2>24. 速查表</h2>
<table>
<thead>
<tr>
<th>想做什么</th>
<th>命令</th>
</tr>
</thead>
<tbody><tr>
<td>查看状态</td>
<td><code>git status</code></td>
</tr>
<tr>
<td>添加所有修改</td>
<td><code>git add -A</code></td>
</tr>
<tr>
<td>提交</td>
<td><code>git commit -m &quot;msg&quot;</code></td>
</tr>
<tr>
<td>拉取 + 变基</td>
<td><code>git pull --rebase</code></td>
</tr>
<tr>
<td>推送</td>
<td><code>git push</code></td>
</tr>
<tr>
<td>新建分支并切换</td>
<td><code>git switch -c feat/xxx</code></td>
</tr>
<tr>
<td>合并分支</td>
<td><code>git merge --no-ff feat/xxx</code></td>
</tr>
<tr>
<td>暂存工作区</td>
<td><code>git stash -u</code></td>
</tr>
<tr>
<td>恢复暂存</td>
<td><code>git stash pop</code></td>
</tr>
<tr>
<td>查看简洁日志</td>
<td><code>git log --oneline --graph</code></td>
</tr>
<tr>
<td>撤销最近提交</td>
<td><code>git reset --soft HEAD~1</code></td>
</tr>
<tr>
<td>安全回退已推送的提交</td>
<td><code>git revert &lt;hash&gt;</code></td>
</tr>
<tr>
<td>找回误删内容</td>
<td><code>git reflog</code></td>
</tr>
<tr>
<td>查看某行代码作者</td>
<td><code>git blame &lt;file&gt;</code></td>
</tr>
<tr>
<td>二分法查 bug</td>
<td><code>git bisect start</code></td>
</tr>
<tr>
<td>只拿某个提交</td>
<td><code>git cherry-pick &lt;hash&gt;</code></td>
</tr>
<tr>
<td>导出代码压缩包</td>
<td><code>git archive HEAD -o out.zip</code></td>
</tr>
</tbody></table>
18:T5d30,<blockquote>
<p>Trie 树（前缀树、字典树）是字符串检索领域最经典的数据结构之一，广泛应用于中文分词、输入法联想、DNA 序列匹配等场景。然而，朴素 Trie 的空间开销极大——每个节点通常需要维护一个大小等于字符集的指针数组，在 Unicode 字符集下这一问题尤为突出。Double Array Trie（DAT）通过两个整型数组 BASE 和 CHECK 对 Trie 进行紧凑编码，在保留 O(m) 查询复杂度（m 为查询串长度）的前提下，将空间占用压缩到接近理论下限。本文从有限自动机的视角出发，系统剖析 DAT 的数据结构设计、构建算法、查询流程、动态更新策略及其工程应用。</p>
</blockquote>
<h2>朴素 Trie 的空间困境</h2>
<p>Trie 树的核心思想是利用字符串的公共前缀来减少存储冗余。给定一组字符串集合，Trie 将每个字符串拆解为字符序列，从根节点出发，沿着字符边依次向下延伸，共享相同前缀的路径。这种结构天然支持前缀匹配和最长前缀查找，查询时间复杂度仅与查询串长度 m 相关，与字典规模 n 无关。</p>
<p>然而朴素实现存在严重的空间浪费问题。最常见的做法是为每个节点分配一个大小为 <code>|Σ|</code> 的数组（<code>Σ</code> 为字符集），数组的第 i 个位置存储字符 i 对应的子节点指针。对于 ASCII 字符集，<code>|Σ| = 128</code>；对于中文场景，常用汉字约 6700 个，若考虑 Unicode 全集则更大。一棵包含数万个词条的中文词典 Trie，节点数可能达到数十万，每个节点都分配一个 6700 大小的指针数组，空间开销将高达 GB 级别，而这些数组中绝大多数位置是空的——一个典型的中文 Trie 节点平均只有 2~5 个子节点。</p>
<p>另一种做法是使用 HashMap 或链表来存储子节点映射，虽然能节省空间，但引入了哈希计算或链表遍历的额外开销，在高频查询场景下性能不够理想。</p>
<p>这就是 Double Array Trie 要解决的核心问题：如何在保持 Trie 的查询效率的同时，将空间占用降低到可接受的水平。</p>
<h2>从 Trie 到 DFA：有限自动机视角</h2>
<p>理解 Double Array Trie 的关键在于将 Trie 树重新建模为一个<strong>确定有限自动机</strong>（Deterministic Finite Automaton，DFA）。</p>
<h3>状态与变量的定义</h3>
<p>在 DFA 的视角下，Trie 的每一个节点对应一个<strong>状态（State）</strong>，每一条边对应一个<strong>输入变量（Input Symbol）</strong>。具体地：</p>
<ul>
<li><strong>状态集合 Q</strong>：Trie 中所有节点的集合。根节点为初始状态 <code>s₀</code>，所有标记为词尾的节点构成接受状态集 <code>F</code>。</li>
<li><strong>输入字母表 Σ</strong>：所有可能出现的字符构成的集合。每个字符被编码为一个正整数（变量编号），例如&quot;啊&quot;编为 1，&quot;阿&quot;编为 2，&quot;胶&quot;编为 5 等。</li>
<li><strong>状态转移函数 δ</strong>：<code>δ(s, c) = t</code> 表示在状态 s 下，接收输入字符 c 后转移到状态 t。</li>
</ul>
<h3>状态转移的核心语义</h3>
<p>以一个简单的中文词典为例，包含词条：<strong>啊、阿胶、阿根廷、阿拉伯、阿拉伯人、埃及</strong>。</p>
<p>从根节点出发，输入&quot;阿&quot;后进入&quot;阿&quot;节点，再输入&quot;胶&quot;进入&quot;阿胶&quot;节点。整个过程就是一系列状态转移的链式执行。DFA 的判定规则是：如果输入串消耗完毕后当前状态属于接受状态集 F，则该串被&quot;接受&quot;（即是词典中的合法词条）；否则拒绝。</p>
<p>这种建模方式的意义在于：DFA 是一个纯数学对象，其状态转移函数可以用任何满足语义约束的数据结构来实现。朴素 Trie 用指针数组实现 δ，而 Double Array Trie 用两个整型数组实现 δ——这正是 DAT 压缩空间的理论基础。</p>
<h2>Double Array Trie 的数据结构</h2>
<p>DAT 的核心数据结构极其简洁：仅由两个等长的整型数组 <code>base[]</code> 和 <code>check[]</code> 构成，整个 Trie 的拓扑结构和状态转移信息都被编码在这两个数组之中。</p>
<h3>BASE 数组与 CHECK 数组的语义</h3>
<p>设 Trie 中存在一条从状态 s 经字符 c 到达状态 t 的转移边（即 <code>δ(s, c) = t</code>），则 DAT 中的编码规则为：</p>
<pre><code>base[s] + c = t
check[t] = s
</code></pre>
<p>其中：</p>
<ul>
<li><code>s</code> 和 <code>t</code> 是状态在数组中的下标位置</li>
<li><code>c</code> 是字符的编号（正整数）</li>
<li><code>base[s]</code> 称为状态 s 的<strong>基地址（base value）</strong>，它决定了 s 的所有子状态在数组中的分布起点</li>
<li><code>check[t]</code> 记录状态 t 的<strong>父状态</strong>，用于验证状态转移的合法性</li>
</ul>
<p>这组公式的含义可以直观理解为：<strong>状态 s 的所有子节点在数组中以 <code>base[s]</code> 为偏移量排列，子节点 t 的位置由 <code>base[s] + c</code> 确定，同时 <code>check[t]</code> 反向指回父节点 s 以确保不冲突。</strong></p>
<h3>词结尾标记</h3>
<p>除了拓扑结构，DAT 还需要记录哪些状态是&quot;接受状态&quot;（即对应一个完整词条的结尾）。标记方式如下：</p>
<ul>
<li>如果状态 i 是某个词的结尾节点：<ul>
<li>若 <code>base[i] == 0</code>（该节点无子节点），则将 <code>base[i]</code> 设为 <code>-i</code></li>
<li>若 <code>base[i] != 0</code>（该节点有子节点，即某个词是另一个词的前缀），则将 <code>base[i]</code> 设为 <code>-base[i]</code>（取负值）</li>
</ul>
</li>
</ul>
<p>这样，通过检查 <code>base[i]</code> 是否为负数即可判定状态 i 是否为词的结尾。在查询时，使用 <code>|base[i]|</code> 取绝对值来恢复真正的基地址以继续转移。</p>
<h3>结构示意</h3>
<p>以词典 {啊, 阿胶, 阿根廷, 阿拉伯, 阿拉伯人, 埃及} 为例，假设变量编号如下：</p>
<table>
<thead>
<tr>
<th>字符</th>
<th>啊</th>
<th>阿</th>
<th>埃</th>
<th>根</th>
<th>胶</th>
<th>拉</th>
<th>及</th>
<th>廷</th>
<th>伯</th>
<th>人</th>
</tr>
</thead>
<tbody><tr>
<td>编号</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
</tr>
</tbody></table>
<p>构建完成后的双数组（简化示意）大致如下：</p>
<table>
<thead>
<tr>
<th>下标 i</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
<th>13</th>
<th>14</th>
<th>15</th>
<th>16</th>
</tr>
</thead>
<tbody><tr>
<td>base[i]</td>
<td>0</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>4</td>
<td>-5</td>
<td>-6</td>
<td>2</td>
<td>-8</td>
<td>-9</td>
<td>8</td>
<td>-11</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>check[i]</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>6</td>
<td>9</td>
<td>10</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody></table>
<p>在该表中，<code>base[1] = -1</code> 表示下标 1 对应的状态&quot;啊&quot;是一个完整词条且无子节点。<code>base[6] = -6</code> 表示&quot;阿胶&quot;既是完整词条，同时 <code>|base[6]| = 6</code> 还可以作为基地址继续向下转移（虽然在本例中&quot;阿胶&quot;无后续词）。</p>
<h2>构建算法</h2>
<p>DAT 的构建过程本质上是将 Trie 的树形结构&quot;铺平&quot;到一维数组中，核心挑战在于为每个父节点找到一个合适的 base 值，使得其所有子节点都能无冲突地映射到数组的空闲位置上。</p>
<h3>层次遍历构建过程</h3>
<p>构建过程采用层次遍历（BFS）策略，逐层处理 Trie 中的每一层节点。</p>
<p><strong>Step 1：处理第一层（根节点的子节点）。</strong></p>
<p>根节点的 base 值通常初始化为 0 或 1。将根的所有子节点按其变量编号直接放入数组。例如根有三个子节点&quot;啊&quot;(编号 1)、&quot;阿&quot;(编号 2)、&quot;埃&quot;(编号 3)，若 <code>base[root] = 0</code>，则它们分别放入位置 1、2、3，并设置对应的 check 值指向根节点。</p>
<p><strong>Step 2：为有子节点的状态分配 base 值。</strong></p>
<p>对于当前层中每一个拥有子节点的状态 s，需要找到一个正整数 k 作为 <code>base[s]</code> 的值，使得对于 s 的所有子节点变量编号 c₁, c₂, ..., cₙ，位置 <code>k + c₁, k + c₂, ..., k + cₙ</code> 在数组中全部为空（即 <code>check[k + cᵢ] == 0</code>）。</p>
<p>具体做法是从 k = 1 开始递增搜索，直到找到满足条件的 k 值。找到后：</p>
<ul>
<li>设置 <code>base[s] = k</code></li>
<li>对每个子节点变量 cᵢ，设置 <code>check[k + cᵢ] = s</code></li>
</ul>
<p><strong>Step 3：逐层重复。</strong></p>
<p>将当前层所有已分配位置的子节点加入下一层待处理队列，重复 Step 2 直至所有层处理完毕。</p>
<p><strong>Step 4：标记词结尾。</strong></p>
<p>遍历数组，对所有属于词尾的状态 i，按前述规则将 <code>base[i]</code> 取负。</p>
<h3>冲突解决：寻找可用偏移量</h3>
<p>Step 2 中寻找 k 的过程是构建算法的性能瓶颈。最朴素的做法是线性扫描，从 1 开始逐一尝试。这种方式的时间复杂度在最坏情况下可达 O(n * |Σ|)，其中 n 为数组长度。</p>
<p>实际工程实现中有若干优化手段：</p>
<ul>
<li><strong>空位链表</strong>：维护一个空闲位置的链表，跳过已占用的位置，减少无效扫描</li>
<li><strong>起始搜索位置优化</strong>：记录上一次成功分配的 k 值，下一次从该值附近开始搜索，利用局部性原理减少搜索范围</li>
<li><strong>字符编号排序</strong>：将子节点按编号从小到大排序，利用最小编号快速排除不可能的 k 值</li>
</ul>
<h3>完整构建示例</h3>
<p>以词典 {啊, 阿胶, 阿根廷, 阿拉伯, 阿拉伯人, 埃及} 为例，逐步演示构建过程。</p>
<p><strong>初始化</strong>：<code>base[root] = 0</code>，root 位于下标 0。</p>
<p><strong>第一层</strong>：根的子节点为&quot;啊&quot;(c=1)、&quot;阿&quot;(c=2)、&quot;埃&quot;(c=3)。</p>
<ul>
<li>k = 0（base[root] = 0）</li>
<li>&quot;啊&quot; → 位置 0+1 = 1，check[1] = 0</li>
<li>&quot;阿&quot; → 位置 0+2 = 2，check[2] = 0</li>
<li>&quot;埃&quot; → 位置 0+3 = 3，check[3] = 0</li>
</ul>
<p><strong>第二层</strong>：处理&quot;啊&quot;、&quot;阿&quot;、&quot;埃&quot;的子节点。</p>
<p>&quot;啊&quot;无子节点，标记为词尾：base[1] = -1。</p>
<p>&quot;阿&quot;有子节点&quot;根&quot;(c=4)、&quot;胶&quot;(c=5)、&quot;拉&quot;(c=6)。需要找 k 使得位置 k+4、k+5、k+6 均为空。k=1 时，位置 5、6、7 均空闲，满足条件。</p>
<ul>
<li>base[2] = 1</li>
<li>&quot;阿根&quot; → 位置 1+4 = 5，check[5] = 2（状态&quot;阿&quot;的下标）</li>
<li>&quot;阿胶&quot; → 位置 1+5 = 6，check[6] = 2</li>
<li>&quot;阿拉&quot; → 位置 1+6 = 7，check[7] = 2（注意此处是&quot;阿拉&quot;对应变量&quot;拉&quot;编号 6）</li>
</ul>
<p>&quot;埃&quot;有子节点&quot;及&quot;(c=7)。需要找 k 使得位置 k+7 为空。k=1 时，位置 8 空闲。</p>
<ul>
<li>base[3] = 1</li>
<li>&quot;埃及&quot; → 位置 1+7 = 8，check[8] = 3</li>
</ul>
<p><strong>第三层及后续</strong>：继续处理&quot;阿根&quot;、&quot;阿胶&quot;、&quot;阿拉&quot;、&quot;埃及&quot;等节点的子节点，按同样的规则分配 base 值和 check 值。</p>
<p>&quot;阿胶&quot;无子节点，标记词尾：base[6] = -6（若原本 base[6] 非零则取负）。</p>
<p>&quot;阿根&quot;有子节点&quot;廷&quot;(c=8)。找 k 使得 k+8 为空闲位置。</p>
<p>&quot;阿拉&quot;有子节点&quot;伯&quot;(c=9)。找 k 使得 k+9 为空闲位置。</p>
<p>以此类推，直到所有叶节点处理完毕，并对&quot;阿根廷&quot;&quot;阿拉伯&quot;&quot;阿拉伯人&quot;&quot;埃及&quot;等词尾状态做标记。</p>
<h2>查询算法</h2>
<p>DAT 的查询过程与 DFA 的运行语义完全一致：从初始状态出发，逐字符消耗输入串，通过状态转移函数判断路径是否合法。</p>
<h3>前缀匹配流程</h3>
<p>给定查询串 <code>w = c₁c₂...cₘ</code>，查询过程如下：</p>
<ol>
<li>初始化当前状态 <code>s = root</code>（下标 0）</li>
<li>对于每个字符 <code>cᵢ</code>（i 从 1 到 m）：<ul>
<li>计算目标位置 <code>t = |base[s]| + code(cᵢ)</code></li>
<li>检查 <code>check[t]</code> 是否等于 s</li>
<li>若相等，则转移成功，令 <code>s = t</code>，继续处理下一个字符</li>
<li>若不等，则转移失败，查询串不存在于词典中</li>
</ul>
</li>
<li>所有字符处理完毕后，检查 <code>base[s]</code> 是否为负数：<ul>
<li>若为负，则 s 是词尾状态，查询串是词典中的完整词条</li>
<li>若为正，则 s 不是词尾状态，查询串仅为某个词的前缀</li>
</ul>
</li>
</ol>
<h3>查询示例</h3>
<p>以查询&quot;阿胶及&quot;为例：</p>
<p><strong>第一步</strong>：当前状态 s = 0（根），输入字符&quot;阿&quot;，编号 2。</p>
<ul>
<li>计算 t = |base[0]| + 2 = 0 + 2 = 2</li>
<li>check[2] == 0（根的下标）？是 → 转移到状态 2</li>
</ul>
<p><strong>第二步</strong>：当前状态 s = 2，输入字符&quot;胶&quot;，编号 5。</p>
<ul>
<li>计算 t = |base[2]| + 5 = 1 + 5 = 6</li>
<li>check[6] == 2？是 → 转移到状态 6</li>
<li>此时 base[6] 为负数，说明&quot;阿胶&quot;是一个完整词条</li>
</ul>
<p><strong>第三步</strong>：当前状态 s = 6，输入字符&quot;及&quot;，编号 7。</p>
<ul>
<li>计算 t = |base[6]| + 7 = 6 + 7 = 13</li>
<li>check[13] == 6？否（check[13] 不等于 6）→ 转移失败</li>
<li>结论：&quot;阿胶及&quot;不是词典中的合法词条</li>
</ul>
<h3>查询失败的快速检测</h3>
<p>DAT 的查询具有&quot;fast-fail&quot;特性。在任意一步中，只要 <code>check[t] != s</code>，即可立即终止查询并返回&quot;不存在&quot;。这意味着：</p>
<ul>
<li>对于不存在的词条，查询通常在消耗少量字符后就能快速拒绝</li>
<li>查询时间复杂度严格为 O(m)，其中 m 为查询串长度</li>
<li>每一步仅涉及一次加法运算、一次数组访问和一次整数比较，Cache 友好且无分支预测负担</li>
</ul>
<p>这种效率是 HashMap 实现难以比拟的——HashMap 在最坏情况下可能退化为 O(m * n) 的逐一比对，而且哈希计算本身也有开销。</p>
<h2>动态更新</h2>
<p>DAT 的一个显著弱点在于动态更新的复杂性。与 HashMap 或链表 Trie 的 O(1) 插入不同，DAT 的插入操作可能触发级联的位置重分配。</p>
<h3>插入新词的冲突处理</h3>
<p>当向已构建好的 DAT 中插入一个新词时，可能出现以下情况：新词的某个前缀已存在于 DAT 中，但在需要分叉的节点处，新子节点的目标位置已被其他状态占用。</p>
<p>例如，假设词典中已有&quot;阿拉伯&quot;和&quot;阿拉伯人&quot;。现在要插入&quot;阿拉根&quot;。在处理到&quot;阿拉&quot;节点时，需要添加子节点&quot;根&quot;(c=4)。计算目标位置 <code>base[阿拉] + 4</code>，若该位置已被占用，则发生冲突。</p>
<h3>子树迁移策略</h3>
<p>冲突解决的基本思路是<strong>子树迁移</strong>：将冲突节点的整个子树迁移到一个新的基地址位置。具体步骤为：</p>
<ol>
<li><p><strong>确定需要迁移的节点</strong>：比较冲突双方（当前节点的子节点集合 vs. 占用位置的节点的子节点集合），选择子节点较少的一方进行迁移，以减少迁移开销。</p>
</li>
<li><p><strong>寻找新的 base 值</strong>：为待迁移的节点找到一个新的 k 值，使得其所有子节点（包括新增的）都能映射到空闲位置。</p>
</li>
<li><p><strong>执行迁移</strong>：</p>
<ul>
<li>将旧位置的子节点逐一复制到新位置</li>
<li>更新每个子节点的 check 值指向新的父节点位置</li>
<li>递归更新所有孙子节点的 check 值（因为它们的 check 指向的是父节点的旧位置）</li>
<li>清空旧位置</li>
</ul>
</li>
<li><p><strong>完成插入</strong>：冲突解除后，在正确位置插入新节点。</p>
</li>
</ol>
<h3>动态更新的性能开销</h3>
<p>子树迁移的时间复杂度取决于被迁移子树的规模。在最坏情况下，一次插入可能触发一个大型子树的完整迁移，导致 O(n) 的时间开销。但在实际应用中，以下策略可以降低平均开销：</p>
<ul>
<li><strong>静态构建优先</strong>：如果词典是已知的，优先采用离线批量构建，避免逐词插入带来的冲突</li>
<li><strong>预留空间</strong>：构建时适当增大数组长度，降低冲突概率</li>
<li><strong>增量更新缓冲</strong>：将增量更新暂存于辅助数据结构（如 HashMap），达到阈值后与主 DAT 合并重建</li>
</ul>
<p>在绝大多数工程场景中，DAT 被用作静态词典的存储结构，动态更新需求较少。因此，动态更新的高开销在实践中并不构成主要瓶颈。</p>
<h2>空间效率分析</h2>
<h3>与朴素 Trie 的空间对比</h3>
<p>空间效率是 DAT 最核心的优势。以下对比基于一个包含 30 万中文词条的词典：</p>
<table>
<thead>
<tr>
<th>结构</th>
<th>空间占用</th>
<th>查询复杂度</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>朴素 Trie（数组实现）</td>
<td>~10 GB</td>
<td>O(m)</td>
<td>每节点分配 6700 大小的指针数组</td>
</tr>
<tr>
<td>朴素 Trie（HashMap 实现）</td>
<td>~150 MB</td>
<td>O(m)（平均）</td>
<td>HashMap 有额外对象头、装载因子等开销</td>
</tr>
<tr>
<td>Double Array Trie</td>
<td>~8 MB</td>
<td>O(m)</td>
<td>仅两个 int 数组，无指针、无对象头</td>
</tr>
</tbody></table>
<p>DAT 的空间效率来源于两个方面：</p>
<ol>
<li><p><strong>共享寻址空间</strong>：不同父节点的子节点可以交错分布在同一段数组区域中，只要它们不发生冲突。这种&quot;紧凑排列&quot;使得数组的利用率远高于朴素 Trie 的稀疏数组。</p>
</li>
<li><p><strong>零指针开销</strong>：DAT 仅使用整数运算定位子节点，不需要存储任何指针或引用。在 64 位系统上，一个指针占 8 字节，而 DAT 中定位一个子节点仅需一个 int 加法。</p>
</li>
</ol>
<h3>与 HashMap 的权衡</h3>
<p>DAT 并非在所有场景下都优于 HashMap。两者的适用边界大致如下：</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>Double Array Trie</th>
<th>HashMap</th>
</tr>
</thead>
<tbody><tr>
<td>空间</td>
<td>极为紧凑</td>
<td>有对象头、链表/红黑树额外开销</td>
</tr>
<tr>
<td>查询速度</td>
<td>O(m)，常数极小</td>
<td>O(m)（平均），哈希计算有固定开销</td>
</tr>
<tr>
<td>前缀查询</td>
<td>天然支持</td>
<td>不支持，需额外结构</td>
</tr>
<tr>
<td>动态更新</td>
<td>代价高</td>
<td>O(1) 均摊</td>
</tr>
<tr>
<td>构建成本</td>
<td>离线构建较慢</td>
<td>逐条插入即可</td>
</tr>
<tr>
<td>序列化/反序列化</td>
<td>极快（直接读写数组）</td>
<td>需要逐条重建</td>
</tr>
</tbody></table>
<p>结论是：<strong>当词典相对稳定、需要前缀匹配能力、对空间和查询延迟有严格要求时，DAT 是更优选择；当词典频繁变动或无前缀查询需求时，HashMap 更为实用。</strong></p>
<h2>工程应用</h2>
<h3>中文分词系统</h3>
<p>DAT 在中文分词领域有着广泛而深入的应用。中文分词的核心任务之一是快速判断一个字符序列是否为词典中的合法词条，以及找到所有可能的分词方案。DAT 的前缀匹配能力使其天然适合这一任务。</p>
<p><strong>HanLP</strong> 是目前主流的中文 NLP 工具包之一，其核心词典采用 DAT 作为底层存储结构。HanLP 在启动时将词典文件加载为 DAT，后续的分词、词性标注等操作均基于 DAT 进行高速检索。由于 DAT 可以直接序列化为字节数组写入文件，HanLP 的词典加载速度极快——30 万词条的词典加载通常在毫秒级完成。</p>
<p><strong>Jieba 分词</strong>（Java 版本）在其词典查询模块中同样使用了 DAT。Jieba 的前缀词典在 DAG（有向无环图）构建阶段需要高频执行前缀查询，DAT 的 O(m) 查询保证了这一阶段的性能。</p>
<h3>AC 自动机的底层存储</h3>
<p>AC 自动机（Aho-Corasick Automaton）是多模式字符串匹配的经典算法，被广泛应用于敏感词过滤、入侵检测等场景。AC 自动机的第一步就是构建一棵 Trie 树，然后在其上添加失败指针（failure link）。</p>
<p>在高性能实现中，AC 自动机底层的 Trie 通常替换为 DAT，以获得更优的空间效率和缓存命中率。例如，在一个包含数十万敏感词的过滤系统中，使用 DAT 替代朴素 Trie 可以将内存占用从数百 MB 降至数十 MB，同时查询性能因更好的 cache locality 而提升 20%~50%。</p>
<h3>输入法词库</h3>
<p>输入法引擎需要根据用户的按键序列实时检索候选词，这一过程对延迟和空间都有极严格的要求——用户每敲一个键，引擎需要在毫秒内返回候选列表，而词库规模通常在百万级。DAT 的常数级别查询延迟和极低的内存占用使其成为输入法词库的理想存储结构。多数主流中文输入法引擎（如 Google 日文输入法开源实现 Mozc）在其词典模块中采用了 DAT 或其变体。</p>
<h3>Darts-java 实现</h3>
<p><a href="https://github.com/komiya-atsushi/darts-java">Darts-java</a> 是 DAT 的一个经典 Java 实现，也是 HanLP 等工具的底层依赖之一。其核心代码结构清晰，值得参考：</p>
<pre><code class="language-java">public class DoubleArrayTrie {
    private int[] base;   // BASE 数组
    private int[] check;  // CHECK 数组

    /**
     * 精确匹配查询
     * @param key 查询字符串
     * @return 匹配结果（词条编号），-1 表示未找到
     */
    public int exactMatchSearch(String key) {
        int result = -1;
        int b = base[0];       // 从根节点出发
        int p;

        for (int i = 0; i &lt; key.length(); i++) {
            p = b + (int)(key.charAt(i)) + 1;
            if (b == check[p]) {
                b = base[p];
            } else {
                return result;  // 转移失败，快速返回
            }
        }

        p = b;                 // 检查是否为完整词条
        int n = base[p];
        if (b == check[p] &amp;&amp; n &lt; 0) {
            result = -n - 1;
        }
        return result;
    }
}
</code></pre>
<p>此外，Darts-java 还提供了 <code>commonPrefixSearch</code> 方法，用于查找查询串的所有前缀匹配结果，这是中文分词中构建词图（word lattice）的关键操作。</p>
<p>在实际工程中，DAT 通常与其他技术组合使用：与 AC 自动机结合实现多模式匹配，与维特比算法结合实现最优分词路径选择，与概率语言模型结合实现统计分词。DAT 扮演的角色始终是最底层的高效词典检索引擎——不起眼但不可或缺。</p>
19:T3dc2,<blockquote>
<p><em>首先强调一下，Maven中央仓库并不支持直接发布jar包。我们需要将jar包发布到一些指定的第三方Maven仓库，然后该仓库再将jar包同步到Maven中央仓库。其中，最”简单”的方式是通过</em><a href="https://central.sonatype.org/pages/ossrh-guide.html">Sonatype OSSRH</a><em>仓库来发布jar包。所以，接下来主要介绍如何将jar包发布到Sonatype OSSRH。</em></p>
</blockquote>
<p>首先，先说一下大体的步骤：</p>
<ul>
<li>注册Sonatype账号</li>
<li>创建Issue，验证域名</li>
<li>安装GPG，发布密钥</li>
<li>配置Maven，发布构件</li>
</ul>
<p>这里面比较重要和容易出错的是第二步和第三步，下面一一详细介绍。</p>
<h4>1、注册Sonatype账号 <a href="#bojci" id="bojci"></a></h4>
<p>第一步很简单，登录官网，注册账号就好了<a href="https://issues.sonatype.org/secure/Signup!default.jspa">Sign up for Jira - Sonatype JIRA</a></p>
<p>注册完成，登陆后的界面如下：</p>
<p><img src="/images/blog/engineering/practice-image_60.png" alt="image_60.png"></p>
<h4>2、创建Issue <a href="#omwqz" id="omwqz"></a></h4>
<p>这里项目选择：Community Support - Open Source Project Repository Hosting (OSSRH)，问题 类型选择：New Project</p>
<p><img src="/images/blog/engineering/practice-image_67.png" alt="image_67.png"></p>
<h4>2.1、补充项目信息</h4>
<p><img src="/images/blog/engineering/practice-image_62.png" alt="image_62.png"></p>
<h4>2.2、验证域名 <a href="#snbg0" id="snbg0"></a></h4>
<p>我们需要使用域名作为Group Id，如果你拥有域&#x540D;<em>&#x65;xample.com，则能够使用com.example开头作为Group Id，例如：com.example.myproject。其他一些栗子如下：</em></p>
<ul>
<li><em>example.com -&gt; com.example.domain</em></li>
<li><a href="http://www.springframework.org/">www.springframework.org</a> -&gt; org.springframework</li>
<li>subdomain.example.com -&gt; example.com</li>
<li>github.com/yourusername -&gt; io.github.yourusername</li>
<li>my-domain.com -&gt; com.my-domain</li>
</ul>
<p>要想使用某个域名作为Group Id，你需要证明拥有该域名，至于如何证明，详见官方文档：<a href="https://central.sonatype.org/faq/how-to-set-txt-record">https://central.sonatype.org/faq/how-to-set-txt-record/</a></p>
<p>如果你没有自己的域名，则可以通过代码托管平台的账号关联子域名。假设你托管平台账户名为myusername，那么你可以通过以下托管平台验证Group Id ：</p>
<p><img src="/images/blog/engineering/practice-image_63.png" alt="image_63.png"></p>
<p>由于我没有自己的域名，这里我选择使用github账号验证Group Id。点击“新建”按钮，完成提交，之后你的注册邮箱会收到一封邮件，显示创建项目信息：</p>
<p><img src="/images/blog/engineering/practice-image_65.png" alt="image_65.png"></p>
<p>稍后还会收到一封审核邮件，提示你进行域名验证，时间延迟大概在十分钟以内。</p>
<p><strong>2.3、人工审核及确认</strong></p>
<p><img src="/images/blog/engineering/practice-image_66.png" alt="image_66.png"></p>
<p>我使用的是github账户，按邮件提示，需要在github平台上创建一个指定的临时工程。创建完成之后，可以在issue下面添加评论，触发验证。验证成功后，你会收到一份邮件：</p>
<p><img src="/images/blog/engineering/practice-image_68.png" alt="image_68.png"></p>
<p>收到上述邮件，就表示完成了Group Id的验证，此时你就可以使用该Group Id或者子Group Id发布Maven构件了。如上，我填写的Group Id是 “io.github.nianien”，因此，我可以使用 “io.github.nianien”或者 “io.github.nianien.xxx” 作为项目的GroupId发布Maven构件。</p>
<p>在通过Maven发布构件之前，我们需要进行Maven配置，这里还需要一些前置工作。</p>
<h4>3、安装GPG，创建密钥 <a href="#dcxco" id="dcxco"></a></h4>
<p>安装GPG的方式有多种，这里推荐图形化安装，因为通过命令行安装，由于找不到合适的密钥服务器，发布密钥时会失败。这里给出Mac版本的下载地址：<a href="https://releases.gpgtools.org/GPG_Suite-2022.1.dmg">https://releases.gpgtools.org/GPG_Suite-2022.1.dmg</a></p>
<ul>
<li>创建密钥</li>
</ul>
<p><img src="/images/blog/engineering/practice-image_69.png" alt="image_69.png"></p>
<p>3.1、发布密钥</p>
<p><img src="/images/blog/engineering/practice-image_70.png" alt="image_70.png"></p>
<p>发布成功后，收到一份邮件：</p>
<p><img src="/images/blog/engineering/practice-image_71.png" alt="image_71.png"></p>
<p>按照邮件指示操作，完成密钥发布。密钥发布成功之后，下一步就是配置maven settings.xml和工程pom.xml文件。</p>
<h4>4、配置Maven，发布构件 <a href="#amad1" id="amad1"></a></h4>
<ul>
<li>第一步，配置setting.xml文件，添加server节点：</li>
</ul>
<pre><code class="language-xml">&lt;servers&gt;
&lt;server&gt;
    &lt;id&gt;ossrh&lt;/id&gt;
    &lt;username&gt;sonatype账户名&lt;/username&gt;
    &lt;password&gt;sonatype账户密码&lt;/password&gt;
&lt;/server&gt;
&lt;/servers&gt;
&lt;profile&gt;
  &lt;id&gt;ossrh&lt;/id&gt;
  &lt;properties&gt;
    &lt;gpg.executable&gt;gpg&lt;/gpg.executable&gt;
    &lt;gpg.passphrase&gt;创建密钥时使用的密码&lt;/gpg.passphrase&gt;
    &lt;gpg.homedir&gt;/Users/yourname/.gnupg&lt;/gpg.homedir&gt;
   &lt;/properties&gt;
&lt;/profile&gt;
</code></pre>
<ul>
<li>第二步，配置pom.xml文件，添加必填项</li>
</ul>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;!--已经验证的Group Id--&gt;
    &lt;groupId&gt;io.github.nianien&lt;/groupId&gt;
    &lt;artifactId&gt;cudrania&lt;/artifactId&gt;
    &lt;version&gt;1.0.1&lt;/version&gt;&lt;!--必填--&gt;
    &lt;name&gt;io.github.nianien:cudrania&lt;/name&gt;&lt;!--必填--&gt;
    &lt;description&gt;support tools for java development&lt;/description&gt;&lt;!--必填--&gt;
    &lt;url&gt;https://github.com/nianien/cudrania&lt;/url&gt;
    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;java.version&gt;17&lt;/java.version&gt;
    &lt;/properties&gt;&lt;!--必填--&gt;
    &lt;licenses&gt;
        &lt;license&gt;
            &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt;
            &lt;url&gt;https://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt;
        &lt;/license&gt;
    &lt;/licenses&gt;&lt;!--必填--&gt;
    &lt;developers&gt;
        &lt;developer&gt;
            &lt;id&gt;nianien&lt;/id&gt;
            &lt;name&gt;nianien&lt;/name&gt;
            &lt;email&gt;nianien@126.com&lt;/email&gt;
        &lt;/developer&gt;
    &lt;/developers&gt;&lt;!--必填--&gt;
    &lt;scm&gt;
        &lt;connection&gt;https://github.com/nianien/cudrania.git&lt;/connection&gt;
        &lt;developerConnection&gt;scm:git:ssh://git@github.com:nianien/cudrania.git
        &lt;/developerConnection&gt;
        &lt;url&gt;https://github.com/nianien/cudrania&lt;/url&gt;
    &lt;/scm&gt;
    &lt;build&gt;
        &lt;pluginManagement&gt;
            &lt;plugins&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                    &lt;version&gt;3.11.0&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;source&gt;${java.version}&lt;/source&gt;
                        &lt;target&gt;${java.version}&lt;/target&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;
                &lt;plugin&gt;&lt;!--必填--&gt;
                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                    &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
                    &lt;version&gt;3.3.0&lt;/version&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;id&gt;attach-sources&lt;/id&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;jar-no-fork&lt;/goal&gt;
                            &lt;/goals&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;
                &lt;plugin&gt;&lt;!--必填--&gt; 
                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                    &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;
                    &lt;version&gt;3.5.0&lt;/version&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;id&gt;attach-javadocs&lt;/id&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;jar&lt;/goal&gt;
                            &lt;/goals&gt;
                            &lt;configuration&gt;
                                &lt;additionalparam&gt;
                                    -Xdoclint:none
                                &lt;/additionalparam&gt;
                            &lt;/configuration&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;&lt;!--必填--&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                    &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt;
                    &lt;version&gt;3.1.0&lt;/version&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;id&gt;sign-artifacts&lt;/id&gt;
                            &lt;phase&gt;verify&lt;/phase&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;sign&lt;/goal&gt;
                            &lt;/goals&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

    &lt;profiles&gt;&lt;!--必填--&gt;
        &lt;profile&gt;
            &lt;id&gt;ossrh&lt;/id&gt;
            &lt;build&gt;
                &lt;plugins&gt;
                    &lt;plugin&gt;&lt;!--必填--&gt;
                        &lt;groupId&gt;org.sonatype.plugins&lt;/groupId&gt;
                        &lt;artifactId&gt;nexus-staging-maven-plugin&lt;/artifactId&gt;
                        &lt;version&gt;1.6.13&lt;/version&gt;
                        &lt;extensions&gt;true&lt;/extensions&gt;
                        &lt;configuration&gt;
                            &lt;serverId&gt;ossrh&lt;/serverId&gt;
                            &lt;nexusUrl&gt;https://s01.oss.sonatype.org/&lt;/nexusUrl&gt; 
                          &lt;autoReleaseAfterClose&gt;true&lt;/autoReleaseAfterClose&gt;
                        &lt;/configuration&gt;
                    &lt;/plugin&gt;
                    &lt;plugin&gt;&lt;!--必填--&gt;
                        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                        &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt;
                    &lt;/plugin&gt;
                &lt;/plugins&gt;
            &lt;/build&gt;&lt;!--必填--&gt;
            &lt;distributionManagement&gt;
                &lt;snapshotRepository&gt;
                    &lt;id&gt;ossrh&lt;/id&gt;
                  &lt;url&gt;https://s01.oss.sonatype.org/content/repositories/snapshots
                    &lt;/url&gt;
                &lt;/snapshotRepository&gt;
                &lt;repository&gt;
                    &lt;id&gt;ossrh&lt;/id&gt;
                    &lt;url&gt;https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/
                    &lt;/url&gt;
                &lt;/repository&gt;
            &lt;/distributionManagement&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;

    &lt;dependencies&gt;&lt;!--maven依赖--&gt;&lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
<p>上面已经是最精简的pom配置了，我已经把必选项标注好了。这里主要包含两部分内容，一部分是snoatype要求的必备信息，包括：证书、开发者信息、仓库地址和发布地址；另一部分是deploy需要的maven插件列表，大家可以根据实际情况酌情修改。</p>
<p>需要说明的是，为了不用默认打包冲突，专门定义了用于发布中央仓库的profile：ossrh，这里只需要添加额外的两个插件：nexus-staging-maven-plugin和maven-gpg-plugin，前者用于jar上传，后者用于密钥签名。</p>
<ul>
<li>第三步，执行maven命令，发布构件</li>
</ul>
<p>配置好pom文件，可以执行maven命令：“mvn clean deploy -Possrh” 进行发布。如果版本号带SNAPSHOT后缀，会发布到snapshots仓库，否则发布到release仓库。</p>
<p>这里nexus-staging-maven-plugin插件有一个配置项：autoReleaseAfterClose，如果设置为true的话，推送完成会自动release。第一次发布成功后，会收到一封邮件：</p>
<p><img src="/images/blog/engineering/practice-image_72.png" alt="image_72.png"></p>
<ul>
<li><em><strong>最后，让jar包更快的在中央仓库被搜索到</strong></em></li>
</ul>
<p>根据邮件提示，Jar包成功发布成功后，大约30分钟后会推到中央仓库，我们可以从仓库地址看到我们发布的Jar包：<a href="https://repo1.maven.org/maven2">https://repo1.maven.org/maven2/</a></p>
<p><img src="/images/blog/engineering/practice-image_73.png" alt="image_73.png"></p>
<p>此时，其他项目就可以通过maven依赖引用我们的构件了，但是这时候通过中央仓库仍然搜不到我们的Maven构件。按照邮件提示可能会需要四小时，实际情况是我等了5个小时依然搜不到。如果遇到这种情况，我们可以通过在对issue添加评论反馈，会有人工回复进行解决：</p>
<p><img src="/images/blog/engineering/practice-image_74.png" alt="image_74.png"></p>
<p>另外，关于mvnrepository与Maven Central的关系，有人咨询，官方也做了解答：</p>
<p><img src="/images/blog/engineering/practice-image_75.png" alt="image_75.png"></p>
<p>根据我的实际经验判断，mvnrepository应该是定时同步的，我发布成功后，第二天才能搜到：</p>
<p><img src="/images/blog/engineering/practice-image_76.png" alt="image_76.png"></p>
<p>下面是官方指导文档，介绍非常详细，基本上不用在网上搜索其他教程了。</p>
<h4>官方参考文档 <a href="#dzquo" id="dzquo"></a></h4>
<p><a href="https://central.sonatype.org/publish/publish-guide">https://central.sonatype.org/publish/publish-guide/</a></p>
1a:T5870,<blockquote>
<p>Java 中的大部分同步工具（ReentrantLock、Semaphore、CountDownLatch、ReentrantReadWriteLock 等）都基于 AbstractQueuedSynchronizer（AQS）实现。理解 AQS，就等于掌握了 Java 并发编程的底层脉络。本文从设计思想出发，逐层深入 AQS 的数据结构、核心流程和源码实现，并通过 ReentrantLock 串联全局，最后梳理 AQS 在 JUC 中的应用全景。</p>
</blockquote>
<h2>AQS 是什么？</h2>
<p>AQS（AbstractQueuedSynchronizer）是 <code>java.util.concurrent.locks</code> 包中的一个<strong>抽象类</strong>，是构建锁和同步器的基础框架。Doug Lea 设计 AQS 的核心目标是：</p>
<ul>
<li>降低构建锁和同步器的工作量</li>
<li>避免在多个位置处理竞争问题</li>
<li>在基于 AQS 的同步器中，阻塞只可能在一个时刻发生，降低上下文切换开销，提高吞吐量</li>
</ul>
<p>AQS 支持两种工作模式：</p>
<table>
<thead>
<tr>
<th>模式</th>
<th>含义</th>
<th>典型实现</th>
</tr>
</thead>
<tbody><tr>
<td><strong>独占模式（Exclusive）</strong></td>
<td>同一时刻只能有一个线程获取到锁</td>
<td>ReentrantLock</td>
</tr>
<tr>
<td><strong>共享模式（Shared）</strong></td>
<td>同一时刻可以有多个线程同时获取</td>
<td>CountDownLatch、ReadWriteLock、Semaphore</td>
</tr>
</tbody></table>
<p>无论哪种模式，本质上都是对 AQS 内部一个 <strong><code>state</code> 变量</strong>的获取和释放。</p>
<h2>AQS 的整体架构</h2>
<p>AQS 框架共分为<strong>五层</strong>，自上而下由浅入深：</p>
<table>
<thead>
<tr>
<th>层次</th>
<th>内容</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>第一层</td>
<td>API 层</td>
<td>自定义同步器需重写的方法（tryAcquire、tryRelease 等）</td>
</tr>
<tr>
<td>第二层</td>
<td>获取/释放方法</td>
<td>acquire、release、acquireShared、releaseShared</td>
</tr>
<tr>
<td>第三层</td>
<td>队列操作</td>
<td>addWaiter、acquireQueued、shouldParkAfterFailedAcquire</td>
</tr>
<tr>
<td>第四层</td>
<td>线程阻塞/唤醒</td>
<td>LockSupport.park / unpark</td>
</tr>
<tr>
<td>第五层</td>
<td>基础数据</td>
<td>state、Node、CLH 变体队列</td>
</tr>
</tbody></table>
<p>当接入自定义同步器时，<strong>只需重写第一层的部分方法即可</strong>，不需要关注底层实现。当加锁或解锁操作触发时，沿着第一层到第五层逐层深入。</p>
<h2>核心数据结构</h2>
<h3>同步状态 State</h3>
<p>AQS 使用一个 <code>volatile int</code> 类型的成员变量 <code>state</code> 来表示同步状态：</p>
<pre><code class="language-java">private volatile int state;
</code></pre>
<p>State 的含义由具体的同步器定义，例如：</p>
<ul>
<li><strong>ReentrantLock</strong>：state 表示锁被重入的次数，0 表示未被持有</li>
<li><strong>Semaphore</strong>：state 表示可用许可的数量</li>
<li><strong>CountDownLatch</strong>：state 表示计数器的值</li>
</ul>
<p>AQS 提供三个方法操作 state，均为 <code>final</code> 修饰，子类不可重写：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>getState()</code></td>
<td>获取当前 state 值</td>
</tr>
<tr>
<td><code>setState(int)</code></td>
<td>设置 state 值</td>
</tr>
<tr>
<td><code>compareAndSetState(int, int)</code></td>
<td>CAS 方式更新 state</td>
</tr>
</tbody></table>
<h3>CLH 变体队列与 Node 节点</h3>
<p>AQS 的核心思想是：如果请求的共享资源空闲，就将当前线程设置为有效的工作线程，并将资源设置为锁定状态；<strong>如果资源被占用，就通过一个 CLH 变体的 FIFO 双向队列来管理等待线程</strong>。</p>
<blockquote>
<p>CLH 队列以其发明者 Craig、Landin 和 Hagersten 命名，原始 CLH 是单向链表。AQS 中的变体是虚拟双向队列，通过将每条请求线程封装成 Node 节点来实现锁的分配。</p>
</blockquote>
<p>Node 节点的关键属性：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>thread</code></td>
<td>该节点代表的线程</td>
</tr>
<tr>
<td><code>waitStatus</code></td>
<td>当前节点在队列中的等待状态</td>
</tr>
<tr>
<td><code>prev</code></td>
<td>前驱指针</td>
</tr>
<tr>
<td><code>next</code></td>
<td>后继指针</td>
</tr>
<tr>
<td><code>nextWaiter</code></td>
<td>指向下一个处于 CONDITION 状态的节点</td>
</tr>
</tbody></table>
<p><code>waitStatus</code> 的枚举值：</p>
<table>
<thead>
<tr>
<th>值</th>
<th>名称</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>默认值</td>
<td>Node 初始化时的状态</td>
</tr>
<tr>
<td>1</td>
<td>CANCELLED</td>
<td>线程获取锁的请求已取消</td>
</tr>
<tr>
<td>-1</td>
<td>SIGNAL</td>
<td>后继节点的线程需要被唤醒</td>
</tr>
<tr>
<td>-2</td>
<td>CONDITION</td>
<td>节点在条件队列中，等待 Condition 唤醒</td>
</tr>
<tr>
<td>-3</td>
<td>PROPAGATE</td>
<td>共享模式下，释放操作需要向后传播</td>
</tr>
</tbody></table>
<p>AQS 内部还维护了<strong>两种队列</strong>：</p>
<ul>
<li><strong>同步队列（Sync Queue）</strong>：获取资源失败的线程进入此队列自旋等待，当前驱节点是头节点时尝试获取资源</li>
<li><strong>条件队列（Condition Queue）</strong>：基于 <code>Condition</code> 实现，调用 <code>await()</code> 时线程进入条件队列，调用 <code>signal()</code> 时转移到同步队列</li>
</ul>
<blockquote>
<p>注意：双向链表的<strong>头节点是一个虚节点</strong>（不存储实际线程信息），真正的第一个有效节点从第二个开始。</p>
</blockquote>
<h2>自定义同步器需要重写的方法</h2>
<p>AQS 采用<strong>模板方法模式</strong>，自定义同步器只需根据需要重写以下方法：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>模式</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>tryAcquire(int)</code></td>
<td>独占</td>
<td>尝试获取资源，成功返回 true</td>
</tr>
<tr>
<td><code>tryRelease(int)</code></td>
<td>独占</td>
<td>尝试释放资源，成功返回 true</td>
</tr>
<tr>
<td><code>tryAcquireShared(int)</code></td>
<td>共享</td>
<td>尝试获取资源，负数=失败，0=成功但无剩余，正数=成功且有剩余</td>
</tr>
<tr>
<td><code>tryReleaseShared(int)</code></td>
<td>共享</td>
<td>尝试释放资源，如果释放后允许唤醒后续节点返回 true</td>
</tr>
<tr>
<td><code>isHeldExclusively()</code></td>
<td>独占</td>
<td>当前线程是否独占资源，用到 Condition 时需实现</td>
</tr>
</tbody></table>
<p>独占模式实现 <code>tryAcquire-tryRelease</code>，共享模式实现 <code>tryAcquireShared-tryReleaseShared</code>。AQS 也支持同时实现两种模式，如 <code>ReentrantReadWriteLock</code>。</p>
<h2>通过 ReentrantLock 理解加锁流程</h2>
<p>ReentrantLock 是 AQS 独占模式最典型的实现。我们以<strong>非公平锁</strong>为例，完整追踪加锁流程。</p>
<h3>第一步：lock()</h3>
<pre><code class="language-java">// ReentrantLock.NonfairSync
final void lock() {
    if (compareAndSetState(0, 1))           // 直接 CAS 尝试获取锁
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);                          // 失败则进入 AQS 框架流程
}
</code></pre>
<p>非公平锁上来就尝试 CAS 抢锁（不管队列中有没有等待线程），这是它&quot;非公平&quot;的体现。</p>
<h3>第二步：acquire()</h3>
<pre><code class="language-java">// AbstractQueuedSynchronizer
public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
</code></pre>
<p>这一行代码浓缩了整个加锁流程的四个步骤：</p>
<pre><code>tryAcquire → addWaiter → acquireQueued → selfInterrupt
</code></pre>
<ol>
<li><strong>tryAcquire</strong>：尝试获取锁（由子类实现）</li>
<li><strong>addWaiter</strong>：获取失败，将当前线程封装为 Node 加入队列尾部</li>
<li><strong>acquireQueued</strong>：在队列中自旋等待，直到获取到锁</li>
<li><strong>selfInterrupt</strong>：如果等待过程中被中断过，补上中断</li>
</ol>
<h3>第三步：tryAcquire（公平 vs 非公平）</h3>
<p><strong>非公平锁</strong>的实现：</p>
<pre><code class="language-java">final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {   // 直接 CAS，不检查队列
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {  // 可重入逻辑
        int nextc = c + acquires;
        if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);
        return true;
    }
    return false;
}
</code></pre>
<p><strong>公平锁</strong>的区别仅在于多了一个 <code>hasQueuedPredecessors()</code> 检查：</p>
<pre><code class="language-java">if (c == 0) {
    if (!hasQueuedPredecessors() &amp;&amp;   // 公平锁：先检查队列中是否有等待线程
        compareAndSetState(0, acquires)) {
        setExclusiveOwnerThread(current);
        return true;
    }
}
</code></pre>
<table>
<thead>
<tr>
<th>锁类型</th>
<th>state == 0 时的行为</th>
<th>可重入逻辑</th>
</tr>
</thead>
<tbody><tr>
<td>非公平锁</td>
<td>直接 CAS 抢锁</td>
<td>相同：state + 1</td>
</tr>
<tr>
<td>公平锁</td>
<td>先检查队列再 CAS</td>
<td>相同：state + 1</td>
</tr>
</tbody></table>
<h3>第四步：addWaiter — 入队</h3>
<pre><code class="language-java">private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    Node pred = tail;
    if (pred != null) {            // 队列已初始化，尝试快速入队
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);                     // 快速入队失败或队列未初始化
    return node;
}
</code></pre>
<p><code>enq()</code> 方法通过<strong>自旋 + CAS</strong> 确保入队成功：</p>
<pre><code class="language-java">private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) {                         // 队列为空，初始化
            if (compareAndSetHead(new Node()))    // 创建虚拟头节点
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
</code></pre>
<p>线程获取锁的过程可以形象理解为：</p>
<pre><code>线程1获取锁成功 → 线程2申请锁失败 → 线程2入队等待 → 线程3申请失败 → 线程3排在线程2后面 → ...
</code></pre>
<h3>第五步：acquireQueued — 自旋获取锁</h3>
<pre><code class="language-java">final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {   // 前驱是头节点，尝试获取锁
                setHead(node);                     // 获取成功，当前节点成为新的头节点
                p.next = null;                     // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())           // 获取失败，判断是否需要挂起
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
</code></pre>
<p>核心逻辑：<strong>只有前驱节点是头节点的线程才有资格尝试获取锁</strong>。获取失败后，通过 <code>shouldParkAfterFailedAcquire</code> 判断是否需要挂起（将前驱节点的 waitStatus 设为 SIGNAL），然后通过 <code>LockSupport.park()</code> 挂起线程，避免空转浪费 CPU。</p>
<h3>shouldParkAfterFailedAcquire 的三种情况</h3>
<pre><code class="language-java">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)        // 前驱已经是 SIGNAL，可以安全挂起
        return true;
    if (ws &gt; 0) {                 // 前驱已取消，向前找到有效节点
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next = node;
    } else {                      // 前驱状态为 0 或 PROPAGATE，设为 SIGNAL
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
</code></pre>
<table>
<thead>
<tr>
<th>前驱 waitStatus</th>
<th>处理</th>
<th>是否挂起</th>
</tr>
</thead>
<tbody><tr>
<td>SIGNAL (-1)</td>
<td>直接返回 true</td>
<td>是</td>
</tr>
<tr>
<td>CANCELLED (&gt;0)</td>
<td>跳过所有取消节点，重新链接</td>
<td>否，下次循环再判断</td>
</tr>
<tr>
<td>0 或 PROPAGATE</td>
<td>CAS 设为 SIGNAL</td>
<td>否，下次循环再判断</td>
</tr>
</tbody></table>
<h2>解锁流程</h2>
<p>ReentrantLock 解锁时<strong>不区分公平和非公平</strong>：</p>
<pre><code class="language-java">// ReentrantLock
public void unlock() {
    sync.release(1);
}
</code></pre>
<pre><code class="language-java">// AbstractQueuedSynchronizer
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);          // 唤醒后继节点
        return true;
    }
    return false;
}
</code></pre>
<h3>tryRelease — 可重入锁的释放</h3>
<pre><code class="language-java">// ReentrantLock.Sync
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;       // state 减 1
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {                         // 只有 state 减到 0，锁才真正释放
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
</code></pre>
<h3>unparkSuccessor — 唤醒后继线程</h3>
<pre><code class="language-java">private void unparkSuccessor(Node node) {
    int ws = node.waitStatus;
    if (ws &lt; 0)
        compareAndSetWaitStatus(node, ws, 0);

    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        // 从尾部向前遍历，找到第一个非取消状态的节点
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);    // 唤醒线程
}
</code></pre>
<blockquote>
<p><strong>为什么要从后向前遍历？</strong> 两个原因：</p>
<ol>
<li><code>addWaiter</code> 中节点入队不是原子操作——<code>node.prev = pred</code> 和 <code>compareAndSetTail</code> 完成后，<code>pred.next = node</code> 可能还未执行。此时从前向后遍历会断链。</li>
<li><code>cancelAcquire</code> 产生 CANCELLED 节点时，先断开的是 next 指针，prev 指针未断开。因此从后向前遍历才能保证遍历完整。</li>
</ol>
</blockquote>
<h2>CANCELLED 节点的处理</h2>
<p>当 <code>acquireQueued</code> 中发生异常时，会执行 <code>cancelAcquire(node)</code> 将节点标记为 CANCELLED。处理逻辑根据节点位置分为三种情况：</p>
<table>
<thead>
<tr>
<th>节点位置</th>
<th>处理方式</th>
</tr>
</thead>
<tbody><tr>
<td>尾节点</td>
<td>将前驱设为新的 tail，其 next 置为 null</td>
</tr>
<tr>
<td>头节点的后继</td>
<td>唤醒当前节点的后继线程（unparkSuccessor）</td>
</tr>
<tr>
<td>中间节点</td>
<td>将前驱的 next 指向当前节点的后继，跳过当前节点</td>
</tr>
</tbody></table>
<blockquote>
<p><code>cancelAcquire</code> 只操作 next 指针，不操作 prev 指针。因为执行 cancel 时前驱可能已经出队，修改 prev 不安全。prev 指针的清理留给 <code>shouldParkAfterFailedAcquire</code>——此方法在获取锁失败时执行，此时共享资源已被占用，前方节点不会变化，修改 prev 是安全的。</p>
</blockquote>
<h2>中断处理机制</h2>
<p>AQS 的 <code>acquire</code> 方法是<strong>不可中断</strong>的——线程在等待过程中不会响应中断，而是记录中断状态，等获取到锁后再&quot;补上&quot;中断：</p>
<pre><code class="language-java">public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))  // 返回 true 说明被中断过
        selfInterrupt();                                  // 补上中断
}

static void selfInterrupt() {
    Thread.currentThread().interrupt();
}
</code></pre>
<p>这种设计的考量是：线程被唤醒时并不知道原因（可能是前驱释放了锁，也可能是被中断），所以通过 <code>Thread.interrupted()</code> 检查并清除中断标记，记录下来，最后在获取锁成功后统一补上。</p>
<h2>park / unpark 机制</h2>
<p>AQS 中线程的阻塞和唤醒通过 <code>LockSupport</code> 实现：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>LockSupport.park(this)</code></td>
<td>阻塞当前线程</td>
</tr>
<tr>
<td><code>LockSupport.unpark(thread)</code></td>
<td>唤醒指定线程</td>
</tr>
</tbody></table>
<p>它们的底层实现是通过 <code>Unsafe</code> 类调用 CPU 原语。相比 <code>Object.wait/notify</code>，park/unpark 的优势在于：</p>
<ul>
<li>不需要在同步块中使用</li>
<li><code>unpark</code> 可以先于 <code>park</code> 调用（基于许可机制）</li>
<li>可以精确唤醒指定线程</li>
</ul>
<p>在 AQS 中使用 park 的主要目的是：<strong>让排队等待的线程挂起，停止自旋以避免浪费 CPU 资源</strong>，并在需要时通过 unpark 精确唤醒。</p>
<h2>AQS 在 JUC 中的应用场景</h2>
<p>AQS 是 JUC 包的基石，几乎所有同步工具都构建在它之上：</p>
<table>
<thead>
<tr>
<th>同步工具</th>
<th>如何使用 AQS</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ReentrantLock</strong></td>
<td>state 表示锁的重入次数。获取锁时 state+1，释放时 state-1。state 为 0 表示锁空闲。同时记录持有锁的线程用于重入检测。</td>
</tr>
<tr>
<td><strong>Semaphore</strong></td>
<td>state 表示可用许可数。<code>acquireShared</code> 减少计数，<code>tryReleaseShared</code> 增加计数。</td>
</tr>
<tr>
<td><strong>CountDownLatch</strong></td>
<td>state 表示计数器。每次 <code>countDown()</code> 减 1，<code>await()</code> 等待 state 变为 0 后所有线程被唤醒。</td>
</tr>
<tr>
<td><strong>ReentrantReadWriteLock</strong></td>
<td>state 的高 16 位保存读锁持有次数，低 16 位保存写锁持有次数。读锁用共享模式，写锁用独占模式。</td>
</tr>
<tr>
<td><strong>ThreadPoolExecutor</strong></td>
<td>Worker 内部类继承 AQS，利用独占模式实现对工作线程的状态管理。</td>
</tr>
</tbody></table>
<h3>State 在不同同步器中的语义</h3>
<pre><code>ReentrantLock:       state = 重入次数 (0 = 空闲)
Semaphore:           state = 可用许可数
CountDownLatch:      state = 剩余计数 (0 = 所有线程放行)
ReadWriteLock:       state = [高16位:读锁次数][低16位:写锁次数]
</code></pre>
<h2>自定义同步器示例</h2>
<p>理解 AQS 后，我们可以用极少的代码实现一个简单的互斥锁：</p>
<pre><code class="language-java">public class SimpleLock {

    private static class Sync extends AbstractQueuedSynchronizer {
        @Override
        protected boolean tryAcquire(int arg) {
            return compareAndSetState(0, 1);
        }

        @Override
        protected boolean tryRelease(int arg) {
            setState(0);
            return true;
        }

        @Override
        protected boolean isHeldExclusively() {
            return getState() == 1;
        }
    }

    private final Sync sync = new Sync();

    public void lock()   { sync.acquire(1); }
    public void unlock() { sync.release(1); }
}
</code></pre>
<p>使用：</p>
<pre><code class="language-java">public static void main(String[] args) throws InterruptedException {
    SimpleLock lock = new SimpleLock();
    int[] count = {0};

    Runnable task = () -&gt; {
        lock.lock();
        try {
            for (int i = 0; i &lt; 10000; i++) count[0]++;
        } finally {
            lock.unlock();
        }
    };

    Thread t1 = new Thread(task);
    Thread t2 = new Thread(task);
    t1.start(); t2.start();
    t1.join();  t2.join();
    System.out.println(count[0]);  // 始终输出 20000
}
</code></pre>
<p>只需重写 <code>tryAcquire</code> 和 <code>tryRelease</code>，AQS 就接管了排队、阻塞、唤醒、中断处理等全部复杂逻辑。</p>
<h2>总结</h2>
<p>AQS 的设计精髓可以归纳为以下几点：</p>
<ol>
<li><strong>一个 state 变量统一抽象</strong>：不同的同步器通过赋予 state 不同的语义（重入次数、许可数、计数器等），复用同一套框架</li>
<li><strong>CLH 变体双向队列管理等待线程</strong>：通过 FIFO 队列保证公平性，通过 CAS + 自旋保证入队的线程安全</li>
<li><strong>模板方法模式降低接入成本</strong>：自定义同步器只需实现 tryAcquire/tryRelease 等少量方法，框架处理全部排队和唤醒逻辑</li>
<li><strong>park/unpark 精确控制线程状态</strong>：避免自旋空转浪费 CPU，同时支持精确唤醒</li>
<li><strong>从后向前遍历保证正确性</strong>：在非原子入队操作和 CANCELLED 节点处理中，始终保证能遍历到所有有效节点</li>
</ol>
<blockquote>
<p>AQS 是 Doug Lea 在并发编程领域的杰作。理解了 AQS，就理解了 JUC 包中绝大部分同步工具的底层运作方式。它不仅是面试的高频考点，更是我们在实际工程中设计自定义同步器时可以直接借鉴的框架。</p>
</blockquote>
5:["$","article",null,{"className":"min-h-screen","children":["$","div",null,{"className":"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12","children":[["$","header",null,{"className":"mb-8","children":[["$","nav",null,{"className":"flex items-center gap-1 text-sm mb-4","children":[["$","$L13",null,{"href":"/blog/page/1","className":"text-gray-500 hover:text-blue-600 transition-colors","children":"博客"}],["$","span",null,{"className":"text-gray-300","children":"/"}],["$","$L13",null,{"href":"/blog/category/engineering/page/1","className":"text-gray-500 hover:text-blue-600 transition-colors","children":"Engineering"}],[["$","span",null,{"className":"text-gray-300","children":"/"}],["$","$L13",null,{"href":"/blog/category/engineering/middleware/page/1","className":"text-blue-600 hover:text-blue-700 transition-colors","children":"中间件"}]]]}],["$","div",null,{"className":"flex items-center mb-6","children":["$","div",null,{"className":"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal","children":[["$","svg",null,{"className":"w-4 h-4 mr-2 text-gray-400","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"}]}],["$","time",null,{"dateTime":"2024-04-07","children":"2024年04月07日"}]]}]}],["$","h1",null,{"className":"text-4xl font-bold text-gray-900 mb-6 text-center","children":"非侵入式SQL监控"}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-6 justify-center","children":[["$","$L13","SQL监控",{"href":"/blog/tag/SQL%E7%9B%91%E6%8E%A7/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"SQL监控"}],["$","$L13","Java",{"href":"/blog/tag/Java/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"Java"}],["$","$L13","非侵入式",{"href":"/blog/tag/%E9%9D%9E%E4%BE%B5%E5%85%A5%E5%BC%8F/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"非侵入式"}]]}]]}],["$","div",null,{"className":"max-w-5xl mx-auto","children":["$","$L14",null,{"content":"$15"}]}],["$","$10",null,{"fallback":["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":"加载导航中..."}],"children":["$","$L16",null,{"globalNav":{"prev":{"slug":"engineering/tooling/Git常用命令","title":"Git 常用命令速查手册","description":"一份面向日常开发的 Git 命令速查手册，覆盖分支管理、暂存与恢复、提交操作、远程协作、文件追踪控制、子模块、日志查询与常见问题处理等场景，适合收藏备用。","pubDate":"2024-04-05","tags":["Git","版本控制","开发工具"],"heroImage":"$undefined","content":"$17"},"next":{"slug":"engineering/algorithm/Double Array Trie：高效字典树的压缩与检索实现","title":"Double Array Trie：高效字典树的压缩与检索实现","description":"深入解析Double Array Trie的DFA建模、BASE/CHECK双数组构建算法、动态更新策略及其在中文分词与信息检索中的工程应用","pubDate":"2024-04-18","tags":["数据结构","Trie","Double Array Trie","中文分词"],"heroImage":"$undefined","content":"$18"}},"tagNav":{"SQL监控":{"prev":null,"next":null},"Java":{"prev":{"slug":"engineering/tooling/Java构件发布到中央仓库","title":"Java构件发布到中央仓库","description":"Maven中央仓库并不支持直接发布jar包。我们需要将jar包发布到一些指定的第三方Maven仓库，然后该仓库再将jar包同步到Maven中央仓库。其中，最”简单”的方式是通过...","pubDate":"2024-04-04","tags":["Maven","Java","开源发布"],"heroImage":"$undefined","content":"$19"},"next":{"slug":"engineering/middleware/深入理解AQS：Java并发的基石","title":"深入理解AQS：Java并发的基石","description":"系统性剖析 AbstractQueuedSynchronizer（AQS）的设计思想、核心数据结构、加锁解锁流程，并通过 ReentrantLock 源码深入理解其工作原理，最后梳理 AQS 在 JUC 中的典型应用场景。","pubDate":"2025-12-28","tags":["Java","并发编程","AQS","ReentrantLock","JUC"],"heroImage":"$undefined","content":"$1a"}},"非侵入式":{"prev":null,"next":null}}}]}],["$","$L1b",null,{}]]}]}]}]
8:null
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
a:{"metadata":[["$","title","0",{"children":"非侵入式SQL监控 - Skyfalling Blog"}],["$","meta","1",{"name":"description","content":"你有没有因为应用程序没有打印SQL而导致问题排查困难？有没有因为SQL没有显示参数而导致日志毫无意义？有没有因为SQL超长而导致查看痛苦？有没有因为缺少SQL性能监控而导致无法报警？..."}],["$","meta","2",{"property":"og:title","content":"非侵入式SQL监控"}],["$","meta","3",{"property":"og:description","content":"你有没有因为应用程序没有打印SQL而导致问题排查困难？有没有因为SQL没有显示参数而导致日志毫无意义？有没有因为SQL超长而导致查看痛苦？有没有因为缺少SQL性能监控而导致无法报警？..."}],["$","meta","4",{"property":"og:type","content":"article"}],["$","meta","5",{"property":"article:published_time","content":"2024-04-07"}],["$","meta","6",{"property":"article:author","content":"Skyfalling"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"非侵入式SQL监控"}],["$","meta","9",{"name":"twitter:description","content":"你有没有因为应用程序没有打印SQL而导致问题排查困难？有没有因为SQL没有显示参数而导致日志毫无意义？有没有因为SQL超长而导致查看痛苦？有没有因为缺少SQL性能监控而导致无法报警？..."}],["$","link","10",{"rel":"shortcut icon","href":"/favicon.png"}],["$","link","11",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","link","12",{"rel":"icon","href":"/favicon.png"}],["$","link","13",{"rel":"apple-touch-icon","href":"/favicon.png"}]],"error":null,"digest":"$undefined"}
12:{"metadata":"$a:metadata","error":null,"digest":"$undefined"}
