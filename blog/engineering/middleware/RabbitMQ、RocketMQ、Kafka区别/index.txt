1:"$Sreact.fragment"
2:I[10616,["6874","static/chunks/6874-7791217feaf05c17.js","7177","static/chunks/app/layout-51baccc14cf1da9e.js"],"default"]
3:I[87555,[],""]
4:I[31295,[],""]
5:I[6874,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],""]
7:I[59665,[],"OutletBoundary"]
a:I[74911,[],"AsyncMetadataOutlet"]
c:I[59665,[],"ViewportBoundary"]
e:I[59665,[],"MetadataBoundary"]
10:I[26614,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/0458d6941a120cde.css","style"]
0:{"P":null,"b":"8CSEQRRrJyhjI8sSOwcIy","p":"","c":["","blog","engineering","middleware","RabbitMQ%E3%80%81RocketMQ%E3%80%81Kafka%E5%8C%BA%E5%88%AB",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","engineering/middleware/RabbitMQ%E3%80%81RocketMQ%E3%80%81Kafka%E5%8C%BA%E5%88%AB","c"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/0458d6941a120cde.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"zh-CN","children":["$","body",null,{"className":"__className_f367f3","children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"bg-[var(--background)]","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 py-12 md:flex md:items-center md:justify-between lg:px-8","children":[["$","div",null,{"className":"flex justify-center space-x-6 md:order-2","children":[["$","$L5",null,{"href":"/about","className":"text-gray-600 hover:text-gray-800","children":"关于"}],["$","$L5",null,{"href":"/blog","className":"text-gray-600 hover:text-gray-800","children":"博客"}],["$","$L5",null,{"href":"/contact","className":"text-gray-600 hover:text-gray-800","children":"联系"}]]}],["$","div",null,{"className":"mt-8 md:order-1 md:mt-0","children":["$","p",null,{"className":"text-center text-xs leading-5 text-gray-600","children":"© 2024 Skyfalling Blog. All rights reserved."}]}]]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","engineering/middleware/RabbitMQ%E3%80%81RocketMQ%E3%80%81Kafka%E5%8C%BA%E5%88%AB","c"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",null,["$","$L7",null,{"children":["$L8","$L9",["$","$La",null,{"promise":"$@b"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","Qbhc3hFkmbKGK3ib4AZ2Lv",{"children":[["$","$Lc",null,{"children":"$Ld"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Le",null,{"children":"$Lf"}]]}],false]],"m":"$undefined","G":["$10","$undefined"],"s":false,"S":true}
11:"$Sreact.suspense"
12:I[74911,[],"AsyncMetadata"]
14:I[32923,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
16:I[40780,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
1a:I[85300,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
f:["$","div",null,{"hidden":true,"children":["$","$11",null,{"fallback":null,"children":["$","$L12",null,{"promise":"$@13"}]}]}]
15:T2b20,<p><a href="https://baijiahao.baidu.com/s?id=1769207484615537227">转载</a></p>
<h4>引言</h4>
<h4>1、队列应用场景：</h4>
<p>MQ（Message Queue，消息队列）<br><strong>消息队列在实际应用中常用的使用场景（优点）</strong>：<code>异步处理</code>，<code>应用解耦</code>，<code>流量削锋</code>和<code>消息通讯</code>四个场景。</p>
<h4>2、目前使用较多的消息队列：</h4>
<p>有老牌的ActiveMQ、RabbitMQ，ZeroMQ，炙手可热的Kafka，MetaMQ，阿里巴巴的RocketMQ。</p>
<h4>3、如何选型（目前现状）：</h4>
<p>ActiveMQ，性能不是很好，因此在高并发的场景下，直接被pass掉了。它的Api很完善，在中小型互联网公司可以去使用。最早大家都用 ActiveMQ，但是现在确实大家用的不多了，社区也不是很活跃，不推荐用这个了；</p>
<p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高，可视化的管理界面比较友好；</p>
<p>不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），它是纯Java开发，它高性能、满足可靠性、分布式事物、支持水平扩展、上亿级别的消息堆积、主从之间的切换等等。MQ的所有优点它基本都满足。但是它最大的缺点：商业版收费。但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则老老实实用 RabbitMQ 吧，毕竟RabbitMQ有活跃的开源社区，绝对不会黄。</p>
<p>所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p>
<p>如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，适合产生大量数据的互联网服务的数据收集业务等。社区活跃度很高，何况几乎是全世界这个领域的事实性规范。kafka，主要强调高性能，如果对业务需要可靠性消息的投递的时候。那么就不能够选择kafka了。</p>
<h4>4、使用消息队列缺点：</h4>
<ul>
<li>系统可用性降低：系统引入的外部依赖越多，越容易挂掉，万一MQ挂了，整套系统崩溃了。</li>
<li>系统复杂性提高：加MQ进来，怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？</li>
<li>一致性问题：A系统处理完了直接返回成功了，后面的如果失败了，这数据就不一致了。</li>
</ul>
<h4>一、RabbitMQ</h4>
<h4>1、RabbitMQ概述</h4>
<p><code>AMQP</code>，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层<strong>标准高级消息队列协议</strong>，是应用层协议的一个开放标准，为面向消息的中间件设计。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。<br>AMQP协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。</p>
<p><code>RabbitMQ</code>是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的。</p>
<p>RabbitMQ 是比较有代表性的，因为是<code>基于主从（非分布式）做高可用性</code>的。</p>
<h4>2、RabbitMQ原理图</h4>
<p>RabbitMQ通过<code>信道</code>的方式传输数据，将消息发布到交换机上，消息拥有一个路邮键，由消息创建时设定，通过队列路由键，可以把队列绑定到交换机上，消息到达交换机后，RabbitMQ将消息的路由键与队列的路由键进行匹配（不同的交换机有不同的路由规则），匹配到相应的队列，消息投递到队列的队列中供消费者消费。</p>
<blockquote>
<p>多个消费者可以订阅同一个Queue，消息将以<code>循环（round-robin）</code>的方式发送给消费者，每条消息只会发给一个订阅的消费者，而不是每个消费者都收到所有的消息并处理。</p>
</blockquote>
<blockquote>
<p>每个Channel运行在独立的线程上，多个线程共享同一个socket。</p>
</blockquote>
<p><img src="https://pic.rmb.bdstatic.com/bjh/beautify/dfde605794cc90a31ce1223c54218372.jpeg@c_1,w_901,h_315,x_0,y_0" alt=""><br><strong>相关概念：</strong></p>
<ul>
<li>ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用；</li>
<li>Broker：简单来说就是消息队列服务器实体。</li>
<li>Channel（信道）：消息推送使用的通道；</li>
<li>Exchange（交换器）：用于接受、分配消息；</li>
<li>Queue（队列）：用于存储生产者的消息；</li>
<li>RoutingKey（路由键）：用于把生成者的数据分配到交换器上；【最大255个字节】</li>
<li>BindingKey（绑定键）：用于把交换器的消息绑定到队列上；【最大255个字节】</li>
<li>vhost（虚拟主机）每个Rabbit都能创建很多vhost，每个虚拟主机其实都是mini版的RabbitMQ，拥有自己的队列，交换器和绑定，拥有自己的权限机制。</li>
</ul>
<h4>3、RabbitMQ常用的三种交换机</h4>
<p><strong>RabbitMQ常用的三种Exchange</strong>：fanout,direct,topic</p>
<h4>（1）Direct Exchange ：</h4>
<p>直连型交换机，根据消息携带的路由键将消息投递给对应队列。<br>　　大致流程，有一个队列绑定到一个直连交换机上，同时赋予一个路由键 routing key。　然后当一个消息携带着路由值为X，这个消息通过生产者发送给交换机时，交换机就会根据这个路由值X去寻找绑定值也是X的队列。</p>
<h4>（2）Fanout Exchange：</h4>
<p>扇型交换机，这个交换机没有路由键概念，就算你绑了路由键也是无视的。 这个交换机在接收到消息后，会直接转发到绑定到它上面的所有队列。</p>
<h4>（3）Topic Exchange：</h4>
<p>主题交换机，这个交换机其实跟直连交换机流程差不多，但是它的特点就是在它的路由键和绑定键之间是有规则的。<br>　　<br><strong>性能排序</strong>：fanout &gt; direct &gt;&gt; topic。</p>
<h4>4、 RabbitMQ集群元数据</h4>
<p>RabbitMQ集群会始终同步四种类型的内部元数据：</p>
<ul>
<li>a. 队列元数据：队列名称和它的属性</li>
<li>b. 交换器元数据：交换器名称、类型和属性</li>
<li>c. 绑定元数据：一张简单的表格展示了如何将消息路由到队列</li>
<li>d. vhost元数据：为vhost内的队列、交换器和绑定提供命名空间和安全属性</li>
</ul>
<h4>5、RabbitMQ镜像集群</h4>
<p><strong>RabbitMQ 有三种模式</strong>：单机模式、普通集群模式（无高可用性）、<code>镜像集群模式</code>（高可用性）。</p>
<p><code>镜像队列</code>将需要消费的队列变成镜像队列，存在于多个节点，实现RabbitMQ的高可用，保证 100% 数据不丢失。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在消费者消费数据时临时拉取，缺点就是集群内部的<code>同步通讯</code>会占去大量的网络带宽。<br><img src="https://pic.rmb.bdstatic.com/bjh/beautify/53a92fdedade9355420e866bbdb51be1.jpeg@c_1,w_613,h_390,x_0,y_0" alt=""></p>
<h4>二、RocketMQ</h4>
<p><code>RocketMQ</code>是阿里开源的消息中间件，目前也已经孵化为Apache顶级项目。用Java语言实现，在设计时参考了Kafka，并做出了自己的一些改进，消息可靠性上比Kafka更好。RocketMQ在阿里内部被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。</p>
<p><strong>RocketMQ缺点：</strong></p>
<ul>
<li>单机支持1万以上持久化队列；</li>
<li>RocketMQ的所有消息都是持久化的，先写入系统PAGECACHE，然后刷盘，可以保证内存与磁盘都有一份数据，而访问时，直接从内存读取。</li>
<li>模型简单，接口易用（JMS的接口很多场合并不太实用）；</li>
<li>性能非常好，可以允许大量堆积消息在Broker中；</li>
<li>支持多种消费模式，包括集群消费、广播消费等；</li>
<li>各个环节分布式扩展设计，支持主从和高可用；</li>
<li>开发度较活跃，版本更新很快。</li>
</ul>
<p><strong>RocketMQ缺点：</strong></p>
<ul>
<li>支持的 客户端语言不多，目前是Java及C++，其中C++还不成熟</li>
<li>维护RocketMQ需要专业的团队</li>
<li>商业版收费，有许多功能是不对外提供的。</li>
<li>没有在MQ核心里实现JMS等接口</li>
</ul>
<h4>三、kafka</h4>
<h4>1、kafka概述</h4>
<p><code>kafka</code>是Linkedin于2010年12月份开源的<code>消息发布订阅</code>系统,它主要用于处理活跃的流式数据,大数据量的数据处理上。作为hadoop生态系统的一部分，被各种商业公司广泛应用。</p>
<p><strong>kafka优点：</strong></p>
<ul>
<li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒</li>
<li>可扩展性：kafka集群支持热扩展</li>
<li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li>容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li>高并发：支持数千个客户端同时读写</li>
</ul>
<p><strong>kafka缺点：</strong></p>
<ul>
<li>快速持久化：可以在O(1)的系统开销下进行消息持久化；</li>
<li>高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率；</li>
<li>完全的分布式系统：Broker、Producer和Consumer都原生自动支持分布式，自动实现负载均衡；</li>
<li>支持同步和异步复制两种高可用机制；</li>
<li>支持数据批量发送和拉取；</li>
<li>零拷贝技术(zero-copy)：减少IO操作步骤，提高系统吞吐量；</li>
<li>数据迁移、扩容对用户透明；</li>
<li>无需停机即可扩展机器；</li>
<li>其他特性：丰富的消息拉取模型、高效订阅者水平扩展、实时的消息订阅、亿级的消息堆积能力、定期删除机制</li>
</ul>
<h4>2、kafka原理图</h4>
<p><img src="https://pic.rmb.bdstatic.com/bjh/beautify/3d90e1705de49c669f22628af2f6004a.jpeg@c_1,w_1010,h_651,x_0,y_0" alt=""><br><img src="https://pic.rmb.bdstatic.com/bjh/beautify/a5531d658050ce7abecb5ad4242d92ab.jpeg@c_1,w_1002,h_300,x_0,y_0" alt=""></p>
<h4>四、总结</h4>
<p><img src="/images/blog/engineering/middleware-img_20250723_04.png" alt="img_20250723_04.png">{: .full-width}</p>
17:T4849,<h2>服务注册中心 <a href="#scroller-1" id="scroller-1"></a></h2>
<p>前面我们对业内几种比较常见的注册中心做了介绍：Eureka、Zookeeper、Consul、Etcd。</p>
<p>并且在各个指标上做了对比：注册方式（watch/polling）、健康检查、雪崩保护、安全与权限，以及在Spring Cloud、Dubbo、Kubernets上的支持程度。方便我们在不同的场景下做正确的技术选型。</p>
<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>Eureka</strong></th>
<th><strong>Zookeeper</strong></th>
<th><strong>Consul</strong></th>
<th><strong>Etcd</strong></th>
</tr>
</thead>
<tbody><tr>
<td>一致性协议</td>
<td>AP</td>
<td>CP（Paxos算法）</td>
<td>CP（Raft算法）</td>
<td>CP（Raft算法）</td>
</tr>
<tr>
<td>健康检查</td>
<td>TTL(Time To Live)</td>
<td>TCP Keep Alive</td>
<td>TTL\HTTP\TCP\Script</td>
<td>Lease TTL KeepAlive</td>
</tr>
<tr>
<td>watch/long polling</td>
<td>不支持</td>
<td>watch</td>
<td>long polling</td>
<td>watch</td>
</tr>
<tr>
<td>雪崩保护</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr>
<td>安全与权限</td>
<td>不支持</td>
<td>ACL</td>
<td>ACL</td>
<td>RBAC</td>
</tr>
<tr>
<td>是否支持多数据中心</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>是否有管理界面</td>
<td>是</td>
<td>否（可用第三方ZkTools）</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>Spring Cloud 集成</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>Dubbo 集成</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>K8S 集成</td>
<td>不支持</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody></table>
<p>我们可以看出，四种技术类型对Spring Cloud的支持度都很高。Spring Cloud是微服务架构的一站式解决方案，我们平时构建微服务的过程中需要做的的如 配置管理、服务发现、负载均衡、断路器、智能路由、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等操作。Spring Cloud 为我们提供了一套简易的编程模型，使我们能在 Spring Boot 的基础上轻松地实现微服务项目的构建。</p>
<p>Spring Cloud包含了多个不同开源产品，来保证一站式的微服务解决方案，如：Spring Cloud Config、Spring Cloud Netflix、Spring Cloud Security、Spring Cloud Commons、Spring Cloud Zookeeper、Spring Cloud CLI等项目。</p>
<h2>Spring Cloud 框架下实现 <a href="#scroller-2" id="scroller-2"></a></h2>
<p>Spring Cloud为服务治理做了一层抽象，这样能够支持多种不同的服务治理框架，比如：Netflix Eureka、Consul。我们这边就以这两个为例子，看看服务治理是如何实现。</p>
<blockquote>
<p><em>在Spring Cloud服务治理抽象层的作用下，可以无缝地切换服务治理实现，且不影响任何其他的服务注册、发现、调用逻辑。</em></p>
<p><em>所以，下面我们通过介绍这两种服务治理的实现来体会Spring Cloud这一层抽象所带来的好处。</em></p>
</blockquote>
<h3>2.Spring Cloud Eureka <a href="#scroller-3" id="scroller-3"></a></h3>
<p>Spring Cloud Eureka是Spring Cloud Netflix项目下的服务治理模块。而Spring Cloud Netflix项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。</p>
<p>通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。</p>
<p>下面，就来具体看看如何使用Spring Cloud Eureka实现服务治理。</p>
<h4>2.1.创建注册中心 <a href="#scroller-4" id="scroller-4"></a></h4>
<p>创建一个Spring Cloud项目，我们命名为micro-service-center，并在<code>pom.xml</code>中引入需要的依赖内容：</p>
<pre><code class="language-xml"> &lt;packaging&gt;pom&lt;/packaging&gt;
</code></pre>
<p>表明这个项目中可以没有Java代码，也不执行任何代码，只是为了聚合工程或者传递依赖，所以可以把src文件夹删了。这是一个父级项目，因为我们还要在下面建立Eureka的注册中心、客户端等多个子项目 。</p>
<p>在micro-service-center下，新建一个命名为 eureka-service 的Module，依旧是Spring Cloud 项目，建完之后，pom.xml做如下改动：</p>
<pre><code class="language-xml">&lt;xml&gt;
    &lt;!--在子工程中添加父工程名称--&gt;
    &lt;parent&gt;
        &lt;groupId&gt;com.microservice&lt;/groupId&gt;
        &lt;artifactId&gt;center&lt;/artifactId&gt;
        &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;/parent&gt;
    &lt;dependencies&gt;
        &lt;!--加入 eureka 服务 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-netflix-eureka-server&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/xml&gt;
</code></pre>
<p>改完之后，回到父项目micro-service-center，修改pom中的信息：</p>
<pre><code class="language-xml">&lt;xml&gt;
    &lt;groupId&gt;com.microservice&lt;/groupId&gt;
    &lt;artifactId&gt;center&lt;/artifactId&gt;
    &lt;packaging&gt;pom&lt;/packaging&gt;
    &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;name&gt;center&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;!--在父工程添加子工程名称--&gt;
    &lt;modules&gt;
        &lt;module&gt;eureka-service&lt;/module&gt;
        &lt;module&gt;eureka-client&lt;/module&gt;
    &lt;/modules&gt;
&lt;/xml&gt;
</code></pre>
<p>对两个项目进行clean + install，应该是成功的。</p>
<p>eureka-service我们是作为注册中心来用的，所以在它的主类Application中加入<code>@EnableEurekaServer</code>注解，就能开启注册中心功能。</p>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaServer
public class ServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(ServiceApplication.class, args);
        System.out.println(&quot;Start Eureka Service&quot;);
    }
}
</code></pre>
<p>但是默认情况下，该注册中心也会把自己当做客户端，那就变成自己注册自己了，这个是可以剔除的，我们看一下它的YAML中的详细配置，注释比较清楚：</p>
<pre><code class="language-yaml">  server:
    port: 1000
  spring:
    application:
      name: eureka-server
  eureka:
    instance:
      hostname: localhost
    client:
    register-with-eureka: false  # 不作为客户端进行注册
    fetch-registry: false  # 不获取注册列表
    service-url:  # 注册地址，客户端需要注册到该地址中
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
</code></pre>
<p>文中的注释还是比较清楚的。 这边可以看到，端口号是1000，所以当工程启动之后，访问 <a href="http://localhost:1000/">http://localhost:1000/</a> 是可以看到Eureka注册中心页面的。其中还没有发现任何服务。</p>
<p><img src="/images/blog/engineering/microservice-image_7_1.png" alt="image_7_1.png"></p>
<h4>2.1.创建客户端 <a href="#scroller-5" id="scroller-5"></a></h4>
<p>目前服务中心还是空的，所以我们创建一个能够提供服务的客户端，并将其注册到注册中心去。</p>
<p>同样的，我们创建一个Spring Cloud的子项目，命名为<code>eureka-client</code>，<code>pom.xml</code>中的配置如下：</p>
<pre><code class="language-xml">  
&lt;xml&gt;
    &lt;!--在子工程中添加父工程名称--&gt;
    &lt;parent&gt;
        &lt;groupId&gt;com.microservice&lt;/groupId&gt;
        &lt;artifactId&gt;center&lt;/artifactId&gt;
        &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;/parent&gt;
    &lt;dependencies&gt;
        &lt;!--加入 eureka 服务 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-netflix-eureka-server&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/xml&gt;
</code></pre>
<p>在应用主类Application文件中通过加上<code>@EnableDiscoveryClient</code>注解，该注解保证当前服务被Eureka当成provider发现。</p>
<pre><code class="language-java">@SpringBootApplication
@EnableDiscoveryClient
public class ClientApplication {
    public static void main(String[] args) {
        SpringApplication.run(ClientApplication.class, args);
        System.out.println(&quot;start client!&quot;);
    }
}jC
</code></pre>
<p>在YAML文件上加上如下配置：</p>
<pre><code class="language-yaml">server:
  port: 1001
spring:
  application:
    name: eureka-client
eureka:
  client:
    service-url:  # 这边就保证了注册到 eureka-service 这个注册中心去
      defaultZone: http://localhost:1000/eureka/
</code></pre>
<p><code>spring.application.name</code>属性，指定了微服务的名称，在调用的时候可以通过该名称进行服务访问。<code>eureka.client.serviceUrl.defaultZone</code>属性对应服务注册中心的配置内容，指定服务注册中心的位置。</p>
<p>大家看到，这边端口设置为1001，那是因为要在本机上测试 服务提供方 和 服务注册中心，所以<code>server的port</code>属性需设置不同的端口。</p>
<p>最后，我们再写一个接口，通过DiscoveryClient对象，在客户端中获取注册中心的所有服务信息。</p>
<pre><code class="language-java">  @Controller
  @RequestMapping(&quot;/eurekacenter&quot;)
  public class EuServiceController {
  
    @Autowired
    DiscoveryClient discoveryClient;
    
    @RequestMapping(value = &quot;/service&quot;, method = {RequestMethod.GET})
    @ResponseBody
    public String getServiceInfo() {
       return  &quot;service:&quot;+discoveryClient.getServices()+&quot; , memo:&quot;+discoveryClient.description();
    }
}
</code></pre>
<p>这时候跑一下试试看，继续访问之前的地址：<a href="http://localhost:1000/">http://localhost:1000/</a> ，可以看到Eureka注册中心页面已经包含一个我们定义的服务了，就是上面新建的 100端口的服务。</p>
<p><img src="/images/blog/engineering/microservice-image_7_2.png" alt="image_7_2.png"></p>
<p>同样，我们可以调用上面的那个获取注册服务信息的接口，从服务发现的角度看看有多少个服务被注册到注册中心去。 <a href="http://localhost:1001/eurekacenter/service">http://localhost:1001/eurekacenter/service</a></p>
<p><img src="/images/blog/engineering/microservice-image_7_3.png" alt="image_7_3.png"></p>
<p>如上图所示，方括号中的<code>eureka-client</code>通过Spring Cloud定义的 getServiceInfo 接口在eureka的实现中获取到的所有服务清单，他是一个String的List，如果注册了多个提供者，就会全部显示。</p>
<h3>2.Spring Cloud Consul <a href="#scroller-6" id="scroller-6"></a></h3>
<p>Consul 用于实现分布式系统的服务发现与配置。与其它分布式服务注册与发现的方案，Consul 的方案更具“一站式”特征，内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value 存储、多数据中心方案，不再需要依赖其它工具（比如 ZooKeeper 之类的）。</p>
<p>而Spring Cloud Consul ，是将其作为一个整体，在微服务架构中为我们的基础设施提供服务发现和服务配置的工具。</p>
<h4>2.2.Consul 的优势 <a href="#scroller-7" id="scroller-7"></a></h4>
<p>1、使用 Raft 算法来保证一致性, 比复杂的 Paxos 算法更直接。</p>
<p>2、支持多数据中心，内外网的服务采用不同的端口进行监听。 多数据中心集群可以避免单数据中心的单点故障,而其部署则需要考虑网络延迟, 分片等情况等。 zookeeper 和 etcd 均不提供多数据中心功能的支持，上面表格中有体现。</p>
<p>3、支持健康检查。</p>
<p>4、支持 http 和 dns 协议接口。 zookeeper 的集成较为复杂, etcd 只支持 http 协议。</p>
<p>5、官方提供 web 管理界面, etcd 无此功能。</p>
<h4>2.2.Consul的特性 <a href="#scroller-8" id="scroller-8"></a></h4>
<p>1、服务发现</p>
<p>2、健康检查</p>
<p>3、Key/Value存储</p>
<p>4、多数据中心</p>
<h4>2.2.安装Consul注册中心 <a href="#scroller-9" id="scroller-9"></a></h4>
<p>1、官方下载64版本 ：<a href="https://www.consul.io/downloads.html">https://www.consul.io/downloads.html</a></p>
<p>2、解压后复制到目录 /usr/local/bin 下</p>
<p>3、启动终端，先看下啥版本的</p>
<pre><code class="language-sh">liyifei@MacPro ~ % consul --version
Consul v1.10.4
Revision 7bbad6fe
Protocol spoken by default, understands to (agent will automatically use protocol &gt;when speaking to compatible agents)
</code></pre>
<p>4、执行安装命令，可以看到他的 Client Addr 的端口为8500。所以访问 8500端口站点，<a href="http://127.0.0.1:8500/ui/dc1/services">http://127.0.0.1:8500/ui/dc1/services</a></p>
<pre><code class="language-sh">  liyifei@MacPro ~ % consul agent -dev
  ==&gt; Starting Consul agent...
             Version: &#39;1.10.4&#39;
             Node ID: &#39;6db154b4-62ff-e67d-e745-1a7270fa1ce8&#39;
           Node name: &#39;B000000147796DS&#39;
          Datacenter: &#39;dc1&#39; (Segment: &#39;&lt;all&gt;&#39;)
              Server: true (Bootstrap: false)
         Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: 8502, DNS: 8600)
        Cluster Addr: 127.0.0.(LAN: 8301, WAN: 8302)
           Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
</code></pre>
<p><img src="/images/blog/engineering/microservice-image_7_4.png" alt="image_7_4.png"></p>
<p>我们可以看到，现在没有客户端注册上来，只有一个自身的实例。</p>
<h4>2.2.创建服务提供者 <a href="#scroller-10" id="scroller-10"></a></h4>
<p>由于Spring Cloud Consul项目的实现，我们可以轻松的将基于Spring Boot的微服务应用注册到Consul上，并通过此实现微服务架构中的服务治理。</p>
<p>我们在micro-service-center下新建一个cloud项目consul-client，该项目pom文件添加如下：</p>
<pre><code class="language-xml">&lt;xml&gt;
  &lt;!--    在子工程中添加父工程名称--&gt;
  &lt;parent&gt;
    &lt;groupId&gt;com.microservice&lt;/groupId&gt;
    &lt;artifactId&gt;center&lt;/artifactId&gt;
    &lt;version&gt;1.0.0&lt;/version&gt;
  &lt;/parent&gt;
  
  &lt;dependencies&gt;
    &lt;!--        Consul服务发现--&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!--        Consul健康检查--&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
&lt;/xml&gt;
</code></pre>
<p>然后修改一下<code>application.yml的配置信息</code>，将consul配置写入，注释应该很清楚了，如下：</p>
<pre><code class="language-yaml">spring:
  application:
    name: consul-producer # 当前服务的名称
  cloud:
    consul: # 以下为Consuk注册中心的地址，如果安装的不是这个host和port，这边可以调整
      host: localhost
      port: 8500
server:
  port: 850# 当前服务的端口
</code></pre>
<p>同样的，我们要在应用主类Application文件中通过加上<code>@EnableDiscoveryClient</code>注解，该注解保证当前服务被Consul当成provider发现。</p>
<p>大家看到这个做法跟Eureka一样，因为Spring Cloud对服务治理做的一层抽象，所以可以屏蔽Eureka和Consul服务治理的实现细节，</p>
<p>程序上不需要做改变，只需要引入不同的服务治理依赖，并配置相关的配置属性 就能轻松的将微服务纳入Spring Cloud的各个服务治理框架中。</p>
<pre><code class="language-java">@SpringBootApplication
@EnableDiscoveryClient
public class ConsulClientApplication {
    public static void main(String[] args) {
        SpringApplication.run(ClientApplication.class, args);
    }
}
</code></pre>
<p>修改完成之后，我们就可以把这个服务提供者启动了，然后再去注册中心查看服务的注册情况，就可以看到被注册进来的Provider（consul-producer）：</p>
<p><img src="/images/blog/engineering/microservice-image_7_5.png" alt="image_7_5.png"></p>
<h2>总结 <a href="#scroller-11" id="scroller-11"></a></h2>
<p>除了 Eureka、Consul，还有其他的的注册中心技术，如Zookeeper、Nocas等。但无论何种注册中心技术，本质上都是为了解决微服务中的如下问题：</p>
<p><strong>解耦服务之间相互依赖的细节</strong></p>
<p>我们知道服务之间的远程调用必须要知道对方的IP、端口信息。我们可以在调用方直接配置被调用方的IP、端口，这种调用方直接依赖IP、端口的方式存在明显的问题，如被调用的IP、端口变化后，调用方法也要同步修改。</p>
<p>通过服务发现，将服务之间IP与端口的依赖转化为服务名的依赖，服务名可以根据具微服务业务来做标识，因此，屏蔽、解耦服务之间的依赖细节是服务发现与注册解决的第一个问题。</p>
<p><strong>对微服务进行动态管理</strong></p>
<p>在微服务架构中，服务众多，服务之间的相互依赖也错综复杂，无论是服务主动停止，意外挂掉，还是因为流量增加对服务实现进行扩容，这些服务数据或状态上的动态变化，都需要尽快的通知到被调用方，被调用方才采取相应的措施。因此，对于服务注册与发现要实时管理者服务的数据与状态，包括服务的注册上线、服务主动下线，异常服务的剔除。</p>
18:T454,<h1>Maven使用技巧</h1>
<h3>1、使用maven.config定制化配置</h3>
<p>Located within the project&#39;s <strong>top level directory</strong>, the files</p>
<ul>
<li><code>maven.config</code></li>
<li><code>jvm.config</code></li>
<li><code>extensions.xml</code></li>
</ul>
<p>contain project specific configuration for running Maven.</p>
<p>This directory is part of the project and may be checked in into your version control.</p>
<blockquote>
<p>ref：<a href="https://maven.apache.org/configure.html">https://maven.apache.org/configure.html</a></p>
</blockquote>
<p>常见配置如：</p>
<pre><code class="language-bash">-Dmaven.test.skip=true
--settings
/Users/skyfalling/.m2/settings.xml
</code></pre>
<p>There must not be a whitespace after <code>--settings,</code>With the introduction of <code>maven 3.9</code>, there was a BREAKING CHANGE that affects the parsing of the <code>maven.config</code> file:</p>
<p>Each line in <code>.mvn/maven.config</code> is now interpreted as a single argument. That is, if the file contains multiple arguments, these must now be placed on separate lines.</p>
19:T1ce1,<p>上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。</p>
<p><img src="/images/blog/engineering/bigdata-image_2_1.png" alt="image_2_1.png"></p>
<p>HLL 算法需要完整遍历所有元素一次，而非多次或采样；该算法只能计算集合中有多少个不重复的元素，不能给出每个元素的出现次数或是判断一个元素是否之前出现过；多个使用 HLL 统计出的基数值可以融合。</p>
<p><img src="/images/blog/engineering/bigdata-image_2_2.png" alt="image_2_2.png"></p>
<p><img src="/images/blog/engineering/bigdata-image_2_3.png" alt="image_2_3.png"></p>
<p>HLL 算法有着非常优异的空间复杂度，可以看到它的空间占用随着基数值的增长并没有变化。HLL 后面不同的数字代表着不同的精度，数字越大，精度越高，占用的空间也越大，可以认为 HLL 的空间占用只和精度成正相关。</p>
<p><strong>HLL算法原理感性认知</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_4.png" alt="image_2_4.png"></p>
<p>HLL 算法的原理会涉及到比较多的数学知识，这边对这些数学原理和证明不会展开。举一个生活中的例子来帮助大家理解HLL算法的原理：比如你在进行一个实验，内容是不停地抛硬币，记录你连续抛到正面的次数（这是数学中的伯努利过程，感兴趣同学可以自行研究下）；如果你最多的连抛正面记录是3次，那可以想象你并没有做这个实验太多次，如果你最长的连抛正面记录是 20 次，那你可能进行了这个实验上千次。</p>
<p>一种理论上存在的情况是，你非常幸运，第一次进行这个实验就连抛了 20 次正面，我们也会认为你进行了很多次这个实验才得到了这个记录，这就会导致错误的预估；改进的方式是请 10 位同学进行这项实验，这样就可以观察到更多的样本数据，降低出现上述情况的概率。这就是 HLL 算法的核心思想。</p>
<p><strong>HLL算法具体实现</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_5.png" alt="image_2_5.png"></p>
<p>HLL 会通过一个 hash 函数来求出集合中所有元素的 hash 值（二进制表示的 hash 值，就可以理解为一串抛硬币正反面结果的序列），得到一个 hash 值的集合，然后找出该 hash 值集合中，第一个 1 出现的最晚的位置。例如有集合为 [010, 100, 001], 集合中元素的第一个 1 出现的位置分别为 2, 1, 3，可以得到里面最大的值为 3，故该集合中第一个1出现的最晚的位置为 3。因为每个位置上出现1的概率都是 1/2，所以我们可以做一个简单的推断，该集合中有 8 个不重复的元素。</p>
<p>可以看到这种简单的推断计算出来集合的基数值是有较大的偏差的，那如何来减少偏差呢？正如我上面的例子里说的一样，HLL 通过多次的进行试验来减少误差。那它是如何进行多次的实验的呢？这里 HLL 使用了分桶的思想，上文中我们一直有提到一个精度的概念，比如说 HLL(10)，这个 10 代表的就是取该元素对应 Hash 值二进制的后 10 位，计算出记录对应的桶，桶中会记录一个数字，代表对应到该桶的 hash 值的第一个 1 出现的最晚的位置。如上图，该 hash 值的后 10 位的 hash 值是 0000001001，转成 10 进制是 9，对应第 9 号桶，而该 hash 值第一个 1 出现的位置是第 6 位，比原先 9 号桶中的数字大，故把 9 号桶中的数字更新为 6。可以看到桶的个数越多，HLL 算法的精度就越高，HLL(10) 有 1024(210) 个桶，HLL(16)有 65536(216) 个桶。同样的，桶的个数越多，所占用的空间也会越大。</p>
<p><img src="/images/blog/engineering/bigdata-image_2_6.png" alt="image_2_6.png"></p>
<p>刚才的例子我们省略了一些细节，为了让大家不至于迷失在细节中而忽视了重点，真实的 HLL 算法的完整描述见上图，这边的重点是计算桶中平均数时使用调和平均数。调和平均数的优点是可以过滤掉不健康的统计值，使用算术平均值容易受到极值的影响（想想你和马云的平均工资），而调和平均数的结果会倾向于集合中比较小的元素。HLL 论文中还有更多的细节和参数，这边就不一一细举，感兴趣的同学可以自己阅读下论文。</p>
<p><strong>HLL评估</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_7.png" alt="image_2_7.png"></p>
<p>HLL 的误差分布服从正态分布，它的空间复杂度: O(m log2log2N), Ｎ 为基数, m 为桶个数。这边给大家推导一下它的空间复杂度，我有 264 个的不重复元素(Long. MAX_VALUE)，表达为二进制一个数是 64 位，这是第一重 log2, 那么第一个1最晚可能出现在第 64 位。64 需要 6 个 bit (26=64) 就可以存储，这是第二重 log2。如果精度为 10，则会有 1024 个桶，所以最外面还要乘以桶的个数。由于需要完整的遍历元素一遍，所以它的时间复杂度是一个线性的时间复杂度。</p>
<p><strong>在Kylin中的应用</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_8.png" alt="image_2_8.png"></p>
<p>在 Kylin 中使用 HLL 非常简单，在编辑度量的页面选择 COUNT DISTINCT，Return Type 选为非 Precisely 的其他选项，大家根据自己的需求选择不同的精度就可以愉快地使用了。</p>
<p><strong>总结</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_9.png" alt="image_2_9.png"></p>
<p>我们回到最开始的去重场景，看看使用了 Bitmap 和 HLL 会给我们带来什么增益：无优化 case 下，每个 item 对应的 user_id 就可以看成存储原始值的一个集合；在使用 Bitmap 优化的case 下，每个 item 对应的 user_id 就可以看成一个 Bitmap 实例，同理 HLL就是一个 HLL 的实例，Bitmap/HLL 实例占用的空间都会比直接存储原始值的集合要小，这就达到了我们开始提的减少 shuffle 数据量的需求。</p>
<p><strong>Q&amp;A</strong></p>
<p>Q：您好，问一下关于精确去重的问题， 我选择了非精确去重，最后的误差率有时候会比界面上提示的值要高一些，这是为什么？</p>
<p>A：首先 HLL 的误差分布服从正态分布，也就是说是在99%的情况下是这个误差，同时 HLL 对于基数比较低的情况，误差会偏高。如果你的基数比较低的话，我推荐使用精确去重。</p>
<p>Q：我想要了解一下 Bitmap 在 Kylin 中，它最终落盘在 HBase 里面是什么样子的？</p>
<p>A：在 HBase 中存储的当然都是 Bytes。这个问题其实就是 Bitmap 的序列化的形式，Roaring Bitmap提供了序列化和反序列化的实现，你也可以写自己的序列化/反序列化的实现。</p>
<p>Q：Roaring Bitmap 里这些 container 要我们自己手动的指定吗。</p>
<p>A：不需要，Roaring Bitmap 会自动选择使用哪个 Container。</p>
6:["$","article",null,{"className":"min-h-screen","children":["$","div",null,{"className":"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12","children":[["$","header",null,{"className":"mb-8","children":[["$","div",null,{"className":"flex items-center mb-6","children":["$","div",null,{"className":"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal","children":[["$","svg",null,{"className":"w-4 h-4 mr-2 text-gray-400","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"}]}],["$","time",null,{"dateTime":"2024-03-31","children":"2024年03月31日"}]]}]}],["$","h1",null,{"className":"text-4xl font-bold text-gray-900 mb-6 text-center","children":"RabbitMQ、RocketMQ、Kafka区别"}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-6 justify-center","children":[["$","$L5","消息队列",{"href":"/blog/tag/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"消息队列"}],["$","$L5","技术专题",{"href":"/blog/tag/%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"技术专题"}]]}]]}],["$","div",null,{"className":"max-w-5xl mx-auto","children":["$","$L14",null,{"content":"$15"}]}],["$","$11",null,{"fallback":["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":"加载导航中..."}],"children":["$","$L16",null,{"globalNav":{"prev":{"slug":"engineering/architecture/服务注册与发现（实践篇）","title":"服务注册与发现（实践篇）","description":"前面我们对业内几种比较常见的注册中心做了介绍：Eureka、Zookeeper、Consul、Etcd。 并且在各个指标上做了对比：注册方式（watch/polling）、健康检查、雪崩保护、安全与权限，以及在Spring Cloud、Dubbo、Kubernets上的支持程度。方便我们在不同的场景...","pubDate":"2024-03-24","tags":["微服务架构","技术专题"],"heroImage":"$undefined","content":"$17"},"next":{"slug":"engineering/tooling/Maven使用技巧","title":"Maven使用技巧","description":"手把手教你如何在工作中巧妙使用Maven，提升开发效率。","pubDate":"2024-04-03","tags":["技术实战"],"heroImage":"$undefined","content":"$18"}},"tagNav":{"消息队列":{"prev":null,"next":null},"技术专题":{"prev":"$6:props:children:props:children:props:children:2:props:children:props:globalNav:prev","next":{"slug":"engineering/data/大数据分析常用去重算法分析之HyperLogLog篇","title":"大数据分析常用去重算法分析之HyperLogLog篇","description":"上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 ","pubDate":"2025-03-25","tags":["大数据","技术专题","去重算法","HyperLogLog"],"heroImage":"$undefined","content":"$19"}}}}]}],["$","$L1a",null,{}]]}]}]}]
9:null
d:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
b:{"metadata":[["$","title","0",{"children":"RabbitMQ、RocketMQ、Kafka区别 - Skyfalling Blog"}],["$","meta","1",{"name":"description","content":"MQ（Message Queue，消息队列） 在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋和消息通讯四个场景。目前使用较多的消息队列有老牌的ActiveMQ、RabbitMQ，ZeroMQ，炙手可热的Kafka，MetaMQ，阿里巴巴的RocketMQ"}],["$","meta","2",{"property":"og:title","content":"RabbitMQ、RocketMQ、Kafka区别"}],["$","meta","3",{"property":"og:description","content":"MQ（Message Queue，消息队列） 在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋和消息通讯四个场景。目前使用较多的消息队列有老牌的ActiveMQ、RabbitMQ，ZeroMQ，炙手可热的Kafka，MetaMQ，阿里巴巴的RocketMQ"}],["$","meta","4",{"property":"og:type","content":"article"}],["$","meta","5",{"property":"article:published_time","content":"2024-03-31"}],["$","meta","6",{"property":"article:author","content":"Skyfalling"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"RabbitMQ、RocketMQ、Kafka区别"}],["$","meta","9",{"name":"twitter:description","content":"MQ（Message Queue，消息队列） 在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋和消息通讯四个场景。目前使用较多的消息队列有老牌的ActiveMQ、RabbitMQ，ZeroMQ，炙手可热的Kafka，MetaMQ，阿里巴巴的RocketMQ"}],["$","link","10",{"rel":"shortcut icon","href":"/favicon.png"}],["$","link","11",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","link","12",{"rel":"icon","href":"/favicon.png"}],["$","link","13",{"rel":"apple-touch-icon","href":"/favicon.png"}]],"error":null,"digest":"$undefined"}
13:{"metadata":"$b:metadata","error":null,"digest":"$undefined"}
