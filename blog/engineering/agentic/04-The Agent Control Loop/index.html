<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/7dd6b3ec14b0b1d8.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42d55485b4428e47.js"/><script src="/_next/static/chunks/4bd1b696-8ec333fca6b38e39.js" async=""></script><script src="/_next/static/chunks/1684-a2aac8a674e5d38c.js" async=""></script><script src="/_next/static/chunks/main-app-2791dc86ed05573e.js" async=""></script><script src="/_next/static/chunks/6874-7791217feaf05c17.js" async=""></script><script src="/_next/static/chunks/app/layout-142e67ac4336647c.js" async=""></script><script src="/_next/static/chunks/968-d7155a2506e36f1d.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js" async=""></script><meta name="next-size-adjust" content=""/><title>The Agent Control Loop: Agent 运行时的核心抽象 - Skyfalling Blog</title><meta name="description" content="Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。"/><meta property="og:title" content="The Agent Control Loop: Agent 运行时的核心抽象"/><meta property="og:description" content="Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-12-14"/><meta property="article:author" content="Skyfalling"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="The Agent Control Loop: Agent 运行时的核心抽象"/><meta name="twitter:description" content="Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。"/><link rel="shortcut icon" href="/favicon.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/favicon.png"/><link rel="apple-touch-icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen flex flex-col"><header class="bg-[var(--background)]"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a class="-m-1.5 p-1.5" href="/"><span class="sr-only">Skyfalling Blog</span><span class="text-2xl font-bold text-gray-900">Skyfalling</span></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">打开主菜单</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/">首页</a><a class="text-base font-semibold leading-6 transition-colors text-blue-600 border-b-2 border-blue-600 pb-1" href="/blog/">博客</a><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/about/">关于</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"></div></nav></header><main class="flex-1"><article class="min-h-screen"><div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8"><div class="rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12"><header class="mb-8"><nav class="flex items-center gap-1 text-sm mb-4"><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/page/1/">博客</a><span class="text-gray-300">/</span><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/category/engineering/page/1/">Engineering</a><span class="text-gray-300">/</span><a class="text-blue-600 hover:text-blue-700 transition-colors" href="/blog/category/engineering/agentic/page/1/">Agentic 系统</a></nav><div class="flex items-center mb-6"><div class="inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal"><svg class="w-4 h-4 mr-2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2025-12-14">2025年12月14日</time></div></div><h1 class="text-4xl font-bold text-gray-900 mb-6 text-center">The Agent Control Loop: Agent 运行时的核心抽象</h1><div class="flex flex-wrap gap-2 mb-6 justify-center"><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Agentic/page/1/">Agentic</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/AI%20Engineering/page/1/">AI Engineering</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Runtime/page/1/">Runtime</a></div></header><div class="max-w-5xl mx-auto"><div class="prose prose-lg prose-gray mx-auto max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:text-blue-700 prose-strong:text-gray-900 prose-strong:font-semibold prose-li:text-gray-700 prose-hr:border-gray-300"><h1>The Agent Control Loop: Agent 运行时的核心抽象</h1>
<blockquote>
<p>如果说 LLM 是 Agent 的大脑，那么 Control Loop 就是 Agent 的心跳。</p>
<p>大多数教程在讲 Agent 时，上来就接框架、调 API、跑 demo。但如果你不理解 Agent 运行时的核心抽象——控制循环——你永远只是在用别人的黑盒。</p>
<p>本文是 Agentic 系列第 04 篇，整个系列的技术基石。我们会从状态机模型出发，逐层拆解 Agent Control Loop 的每一个阶段，给出完整的 Python 实现，并深入分析实际工程中的 trade-off。</p>
</blockquote>
<hr>
<h2>1. Agent 的本质：可中断的控制循环</h2>
<p>一个常见的误解是把 Agent 等同于&quot;一次 LLM 调用&quot;。实际上，Agent 和 LLM 的关系，类似于操作系统和 CPU 的关系——LLM 是执行推理的计算单元，而 Agent 是管理整个执行生命周期的运行时系统。</p>
<p><strong>LLM 是一个函数：</strong> <code>f(prompt) -&gt; completion</code>，输入文本，输出文本，调用一次就结束。</p>
<p><strong>Agent 是一个循环：</strong> 它持续运行，在每一轮中观察环境、调用 LLM 进行推理、执行动作、评估结果，然后决定是否继续。</p>
<pre><code>LLM:    Input ──→ Output            (一次调用)

Agent:  Input ──→ [Observe → Think → Act → Reflect] ──→ ... ──→ Output
                  └──────── 循环 N 次 ────────────┘     (多轮控制)
</code></pre>
<p>这个循环有几个关键特性：</p>
<ul>
<li><strong>可中断</strong>：循环可以在任何阶段暂停，等待外部输入（用户确认、异步工具返回）后恢复</li>
<li><strong>有状态</strong>：循环维护上下文信息，每一轮的输出影响下一轮的输入</li>
<li><strong>有终止条件</strong>：循环不会无限运行，它在满足特定条件时停止</li>
<li><strong>可观测</strong>：循环的每一步都应该是可追踪、可回溯的</li>
</ul>
<p>理解了这一点，Agent 编程的核心问题就变成了：<strong>如何设计和实现这个控制循环？</strong></p>
<hr>
<h2>2. 状态机模型：形式化定义</h2>
<p>要严谨地描述 Control Loop，最自然的方式是用<strong>有限状态机（FSM）</strong>。</p>
<h3>2.1 状态定义</h3>
<p>一个 Agent Control Loop 可以用以下状态集合描述：</p>
<pre><code class="language-python">from enum import Enum

class AgentState(Enum):
    OBSERVE  = &quot;observe&quot;   # 接收并归一化输入
    THINK    = &quot;think&quot;     # LLM 推理，决定下一步行动
    ACT      = &quot;act&quot;       # 执行工具调用或产出结果
    REFLECT  = &quot;reflect&quot;   # 评估执行结果，决定是否继续
    DONE     = &quot;done&quot;      # 终止：任务完成
    ERROR    = &quot;error&quot;     # 终止：不可恢复错误
</code></pre>
<h3>2.2 状态转移图</h3>
<pre><code>                    ┌─────────────────────────────────────────┐
                    │                                         │
                    ▼                                         │
              ┌──────────┐                                    │
   Input ───→│ OBSERVE  │                                    │
              └────┬─────┘                                    │
                   │                                         │
                   ▼                                         │
              ┌──────────┐    need_action    ┌──────────┐    │
              │  THINK   │ ───────────────→ │   ACT    │    │
              └────┬─────┘                   └────┬─────┘    │
                   │                              │          │
                   │ has_answer                   │          │
                   │                              ▼          │
                   │                        ┌──────────┐     │
                   │                        │ REFLECT  │ ────┘
                   │                        └────┬─────┘  continue
                   │                             │
                   ▼                             ▼
              ┌──────────┐                  ┌──────────┐
              │   DONE   │                  │  ERROR   │
              └──────────┘                  └──────────┘
                                       (max_retries exceeded
                                        / unrecoverable)
</code></pre>
<p>状态转移规则：</p>
<table>
<thead>
<tr>
<th>当前状态</th>
<th>条件</th>
<th>下一状态</th>
</tr>
</thead>
<tbody><tr>
<td>OBSERVE</td>
<td>输入就绪</td>
<td>THINK</td>
</tr>
<tr>
<td>THINK</td>
<td>LLM 返回 tool_call</td>
<td>ACT</td>
</tr>
<tr>
<td>THINK</td>
<td>LLM 返回最终回答</td>
<td>DONE</td>
</tr>
<tr>
<td>THINK</td>
<td>LLM 调用异常</td>
<td>ERROR</td>
</tr>
<tr>
<td>ACT</td>
<td>工具执行完成</td>
<td>REFLECT</td>
</tr>
<tr>
<td>ACT</td>
<td>工具执行失败</td>
<td>REFLECT (带错误信息)</td>
</tr>
<tr>
<td>REFLECT</td>
<td>需要继续</td>
<td>OBSERVE (将结果作为新输入)</td>
</tr>
<tr>
<td>REFLECT</td>
<td>任务完成</td>
<td>DONE</td>
</tr>
<tr>
<td>REFLECT</td>
<td>超过重试上限</td>
<td>ERROR</td>
</tr>
</tbody></table>
<h3>2.3 与 OODA Loop 的对比</h3>
<p>Agent Control Loop 并不是凭空发明的，它和军事决策理论中的 <strong>OODA Loop（Observe-Orient-Decide-Act）</strong> 有深层的结构对应：</p>
<pre><code>OODA Loop:          Agent Control Loop:
┌─────────┐         ┌─────────┐
│ Observe │ ──────→ │ OBSERVE │  感知环境
├─────────┤         ├─────────┤
│ Orient  │ ──────→ │ THINK   │  理解上下文，形成判断
├─────────┤         │         │
│ Decide  │ ──────→ │         │  (LLM 在 THINK 中同时完成 Orient+Decide)
├─────────┤         ├─────────┤
│  Act    │ ──────→ │  ACT    │  执行行动
└─────────┘         ├─────────┤
                    │ REFLECT │  OODA 中没有显式的反思阶段
                    └─────────┘
</code></pre>
<p>关键区别在于 <strong>REFLECT 阶段</strong>。传统 OODA Loop 假设决策者能实时感知行动效果并自然融入下一轮 Observe。但 LLM Agent 不具备这种连续感知能力——它需要一个显式的反思步骤来评估工具返回值、判断是否需要修正。这是 Agent Control Loop 相对于经典决策循环的重要改进。</p>
<hr>
<h2>3. 循环中每个阶段的深入分析</h2>
<h3>3.1 OBSERVE：输入归一化</h3>
<p>OBSERVE 阶段的职责是<strong>收集并归一化各种来源的输入</strong>，将它们统一为 LLM 可理解的格式。</p>
<p>输入来源远不止&quot;用户消息&quot;一种：</p>
<pre><code>输入来源                    归一化后
┌─────────────────┐       ┌──────────────────────┐
│ 用户消息         │ ────→ │ {&quot;role&quot;: &quot;user&quot;,     │
│ 工具返回值       │ ────→ │  &quot;content&quot;: &quot;...&quot;}   │
│ 系统事件         │ ────→ │                      │
│ 定时触发         │ ────→ │ {&quot;role&quot;: &quot;system&quot;,   │
│ 外部 Webhook    │ ────→ │  &quot;content&quot;: &quot;...&quot;}   │
│ 上一轮反思结果   │ ────→ │                      │
└─────────────────┘       └──────────────────────┘
</code></pre>
<p><strong>输入归一化的核心原则：</strong></p>
<ol>
<li><p><strong>所有输入都必须序列化为 message 格式</strong>。不管来源是什么，最终都要变成 <code>{&quot;role&quot;: ..., &quot;content&quot;: ...}</code> 的形式，因为 LLM 只理解 message 序列。</p>
</li>
<li><p><strong>工具返回值需要结构化包装</strong>。不要直接把原始 JSON 甩给 LLM，要附上工具名称、执行状态和必要的摘要信息。</p>
</li>
<li><p><strong>输入需要截断和优先级排序</strong>。当多个输入同时到达时，需要决定哪些放进当前轮次的 Context Window，哪些缓存到下一轮。</p>
</li>
</ol>
<pre><code class="language-python">def observe(self, raw_inputs: list[dict]) -&gt; list[dict]:
    &quot;&quot;&quot;将原始输入归一化为 LLM message 格式&quot;&quot;&quot;
    messages = []
    for inp in raw_inputs:
        match inp[&quot;type&quot;]:
            case &quot;user_message&quot;:
                messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: inp[&quot;text&quot;]})
            case &quot;tool_result&quot;:
                messages.append({
                    &quot;role&quot;: &quot;tool&quot;,
                    &quot;tool_call_id&quot;: inp[&quot;call_id&quot;],
                    &quot;content&quot;: self._format_tool_result(inp),
                })
            case &quot;system_event&quot;:
                messages.append({
                    &quot;role&quot;: &quot;system&quot;,
                    &quot;content&quot;: f&quot;[System Event] {inp[&#39;event&#39;]}&quot;,
                })
    return messages
</code></pre>
<h3>3.2 THINK：LLM 推理</h3>
<p>THINK 阶段是控制循环中最核心的一环——调用 LLM，让它基于当前上下文做出决策。</p>
<p>这个阶段要解决三个问题：</p>
<p><strong>问题一：Context Window 构建</strong></p>
<p>LLM 的输入不是当前轮次的消息，而是<strong>从任务开始到现在的完整上下文</strong>。构建 Context Window 的典型结构：</p>
<pre><code>┌─────────────────────────────────────────────┐
│ System Prompt                               │  固定不变
│ (角色定义 + 能力边界 + 输出格式要求)           │
├─────────────────────────────────────────────┤
│ Tool Definitions                            │  固定不变
│ (可用工具的 JSON Schema 定义)                │
├─────────────────────────────────────────────┤
│ Message History                             │  随轮次增长
│ (user → assistant → tool → assistant → ...) │
├─────────────────────────────────────────────┤
│ Current Turn Input                          │  当前轮次
│ (本轮 OBSERVE 阶段归一化的输入)              │
└─────────────────────────────────────────────┘
</code></pre>
<p><strong>问题二：Token 预算控制</strong></p>
<p>Context Window 有上限（4K / 8K / 128K / 200K），而每一轮循环都会增加 message history。如果不加控制，几轮之后就会超限。</p>
<p>常见的预算控制策略：</p>
<table>
<thead>
<tr>
<th>策略</th>
<th>实现方式</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>硬截断</td>
<td>只保留最近 N 条消息</td>
<td>简单场景</td>
</tr>
<tr>
<td>滑动窗口</td>
<td>System Prompt 固定 + 最近 K 轮对话</td>
<td>工具调用场景</td>
</tr>
<tr>
<td>摘要压缩</td>
<td>将早期对话用 LLM 生成摘要后替换</td>
<td>长对话场景</td>
</tr>
<tr>
<td>优先级保留</td>
<td>按消息重要性排序，低优先级先丢弃</td>
<td>复杂多步任务</td>
</tr>
</tbody></table>
<pre><code class="language-python">def _build_context(self, new_messages: list[dict]) -&gt; list[dict]:
    &quot;&quot;&quot;构建符合 Token 预算的 Context Window&quot;&quot;&quot;
    self.message_history.extend(new_messages)

    context = [self.system_prompt] + self.tool_definitions
    remaining_budget = self.max_tokens - self._count_tokens(context)

    # 从最新消息开始向前填充，直到预算耗尽
    selected = []
    for msg in reversed(self.message_history):
        msg_tokens = self._count_tokens([msg])
        if msg_tokens &gt; remaining_budget:
            break
        selected.insert(0, msg)
        remaining_budget -= msg_tokens

    return context + selected
</code></pre>
<p><strong>问题三：LLM 输出解析</strong></p>
<p>LLM 的返回可能是纯文本回答（任务完成），也可能是工具调用请求。需要根据返回类型决定下一步状态转移：</p>
<pre><code class="language-python">def think(self, context: list[dict]) -&gt; ThinkResult:
    &quot;&quot;&quot;调用 LLM 进行推理&quot;&quot;&quot;
    response = self.client.chat.completions.create(
        model=self.model,
        messages=context,
        tools=self.tool_schemas,
    )
    choice = response.choices[0]

    if choice.finish_reason == &quot;tool_calls&quot;:
        return ThinkResult(
            action=&quot;tool_call&quot;,
            tool_calls=choice.message.tool_calls,
            raw_message=choice.message,
        )
    else:
        return ThinkResult(
            action=&quot;answer&quot;,
            content=choice.message.content,
            raw_message=choice.message,
        )
</code></pre>
<h3>3.3 ACT：执行层</h3>
<p>ACT 阶段负责<strong>执行 THINK 阶段决定的动作</strong>——通常是调用工具（Tool Calling）。</p>
<p>执行层的核心挑战不是&quot;调用工具&quot;本身，而是以下几个工程问题：</p>
<p><strong>同步 vs 异步执行</strong></p>
<pre><code>同步执行（Simple）：
  think → call_tool_1 → wait → call_tool_2 → wait → reflect
  延迟 = T1 + T2

异步 / 并行执行（Optimized）：
  think → call_tool_1 ─┬─→ reflect
        → call_tool_2 ─┘
  延迟 = max(T1, T2)
</code></pre>
<p>当 LLM 在一次返回中请求多个工具调用（parallel tool calling）时，应该并行执行以降低延迟：</p>
<pre><code class="language-python">import asyncio

async def act(self, tool_calls: list[ToolCall]) -&gt; list[dict]:
    &quot;&quot;&quot;并行执行多个工具调用&quot;&quot;&quot;
    tasks = [self._execute_tool(tc) for tc in tool_calls]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    tool_results = []
    for tc, result in zip(tool_calls, results):
        if isinstance(result, Exception):
            tool_results.append({
                &quot;type&quot;: &quot;tool_result&quot;,
                &quot;call_id&quot;: tc.id,
                &quot;status&quot;: &quot;error&quot;,
                &quot;content&quot;: f&quot;Tool &#39;{tc.function.name}&#39; failed: {result}&quot;,
            })
        else:
            tool_results.append({
                &quot;type&quot;: &quot;tool_result&quot;,
                &quot;call_id&quot;: tc.id,
                &quot;status&quot;: &quot;success&quot;,
                &quot;content&quot;: str(result),
            })
    return tool_results
</code></pre>
<p><strong>执行安全</strong></p>
<p>工具执行不是无条件信任的。需要考虑：</p>
<ul>
<li><strong>超时控制</strong>：每个工具调用必须有 timeout，防止阻塞整个循环</li>
<li><strong>结果大小限制</strong>：工具返回值可能非常大（比如查数据库返回 10 万行），需要截断</li>
<li><strong>权限校验</strong>：某些工具（文件写入、网络请求、代码执行）需要额外的权限检查</li>
<li><strong>沙箱执行</strong>：代码执行类工具应该在沙箱中运行</li>
</ul>
<h3>3.4 REFLECT：输出质量评估</h3>
<p>REFLECT 阶段回答一个关键问题：<strong>上一步的执行结果是否满意？是继续、重试还是停止？</strong></p>
<p>这个阶段有两种实现方式：</p>
<p><strong>方式一：隐式反思——让 LLM 在下一轮 THINK 中自行判断</strong></p>
<p>这是最简单的方式。把工具返回值直接送进下一轮 THINK，让 LLM 自己决定是否需要修正。大多数框架（如 OpenAI Assistants API）默认采用这种方式。</p>
<p>优点：实现简单，不增加额外的 LLM 调用。</p>
<p>缺点：LLM 可能&quot;自信地&quot;忽略错误，特别是在返回值看起来合理但语义错误的情况下。</p>
<p><strong>方式二：显式反思——用独立的 LLM 调用进行自我评估</strong></p>
<pre><code class="language-python">def reflect(self, action_result: dict, task_goal: str) -&gt; ReflectResult:
    &quot;&quot;&quot;显式反思：评估执行结果&quot;&quot;&quot;
    prompt = f&quot;&quot;&quot;评估以下工具执行结果是否达成了任务目标。

任务目标: {task_goal}
执行结果: {json.dumps(action_result, ensure_ascii=False)}

请回答：
1. 结果是否正确？(yes/no)
2. 是否需要进一步行动？(yes/no)
3. 如果需要，下一步应该做什么？
&quot;&quot;&quot;
    response = self.client.chat.completions.create(
        model=self.model,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
    )
    # 解析反思结果...
    return ReflectResult(
        is_correct=...,
        needs_more_action=...,
        next_step_hint=...,
    )
</code></pre>
<p><strong>Trade-off 分析：</strong></p>
<table>
<thead>
<tr>
<th>维度</th>
<th>隐式反思</th>
<th>显式反思</th>
</tr>
</thead>
<tbody><tr>
<td>Token 消耗</td>
<td>低</td>
<td>高（额外一次 LLM 调用）</td>
</tr>
<tr>
<td>质量把控</td>
<td>依赖 LLM 自觉</td>
<td>有独立的质量评估</td>
</tr>
<tr>
<td>延迟</td>
<td>低</td>
<td>增加一轮 LLM 延迟</td>
</tr>
<tr>
<td>适用场景</td>
<td>简单工具调用</td>
<td>复杂推理链、高准确性要求</td>
</tr>
</tbody></table>
<p>实际工程中，常用的折中方案是：<strong>对关键步骤用显式反思，对常规步骤用隐式反思</strong>。</p>
<h3>3.5 终止条件：什么时候停下来？</h3>
<p>一个 Agent 如果不知道什么时候停，就是一个烧钱的死循环。终止条件的设计是 Control Loop 中最容易被忽视、但对生产环境最重要的部分。</p>
<pre><code class="language-python">def should_stop(self, state: LoopState) -&gt; tuple[bool, str]:
    &quot;&quot;&quot;判断是否应该终止循环&quot;&quot;&quot;
    # 1. LLM 认为任务完成
    if state.last_think_result.action == &quot;answer&quot;:
        return True, &quot;task_completed&quot;

    # 2. 达到最大轮次
    if state.turn_count &gt;= self.max_turns:
        return True, &quot;max_turns_exceeded&quot;

    # 3. Token 预算耗尽
    if state.total_tokens &gt;= self.token_budget:
        return True, &quot;token_budget_exceeded&quot;

    # 4. 连续错误过多
    if state.consecutive_errors &gt;= self.max_consecutive_errors:
        return True, &quot;too_many_errors&quot;

    # 5. 死循环检测（重复输出相同内容）
    if self._detect_loop(state.recent_outputs):
        return True, &quot;loop_detected&quot;

    return False, &quot;&quot;
</code></pre>
<p>各终止条件的设计考量：</p>
<ul>
<li><strong>max_turns</strong>：硬上限，防止失控。一般设 10-30 轮。过小会导致复杂任务被截断，过大会导致 Token 浪费</li>
<li><strong>token_budget</strong>：成本控制。根据业务场景设定每次交互的 Token 上限</li>
<li><strong>consecutive_errors</strong>：容错阈值。工具偶尔失败是正常的，但连续 3 次以上通常意味着系统性问题</li>
<li><strong>loop_detected</strong>：死循环检测。如果 Agent 连续 N 轮输出相同或高度相似的内容，说明它陷入了无效循环</li>
</ul>
<hr>
<h2>4. 两种主流 Loop 模式对比</h2>
<h3>4.1 ReAct 模式</h3>
<p><strong>ReAct（Reason + Act）</strong> 是目前最主流的 Agent Loop 模式，由 Yao et al. 2022 提出。其核心思想是让 LLM 交替进行推理和行动：</p>
<pre><code>┌──────────────────────────────────────────────────────┐
│                   ReAct Loop                         │
│                                                      │
│  ┌─────────┐    ┌─────────┐    ┌─────────────────┐  │
│  │ Thought │ →  │ Action  │ →  │  Observation    │  │
│  │(LLM推理)│    │(工具调用)│    │(工具返回值)      │  │
│  └─────────┘    └─────────┘    └────────┬────────┘  │
│       ▲                                  │          │
│       └──────────────────────────────────┘          │
│                  循环直到完成                         │
└──────────────────────────────────────────────────────┘
</code></pre>
<p>一个典型的 ReAct 执行轨迹（Trace）：</p>
<pre><code>Thought: 用户想知道北京今天的天气。我需要调用天气 API。
Action:  get_weather(city=&quot;北京&quot;)
Observation: {&quot;temp&quot;: 28, &quot;condition&quot;: &quot;晴&quot;, &quot;humidity&quot;: 45}

Thought: 已经获取到天气数据，我可以直接回答用户。
Answer:  北京今天晴天，气温 28°C，湿度 45%。
</code></pre>
<p><strong>ReAct 的优势：</strong></p>
<ul>
<li>每一步都基于最新的观察结果做决策，<strong>适应性强</strong></li>
<li>Thought 过程可见，<strong>可解释性好</strong></li>
<li>实现简单，与 Tool Calling API 天然契合</li>
</ul>
<p><strong>ReAct 的劣势：</strong></p>
<ul>
<li>逐步决策，无法全局优化执行顺序</li>
<li>每一步都需要一次 LLM 调用，<strong>延迟累积</strong></li>
<li>对于需要协调多个子任务的复杂场景，容易陷入局部最优</li>
</ul>
<h3>4.2 Plan-then-Execute 模式</h3>
<p>与 ReAct 的&quot;走一步看一步&quot;不同，Plan-then-Execute 先生成一个<strong>完整的执行计划</strong>，然后按计划依次执行：</p>
<pre><code>┌──────────────────────────────────────────────────────────┐
│              Plan-then-Execute Loop                       │
│                                                          │
│  ┌──────────────────────────────────────┐                │
│  │           Planning Phase             │                │
│  │  Input → LLM → [Step1, Step2, ...]   │                │
│  └───────────────┬──────────────────────┘                │
│                  │                                        │
│                  ▼                                        │
│  ┌──────────────────────────────────────┐                │
│  │         Execution Phase              │                │
│  │  Step1 → Execute → Result1           │                │
│  │  Step2 → Execute → Result2           │                │
│  │  ...                                 │                │
│  └───────────────┬──────────────────────┘                │
│                  │                                        │
│                  ▼                                        │
│  ┌──────────────────────────────────────┐                │
│  │    Replan (if needed)                │                │
│  │  检查是否需要调整计划                   │                │
│  └──────────────────────────────────────┘                │
└──────────────────────────────────────────────────────────┘
</code></pre>
<p>执行轨迹示例：</p>
<pre><code>Plan:
  1. 查询北京天气
  2. 查询上海天气
  3. 对比两地天气差异
  4. 生成出行建议

Execute Step 1: get_weather(city=&quot;北京&quot;) → {&quot;temp&quot;: 28, &quot;condition&quot;: &quot;晴&quot;}
Execute Step 2: get_weather(city=&quot;上海&quot;) → {&quot;temp&quot;: 32, &quot;condition&quot;: &quot;多云&quot;}
Execute Step 3: (LLM 对比分析)
Execute Step 4: (LLM 生成建议)

Answer: ...
</code></pre>
<h3>4.3 Trade-off 分析</h3>
<pre><code>                        灵活性
                          ▲
                          │
                 ReAct ●  │
                          │
                          │        ● Hybrid
                          │          (ReAct + Plan)
                          │
              Plan-then   │
              -Execute ●  │
                          │
                          └──────────────────→ 效率
                                          (LLM 调用次数)
</code></pre>
<table>
<thead>
<tr>
<th>维度</th>
<th>ReAct</th>
<th>Plan-then-Execute</th>
</tr>
</thead>
<tbody><tr>
<td>灵活性</td>
<td>高。每步实时调整</td>
<td>低。偏离计划时需要 Replan</td>
</tr>
<tr>
<td>LLM 调用次数</td>
<td>多（每步一次推理）</td>
<td>少（规划一次 + 执行时可能不需要 LLM）</td>
</tr>
<tr>
<td>可控性</td>
<td>低。难以预测执行路径</td>
<td>高。计划可审核、可修改</td>
</tr>
<tr>
<td>适合场景</td>
<td>工具调用为主、步骤不确定</td>
<td>多步骤、有依赖关系、需要全局协调</td>
</tr>
<tr>
<td>错误恢复</td>
<td>自然。下一步可以直接修正</td>
<td>需要 Replan 机制</td>
</tr>
<tr>
<td>人类干预</td>
<td>难以在中途插入</td>
<td>容易。可以审核和修改计划</td>
</tr>
</tbody></table>
<p><strong>实际工程建议：</strong> 大多数场景从 ReAct 开始。当你发现 Agent 频繁在多步任务中&quot;迷路&quot;或做出低效的工具调用序列时，再考虑引入 Plan-then-Execute 或混合模式。</p>
<hr>
<h2>5. 状态管理</h2>
<p>Control Loop 的状态管理决定了 Agent 的<strong>持久性</strong>和<strong>可恢复性</strong>。</p>
<h3>5.1 Stateless Agent</h3>
<p>Stateless Agent 不维护执行状态，所有上下文通过 <strong>message history</strong> 传递。</p>
<pre><code>Request 1:  [system, user_msg_1]                     → response_1
Request 2:  [system, user_msg_1, response_1, user_2] → response_2
Request 3:  [system, user_msg_1, response_1, user_2, response_2, user_3] → response_3
</code></pre>
<p><strong>特点：</strong></p>
<ul>
<li>实现最简单，无需持久化</li>
<li>每次请求都是自包含的</li>
<li>message history 不断膨胀，最终超过 Context Window</li>
<li>不支持暂停/恢复</li>
</ul>
<p>这是大多数 &quot;chat completion&quot; 应用的工作方式。适合单轮或短对话场景。</p>
<h3>5.2 Stateful Agent</h3>
<p>Stateful Agent 维护一个独立的 <strong>execution state</strong>，它不仅包含 message history，还包含任务进度、中间结果、工具状态等信息。</p>
<pre><code class="language-python">@dataclass
class ExecutionState:
    &quot;&quot;&quot;Agent 执行状态&quot;&quot;&quot;
    session_id: str
    status: AgentState
    turn_count: int
    message_history: list[dict]

    # 任务状态
    task_goal: str
    current_plan: list[str] | None
    completed_steps: list[str]

    # 资源消耗
    total_input_tokens: int
    total_output_tokens: int

    # 错误追踪
    consecutive_errors: int
    error_log: list[dict]

    # 时间戳
    created_at: float
    updated_at: float
</code></pre>
<h3>5.3 状态持久化方案</h3>
<p>当 Agent 需要支持暂停/恢复、跨进程执行、或长时间运行时，执行状态必须持久化。</p>
<pre><code>┌─────────────┐     ┌──────────────┐     ┌──────────────┐
│   In-Memory  │     │    Redis     │     │   Database   │
│  (dict/obj)  │     │  (KV Store)  │     │ (PostgreSQL) │
├─────────────┤     ├──────────────┤     ├──────────────┤
│ 最快         │     │ 快，支持 TTL  │     │ 持久可靠     │
│ 进程重启丢失  │     │ 跨进程共享    │     │ 支持查询分析  │
│ 单进程使用    │     │ 重启后可保留  │     │ 适合生产环境  │
│ 适合开发/测试 │     │ 适合 session  │     │ 适合审计追溯  │
└─────────────┘     └──────────────┘     └──────────────┘
</code></pre>
<p><strong>Checkpoint 与恢复</strong> 是 Stateful Agent 的核心能力。思路很直接：在每轮循环的关键节点保存一次快照，异常恢复时从最近的快照重新开始。</p>
<pre><code class="language-python">class CheckpointManager:
    def save(self, state: ExecutionState) -&gt; str:
        &quot;&quot;&quot;保存 checkpoint，返回 checkpoint_id&quot;&quot;&quot;
        snapshot = {
            &quot;state&quot;: asdict(state),
            &quot;timestamp&quot;: time.time(),
        }
        checkpoint_id = f&quot;{state.session_id}:{state.turn_count}&quot;
        self.store.set(checkpoint_id, json.dumps(snapshot))
        return checkpoint_id

    def restore(self, checkpoint_id: str) -&gt; ExecutionState:
        &quot;&quot;&quot;从 checkpoint 恢复执行状态&quot;&quot;&quot;
        snapshot = json.loads(self.store.get(checkpoint_id))
        return ExecutionState(**snapshot[&quot;state&quot;])
</code></pre>
<p>实际系统中，checkpoint 的保存频率需要权衡：</p>
<ul>
<li><strong>每轮都保存</strong>：恢复粒度最细，但写入开销大</li>
<li><strong>关键节点保存</strong>（如每次工具调用前后）：开销适中，覆盖最重要的故障场景</li>
<li><strong>定时保存</strong>：实现简单，但可能丢失最近几轮的状态</li>
</ul>
<hr>
<h2>6. 完整代码实现</h2>
<p>下面是一个最小但完整的 Agent Control Loop 实现。不依赖任何框架，仅使用 Python 标准库 + OpenAI SDK。</p>
<pre><code class="language-python">&quot;&quot;&quot;
Minimal Agent Control Loop
不依赖任何框架，纯 Python + OpenAI SDK
&quot;&quot;&quot;
import json
import time
from enum import Enum
from dataclasses import dataclass, field
from openai import OpenAI


class State(Enum):
    OBSERVE = &quot;observe&quot;
    THINK = &quot;think&quot;
    ACT = &quot;act&quot;
    REFLECT = &quot;reflect&quot;
    DONE = &quot;done&quot;
    ERROR = &quot;error&quot;


@dataclass
class LoopContext:
    messages: list[dict] = field(default_factory=list)
    turn: int = 0
    total_tokens: int = 0
    consecutive_errors: int = 0
    recent_outputs: list[str] = field(default_factory=list)


# ── Tool Registry ────────────────────────────────────

TOOL_FUNCTIONS = {}

def register_tool(name: str, description: str, parameters: dict):
    &quot;&quot;&quot;装饰器：注册工具函数及其 schema&quot;&quot;&quot;
    def decorator(fn):
        TOOL_FUNCTIONS[name] = {
            &quot;fn&quot;: fn,
            &quot;schema&quot;: {
                &quot;type&quot;: &quot;function&quot;,
                &quot;function&quot;: {
                    &quot;name&quot;: name,
                    &quot;description&quot;: description,
                    &quot;parameters&quot;: parameters,
                },
            },
        }
        return fn
    return decorator


@register_tool(
    name=&quot;get_weather&quot;,
    description=&quot;获取指定城市的当前天气&quot;,
    parameters={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;city&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;城市名称&quot;},
        },
        &quot;required&quot;: [&quot;city&quot;],
    },
)
def get_weather(city: str) -&gt; str:
    # 示例实现，实际中调用真实 API
    return json.dumps({&quot;city&quot;: city, &quot;temp&quot;: 28, &quot;condition&quot;: &quot;晴&quot;})


# ── Agent Control Loop ───────────────────────────────

class Agent:
    def __init__(
        self,
        system_prompt: str,
        model: str = &quot;gpt-4o&quot;,
        max_turns: int = 15,
        token_budget: int = 50_000,
        max_consecutive_errors: int = 3,
    ):
        self.client = OpenAI()
        self.model = model
        self.system_prompt = system_prompt
        self.max_turns = max_turns
        self.token_budget = token_budget
        self.max_errors = max_consecutive_errors
        self.tool_schemas = [t[&quot;schema&quot;] for t in TOOL_FUNCTIONS.values()]

    def run(self, user_input: str) -&gt; str:
        ctx = LoopContext()
        ctx.messages = [
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: self.system_prompt},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input},
        ]
        state = State.THINK  # 首轮输入已就绪，直接进入 THINK

        while state not in (State.DONE, State.ERROR):
            match state:
                case State.THINK:
                    state, ctx = self._think(ctx)
                case State.ACT:
                    state, ctx = self._act(ctx)
                case State.REFLECT:
                    state, ctx = self._reflect(ctx)
            ctx.turn += 1

        # 提取最终回答
        for msg in reversed(ctx.messages):
            if msg[&quot;role&quot;] == &quot;assistant&quot; and msg.get(&quot;content&quot;):
                return msg[&quot;content&quot;]
        return &quot;[Agent finished without a final answer]&quot;

    def _think(self, ctx: LoopContext) -&gt; tuple[State, LoopContext]:
        &quot;&quot;&quot;调用 LLM 推理&quot;&quot;&quot;
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=ctx.messages,
                tools=self.tool_schemas or None,
            )
        except Exception as e:
            ctx.consecutive_errors += 1
            ctx.messages.append({
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;content&quot;: f&quot;[LLM Error] {e}&quot;,
            })
            if ctx.consecutive_errors &gt;= self.max_errors:
                return State.ERROR, ctx
            return State.THINK, ctx  # 重试

        # 记录 token 消耗
        usage = response.usage
        ctx.total_tokens += (usage.prompt_tokens + usage.completion_tokens)
        ctx.consecutive_errors = 0

        choice = response.choices[0]
        assistant_msg = choice.message.model_dump()
        ctx.messages.append(assistant_msg)

        # 决定下一状态
        if choice.message.tool_calls:
            return State.ACT, ctx
        else:
            return State.DONE, ctx

    def _act(self, ctx: LoopContext) -&gt; tuple[State, LoopContext]:
        &quot;&quot;&quot;执行工具调用&quot;&quot;&quot;
        assistant_msg = ctx.messages[-1]
        tool_calls = assistant_msg.get(&quot;tool_calls&quot;, [])

        for tc in tool_calls:
            fn_name = tc[&quot;function&quot;][&quot;name&quot;]
            fn_args = json.loads(tc[&quot;function&quot;][&quot;arguments&quot;])

            tool_entry = TOOL_FUNCTIONS.get(fn_name)
            if not tool_entry:
                result = f&quot;Error: unknown tool &#39;{fn_name}&#39;&quot;
            else:
                try:
                    result = tool_entry[&quot;fn&quot;](**fn_args)
                except Exception as e:
                    result = f&quot;Error: tool &#39;{fn_name}&#39; raised {type(e).__name__}: {e}&quot;
                    ctx.consecutive_errors += 1

            ctx.messages.append({
                &quot;role&quot;: &quot;tool&quot;,
                &quot;tool_call_id&quot;: tc[&quot;id&quot;],
                &quot;content&quot;: str(result),
            })

        return State.REFLECT, ctx

    def _reflect(self, ctx: LoopContext) -&gt; tuple[State, LoopContext]:
        &quot;&quot;&quot;反思：检查终止条件&quot;&quot;&quot;
        # 最大轮次
        if ctx.turn &gt;= self.max_turns:
            ctx.messages.append({
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;content&quot;: &quot;[Agent stopped: max turns exceeded]&quot;,
            })
            return State.ERROR, ctx

        # Token 预算
        if ctx.total_tokens &gt;= self.token_budget:
            ctx.messages.append({
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;content&quot;: &quot;[Agent stopped: token budget exceeded]&quot;,
            })
            return State.ERROR, ctx

        # 连续错误
        if ctx.consecutive_errors &gt;= self.max_errors:
            return State.ERROR, ctx

        # 死循环检测：最近 3 次输出相同
        tool_results = [
            m[&quot;content&quot;] for m in ctx.messages[-6:]
            if m.get(&quot;role&quot;) == &quot;tool&quot;
        ]
        if len(tool_results) &gt;= 3 and len(set(tool_results[-3:])) == 1:
            ctx.messages.append({
                &quot;role&quot;: &quot;assistant&quot;,
                &quot;content&quot;: &quot;[Agent stopped: loop detected]&quot;,
            })
            return State.ERROR, ctx

        # 继续下一轮推理
        return State.THINK, ctx


# ── 使用示例 ─────────────────────────────────────────

if __name__ == &quot;__main__&quot;:
    agent = Agent(
        system_prompt=&quot;你是一个天气助手。使用 get_weather 工具回答天气问题。&quot;,
        max_turns=10,
    )
    answer = agent.run(&quot;北京今天天气怎么样？&quot;)
    print(answer)
</code></pre>
<p>这段代码约 130 行，涵盖了 Control Loop 的所有核心要素：</p>
<ul>
<li>状态机驱动的循环控制</li>
<li>工具注册与动态调用</li>
<li>LLM 异常重试</li>
<li>Token 消耗追踪</li>
<li>多种终止条件（max_turns / token_budget / consecutive_errors / loop_detected）</li>
<li>工具执行错误处理</li>
</ul>
<p>它不是生产级代码，但足以说明 Control Loop 的核心机制。在此基础上增加异步执行、状态持久化、日志追踪，就能逐步演进为生产级实现。</p>
<hr>
<h2>7. 错误处理策略</h2>
<p>生产环境中，Agent Control Loop 最常遇到的四类错误：</p>
<h3>7.1 Tool 调用失败</h3>
<p>工具调用失败是最高频的错误。正确的处理方式不是抛异常终止，而是<strong>将错误信息作为 Observation 返回给 LLM</strong>，让它决定如何应对。</p>
<pre><code class="language-python"># 错误的做法：直接终止
try:
    result = call_tool(name, args)
except Exception:
    raise  # Agent 直接崩溃

# 正确的做法：将错误反馈给 LLM
try:
    result = call_tool(name, args)
except TimeoutError:
    result = &quot;Tool timed out after 30s. Consider using different parameters.&quot;
except ValueError as e:
    result = f&quot;Invalid arguments: {e}. Please check parameter types.&quot;
except Exception as e:
    result = f&quot;Tool failed: {type(e).__name__}: {e}&quot;
</code></pre>
<p>LLM 在收到错误信息后，通常能自主修正——换一组参数重试、换一个工具、或者告知用户当前无法完成任务。</p>
<h3>7.2 LLM 返回格式异常</h3>
<p>LLM 偶尔会返回不符合预期的格式：JSON 不合法、tool_call 参数缺失、content 为空等。</p>
<pre><code class="language-python">def _parse_tool_call_safe(self, tool_call) -&gt; tuple[str, dict]:
    &quot;&quot;&quot;安全解析工具调用参数&quot;&quot;&quot;
    name = tool_call.function.name
    try:
        args = json.loads(tool_call.function.arguments)
    except json.JSONDecodeError:
        # LLM 返回了非法 JSON，尝试修复或跳过
        args = {}
        self.logger.warning(
            f&quot;Invalid JSON in tool_call arguments: &quot;
            f&quot;{tool_call.function.arguments}&quot;
        )
    return name, args
</code></pre>
<h3>7.3 超时处理</h3>
<p>整个 Agent 执行需要有全局超时，防止无限挂起：</p>
<pre><code class="language-python">import signal

class TimeoutError(Exception):
    pass

def run_with_timeout(fn, timeout_seconds: int, *args, **kwargs):
    &quot;&quot;&quot;为函数执行添加超时限制&quot;&quot;&quot;
    def handler(signum, frame):
        raise TimeoutError(f&quot;Execution timed out after {timeout_seconds}s&quot;)

    old_handler = signal.signal(signal.SIGALRM, handler)
    signal.alarm(timeout_seconds)
    try:
        return fn(*args, **kwargs)
    finally:
        signal.alarm(0)
        signal.signal(signal.SIGALRM, old_handler)
</code></pre>
<h3>7.4 死循环检测</h3>
<p>当 Agent 陷入死循环时，它会反复执行相同的操作序列。检测策略：</p>
<pre><code class="language-python">def _detect_loop(self, messages: list[dict], window: int = 6) -&gt; bool:
    &quot;&quot;&quot;检测 Agent 是否陷入重复循环&quot;&quot;&quot;
    recent = messages[-window:]

    # 策略 1：完全重复检测
    contents = [m.get(&quot;content&quot;, &quot;&quot;) for m in recent if m[&quot;role&quot;] == &quot;assistant&quot;]
    if len(contents) &gt;= 3 and len(set(contents[-3:])) == 1:
        return True

    # 策略 2：工具调用序列重复检测
    tool_calls = []
    for m in recent:
        if m.get(&quot;tool_calls&quot;):
            for tc in m[&quot;tool_calls&quot;]:
                tool_calls.append(f&quot;{tc[&#39;function&#39;][&#39;name&#39;]}:{tc[&#39;function&#39;][&#39;arguments&#39;]}&quot;)

    if len(tool_calls) &gt;= 4:
        half = len(tool_calls) // 2
        if tool_calls[:half] == tool_calls[half:2*half]:
            return True

    return False
</code></pre>
<hr>
<h2>8. 性能考量</h2>
<h3>8.1 Token 消耗与循环次数的关系</h3>
<p>Agent Control Loop 的 Token 消耗不是线性增长，而是<strong>二次增长</strong>——因为每一轮都要携带之前所有轮次的 message history。</p>
<pre><code>轮次    新增消息 Token    累计 Context Token    本轮总消耗
1       T               S + T                S + T
2       T               S + 2T               S + 2T
3       T               S + 3T               S + 3T
...
N       T               S + NT               S + NT

总消耗 = N*S + T*(1+2+...+N) = N*S + T*N*(N+1)/2

其中 S = System Prompt Token 数，T = 平均每轮消息 Token 数
</code></pre>
<p>这意味着 <strong>10 轮的 Agent 消耗的 Token 不是 1 轮的 10 倍，而可能是 55 倍</strong>。这对成本控制至关重要。</p>
<h3>8.2 Context Window 膨胀问题</h3>
<p>随着轮次增加，Context Window 持续膨胀，导致：</p>
<ol>
<li><strong>延迟增加</strong>：LLM 推理时间与输入 Token 数正相关</li>
<li><strong>成本增加</strong>：按 Token 计费，输入越长越贵</li>
<li><strong>质量下降</strong>：过长的 Context 会导致 LLM &quot;注意力分散&quot;，关键信息被淹没（lost in the middle 问题）</li>
</ol>
<h3>8.3 消息压缩/摘要策略</h3>
<p>应对 Context Window 膨胀的核心策略：</p>
<p><strong>策略一：滑动窗口</strong></p>
<p>只保留最近 K 轮对话，丢弃更早的历史。简单粗暴但有效。</p>
<pre><code class="language-python">def _sliding_window(self, messages: list[dict], keep_last: int = 10) -&gt; list[dict]:
    system_msgs = [m for m in messages if m[&quot;role&quot;] == &quot;system&quot;]
    non_system = [m for m in messages if m[&quot;role&quot;] != &quot;system&quot;]
    return system_msgs + non_system[-keep_last:]
</code></pre>
<p><strong>策略二：摘要压缩</strong></p>
<p>当 message history 超过阈值时，用 LLM 对早期对话生成摘要，替换原始消息。</p>
<pre><code class="language-python">def _compress_history(self, messages: list[dict], threshold: int = 20) -&gt; list[dict]:
    if len(messages) &lt;= threshold:
        return messages

    # 将早期消息压缩为摘要
    early = messages[1:-threshold]  # 跳过 system prompt，保留最近的
    summary_prompt = (
        &quot;请用 3-5 句话总结以下对话的关键信息和已完成的操作：\n&quot;
        + &quot;\n&quot;.join(m.get(&quot;content&quot;, &quot;&quot;) for m in early if m.get(&quot;content&quot;))
    )

    summary = self.client.chat.completions.create(
        model=&quot;gpt-4o-mini&quot;,  # 用小模型做摘要，节省成本
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: summary_prompt}],
    ).choices[0].message.content

    return (
        [messages[0]]  # system prompt
        + [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: f&quot;[Earlier conversation summary] {summary}&quot;}]
        + messages[-threshold:]
    )
</code></pre>
<p><strong>策略三：选择性保留</strong></p>
<p>不是所有消息都同等重要。工具的原始返回值（可能非常长）通常可以只保留摘要：</p>
<pre><code class="language-python">def _trim_tool_results(self, messages: list[dict], max_len: int = 500) -&gt; list[dict]:
    &quot;&quot;&quot;截断过长的工具返回值&quot;&quot;&quot;
    trimmed = []
    for m in messages:
        if m[&quot;role&quot;] == &quot;tool&quot; and len(m.get(&quot;content&quot;, &quot;&quot;)) &gt; max_len:
            m = {**m, &quot;content&quot;: m[&quot;content&quot;][:max_len] + &quot;\n...[truncated]&quot;}
        trimmed.append(m)
    return trimmed
</code></pre>
<p><strong>三种策略的对比：</strong></p>
<table>
<thead>
<tr>
<th>策略</th>
<th>信息保留</th>
<th>实现成本</th>
<th>Token 节省</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>滑动窗口</td>
<td>低</td>
<td>极低</td>
<td>高</td>
<td>短对话、工具调用为主</td>
</tr>
<tr>
<td>摘要压缩</td>
<td>中</td>
<td>中（需要额外 LLM 调用）</td>
<td>高</td>
<td>长对话、需要历史上下文</td>
</tr>
<tr>
<td>选择性保留</td>
<td>高</td>
<td>低</td>
<td>中</td>
<td>工具返回值较大的场景</td>
</tr>
</tbody></table>
<p>实际工程中，通常<strong>组合使用</strong>：先用选择性保留截断大结果，再用滑动窗口控制总长度，在关键节点用摘要压缩保留全局上下文。</p>
<hr>
<h2>9. 小结与进一步思考</h2>
<p>本文从状态机模型出发，完整地拆解了 Agent Control Loop 的核心抽象：</p>
<ul>
<li><strong>OBSERVE</strong> 负责输入归一化——将各种来源的信息统一为 LLM 可理解的 message 格式</li>
<li><strong>THINK</strong> 是核心推理阶段——管理 Context Window、控制 Token 预算、解析 LLM 输出</li>
<li><strong>ACT</strong> 是执行层——处理工具调用的同步/异步执行、超时控制、安全隔离</li>
<li><strong>REFLECT</strong> 负责质量评估——决定是继续、重试还是终止</li>
<li><strong>终止条件</strong>是成本和安全的兜底——max_turns、token_budget、error_threshold、loop_detection</li>
</ul>
<p>我们对比了 ReAct 和 Plan-then-Execute 两种主流模式，分析了 Stateless 与 Stateful 两种状态管理策略，并实现了一个不依赖任何框架的完整 Control Loop。</p>
<p>但控制循环只是 Agent 运行时的骨架。它的灵魂在于 <strong>Tool Calling</strong>——正是工具让 Agent 从&quot;能说会道的语言模型&quot;变成&quot;能做事的智能体&quot;。</p>
<p>在下一篇 <strong>《Tool Calling Deep Dive: 让 LLM 成为可编程接口》</strong> 中，我们会深入工具调用的设计哲学：JSON Schema 作为契约、Tool Registry 的实现、参数校验、错误传播，以及 Structured Output 为什么优于自由文本。</p>
<p>留几个值得进一步思考的问题：</p>
<ol>
<li><strong>Control Loop 的嵌套</strong>：当一个 Agent 的工具是另一个 Agent 时，控制循环如何嵌套？外层循环和内层循环的终止条件如何协调？</li>
<li><strong>人机协作中的循环</strong>：如何在 Control Loop 中优雅地插入人类审批节点？这和 Stateful Agent 的 checkpoint 机制有什么关系？</li>
<li><strong>流式输出与控制循环</strong>：当 Agent 需要边思考边输出（streaming）时，状态机模型还适用吗？需要做哪些调整？</li>
<li><strong>多模态输入的归一化</strong>：当 OBSERVE 阶段接收的不只是文本，还有图片、音频、视频时，输入归一化策略如何演化？</li>
</ol>
<hr>
<blockquote>
<p><strong>系列导航</strong>：本文是 Agentic 系列的第 04 篇。</p>
<ul>
<li>上一篇：<a href="/blog/engineering/agentic/03-Agent%20vs%20Workflow%20vs%20Automation">03 | Agent vs Workflow vs Automation</a></li>
<li>下一篇：<a href="/blog/engineering/agentic/05-Tool%20Calling%20Deep%20Dive">05 | Tool Calling Deep Dive</a></li>
<li>完整目录：<a href="/blog/engineering/agentic/01-From%20LLM%20to%20Agent">01 | From LLM to Agent</a></li>
</ul>
</blockquote>
</div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="mt-12 pt-8 border-t border-gray-200">加载导航中...</div><!--/$--><div class="mt-16 border-t border-gray-200 pt-8"><div class="mx-auto max-w-3xl"><h3 class="text-2xl font-bold text-gray-900 mb-8">评论</h3></div></div></div></div></article><!--$--><!--/$--></main><footer class="bg-[var(--background)]"><div class="mx-auto max-w-7xl px-6 py-12 lg:px-8"><p class="text-center text-xs leading-5 text-gray-400">© <!-- -->2026<!-- --> Skyfalling</p></div></footer></div><script src="/_next/static/chunks/webpack-42d55485b4428e47.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[10616,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"7177\",\"static/chunks/app/layout-142e67ac4336647c.js\"],\"default\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n6:I[59665,[],\"OutletBoundary\"]\n9:I[74911,[],\"AsyncMetadataOutlet\"]\nb:I[59665,[],\"ViewportBoundary\"]\nd:I[59665,[],\"MetadataBoundary\"]\nf:I[26614,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/7dd6b3ec14b0b1d8.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"kLuGQpYNrv7rzQ0jpQCVp\",\"p\":\"\",\"c\":[\"\",\"blog\",\"engineering\",\"agentic\",\"04-The%20Agent%20Control%20Loop\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"engineering/agentic/04-The%20Agent%20Control%20Loop\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7dd6b3ec14b0b1d8.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-[var(--background)]\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-6 py-12 lg:px-8\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs leading-5 text-gray-400\",\"children\":[\"© \",2026,\" Skyfalling\"]}]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"engineering/agentic/04-The%20Agent%20Control%20Loop\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",null,[\"$\",\"$L6\",null,{\"children\":[\"$L7\",\"$L8\",[\"$\",\"$L9\",null,{\"promise\":\"$@a\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"-GADM6C9B-FMqZqGFsDFiv\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:\"$Sreact.suspense\"\n11:I[74911,[],\"AsyncMetadata\"]\n13:I[6874,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"\"]\n14:I[32923,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n16:I[40780,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n1c:I[85300,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\ne:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]}]}]\n15:Tc7d3,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eThe Agent Control Loop: Agent 运行时的核心抽象\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如果说 LLM 是 Agent 的大脑，那么 Control Loop 就是 Agent 的心跳。\u003c/p\u003e\n\u003cp\u003e大多数教程在讲 Agent 时，上来就接框架、调 API、跑 demo。但如果你不理解 Agent 运行时的核心抽象——控制循环——你永远只是在用别人的黑盒。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 04 篇，整个系列的技术基石。我们会从状态机模型出发，逐层拆解 Agent Control Loop 的每一个阶段，给出完整的 Python 实现，并深入分析实际工程中的 trade-off。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. Agent 的本质：可中断的控制循环\u003c/h2\u003e\n\u003cp\u003e一个常见的误解是把 Agent 等同于\u0026quot;一次 LLM 调用\u0026quot;。实际上，Agent 和 LLM 的关系，类似于操作系统和 CPU 的关系——LLM 是执行推理的计算单元，而 Agent 是管理整个执行生命周期的运行时系统。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLLM 是一个函数：\u003c/strong\u003e \u003ccode\u003ef(prompt) -\u0026gt; completion\u003c/code\u003e，输入文本，输出文本，调用一次就结束。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAgent 是一个循环：\u003c/strong\u003e 它持续运行，在每一轮中观察环境、调用 LLM 进行推理、执行动作、评估结果，然后决定是否继续。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eLLM:    Input ──→ Output            (一次调用)\n\nAgent:  Input ──→ [Observe → Think → Act → Reflect] ──→ ... ──→ Output\n                  └──────── 循环 N 次 ────────────┘     (多轮控制)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这个循环有几个关键特性：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可中断\u003c/strong\u003e：循环可以在任何阶段暂停，等待外部输入（用户确认、异步工具返回）后恢复\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有状态\u003c/strong\u003e：循环维护上下文信息，每一轮的输出影响下一轮的输入\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有终止条件\u003c/strong\u003e：循环不会无限运行，它在满足特定条件时停止\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可观测\u003c/strong\u003e：循环的每一步都应该是可追踪、可回溯的\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e理解了这一点，Agent 编程的核心问题就变成了：\u003cstrong\u003e如何设计和实现这个控制循环？\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 状态机模型：形式化定义\u003c/h2\u003e\n\u003cp\u003e要严谨地描述 Control Loop，最自然的方式是用\u003cstrong\u003e有限状态机（FSM）\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e2.1 状态定义\u003c/h3\u003e\n\u003cp\u003e一个 Agent Control Loop 可以用以下状态集合描述：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom enum import Enum\n\nclass AgentState(Enum):\n    OBSERVE  = \u0026quot;observe\u0026quot;   # 接收并归一化输入\n    THINK    = \u0026quot;think\u0026quot;     # LLM 推理，决定下一步行动\n    ACT      = \u0026quot;act\u0026quot;       # 执行工具调用或产出结果\n    REFLECT  = \u0026quot;reflect\u0026quot;   # 评估执行结果，决定是否继续\n    DONE     = \u0026quot;done\u0026quot;      # 终止：任务完成\n    ERROR    = \u0026quot;error\u0026quot;     # 终止：不可恢复错误\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.2 状态转移图\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌─────────────────────────────────────────┐\n                    │                                         │\n                    ▼                                         │\n              ┌──────────┐                                    │\n   Input ───→│ OBSERVE  │                                    │\n              └────┬─────┘                                    │\n                   │                                         │\n                   ▼                                         │\n              ┌──────────┐    need_action    ┌──────────┐    │\n              │  THINK   │ ───────────────→ │   ACT    │    │\n              └────┬─────┘                   └────┬─────┘    │\n                   │                              │          │\n                   │ has_answer                   │          │\n                   │                              ▼          │\n                   │                        ┌──────────┐     │\n                   │                        │ REFLECT  │ ────┘\n                   │                        └────┬─────┘  continue\n                   │                             │\n                   ▼                             ▼\n              ┌──────────┐                  ┌──────────┐\n              │   DONE   │                  │  ERROR   │\n              └──────────┘                  └──────────┘\n                                       (max_retries exceeded\n                                        / unrecoverable)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e状态转移规则：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e当前状态\u003c/th\u003e\n\u003cth\u003e条件\u003c/th\u003e\n\u003cth\u003e下一状态\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eOBSERVE\u003c/td\u003e\n\u003ctd\u003e输入就绪\u003c/td\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003ctd\u003eLLM 返回 tool_call\u003c/td\u003e\n\u003ctd\u003eACT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003ctd\u003eLLM 返回最终回答\u003c/td\u003e\n\u003ctd\u003eDONE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003ctd\u003eLLM 调用异常\u003c/td\u003e\n\u003ctd\u003eERROR\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eACT\u003c/td\u003e\n\u003ctd\u003e工具执行完成\u003c/td\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eACT\u003c/td\u003e\n\u003ctd\u003e工具执行失败\u003c/td\u003e\n\u003ctd\u003eREFLECT (带错误信息)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003ctd\u003e需要继续\u003c/td\u003e\n\u003ctd\u003eOBSERVE (将结果作为新输入)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003ctd\u003e任务完成\u003c/td\u003e\n\u003ctd\u003eDONE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003ctd\u003e超过重试上限\u003c/td\u003e\n\u003ctd\u003eERROR\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e2.3 与 OODA Loop 的对比\u003c/h3\u003e\n\u003cp\u003eAgent Control Loop 并不是凭空发明的，它和军事决策理论中的 \u003cstrong\u003eOODA Loop（Observe-Orient-Decide-Act）\u003c/strong\u003e 有深层的结构对应：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eOODA Loop:          Agent Control Loop:\n┌─────────┐         ┌─────────┐\n│ Observe │ ──────→ │ OBSERVE │  感知环境\n├─────────┤         ├─────────┤\n│ Orient  │ ──────→ │ THINK   │  理解上下文，形成判断\n├─────────┤         │         │\n│ Decide  │ ──────→ │         │  (LLM 在 THINK 中同时完成 Orient+Decide)\n├─────────┤         ├─────────┤\n│  Act    │ ──────→ │  ACT    │  执行行动\n└─────────┘         ├─────────┤\n                    │ REFLECT │  OODA 中没有显式的反思阶段\n                    └─────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键区别在于 \u003cstrong\u003eREFLECT 阶段\u003c/strong\u003e。传统 OODA Loop 假设决策者能实时感知行动效果并自然融入下一轮 Observe。但 LLM Agent 不具备这种连续感知能力——它需要一个显式的反思步骤来评估工具返回值、判断是否需要修正。这是 Agent Control Loop 相对于经典决策循环的重要改进。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. 循环中每个阶段的深入分析\u003c/h2\u003e\n\u003ch3\u003e3.1 OBSERVE：输入归一化\u003c/h3\u003e\n\u003cp\u003eOBSERVE 阶段的职责是\u003cstrong\u003e收集并归一化各种来源的输入\u003c/strong\u003e，将它们统一为 LLM 可理解的格式。\u003c/p\u003e\n\u003cp\u003e输入来源远不止\u0026quot;用户消息\u0026quot;一种：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e输入来源                    归一化后\n┌─────────────────┐       ┌──────────────────────┐\n│ 用户消息         │ ────→ │ {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,     │\n│ 工具返回值       │ ────→ │  \u0026quot;content\u0026quot;: \u0026quot;...\u0026quot;}   │\n│ 系统事件         │ ────→ │                      │\n│ 定时触发         │ ────→ │ {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,   │\n│ 外部 Webhook    │ ────→ │  \u0026quot;content\u0026quot;: \u0026quot;...\u0026quot;}   │\n│ 上一轮反思结果   │ ────→ │                      │\n└─────────────────┘       └──────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e输入归一化的核心原则：\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e所有输入都必须序列化为 message 格式\u003c/strong\u003e。不管来源是什么，最终都要变成 \u003ccode\u003e{\u0026quot;role\u0026quot;: ..., \u0026quot;content\u0026quot;: ...}\u003c/code\u003e 的形式，因为 LLM 只理解 message 序列。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e工具返回值需要结构化包装\u003c/strong\u003e。不要直接把原始 JSON 甩给 LLM，要附上工具名称、执行状态和必要的摘要信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e输入需要截断和优先级排序\u003c/strong\u003e。当多个输入同时到达时，需要决定哪些放进当前轮次的 Context Window，哪些缓存到下一轮。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef observe(self, raw_inputs: list[dict]) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;将原始输入归一化为 LLM message 格式\u0026quot;\u0026quot;\u0026quot;\n    messages = []\n    for inp in raw_inputs:\n        match inp[\u0026quot;type\u0026quot;]:\n            case \u0026quot;user_message\u0026quot;:\n                messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: inp[\u0026quot;text\u0026quot;]})\n            case \u0026quot;tool_result\u0026quot;:\n                messages.append({\n                    \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                    \u0026quot;tool_call_id\u0026quot;: inp[\u0026quot;call_id\u0026quot;],\n                    \u0026quot;content\u0026quot;: self._format_tool_result(inp),\n                })\n            case \u0026quot;system_event\u0026quot;:\n                messages.append({\n                    \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                    \u0026quot;content\u0026quot;: f\u0026quot;[System Event] {inp[\u0026#39;event\u0026#39;]}\u0026quot;,\n                })\n    return messages\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.2 THINK：LLM 推理\u003c/h3\u003e\n\u003cp\u003eTHINK 阶段是控制循环中最核心的一环——调用 LLM，让它基于当前上下文做出决策。\u003c/p\u003e\n\u003cp\u003e这个阶段要解决三个问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题一：Context Window 构建\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLLM 的输入不是当前轮次的消息，而是\u003cstrong\u003e从任务开始到现在的完整上下文\u003c/strong\u003e。构建 Context Window 的典型结构：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────┐\n│ System Prompt                               │  固定不变\n│ (角色定义 + 能力边界 + 输出格式要求)           │\n├─────────────────────────────────────────────┤\n│ Tool Definitions                            │  固定不变\n│ (可用工具的 JSON Schema 定义)                │\n├─────────────────────────────────────────────┤\n│ Message History                             │  随轮次增长\n│ (user → assistant → tool → assistant → ...) │\n├─────────────────────────────────────────────┤\n│ Current Turn Input                          │  当前轮次\n│ (本轮 OBSERVE 阶段归一化的输入)              │\n└─────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e问题二：Token 预算控制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eContext Window 有上限（4K / 8K / 128K / 200K），而每一轮循环都会增加 message history。如果不加控制，几轮之后就会超限。\u003c/p\u003e\n\u003cp\u003e常见的预算控制策略：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e实现方式\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e硬截断\u003c/td\u003e\n\u003ctd\u003e只保留最近 N 条消息\u003c/td\u003e\n\u003ctd\u003e简单场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e滑动窗口\u003c/td\u003e\n\u003ctd\u003eSystem Prompt 固定 + 最近 K 轮对话\u003c/td\u003e\n\u003ctd\u003e工具调用场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e摘要压缩\u003c/td\u003e\n\u003ctd\u003e将早期对话用 LLM 生成摘要后替换\u003c/td\u003e\n\u003ctd\u003e长对话场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e优先级保留\u003c/td\u003e\n\u003ctd\u003e按消息重要性排序，低优先级先丢弃\u003c/td\u003e\n\u003ctd\u003e复杂多步任务\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _build_context(self, new_messages: list[dict]) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;构建符合 Token 预算的 Context Window\u0026quot;\u0026quot;\u0026quot;\n    self.message_history.extend(new_messages)\n\n    context = [self.system_prompt] + self.tool_definitions\n    remaining_budget = self.max_tokens - self._count_tokens(context)\n\n    # 从最新消息开始向前填充，直到预算耗尽\n    selected = []\n    for msg in reversed(self.message_history):\n        msg_tokens = self._count_tokens([msg])\n        if msg_tokens \u0026gt; remaining_budget:\n            break\n        selected.insert(0, msg)\n        remaining_budget -= msg_tokens\n\n    return context + selected\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e问题三：LLM 输出解析\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLLM 的返回可能是纯文本回答（任务完成），也可能是工具调用请求。需要根据返回类型决定下一步状态转移：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef think(self, context: list[dict]) -\u0026gt; ThinkResult:\n    \u0026quot;\u0026quot;\u0026quot;调用 LLM 进行推理\u0026quot;\u0026quot;\u0026quot;\n    response = self.client.chat.completions.create(\n        model=self.model,\n        messages=context,\n        tools=self.tool_schemas,\n    )\n    choice = response.choices[0]\n\n    if choice.finish_reason == \u0026quot;tool_calls\u0026quot;:\n        return ThinkResult(\n            action=\u0026quot;tool_call\u0026quot;,\n            tool_calls=choice.message.tool_calls,\n            raw_message=choice.message,\n        )\n    else:\n        return ThinkResult(\n            action=\u0026quot;answer\u0026quot;,\n            content=choice.message.content,\n            raw_message=choice.message,\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.3 ACT：执行层\u003c/h3\u003e\n\u003cp\u003eACT 阶段负责\u003cstrong\u003e执行 THINK 阶段决定的动作\u003c/strong\u003e——通常是调用工具（Tool Calling）。\u003c/p\u003e\n\u003cp\u003e执行层的核心挑战不是\u0026quot;调用工具\u0026quot;本身，而是以下几个工程问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e同步 vs 异步执行\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e同步执行（Simple）：\n  think → call_tool_1 → wait → call_tool_2 → wait → reflect\n  延迟 = T1 + T2\n\n异步 / 并行执行（Optimized）：\n  think → call_tool_1 ─┬─→ reflect\n        → call_tool_2 ─┘\n  延迟 = max(T1, T2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e当 LLM 在一次返回中请求多个工具调用（parallel tool calling）时，应该并行执行以降低延迟：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport asyncio\n\nasync def act(self, tool_calls: list[ToolCall]) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;并行执行多个工具调用\u0026quot;\u0026quot;\u0026quot;\n    tasks = [self._execute_tool(tc) for tc in tool_calls]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    tool_results = []\n    for tc, result in zip(tool_calls, results):\n        if isinstance(result, Exception):\n            tool_results.append({\n                \u0026quot;type\u0026quot;: \u0026quot;tool_result\u0026quot;,\n                \u0026quot;call_id\u0026quot;: tc.id,\n                \u0026quot;status\u0026quot;: \u0026quot;error\u0026quot;,\n                \u0026quot;content\u0026quot;: f\u0026quot;Tool \u0026#39;{tc.function.name}\u0026#39; failed: {result}\u0026quot;,\n            })\n        else:\n            tool_results.append({\n                \u0026quot;type\u0026quot;: \u0026quot;tool_result\u0026quot;,\n                \u0026quot;call_id\u0026quot;: tc.id,\n                \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;,\n                \u0026quot;content\u0026quot;: str(result),\n            })\n    return tool_results\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e执行安全\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e工具执行不是无条件信任的。需要考虑：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e超时控制\u003c/strong\u003e：每个工具调用必须有 timeout，防止阻塞整个循环\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e结果大小限制\u003c/strong\u003e：工具返回值可能非常大（比如查数据库返回 10 万行），需要截断\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e权限校验\u003c/strong\u003e：某些工具（文件写入、网络请求、代码执行）需要额外的权限检查\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e沙箱执行\u003c/strong\u003e：代码执行类工具应该在沙箱中运行\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.4 REFLECT：输出质量评估\u003c/h3\u003e\n\u003cp\u003eREFLECT 阶段回答一个关键问题：\u003cstrong\u003e上一步的执行结果是否满意？是继续、重试还是停止？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这个阶段有两种实现方式：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方式一：隐式反思——让 LLM 在下一轮 THINK 中自行判断\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是最简单的方式。把工具返回值直接送进下一轮 THINK，让 LLM 自己决定是否需要修正。大多数框架（如 OpenAI Assistants API）默认采用这种方式。\u003c/p\u003e\n\u003cp\u003e优点：实现简单，不增加额外的 LLM 调用。\u003c/p\u003e\n\u003cp\u003e缺点：LLM 可能\u0026quot;自信地\u0026quot;忽略错误，特别是在返回值看起来合理但语义错误的情况下。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方式二：显式反思——用独立的 LLM 调用进行自我评估\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef reflect(self, action_result: dict, task_goal: str) -\u0026gt; ReflectResult:\n    \u0026quot;\u0026quot;\u0026quot;显式反思：评估执行结果\u0026quot;\u0026quot;\u0026quot;\n    prompt = f\u0026quot;\u0026quot;\u0026quot;评估以下工具执行结果是否达成了任务目标。\n\n任务目标: {task_goal}\n执行结果: {json.dumps(action_result, ensure_ascii=False)}\n\n请回答：\n1. 结果是否正确？(yes/no)\n2. 是否需要进一步行动？(yes/no)\n3. 如果需要，下一步应该做什么？\n\u0026quot;\u0026quot;\u0026quot;\n    response = self.client.chat.completions.create(\n        model=self.model,\n        messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: prompt}],\n    )\n    # 解析反思结果...\n    return ReflectResult(\n        is_correct=...,\n        needs_more_action=...,\n        next_step_hint=...,\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off 分析：\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e隐式反思\u003c/th\u003e\n\u003cth\u003e显式反思\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eToken 消耗\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e高（额外一次 LLM 调用）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e质量把控\u003c/td\u003e\n\u003ctd\u003e依赖 LLM 自觉\u003c/td\u003e\n\u003ctd\u003e有独立的质量评估\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e延迟\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e增加一轮 LLM 延迟\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用场景\u003c/td\u003e\n\u003ctd\u003e简单工具调用\u003c/td\u003e\n\u003ctd\u003e复杂推理链、高准确性要求\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e实际工程中，常用的折中方案是：\u003cstrong\u003e对关键步骤用显式反思，对常规步骤用隐式反思\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e3.5 终止条件：什么时候停下来？\u003c/h3\u003e\n\u003cp\u003e一个 Agent 如果不知道什么时候停，就是一个烧钱的死循环。终止条件的设计是 Control Loop 中最容易被忽视、但对生产环境最重要的部分。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef should_stop(self, state: LoopState) -\u0026gt; tuple[bool, str]:\n    \u0026quot;\u0026quot;\u0026quot;判断是否应该终止循环\u0026quot;\u0026quot;\u0026quot;\n    # 1. LLM 认为任务完成\n    if state.last_think_result.action == \u0026quot;answer\u0026quot;:\n        return True, \u0026quot;task_completed\u0026quot;\n\n    # 2. 达到最大轮次\n    if state.turn_count \u0026gt;= self.max_turns:\n        return True, \u0026quot;max_turns_exceeded\u0026quot;\n\n    # 3. Token 预算耗尽\n    if state.total_tokens \u0026gt;= self.token_budget:\n        return True, \u0026quot;token_budget_exceeded\u0026quot;\n\n    # 4. 连续错误过多\n    if state.consecutive_errors \u0026gt;= self.max_consecutive_errors:\n        return True, \u0026quot;too_many_errors\u0026quot;\n\n    # 5. 死循环检测（重复输出相同内容）\n    if self._detect_loop(state.recent_outputs):\n        return True, \u0026quot;loop_detected\u0026quot;\n\n    return False, \u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e各终止条件的设计考量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003emax_turns\u003c/strong\u003e：硬上限，防止失控。一般设 10-30 轮。过小会导致复杂任务被截断，过大会导致 Token 浪费\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003etoken_budget\u003c/strong\u003e：成本控制。根据业务场景设定每次交互的 Token 上限\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003econsecutive_errors\u003c/strong\u003e：容错阈值。工具偶尔失败是正常的，但连续 3 次以上通常意味着系统性问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eloop_detected\u003c/strong\u003e：死循环检测。如果 Agent 连续 N 轮输出相同或高度相似的内容，说明它陷入了无效循环\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e4. 两种主流 Loop 模式对比\u003c/h2\u003e\n\u003ch3\u003e4.1 ReAct 模式\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eReAct（Reason + Act）\u003c/strong\u003e 是目前最主流的 Agent Loop 模式，由 Yao et al. 2022 提出。其核心思想是让 LLM 交替进行推理和行动：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────┐\n│                   ReAct Loop                         │\n│                                                      │\n│  ┌─────────┐    ┌─────────┐    ┌─────────────────┐  │\n│  │ Thought │ →  │ Action  │ →  │  Observation    │  │\n│  │(LLM推理)│    │(工具调用)│    │(工具返回值)      │  │\n│  └─────────┘    └─────────┘    └────────┬────────┘  │\n│       ▲                                  │          │\n│       └──────────────────────────────────┘          │\n│                  循环直到完成                         │\n└──────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e一个典型的 ReAct 执行轨迹（Trace）：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eThought: 用户想知道北京今天的天气。我需要调用天气 API。\nAction:  get_weather(city=\u0026quot;北京\u0026quot;)\nObservation: {\u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;, \u0026quot;humidity\u0026quot;: 45}\n\nThought: 已经获取到天气数据，我可以直接回答用户。\nAnswer:  北京今天晴天，气温 28°C，湿度 45%。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eReAct 的优势：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每一步都基于最新的观察结果做决策，\u003cstrong\u003e适应性强\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThought 过程可见，\u003cstrong\u003e可解释性好\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e实现简单，与 Tool Calling API 天然契合\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eReAct 的劣势：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e逐步决策，无法全局优化执行顺序\u003c/li\u003e\n\u003cli\u003e每一步都需要一次 LLM 调用，\u003cstrong\u003e延迟累积\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e对于需要协调多个子任务的复杂场景，容易陷入局部最优\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.2 Plan-then-Execute 模式\u003c/h3\u003e\n\u003cp\u003e与 ReAct 的\u0026quot;走一步看一步\u0026quot;不同，Plan-then-Execute 先生成一个\u003cstrong\u003e完整的执行计划\u003c/strong\u003e，然后按计划依次执行：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────────┐\n│              Plan-then-Execute Loop                       │\n│                                                          │\n│  ┌──────────────────────────────────────┐                │\n│  │           Planning Phase             │                │\n│  │  Input → LLM → [Step1, Step2, ...]   │                │\n│  └───────────────┬──────────────────────┘                │\n│                  │                                        │\n│                  ▼                                        │\n│  ┌──────────────────────────────────────┐                │\n│  │         Execution Phase              │                │\n│  │  Step1 → Execute → Result1           │                │\n│  │  Step2 → Execute → Result2           │                │\n│  │  ...                                 │                │\n│  └───────────────┬──────────────────────┘                │\n│                  │                                        │\n│                  ▼                                        │\n│  ┌──────────────────────────────────────┐                │\n│  │    Replan (if needed)                │                │\n│  │  检查是否需要调整计划                   │                │\n│  └──────────────────────────────────────┘                │\n└──────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e执行轨迹示例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePlan:\n  1. 查询北京天气\n  2. 查询上海天气\n  3. 对比两地天气差异\n  4. 生成出行建议\n\nExecute Step 1: get_weather(city=\u0026quot;北京\u0026quot;) → {\u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;}\nExecute Step 2: get_weather(city=\u0026quot;上海\u0026quot;) → {\u0026quot;temp\u0026quot;: 32, \u0026quot;condition\u0026quot;: \u0026quot;多云\u0026quot;}\nExecute Step 3: (LLM 对比分析)\nExecute Step 4: (LLM 生成建议)\n\nAnswer: ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.3 Trade-off 分析\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                        灵活性\n                          ▲\n                          │\n                 ReAct ●  │\n                          │\n                          │        ● Hybrid\n                          │          (ReAct + Plan)\n                          │\n              Plan-then   │\n              -Execute ●  │\n                          │\n                          └──────────────────→ 效率\n                                          (LLM 调用次数)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eReAct\u003c/th\u003e\n\u003cth\u003ePlan-then-Execute\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e灵活性\u003c/td\u003e\n\u003ctd\u003e高。每步实时调整\u003c/td\u003e\n\u003ctd\u003e低。偏离计划时需要 Replan\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLLM 调用次数\u003c/td\u003e\n\u003ctd\u003e多（每步一次推理）\u003c/td\u003e\n\u003ctd\u003e少（规划一次 + 执行时可能不需要 LLM）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可控性\u003c/td\u003e\n\u003ctd\u003e低。难以预测执行路径\u003c/td\u003e\n\u003ctd\u003e高。计划可审核、可修改\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适合场景\u003c/td\u003e\n\u003ctd\u003e工具调用为主、步骤不确定\u003c/td\u003e\n\u003ctd\u003e多步骤、有依赖关系、需要全局协调\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e错误恢复\u003c/td\u003e\n\u003ctd\u003e自然。下一步可以直接修正\u003c/td\u003e\n\u003ctd\u003e需要 Replan 机制\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e人类干预\u003c/td\u003e\n\u003ctd\u003e难以在中途插入\u003c/td\u003e\n\u003ctd\u003e容易。可以审核和修改计划\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e实际工程建议：\u003c/strong\u003e 大多数场景从 ReAct 开始。当你发现 Agent 频繁在多步任务中\u0026quot;迷路\u0026quot;或做出低效的工具调用序列时，再考虑引入 Plan-then-Execute 或混合模式。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 状态管理\u003c/h2\u003e\n\u003cp\u003eControl Loop 的状态管理决定了 Agent 的\u003cstrong\u003e持久性\u003c/strong\u003e和\u003cstrong\u003e可恢复性\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e5.1 Stateless Agent\u003c/h3\u003e\n\u003cp\u003eStateless Agent 不维护执行状态，所有上下文通过 \u003cstrong\u003emessage history\u003c/strong\u003e 传递。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eRequest 1:  [system, user_msg_1]                     → response_1\nRequest 2:  [system, user_msg_1, response_1, user_2] → response_2\nRequest 3:  [system, user_msg_1, response_1, user_2, response_2, user_3] → response_3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e特点：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e实现最简单，无需持久化\u003c/li\u003e\n\u003cli\u003e每次请求都是自包含的\u003c/li\u003e\n\u003cli\u003emessage history 不断膨胀，最终超过 Context Window\u003c/li\u003e\n\u003cli\u003e不支持暂停/恢复\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这是大多数 \u0026quot;chat completion\u0026quot; 应用的工作方式。适合单轮或短对话场景。\u003c/p\u003e\n\u003ch3\u003e5.2 Stateful Agent\u003c/h3\u003e\n\u003cp\u003eStateful Agent 维护一个独立的 \u003cstrong\u003eexecution state\u003c/strong\u003e，它不仅包含 message history，还包含任务进度、中间结果、工具状态等信息。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ExecutionState:\n    \u0026quot;\u0026quot;\u0026quot;Agent 执行状态\u0026quot;\u0026quot;\u0026quot;\n    session_id: str\n    status: AgentState\n    turn_count: int\n    message_history: list[dict]\n\n    # 任务状态\n    task_goal: str\n    current_plan: list[str] | None\n    completed_steps: list[str]\n\n    # 资源消耗\n    total_input_tokens: int\n    total_output_tokens: int\n\n    # 错误追踪\n    consecutive_errors: int\n    error_log: list[dict]\n\n    # 时间戳\n    created_at: float\n    updated_at: float\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.3 状态持久化方案\u003c/h3\u003e\n\u003cp\u003e当 Agent 需要支持暂停/恢复、跨进程执行、或长时间运行时，执行状态必须持久化。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────┐     ┌──────────────┐     ┌──────────────┐\n│   In-Memory  │     │    Redis     │     │   Database   │\n│  (dict/obj)  │     │  (KV Store)  │     │ (PostgreSQL) │\n├─────────────┤     ├──────────────┤     ├──────────────┤\n│ 最快         │     │ 快，支持 TTL  │     │ 持久可靠     │\n│ 进程重启丢失  │     │ 跨进程共享    │     │ 支持查询分析  │\n│ 单进程使用    │     │ 重启后可保留  │     │ 适合生产环境  │\n│ 适合开发/测试 │     │ 适合 session  │     │ 适合审计追溯  │\n└─────────────┘     └──────────────┘     └──────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eCheckpoint 与恢复\u003c/strong\u003e 是 Stateful Agent 的核心能力。思路很直接：在每轮循环的关键节点保存一次快照，异常恢复时从最近的快照重新开始。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass CheckpointManager:\n    def save(self, state: ExecutionState) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;保存 checkpoint，返回 checkpoint_id\u0026quot;\u0026quot;\u0026quot;\n        snapshot = {\n            \u0026quot;state\u0026quot;: asdict(state),\n            \u0026quot;timestamp\u0026quot;: time.time(),\n        }\n        checkpoint_id = f\u0026quot;{state.session_id}:{state.turn_count}\u0026quot;\n        self.store.set(checkpoint_id, json.dumps(snapshot))\n        return checkpoint_id\n\n    def restore(self, checkpoint_id: str) -\u0026gt; ExecutionState:\n        \u0026quot;\u0026quot;\u0026quot;从 checkpoint 恢复执行状态\u0026quot;\u0026quot;\u0026quot;\n        snapshot = json.loads(self.store.get(checkpoint_id))\n        return ExecutionState(**snapshot[\u0026quot;state\u0026quot;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实际系统中，checkpoint 的保存频率需要权衡：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e每轮都保存\u003c/strong\u003e：恢复粒度最细，但写入开销大\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e关键节点保存\u003c/strong\u003e（如每次工具调用前后）：开销适中，覆盖最重要的故障场景\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e定时保存\u003c/strong\u003e：实现简单，但可能丢失最近几轮的状态\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 完整代码实现\u003c/h2\u003e\n\u003cp\u003e下面是一个最小但完整的 Agent Control Loop 实现。不依赖任何框架，仅使用 Python 标准库 + OpenAI SDK。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u0026quot;\u0026quot;\u0026quot;\nMinimal Agent Control Loop\n不依赖任何框架，纯 Python + OpenAI SDK\n\u0026quot;\u0026quot;\u0026quot;\nimport json\nimport time\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom openai import OpenAI\n\n\nclass State(Enum):\n    OBSERVE = \u0026quot;observe\u0026quot;\n    THINK = \u0026quot;think\u0026quot;\n    ACT = \u0026quot;act\u0026quot;\n    REFLECT = \u0026quot;reflect\u0026quot;\n    DONE = \u0026quot;done\u0026quot;\n    ERROR = \u0026quot;error\u0026quot;\n\n\n@dataclass\nclass LoopContext:\n    messages: list[dict] = field(default_factory=list)\n    turn: int = 0\n    total_tokens: int = 0\n    consecutive_errors: int = 0\n    recent_outputs: list[str] = field(default_factory=list)\n\n\n# ── Tool Registry ────────────────────────────────────\n\nTOOL_FUNCTIONS = {}\n\ndef register_tool(name: str, description: str, parameters: dict):\n    \u0026quot;\u0026quot;\u0026quot;装饰器：注册工具函数及其 schema\u0026quot;\u0026quot;\u0026quot;\n    def decorator(fn):\n        TOOL_FUNCTIONS[name] = {\n            \u0026quot;fn\u0026quot;: fn,\n            \u0026quot;schema\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n                \u0026quot;function\u0026quot;: {\n                    \u0026quot;name\u0026quot;: name,\n                    \u0026quot;description\u0026quot;: description,\n                    \u0026quot;parameters\u0026quot;: parameters,\n                },\n            },\n        }\n        return fn\n    return decorator\n\n\n@register_tool(\n    name=\u0026quot;get_weather\u0026quot;,\n    description=\u0026quot;获取指定城市的当前天气\u0026quot;,\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;city\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;城市名称\u0026quot;},\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;],\n    },\n)\ndef get_weather(city: str) -\u0026gt; str:\n    # 示例实现，实际中调用真实 API\n    return json.dumps({\u0026quot;city\u0026quot;: city, \u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;})\n\n\n# ── Agent Control Loop ───────────────────────────────\n\nclass Agent:\n    def __init__(\n        self,\n        system_prompt: str,\n        model: str = \u0026quot;gpt-4o\u0026quot;,\n        max_turns: int = 15,\n        token_budget: int = 50_000,\n        max_consecutive_errors: int = 3,\n    ):\n        self.client = OpenAI()\n        self.model = model\n        self.system_prompt = system_prompt\n        self.max_turns = max_turns\n        self.token_budget = token_budget\n        self.max_errors = max_consecutive_errors\n        self.tool_schemas = [t[\u0026quot;schema\u0026quot;] for t in TOOL_FUNCTIONS.values()]\n\n    def run(self, user_input: str) -\u0026gt; str:\n        ctx = LoopContext()\n        ctx.messages = [\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self.system_prompt},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_input},\n        ]\n        state = State.THINK  # 首轮输入已就绪，直接进入 THINK\n\n        while state not in (State.DONE, State.ERROR):\n            match state:\n                case State.THINK:\n                    state, ctx = self._think(ctx)\n                case State.ACT:\n                    state, ctx = self._act(ctx)\n                case State.REFLECT:\n                    state, ctx = self._reflect(ctx)\n            ctx.turn += 1\n\n        # 提取最终回答\n        for msg in reversed(ctx.messages):\n            if msg[\u0026quot;role\u0026quot;] == \u0026quot;assistant\u0026quot; and msg.get(\u0026quot;content\u0026quot;):\n                return msg[\u0026quot;content\u0026quot;]\n        return \u0026quot;[Agent finished without a final answer]\u0026quot;\n\n    def _think(self, ctx: LoopContext) -\u0026gt; tuple[State, LoopContext]:\n        \u0026quot;\u0026quot;\u0026quot;调用 LLM 推理\u0026quot;\u0026quot;\u0026quot;\n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=ctx.messages,\n                tools=self.tool_schemas or None,\n            )\n        except Exception as e:\n            ctx.consecutive_errors += 1\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: f\u0026quot;[LLM Error] {e}\u0026quot;,\n            })\n            if ctx.consecutive_errors \u0026gt;= self.max_errors:\n                return State.ERROR, ctx\n            return State.THINK, ctx  # 重试\n\n        # 记录 token 消耗\n        usage = response.usage\n        ctx.total_tokens += (usage.prompt_tokens + usage.completion_tokens)\n        ctx.consecutive_errors = 0\n\n        choice = response.choices[0]\n        assistant_msg = choice.message.model_dump()\n        ctx.messages.append(assistant_msg)\n\n        # 决定下一状态\n        if choice.message.tool_calls:\n            return State.ACT, ctx\n        else:\n            return State.DONE, ctx\n\n    def _act(self, ctx: LoopContext) -\u0026gt; tuple[State, LoopContext]:\n        \u0026quot;\u0026quot;\u0026quot;执行工具调用\u0026quot;\u0026quot;\u0026quot;\n        assistant_msg = ctx.messages[-1]\n        tool_calls = assistant_msg.get(\u0026quot;tool_calls\u0026quot;, [])\n\n        for tc in tool_calls:\n            fn_name = tc[\u0026quot;function\u0026quot;][\u0026quot;name\u0026quot;]\n            fn_args = json.loads(tc[\u0026quot;function\u0026quot;][\u0026quot;arguments\u0026quot;])\n\n            tool_entry = TOOL_FUNCTIONS.get(fn_name)\n            if not tool_entry:\n                result = f\u0026quot;Error: unknown tool \u0026#39;{fn_name}\u0026#39;\u0026quot;\n            else:\n                try:\n                    result = tool_entry[\u0026quot;fn\u0026quot;](**fn_args)\n                except Exception as e:\n                    result = f\u0026quot;Error: tool \u0026#39;{fn_name}\u0026#39; raised {type(e).__name__}: {e}\u0026quot;\n                    ctx.consecutive_errors += 1\n\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;tool_call_id\u0026quot;: tc[\u0026quot;id\u0026quot;],\n                \u0026quot;content\u0026quot;: str(result),\n            })\n\n        return State.REFLECT, ctx\n\n    def _reflect(self, ctx: LoopContext) -\u0026gt; tuple[State, LoopContext]:\n        \u0026quot;\u0026quot;\u0026quot;反思：检查终止条件\u0026quot;\u0026quot;\u0026quot;\n        # 最大轮次\n        if ctx.turn \u0026gt;= self.max_turns:\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: \u0026quot;[Agent stopped: max turns exceeded]\u0026quot;,\n            })\n            return State.ERROR, ctx\n\n        # Token 预算\n        if ctx.total_tokens \u0026gt;= self.token_budget:\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: \u0026quot;[Agent stopped: token budget exceeded]\u0026quot;,\n            })\n            return State.ERROR, ctx\n\n        # 连续错误\n        if ctx.consecutive_errors \u0026gt;= self.max_errors:\n            return State.ERROR, ctx\n\n        # 死循环检测：最近 3 次输出相同\n        tool_results = [\n            m[\u0026quot;content\u0026quot;] for m in ctx.messages[-6:]\n            if m.get(\u0026quot;role\u0026quot;) == \u0026quot;tool\u0026quot;\n        ]\n        if len(tool_results) \u0026gt;= 3 and len(set(tool_results[-3:])) == 1:\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: \u0026quot;[Agent stopped: loop detected]\u0026quot;,\n            })\n            return State.ERROR, ctx\n\n        # 继续下一轮推理\n        return State.THINK, ctx\n\n\n# ── 使用示例 ─────────────────────────────────────────\n\nif __name__ == \u0026quot;__main__\u0026quot;:\n    agent = Agent(\n        system_prompt=\u0026quot;你是一个天气助手。使用 get_weather 工具回答天气问题。\u0026quot;,\n        max_turns=10,\n    )\n    answer = agent.run(\u0026quot;北京今天天气怎么样？\u0026quot;)\n    print(answer)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码约 130 行，涵盖了 Control Loop 的所有核心要素：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e状态机驱动的循环控制\u003c/li\u003e\n\u003cli\u003e工具注册与动态调用\u003c/li\u003e\n\u003cli\u003eLLM 异常重试\u003c/li\u003e\n\u003cli\u003eToken 消耗追踪\u003c/li\u003e\n\u003cli\u003e多种终止条件（max_turns / token_budget / consecutive_errors / loop_detected）\u003c/li\u003e\n\u003cli\u003e工具执行错误处理\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e它不是生产级代码，但足以说明 Control Loop 的核心机制。在此基础上增加异步执行、状态持久化、日志追踪，就能逐步演进为生产级实现。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 错误处理策略\u003c/h2\u003e\n\u003cp\u003e生产环境中，Agent Control Loop 最常遇到的四类错误：\u003c/p\u003e\n\u003ch3\u003e7.1 Tool 调用失败\u003c/h3\u003e\n\u003cp\u003e工具调用失败是最高频的错误。正确的处理方式不是抛异常终止，而是\u003cstrong\u003e将错误信息作为 Observation 返回给 LLM\u003c/strong\u003e，让它决定如何应对。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 错误的做法：直接终止\ntry:\n    result = call_tool(name, args)\nexcept Exception:\n    raise  # Agent 直接崩溃\n\n# 正确的做法：将错误反馈给 LLM\ntry:\n    result = call_tool(name, args)\nexcept TimeoutError:\n    result = \u0026quot;Tool timed out after 30s. Consider using different parameters.\u0026quot;\nexcept ValueError as e:\n    result = f\u0026quot;Invalid arguments: {e}. Please check parameter types.\u0026quot;\nexcept Exception as e:\n    result = f\u0026quot;Tool failed: {type(e).__name__}: {e}\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLLM 在收到错误信息后，通常能自主修正——换一组参数重试、换一个工具、或者告知用户当前无法完成任务。\u003c/p\u003e\n\u003ch3\u003e7.2 LLM 返回格式异常\u003c/h3\u003e\n\u003cp\u003eLLM 偶尔会返回不符合预期的格式：JSON 不合法、tool_call 参数缺失、content 为空等。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _parse_tool_call_safe(self, tool_call) -\u0026gt; tuple[str, dict]:\n    \u0026quot;\u0026quot;\u0026quot;安全解析工具调用参数\u0026quot;\u0026quot;\u0026quot;\n    name = tool_call.function.name\n    try:\n        args = json.loads(tool_call.function.arguments)\n    except json.JSONDecodeError:\n        # LLM 返回了非法 JSON，尝试修复或跳过\n        args = {}\n        self.logger.warning(\n            f\u0026quot;Invalid JSON in tool_call arguments: \u0026quot;\n            f\u0026quot;{tool_call.function.arguments}\u0026quot;\n        )\n    return name, args\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.3 超时处理\u003c/h3\u003e\n\u003cp\u003e整个 Agent 执行需要有全局超时，防止无限挂起：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport signal\n\nclass TimeoutError(Exception):\n    pass\n\ndef run_with_timeout(fn, timeout_seconds: int, *args, **kwargs):\n    \u0026quot;\u0026quot;\u0026quot;为函数执行添加超时限制\u0026quot;\u0026quot;\u0026quot;\n    def handler(signum, frame):\n        raise TimeoutError(f\u0026quot;Execution timed out after {timeout_seconds}s\u0026quot;)\n\n    old_handler = signal.signal(signal.SIGALRM, handler)\n    signal.alarm(timeout_seconds)\n    try:\n        return fn(*args, **kwargs)\n    finally:\n        signal.alarm(0)\n        signal.signal(signal.SIGALRM, old_handler)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.4 死循环检测\u003c/h3\u003e\n\u003cp\u003e当 Agent 陷入死循环时，它会反复执行相同的操作序列。检测策略：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _detect_loop(self, messages: list[dict], window: int = 6) -\u0026gt; bool:\n    \u0026quot;\u0026quot;\u0026quot;检测 Agent 是否陷入重复循环\u0026quot;\u0026quot;\u0026quot;\n    recent = messages[-window:]\n\n    # 策略 1：完全重复检测\n    contents = [m.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;) for m in recent if m[\u0026quot;role\u0026quot;] == \u0026quot;assistant\u0026quot;]\n    if len(contents) \u0026gt;= 3 and len(set(contents[-3:])) == 1:\n        return True\n\n    # 策略 2：工具调用序列重复检测\n    tool_calls = []\n    for m in recent:\n        if m.get(\u0026quot;tool_calls\u0026quot;):\n            for tc in m[\u0026quot;tool_calls\u0026quot;]:\n                tool_calls.append(f\u0026quot;{tc[\u0026#39;function\u0026#39;][\u0026#39;name\u0026#39;]}:{tc[\u0026#39;function\u0026#39;][\u0026#39;arguments\u0026#39;]}\u0026quot;)\n\n    if len(tool_calls) \u0026gt;= 4:\n        half = len(tool_calls) // 2\n        if tool_calls[:half] == tool_calls[half:2*half]:\n            return True\n\n    return False\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 性能考量\u003c/h2\u003e\n\u003ch3\u003e8.1 Token 消耗与循环次数的关系\u003c/h3\u003e\n\u003cp\u003eAgent Control Loop 的 Token 消耗不是线性增长，而是\u003cstrong\u003e二次增长\u003c/strong\u003e——因为每一轮都要携带之前所有轮次的 message history。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e轮次    新增消息 Token    累计 Context Token    本轮总消耗\n1       T               S + T                S + T\n2       T               S + 2T               S + 2T\n3       T               S + 3T               S + 3T\n...\nN       T               S + NT               S + NT\n\n总消耗 = N*S + T*(1+2+...+N) = N*S + T*N*(N+1)/2\n\n其中 S = System Prompt Token 数，T = 平均每轮消息 Token 数\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这意味着 \u003cstrong\u003e10 轮的 Agent 消耗的 Token 不是 1 轮的 10 倍，而可能是 55 倍\u003c/strong\u003e。这对成本控制至关重要。\u003c/p\u003e\n\u003ch3\u003e8.2 Context Window 膨胀问题\u003c/h3\u003e\n\u003cp\u003e随着轮次增加，Context Window 持续膨胀，导致：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e延迟增加\u003c/strong\u003e：LLM 推理时间与输入 Token 数正相关\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成本增加\u003c/strong\u003e：按 Token 计费，输入越长越贵\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e质量下降\u003c/strong\u003e：过长的 Context 会导致 LLM \u0026quot;注意力分散\u0026quot;，关键信息被淹没（lost in the middle 问题）\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e8.3 消息压缩/摘要策略\u003c/h3\u003e\n\u003cp\u003e应对 Context Window 膨胀的核心策略：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e策略一：滑动窗口\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e只保留最近 K 轮对话，丢弃更早的历史。简单粗暴但有效。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _sliding_window(self, messages: list[dict], keep_last: int = 10) -\u0026gt; list[dict]:\n    system_msgs = [m for m in messages if m[\u0026quot;role\u0026quot;] == \u0026quot;system\u0026quot;]\n    non_system = [m for m in messages if m[\u0026quot;role\u0026quot;] != \u0026quot;system\u0026quot;]\n    return system_msgs + non_system[-keep_last:]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e策略二：摘要压缩\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e当 message history 超过阈值时，用 LLM 对早期对话生成摘要，替换原始消息。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _compress_history(self, messages: list[dict], threshold: int = 20) -\u0026gt; list[dict]:\n    if len(messages) \u0026lt;= threshold:\n        return messages\n\n    # 将早期消息压缩为摘要\n    early = messages[1:-threshold]  # 跳过 system prompt，保留最近的\n    summary_prompt = (\n        \u0026quot;请用 3-5 句话总结以下对话的关键信息和已完成的操作：\\n\u0026quot;\n        + \u0026quot;\\n\u0026quot;.join(m.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;) for m in early if m.get(\u0026quot;content\u0026quot;))\n    )\n\n    summary = self.client.chat.completions.create(\n        model=\u0026quot;gpt-4o-mini\u0026quot;,  # 用小模型做摘要，节省成本\n        messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: summary_prompt}],\n    ).choices[0].message.content\n\n    return (\n        [messages[0]]  # system prompt\n        + [{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;[Earlier conversation summary] {summary}\u0026quot;}]\n        + messages[-threshold:]\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e策略三：选择性保留\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e不是所有消息都同等重要。工具的原始返回值（可能非常长）通常可以只保留摘要：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _trim_tool_results(self, messages: list[dict], max_len: int = 500) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;截断过长的工具返回值\u0026quot;\u0026quot;\u0026quot;\n    trimmed = []\n    for m in messages:\n        if m[\u0026quot;role\u0026quot;] == \u0026quot;tool\u0026quot; and len(m.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;)) \u0026gt; max_len:\n            m = {**m, \u0026quot;content\u0026quot;: m[\u0026quot;content\u0026quot;][:max_len] + \u0026quot;\\n...[truncated]\u0026quot;}\n        trimmed.append(m)\n    return trimmed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e三种策略的对比：\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e信息保留\u003c/th\u003e\n\u003cth\u003e实现成本\u003c/th\u003e\n\u003cth\u003eToken 节省\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e滑动窗口\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e极低\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e短对话、工具调用为主\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e摘要压缩\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e中（需要额外 LLM 调用）\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e长对话、需要历史上下文\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e选择性保留\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e工具返回值较大的场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e实际工程中，通常\u003cstrong\u003e组合使用\u003c/strong\u003e：先用选择性保留截断大结果，再用滑动窗口控制总长度，在关键节点用摘要压缩保留全局上下文。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 小结与进一步思考\u003c/h2\u003e\n\u003cp\u003e本文从状态机模型出发，完整地拆解了 Agent Control Loop 的核心抽象：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOBSERVE\u003c/strong\u003e 负责输入归一化——将各种来源的信息统一为 LLM 可理解的 message 格式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTHINK\u003c/strong\u003e 是核心推理阶段——管理 Context Window、控制 Token 预算、解析 LLM 输出\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eACT\u003c/strong\u003e 是执行层——处理工具调用的同步/异步执行、超时控制、安全隔离\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eREFLECT\u003c/strong\u003e 负责质量评估——决定是继续、重试还是终止\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e终止条件\u003c/strong\u003e是成本和安全的兜底——max_turns、token_budget、error_threshold、loop_detection\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我们对比了 ReAct 和 Plan-then-Execute 两种主流模式，分析了 Stateless 与 Stateful 两种状态管理策略，并实现了一个不依赖任何框架的完整 Control Loop。\u003c/p\u003e\n\u003cp\u003e但控制循环只是 Agent 运行时的骨架。它的灵魂在于 \u003cstrong\u003eTool Calling\u003c/strong\u003e——正是工具让 Agent 从\u0026quot;能说会道的语言模型\u0026quot;变成\u0026quot;能做事的智能体\u0026quot;。\u003c/p\u003e\n\u003cp\u003e在下一篇 \u003cstrong\u003e《Tool Calling Deep Dive: 让 LLM 成为可编程接口》\u003c/strong\u003e 中，我们会深入工具调用的设计哲学：JSON Schema 作为契约、Tool Registry 的实现、参数校验、错误传播，以及 Structured Output 为什么优于自由文本。\u003c/p\u003e\n\u003cp\u003e留几个值得进一步思考的问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eControl Loop 的嵌套\u003c/strong\u003e：当一个 Agent 的工具是另一个 Agent 时，控制循环如何嵌套？外层循环和内层循环的终止条件如何协调？\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e人机协作中的循环\u003c/strong\u003e：如何在 Control Loop 中优雅地插入人类审批节点？这和 Stateful Agent 的 checkpoint 机制有什么关系？\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e流式输出与控制循环\u003c/strong\u003e：当 Agent 需要边思考边输出（streaming）时，状态机模型还适用吗？需要做哪些调整？\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多模态输入的归一化\u003c/strong\u003e：当 OBSERVE 阶段接收的不只是文本，还有图片、音频、视频时，输入归一化策略如何演化？\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 04 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/03-Agent%20vs%20Workflow%20vs%20Automation\"\u003e03 | Agent vs Workflow vs Automation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/05-Tool%20Calling%20Deep%20Dive\"\u003e05 | Tool Calling Deep Dive\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"17:T5c64,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e微服务架构已经成为互联网后端系统的主流架构范式。然而，从单体架构迁移到微服务，绝不仅仅是把代码拆成几个服务那么简单——它涉及服务如何注册与发现、如何通信与容错、如何部署与监控等一系列基础设施问题。本文从架构设计的核心关注点出发，结合业界最佳实践，系统性地梳理微服务架构落地所需的技术体系。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e微服务架构概览\u003c/h2\u003e\n\u003ch3\u003e什么是微服务架构？\u003c/h3\u003e\n\u003cp\u003e与单体（Monolithic）架构不同，微服务架构是由一系列\u003cstrong\u003e职责单一的细粒度服务\u003c/strong\u003e构成的分布式网状结构，服务之间通过轻量级机制进行通信。这种架构带来了独立部署、技术异构、弹性伸缩等优势，但同时也引入了一系列新的技术挑战。\u003c/p\u003e\n\u003ch3\u003e核心技术关注点\u003c/h3\u003e\n\u003cp\u003e一个完整的微服务架构需要关注以下层面：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e层面\u003c/th\u003e\n\u003cth\u003e关注点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e通信\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e服务注册与发现、负载均衡、RPC 框架、API 网关\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e可靠性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e服务容错（熔断、隔离、限流、降级）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e基础设施\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e配置中心、缓存、消息队列、数据库\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e交付\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCI/CD 流水线、自动化测试、灰度发布\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e可观测性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e日志系统、监控告警、链路追踪\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e部署\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e负载均衡、DNS、CDN\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e接下来，我们逐一展开讨论。\u003c/p\u003e\n\u003ch2\u003e服务注册、发现与负载均衡\u003c/h2\u003e\n\u003cp\u003e微服务架构下，服务提供方需要注册通告服务地址，服务调用方需要发现目标服务，同时服务提供方一般以集群方式提供服务，这就引入了负载均衡和健康检查问题。\u003c/p\u003e\n\u003cp\u003e根据负载均衡器（LB）所在位置的不同，目前主要有三种方案：\u003c/p\u003e\n\u003ch3\u003e方案一：集中式 LB\u003c/h3\u003e\n\u003cp\u003e在服务消费者和服务提供者之间设置独立的 LB（如 F5 硬件或 LVS/HAProxy 软件），LB 上有所有服务的地址映射表，由运维配置注册。服务消费方通过 DNS 域名指向 LB。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e实现简单，当前业界主流\u003c/td\u003e\n\u003ctd\u003e单点问题，LB 容易成为瓶颈\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e易于做集中式访问控制\u003c/td\u003e\n\u003ctd\u003e增加一跳（hop），有性能开销\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e一旦 LB 故障，影响是灾难性的\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e方案二：进程内 LB（客户端负载）\u003c/h3\u003e\n\u003cp\u003e将 LB 功能以库的形式集成到服务消费方进程内，也称为\u003cstrong\u003e软负载（Soft Load Balancing）\u003c/strong\u003e。需要配合服务注册表（Service Registry）支持服务自注册和自发现。\u003c/p\u003e\n\u003cp\u003e工作原理：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e服务提供方启动时，将地址注册到服务注册表，并定期发送心跳\u003c/li\u003e\n\u003cli\u003e服务消费方通过内置 LB 组件查询注册表，缓存并定期刷新目标地址列表\u003c/li\u003e\n\u003cli\u003e以某种负载均衡策略选择目标地址，直接发起请求\u003c/li\u003e\n\u003c/ol\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e分布式方案，无单点问题\u003c/td\u003e\n\u003ctd\u003e多语言栈需开发多种客户端库\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e服务间直接调用，性能好\u003c/td\u003e\n\u003ctd\u003e客户端库升级需服务方重新发布\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e典型案例：Netflix OSS（Eureka + Ribbon + Karyon）、阿里 Dubbo。\u003c/p\u003e\n\u003ch3\u003e方案三：主机独立 LB 进程（Sidecar 模式）\u003c/h3\u003e\n\u003cp\u003e将 LB 和服务发现功能从进程内移出，变成主机上的独立进程。同一主机上的多个服务共享该 LB 进程完成服务发现和负载均衡。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e无单点，一个 LB 挂只影响该主机\u003c/td\u003e\n\u003ctd\u003e部署较复杂，环节多\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e不需要为不同语言开发客户端库\u003c/td\u003e\n\u003ctd\u003e出错调试排查不方便\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLB 升级不需要服务方改代码\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e典型案例：Airbnb SmartStack（Zookeeper + Nerve + Synapse/HAProxy）、Kubernetes 内部服务发现。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e三种方案各有取舍，选择时需要综合考虑团队技术栈的多样性、运维能力和性能要求。当前趋势是方案三（Sidecar 模式）逐渐演化为 Service Mesh（服务网格），如 Istio + Envoy。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003eAPI 网关（Service Gateway）\u003c/h2\u003e\n\u003cp\u003e微服务最终需要以某种方式暴露给外部系统访问，这就需要\u003cstrong\u003e服务网关\u003c/strong\u003e。网关是连接企业内部和外部系统的一道门，承担以下关键职责：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e反向路由\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e将外部请求路由到内部具体的微服务，对外呈现统一入口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e安全认证\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e集中处理用户认证、授权和防爬虫\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e限流容错\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e流量高峰期限流保护后台，内部故障时集中容错\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e监控\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e集中监控访问量、调用延迟、错误计数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e日志\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e收集所有访问日志，为后续分析提供数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e除此之外，网关还可以实现\u003cstrong\u003e线上引流、线上压测、金丝雀发布（Canary Testing）、数据中心双活\u003c/strong\u003e等高级功能。\u003c/p\u003e\n\u003ch3\u003e微服务的分层架构\u003c/h3\u003e\n\u003cp\u003e引入网关和服务注册表之后，微服务可以简化为两层结构：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e后端通用服务（Middle Tier Service）\u003c/strong\u003e：启动时注册地址到注册表\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e前端边缘服务（Edge Service）\u003c/strong\u003e：查询注册表发现后端服务，对后端服务做聚合和裁剪后暴露给外部设备\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e网关通过查询注册表将外部请求路由到前端服务，整个微服务体系的自注册、自发现和软路由就此串联起来。如果用设计模式的视角看——\u003cstrong\u003e网关类似 Proxy/Facade 模式，服务注册表类似 IoC 依赖注入模式\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e常见的网关组件：Netflix Zuul、Kong、APISIX、Spring Cloud Gateway。\u003c/p\u003e\n\u003ch2\u003e服务容错\u003c/h2\u003e\n\u003cp\u003e当企业微服务化后，服务之间存在错综复杂的依赖关系。一个前端请求一般依赖多个后端服务（1→N 扇出）。在生产环境中，如果一个应用不能对其依赖的故障进行容错和隔离，就面临被拖垮的风险。在高流量场景下，某个单一后端一旦发生延迟，可能在数秒内导致所有应用资源（线程、队列等）被耗尽，造成\u003cstrong\u003e雪崩效应（Cascading Failure）\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e业界总结出以下核心容错模式：\u003c/p\u003e\n\u003ch3\u003e熔断器模式（Circuit Breaker）\u003c/h3\u003e\n\u003cp\u003e原理类似家用电路熔断器。当目标服务慢或大量超时时，调用方主动熔断，防止服务被进一步拖垮。\u003c/p\u003e\n\u003cp\u003e熔断器有三种状态：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eClosed（正常）→ Open（熔断）→ Half-Open（半熔断）→ Closed/Open\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eClosed\u003c/strong\u003e：正常状态，请求正常通过\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen\u003c/strong\u003e：调用持续出错或超时，进入熔断状态，后续请求直接拒绝（Fail Fast）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHalf-Open\u003c/strong\u003e：一段时间后允许少量请求尝试，成功则恢复，失败则继续熔断\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e舱壁隔离模式（Bulkhead Isolation）\u003c/h3\u003e\n\u003cp\u003e像船舱一样对资源进行隔离。典型实现是\u003cstrong\u003e线程隔离\u003c/strong\u003e：假定应用 A 调用 Svc1/Svc2/Svc3 三个服务，容器共有 120 个工作线程，可以给每个服务各分配 40 个线程。当 Svc2 变慢时，只有分配给 Svc2 的 40 个线程被耗尽，Svc1 和 Svc3 的 80 个线程不受影响。\u003c/p\u003e\n\u003ch3\u003e限流（Rate Limiting）\u003c/h3\u003e\n\u003cp\u003e对服务限定并发访问量，比如单位时间只允许 100 个并发调用，超过限制的请求拒绝并回退。没有限流机制的服务在突发流量（秒杀、大促）时极易被冲垮。\u003c/p\u003e\n\u003ch3\u003e降级回退（Fallback）\u003c/h3\u003e\n\u003cp\u003e当熔断或限流发生时的后续处理策略：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eFail Fast\u003c/td\u003e\n\u003ctd\u003e直接抛出异常\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e返回缺省值\u003c/td\u003e\n\u003ctd\u003e返回空值或默认数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e备份服务\u003c/td\u003e\n\u003ctd\u003e从备份数据源获取数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNetflix 将上述容错模式集成到 Hystrix 开源组件中（现已进入维护模式，社区推荐 Resilience4j 或 Sentinel 作为替代）。Spring Cloud Circuit Breaker 提供了统一的抽象层。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e服务框架的核心能力\u003c/h2\u003e\n\u003cp\u003e微服务化后，为了让业务开发人员专注于业务逻辑，避免冗余和重复劳动，需要将公共关注点推到框架层面。一个成熟的服务框架应当封装以下能力：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e能力\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e服务注册发现\u003c/td\u003e\n\u003ctd\u003e服务端自注册，客户端自发现和负载均衡\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e监控日志\u003c/td\u003e\n\u003ctd\u003e框架层日志、Metrics、调用链数据的记录和暴露\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREST/RPC 与序列化\u003c/td\u003e\n\u003ctd\u003e支持 HTTP/REST 和 Binary/RPC，可定制序列化（JSON/Protobuf 等）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e动态配置\u003c/td\u003e\n\u003ctd\u003e运行时动态调整参数和配置\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e限流容错\u003c/td\u003e\n\u003ctd\u003e集成限流和熔断组件，结合动态配置实现动态限流\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e管理接口\u003c/td\u003e\n\u003ctd\u003e在线查看和动态调整框架及服务内部状态（如 Spring Boot Actuator）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e统一错误处理\u003c/td\u003e\n\u003ctd\u003e框架层统一处理异常并记录日志\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e安全\u003c/td\u003e\n\u003ctd\u003e访问控制逻辑的插件化封装\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e文档自动生成\u003c/td\u003e\n\u003ctd\u003e如 Swagger/OpenAPI 的自动化文档方案\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e当前业界成熟的微服务框架有：Spring Cloud/Spring Boot、Apache Dubbo、Go-Micro、gRPC 等。\u003c/p\u003e\n\u003ch2\u003e基础设施选型\u003c/h2\u003e\n\u003ch3\u003eRPC 框架选型\u003c/h3\u003e\n\u003cp\u003eRPC（Remote Procedure Call）框架大致分为两大流派：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e类型\u003c/th\u003e\n\u003cth\u003e代表框架\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e跨语言调用型\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003egRPC、Thrift、Hprose\u003c/td\u003e\n\u003ctd\u003e支持多语言调用，无服务治理机制\u003c/td\u003e\n\u003ctd\u003e多语言调用场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e服务治理型\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eDubbo、Motan、rpcx\u003c/td\u003e\n\u003ctd\u003e功能丰富，含服务发现和治理能力\u003c/td\u003e\n\u003ctd\u003e大型服务的解耦和治理\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e选型建议\u003c/strong\u003e：如果是 Java 为主的团队，推荐 \u003cstrong\u003eDubbo\u003c/strong\u003e（高性能，性能测试中比 Feign 强约 10 倍）。如果需要跨语言支持，Dubbo 也支持通过 Dubbo-Go 实现 Java + Go 双语言微服务架构。如果是纯粹的跨语言场景，\u003cstrong\u003egRPC\u003c/strong\u003e 基于 HTTP/2 + Protobuf，是业界标准选择。\u003c/p\u003e\n\u003ch3\u003e注册中心选型\u003c/h3\u003e\n\u003cp\u003e所有的服务发现都依赖于一个高可用的服务注册表。主流选择：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e注册中心\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003cth\u003e一致性模型\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eNacos\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e同时支持注册中心和配置中心，功能全面\u003c/td\u003e\n\u003ctd\u003eAP/CP 可切换\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eZooKeeper\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e最早的分布式协调服务，生态成熟\u003c/td\u003e\n\u003ctd\u003eCP\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eEtcd\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eKubernetes 默认存储，高可用和一致性\u003c/td\u003e\n\u003ctd\u003eCP\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eConsul\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e支持多数据中心，内置健康检查\u003c/td\u003e\n\u003ctd\u003eCP\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eEureka\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eNetflix 开源，AP 模型，已停止维护\u003c/td\u003e\n\u003ctd\u003eAP\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e选型建议\u003c/strong\u003e：推荐 \u003cstrong\u003eNacos\u003c/strong\u003e（nacos + MySQL 高可用部署），一站式解决注册中心和配置中心的需求。\u003c/p\u003e\n\u003ch3\u003e配置中心选型\u003c/h3\u003e\n\u003cp\u003e随着系统复杂度增长，配置管理面临越来越高的要求：配置修改实时生效、灰度发布、分环境/分集群管理、完善的权限审核机制。传统的配置文件方式已经无法满足需求。\u003c/p\u003e\n\u003cp\u003e配置中心的核心架构组件：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e配置服务端\u003c/strong\u003e：集中存储和管理所有配置信息\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e配置客户端\u003c/strong\u003e：通过\u003cstrong\u003e定期拉取（Pull）\u003c/strong\u003e 或 \u003cstrong\u003e服务端推送（Push）\u003c/strong\u003e 方式获取配置更新\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e管理界面\u003c/strong\u003e：配置的增删改查和审计\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e配置中心\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eNacos\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e阿里开源，同时支持注册和配置，生态活跃\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eApollo\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e携程开源，功能完善，支持灰度发布和权限管理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSpring Cloud Config\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eSpring 生态原生支持，基于 Git 存储\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e缓存中间件选型\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e缓存\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRedis\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e多数据结构，支持持久化和集群\u003c/td\u003e\n\u003ctd\u003e通用缓存、分布式锁、排行榜等\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eMemcached\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e纯内存 KV，简单高效\u003c/td\u003e\n\u003ctd\u003e简单的对象缓存\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e选型建议\u003c/strong\u003e：推荐 \u003cstrong\u003eRedis Cluster\u003c/strong\u003e 高可用集群部署。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e需要特别关注 Redis 的 Big Key 问题。在高并发场景下，Big Key 会导致单个节点内存和网络带宽瓶颈，严重时可造成系统瘫痪。建议制定 Key 规范并定期扫描。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003e消息中间件选型\u003c/h3\u003e\n\u003cp\u003e消息中间件的三大核心场景：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003cth\u003e典型案例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e异步处理\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e减少主流程等待时间，非核心逻辑异步执行\u003c/td\u003e\n\u003ctd\u003e注册后发送邮件、异步更新缓存\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e系统解耦\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e上下游系统通过消息通信，不需要强一致\u003c/td\u003e\n\u003ctd\u003e支付成功后通知 ERP/WMS/推荐等系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e削峰填谷\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e大流量请求放入队列，消费者按能力消化\u003c/td\u003e\n\u003ctd\u003e秒杀系统的下单排队\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e主流消息中间件对比：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e中间件\u003c/th\u003e\n\u003cth\u003e吞吐量\u003c/th\u003e\n\u003cth\u003e延迟\u003c/th\u003e\n\u003cth\u003e可靠性\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eKafka\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e极高\u003c/td\u003e\n\u003ctd\u003e毫秒级\u003c/td\u003e\n\u003ctd\u003e高（可配置）\u003c/td\u003e\n\u003ctd\u003e日志收集、大数据流处理、事件溯源\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRocketMQ\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e毫秒级\u003c/td\u003e\n\u003ctd\u003e极高（事务消息）\u003c/td\u003e\n\u003ctd\u003e电商交易、金融场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRabbitMQ\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e中等\u003c/td\u003e\n\u003ctd\u003e微秒级\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e实时性要求高、路由复杂的场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e选型建议\u003c/strong\u003e：\u003cstrong\u003eKafka\u003c/strong\u003e 用于日志采集和大数据场景，\u003cstrong\u003eRocketMQ\u003c/strong\u003e 用于业务消息和交易场景，二者搭配使用。\u003c/p\u003e\n\u003ch3\u003e数据库选型\u003c/h3\u003e\n\u003ch4\u003e关系型数据库\u003c/h4\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e类别\u003c/th\u003e\n\u003cth\u003e代表\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e传统 RDBMS\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eMySQL、PostgreSQL\u003c/td\u003e\n\u003ctd\u003e成熟稳定，生态丰富，百万级 PV 搭配主从 + 缓存可满足\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eNewSQL\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eTiDB、CockroachDB\u003c/td\u003e\n\u003ctd\u003e完整 SQL 支持 + ACID 事务 + 弹性伸缩 + 高可用 + 大数据分析能力\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e当 MySQL 需要分库分表且逻辑复杂度高、扩展性不足时，可以考虑 TiDB。\u003c/p\u003e\n\u003ch4\u003eNoSQL 数据库\u003c/h4\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e类型\u003c/th\u003e\n\u003cth\u003e代表\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e键值型\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eRedis、Memcache\u003c/td\u003e\n\u003ctd\u003e缓存、会话管理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e列式\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eHBase、Cassandra\u003c/td\u003e\n\u003ctd\u003e写多读少、时序数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e文档型\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eMongoDB、CouchDB\u003c/td\u003e\n\u003ctd\u003e非结构化数据、灵活 Schema\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e图数据库\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eNeo4J\u003c/td\u003e\n\u003ctd\u003e社交网络、推荐系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003eCI/CD 流水线\u003c/h2\u003e\n\u003cp\u003e从代码到最终服务用户，可以分为三个阶段：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eCode → Artifact（制品库）→ Running Service → Production\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e代码到制品\u003c/strong\u003e：持续构建，制品集中管理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e制品到服务\u003c/strong\u003e：部署到指定环境\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e开发到生产\u003c/strong\u003e：变更在不同环境间的迁移和灰度发布\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e工具链推荐\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e环节\u003c/th\u003e\n\u003cth\u003e推荐工具\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e代码管理\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eGitLab\u003c/td\u003e\n\u003ctd\u003e社区版功能丰富，结合 Gerrit 做 Code Review\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e持续集成\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eJenkins / GitLab CI\u003c/td\u003e\n\u003ctd\u003eJenkins 插件生态强大；GitLab CI 与 GitLab 深度集成\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e制品仓库\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eHarbor\u003c/td\u003e\n\u003ctd\u003e开源的 Docker 镜像仓库，支持镜像签名和漏洞扫描\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e部署编排\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eKubernetes\u003c/td\u003e\n\u003ctd\u003e容器编排的事实标准，支持声明式部署和自动伸缩\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e项目管理\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eJira + Confluence\u003c/td\u003e\n\u003ctd\u003e项目管理、任务跟踪和知识管理的行业标配\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e初期建议\u003c/strong\u003e：Jenkins + GitLab + Harbor 的组合，可以覆盖制品管理、发布流程、权限控制、版本变更和服务回滚。\u003c/p\u003e\n\u003ch3\u003e自动化测试\u003c/h3\u003e\n\u003cp\u003e自动化测试平台是 CI/CD 流水线的重要一环：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e单元测试\u003c/strong\u003e：JUnit / TestNG，覆盖核心业务逻辑\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e接口测试\u003c/strong\u003e：可基于开源框架（如 SpringBoot + TestNG）搭建\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e性能测试\u003c/strong\u003e：JMeter / Gatling\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e端到端测试\u003c/strong\u003e：Selenium / Cypress\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e可观测性体系\u003c/h2\u003e\n\u003ch3\u003e日志系统\u003c/h3\u003e\n\u003cp\u003e日志系统涵盖日志打印、采集、中转、存储、分析、搜索和分发。日志系统的建设不仅是工具建设，还包括规范和组件建设——基本的日志（如全链路追踪 ID）应在框架和组件层面统一注入。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e常规方案：ELK Stack\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e组件\u003c/th\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFilebeat\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e轻量级日志采集器，替代 Logstash-Forwarder\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eLogstash\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e日志收集、过滤和转换\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eElasticsearch\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e分布式搜索引擎，存储和索引日志\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eKibana\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e可视化界面，日志搜索和分析\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e免费版 ELK 没有安全机制，建议前置 Nginx 做反向代理和简单用户认证。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e实时计算方案\u003c/strong\u003e：对于需要实时分析的场景，可以采用 Flume + Kafka + Flink（或 Storm）的架构。Kafka 负责高吞吐的消息缓冲，Flume 负责多样化的数据采集，Flink 负责实时流计算。\u003c/p\u003e\n\u003ch3\u003e监控系统\u003c/h3\u003e\n\u003cp\u003e监控系统主要覆盖两个层面：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e层面\u003c/th\u003e\n\u003cth\u003e监控指标\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e基础设施\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e机器负载、IO、网络流量、CPU、内存\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e服务质量\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e可用性、成功率、失败率、QPS、延迟\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e推荐方案：Prometheus + Grafana\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePrometheus 是 Google BorgMon 的开源版本，使用 Go 开发，采用 \u003cstrong\u003ePull\u003c/strong\u003e 模式主动拉取指标数据。其核心组件：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e组件\u003c/th\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ePrometheus Server\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e数据采集和存储，提供 PromQL 查询\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eExporter\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e各类数据采集组件（数据库、硬件、MQ、HTTP 服务器等）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ePush Gateway\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e支持短生命周期 Job 主动推送指标\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAlertmanager\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e灵活的报警规则和通知管理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eGrafana\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e高度定制化的可视化监控面板\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003ePrometheus + Grafana 搭配统一的服务框架，可以满足绝大部分中小团队的监控需求。\u003c/p\u003e\n\u003ch2\u003e生产环境部署架构\u003c/h2\u003e\n\u003ch3\u003eDNS\u003c/h3\u003e\n\u003cp\u003eDNS 是基础服务，一般直接选择云厂商：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e国内\u003c/strong\u003e：阿里云 DNS 或腾讯 DNSPod，线上产品建议使用付费版\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e海外\u003c/strong\u003e：优先选择 AWS Route 53\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e国内外互通\u003c/strong\u003e：建议在 APP 层实现容灾逻辑或智能调度，因为没有单一 DNS 服务能同时很好地覆盖国内外\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e负载均衡（LB）\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景\u003c/th\u003e\n\u003cth\u003e方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e云服务环境\u003c/td\u003e\n\u003ctd\u003e直接使用云厂商 LB（阿里云 SLB / 腾讯云 CLB / AWS ELB）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e自建机房\u003c/td\u003e\n\u003ctd\u003eLVS（四层）+ Nginx（七层）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e云厂商 LB 通常支持四层（TCP/UDP）和七层（HTTP/HTTPS）协议、集中化证书管理和健康检查。\u003c/p\u003e\n\u003ch3\u003eCDN\u003c/h3\u003e\n\u003cp\u003eCDN 的选型主要看业务覆盖区域：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e区域\u003c/th\u003e\n\u003cth\u003e推荐\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e国内\u003c/td\u003e\n\u003ctd\u003e阿里云 CDN、腾讯云 CDN\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e海外\u003c/td\u003e\n\u003ctd\u003eAWS CloudFront、Akamai\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e总结\u003c/h2\u003e\n\u003cp\u003e微服务架构的落地是一个系统工程，核心技术关注点可以归纳为以下几个层面：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e服务通信\u003c/strong\u003e：通过注册中心 + 负载均衡 + API 网关，构建服务间和内外部的通信体系\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e服务可靠性\u003c/strong\u003e：通过熔断、隔离、限流和降级四大模式，保障系统在故障和高峰期的稳定性\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e服务框架\u003c/strong\u003e：将公共关注点下沉到框架层，让业务开发专注于业务逻辑\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e基础设施\u003c/strong\u003e：根据业务需求和团队技术栈，选择合适的 RPC、注册中心、缓存、消息队列和数据库\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e持续交付\u003c/strong\u003e：通过 CI/CD 流水线实现代码到生产环境的自动化、可重复的发布流程\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可观测性\u003c/strong\u003e：通过日志、监控和链路追踪构建系统的透明度，为问题排查和性能优化提供数据支撑\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e好的架构不是设计出来的，而是演进出来的。架构师需要在不同阶段做出合适的判断——既不过度设计，也不欠缺考虑。关键是保持对技术的敏锐度，在实践中不断验证和调整。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e路漫漫其修远兮，架构求索无止尽也。\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"18:T602d,"])</script><script>self.__next_f.push([1,"\u003ch1\u003e高并发系统设计：原理、策略与工程实践\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e高并发不是一个单点问题，而是一个系统性工程。它要求在计算、存储、网络、容错等多个维度协同设计，在吞吐量、延迟、一致性、可用性之间做出精确的权衡。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e高并发系统的本质目标是：\u003cstrong\u003e在保证系统整体可用的前提下，最大化单位时间内的请求处理能力\u003c/strong\u003e。这涉及两个核心指标——\u003cstrong\u003e吞吐量\u003c/strong\u003e（TPS/QPS）和\u003cstrong\u003e响应延迟\u003c/strong\u003e（Latency），以及一个隐含约束——\u003cstrong\u003e资源成本\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e本文将高并发设计策略按作用层次分为四大类，逐一分析每种策略的底层原理、适用场景与决策依据。\u003c/p\u003e\n\u003ch2\u003e一、计算层：提升处理能力\u003c/h2\u003e\n\u003cp\u003e计算层的核心矛盾是\u003cstrong\u003e单节点处理能力有限\u003c/strong\u003e。解决思路有两条：纵向压榨单机性能，横向扩展节点数量。\u003c/p\u003e\n\u003ch3\u003e1.1 水平扩展\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将请求分散到多个对等节点并行处理，系统吞吐量随节点数近线性增长。\u003c/p\u003e\n\u003cp\u003e水平扩展是高并发的第一性原理——当单机无法承载时，加机器是最直接的手段。但前提是系统必须具备\u003cstrong\u003e无状态性\u003c/strong\u003e，否则扩展只是增加复杂度。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e条件\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e无状态服务\u003c/td\u003e\n\u003ctd\u003e请求可被任意节点处理，不依赖本地状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e负载均衡\u003c/td\u003e\n\u003ctd\u003e流量均匀分配到各节点（轮询、加权、一致性哈希）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e服务发现\u003c/td\u003e\n\u003ctd\u003e新增/下线节点时自动感知\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e水平扩展的收益存在拐点。当瓶颈不在计算层（如数据库连接数耗尽），加应用节点无法提升吞吐\u003c/li\u003e\n\u003cli\u003e扩展前先确认瓶颈位置：CPU 密集型看计算节点数，I/O 密集型看下游容量\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e1.2 服务拆分\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将单体应用按业务域拆分为独立服务，每个服务独立部署、独立扩展，使资源投放更精准。\u003c/p\u003e\n\u003cp\u003e服务拆分的高并发价值不在于\u0026quot;拆\u0026quot;本身，而在于\u003cstrong\u003e差异化扩展\u003c/strong\u003e——热点服务可以单独扩容，而不必整体扩展。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e单体应用：所有模块共享资源池\n  → 商品查询 QPS 暴涨时，订单、支付模块的资源也被占用\n\n服务拆分后：\n  → 商品服务独立扩容 10 倍，订单服务保持不变\n  → 资源利用率提升，扩容成本下降\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e拆分粒度不是越细越好。过度拆分导致服务间调用链路变长，网络开销和故障概率增加\u003c/li\u003e\n\u003cli\u003e拆分的依据是\u003cstrong\u003e业务边界\u003c/strong\u003e和\u003cstrong\u003e扩展需求\u003c/strong\u003e，而非代码量\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e1.3 异步化\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将同步阻塞调用转为异步非阻塞，释放线程资源去处理更多请求，从而提升单位时间内的吞吐量。\u003c/p\u003e\n\u003cp\u003e同步模型下，线程在等待下游响应期间处于阻塞状态，无法处理新请求。异步化的本质是\u003cstrong\u003e把等待时间转化为处理能力\u003c/strong\u003e。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e异步方式\u003c/th\u003e\n\u003cth\u003e机制\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e消息队列\u003c/td\u003e\n\u003ctd\u003e请求写入 MQ 后立即返回，消费者异步处理\u003c/td\u003e\n\u003ctd\u003e非实时性业务（通知、日志、数据同步）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e异步 I/O\u003c/td\u003e\n\u003ctd\u003eNIO / Reactor 模型\u003c/td\u003e\n\u003ctd\u003e高并发网络通信（Netty、WebFlux）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并行调用\u003c/td\u003e\n\u003ctd\u003eCompletableFuture / 协程\u003c/td\u003e\n\u003ctd\u003e多个独立下游调用并行执行\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e事件驱动\u003c/td\u003e\n\u003ctd\u003e发布-订阅模式\u003c/td\u003e\n\u003ctd\u003e服务间解耦\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e异步化的前提是业务允许\u003cstrong\u003e延迟处理\u003c/strong\u003e。对于实时性要求高的链路（如支付扣款），不宜异步\u003c/li\u003e\n\u003cli\u003e引入异步后需要处理\u003cstrong\u003e结果通知\u003c/strong\u003e（回调、轮询）和\u003cstrong\u003e失败重试\u003c/strong\u003e，系统复杂度会上升\u003c/li\u003e\n\u003cli\u003e消息队列的削峰价值：瞬时 5000 QPS 的流量冲击，系统处理能力 2000 QPS，MQ 作为缓冲区，将超出部分排队处理，避免系统过载\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e1.4 池化\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：预先创建并复用昂贵资源（连接、线程、对象），避免频繁创建/销毁带来的开销。\u003c/p\u003e\n\u003cp\u003e每次创建数据库连接需要 TCP 三次握手 + 认证，耗时通常在毫秒级。在高并发场景下，这些开销会被放大数百倍。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e池化类型\u003c/th\u003e\n\u003cth\u003e复用的资源\u003c/th\u003e\n\u003cth\u003e关键参数\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e数据库连接池\u003c/td\u003e\n\u003ctd\u003eTCP 连接 + 认证会话\u003c/td\u003e\n\u003ctd\u003e最大连接数、最小空闲数、获取超时\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHTTP 连接池\u003c/td\u003e\n\u003ctd\u003eTCP 连接（Keep-Alive）\u003c/td\u003e\n\u003ctd\u003e最大连接数、每路由最大连接数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e线程池\u003c/td\u003e\n\u003ctd\u003e线程\u003c/td\u003e\n\u003ctd\u003e核心线程数、最大线程数、队列长度、拒绝策略\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e对象池\u003c/td\u003e\n\u003ctd\u003e重量级对象（如序列化器）\u003c/td\u003e\n\u003ctd\u003e池大小、借出超时\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e连接池大小不是越大越好。过多连接会导致数据库端线程竞争加剧，反而降低性能。PostgreSQL 官方建议的公式：\u003ccode\u003e连接数 = ((核心数 * 2) + 有效磁盘数)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e线程池的队列策略直接影响系统行为：无界队列可能导致 OOM，有界队列需要配合合理的拒绝策略\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e二、数据层：突破存储瓶颈\u003c/h2\u003e\n\u003cp\u003e高并发系统中，数据库通常是第一个到达瓶颈的组件。数据层优化的核心思路是\u003cstrong\u003e减少对数据库的直接访问\u003c/strong\u003e和\u003cstrong\u003e提升数据库本身的承载能力\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e2.1 缓存\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将热点数据存储在访问速度更快的介质中（内存），减少对慢速存储（磁盘数据库）的访问。\u003c/p\u003e\n\u003cp\u003e缓存是高并发系统中 ROI 最高的优化手段。一次 Redis 查询耗时约 0.5ms，一次 MySQL 查询耗时约 5\u003cdel\u003e50ms，性能差距在 10\u003c/del\u003e100 倍。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e多级缓存架构\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e请求 → L1 本地缓存（Caffeine）    命中率 ~60%\n     → L2 分布式缓存（Redis）      命中率 ~95%\n     → L3 数据库（MySQL）          兜底查询\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e每一层拦截掉大部分请求，最终到达数据库的流量可能不到总量的 5%。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缓存三大问题及应对\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e问题\u003c/th\u003e\n\u003cth\u003e成因\u003c/th\u003e\n\u003cth\u003e解决方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e穿透\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e查询不存在的 Key，每次都打到 DB\u003c/td\u003e\n\u003ctd\u003e布隆过滤器拦截；空值缓存（TTL 设短）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e击穿\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e热点 Key 过期瞬间，大量请求涌入 DB\u003c/td\u003e\n\u003ctd\u003e互斥锁重建；逻辑过期 + 异步刷新\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e雪崩\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e大批 Key 同时过期\u003c/td\u003e\n\u003ctd\u003e过期时间加随机偏移；多级缓存兜底\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e缓存适用于\u003cstrong\u003e读多写少\u003c/strong\u003e的场景。写频繁的数据缓存命中率低，且一致性维护成本高\u003c/li\u003e\n\u003cli\u003e缓存与数据库的一致性没有完美方案。常用策略是\u003cstrong\u003eCache Aside（旁路缓存）\u003c/strong\u003e：读时先查缓存，miss 则查 DB 并回填；写时先更新 DB，再删除缓存\u003c/li\u003e\n\u003cli\u003e本地缓存适合体积小、变化少、一致性要求低的数据（如配置信息）；分布式缓存适合体积大、需要跨节点共享的数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.2 读写分离\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将数据库的读写流量分离到不同实例，主库承担写操作，从库承担读操作，利用数据复制实现读能力的水平扩展。\u003c/p\u003e\n\u003cp\u003e大多数业务系统的读写比在 7:3 到 9:1 之间。读写分离的本质是\u003cstrong\u003e用廉价的从库分担主库的读压力\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e写请求 → 主库（Master）\n                ↓ Binlog 复制\n读请求 → 从库 1 / 从库 2 / 从库 N\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e需要处理的关键问题\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e问题\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003cth\u003e解决方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e主从延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e从库数据滞后于主库（通常 ms~s 级）\u003c/td\u003e\n\u003ctd\u003e强一致读走主库；半同步复制减少延迟\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e延迟感知\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e刚写入的数据立即读取可能读到旧值\u003c/td\u003e\n\u003ctd\u003e写后读强制路由到主库（Session 级别）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e从库故障\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e某个从库不可用\u003c/td\u003e\n\u003ctd\u003e负载均衡自动摘除；从库集群冗余\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e读写分离能解决读瓶颈，但无法解决写瓶颈。如果写 QPS 过高，需要考虑分库\u003c/li\u003e\n\u003cli\u003e对于实时性要求高的读操作（如支付后查询订单状态），必须路由到主库\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.3 分库分表\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将数据分散到多个数据库实例（分库）或多张表（分表），突破单实例的存储容量和连接数限制。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e解决的问题\u003c/th\u003e\n\u003cth\u003e拆分维度\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e垂直分库\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不同业务的数据隔离\u003c/td\u003e\n\u003ctd\u003e按业务域拆分（用户库、订单库、商品库）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e水平分库\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单库连接数/写入能力不足\u003c/td\u003e\n\u003ctd\u003e按路由键分片到多个库实例\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e水平分表\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单表数据量过大导致查询变慢\u003c/td\u003e\n\u003ctd\u003e按路由键分片到多张表\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e分片策略对比\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eHash 取模\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eshardId = hash(key) % N\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e数据分布均匀\u003c/td\u003e\n\u003ctd\u003e扩容需要数据迁移\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e范围分片\u003c/td\u003e\n\u003ctd\u003e按 ID 或时间范围划分\u003c/td\u003e\n\u003ctd\u003e扩容简单，支持范围查询\u003c/td\u003e\n\u003ctd\u003e可能出现热点分片\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一致性哈希\u003c/td\u003e\n\u003ctd\u003e哈希环 + 虚拟节点\u003c/td\u003e\n\u003ctd\u003e扩容仅迁移部分数据\u003c/td\u003e\n\u003ctd\u003e实现复杂度较高\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e单表数据量超过 \u003cstrong\u003e1000 万~2000 万行\u003c/strong\u003e时，B+ 树索引层级增加，查询性能开始下降，应考虑分表\u003c/li\u003e\n\u003cli\u003e分库分表会引入\u003cstrong\u003e分布式事务\u003c/strong\u003e和\u003cstrong\u003e跨分片查询\u003c/strong\u003e两大难题，在决策前需评估这些成本是否可接受\u003c/li\u003e\n\u003cli\u003e路由键的选择至关重要：选择查询最频繁的字段（通常是用户 ID），避免绝大多数查询变成跨分片查询\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.4 搜索引擎分流\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将搜索、模糊查询、聚合统计等对关系型数据库不友好的查询，分流到专用搜索引擎（Elasticsearch），减轻数据库压力。\u003c/p\u003e\n\u003cp\u003eMySQL 的 \u003ccode\u003eLIKE \u0026#39;%keyword%\u0026#39;\u003c/code\u003e 无法走索引，在大数据量下性能急剧下降。Elasticsearch 基于倒排索引，天然支持全文检索和聚合查询，且具备水平扩展能力。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e适合搜索引擎的场景\u003c/th\u003e\n\u003cth\u003e不适合的场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e全文搜索、模糊匹配\u003c/td\u003e\n\u003ctd\u003e强事务性写入\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e多维度组合筛选\u003c/td\u003e\n\u003ctd\u003e实时一致性要求高的读取\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e聚合统计分析\u003c/td\u003e\n\u003ctd\u003e频繁更新的热点数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eES 的数据来源于数据库同步（Binlog 订阅或双写），存在秒级延迟，不适合作为事务性读取的主存储\u003c/li\u003e\n\u003cli\u003eES 集群的运维成本较高（分片管理、索引优化、GC 调优），引入前需评估团队的运维能力\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e三、流量层：控制入口压力\u003c/h2\u003e\n\u003cp\u003e当流量超过系统承载能力时，需要在入口层进行管控，避免系统被打垮。\u003c/p\u003e\n\u003ch3\u003e3.1 CDN 静态加速\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将静态资源（图片、CSS、JS）分发到离用户最近的边缘节点，用户就近访问，减少源站压力和网络延迟。\u003c/p\u003e\n\u003cp\u003eCDN 的价值不仅是加速，更是\u003cstrong\u003e将静态请求从应用服务器完全卸载\u003c/strong\u003e。一个电商页面中，静态资源请求可能占总请求量的 80% 以上。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e无 CDN：  用户（深圳） → 源站（北京）   RTT ~40ms\n有 CDN：  用户（深圳） → CDN 节点（深圳）  RTT ~5ms\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e静态资源使用独立域名，避免携带不必要的 Cookie\u003c/li\u003e\n\u003cli\u003e文件名带内容哈希（如 \u003ccode\u003eapp.a3b2c1.js\u003c/code\u003e），配合长缓存策略，既保证缓存命中率又支持即时更新\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.2 限流\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：当入口流量超过系统容量时，主动丢弃超出部分的请求，保证系统在承载范围内正常服务。\u003c/p\u003e\n\u003cp\u003e限流是\u003cstrong\u003e保护系统不被打垮的最后一道防线\u003c/strong\u003e。它的前提假设是：服务部分用户优于服务零用户。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主流限流算法对比\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e算法\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e固定窗口\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e固定时间窗口内计数\u003c/td\u003e\n\u003ctd\u003e实现简单\u003c/td\u003e\n\u003ctd\u003e存在窗口边界突发问题\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e滑动窗口\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e滑动时间窗口内计数\u003c/td\u003e\n\u003ctd\u003e平滑度优于固定窗口\u003c/td\u003e\n\u003ctd\u003e内存占用略高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e漏桶\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e请求以固定速率流出\u003c/td\u003e\n\u003ctd\u003e流量绝对平滑\u003c/td\u003e\n\u003ctd\u003e无法应对合理的突发流量\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e令牌桶\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e令牌以固定速率生成，请求消耗令牌\u003c/td\u003e\n\u003ctd\u003e允许一定突发流量\u003c/td\u003e\n\u003ctd\u003e参数调优有一定复杂度\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e限流的层次\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e接入层限流（Nginx / API Gateway）   → 粗粒度，按 IP 或接口\n应用层限流（Sentinel / Guava）      → 细粒度，按用户、业务维度\n数据层限流（连接池 / 信号量）         → 保护下游资源\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e限流阈值必须基于\u003cstrong\u003e压测数据\u003c/strong\u003e设定，而非拍脑袋。先压测确定系统容量，再按容量的 70%~80% 设置限流阈值\u003c/li\u003e\n\u003cli\u003e被限流的请求应返回明确的状态码（如 HTTP 429）和友好的提示，而非超时或错误\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.3 负载均衡\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将入口流量按策略分配到多个后端节点，避免单节点过载，同时实现故障自动摘除。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e层级\u003c/th\u003e\n\u003cth\u003e实现\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eDNS 负载均衡\u003c/td\u003e\n\u003ctd\u003eDNS 多 A 记录\u003c/td\u003e\n\u003ctd\u003e粗粒度，无法感知后端状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eL4 负载均衡\u003c/td\u003e\n\u003ctd\u003eLVS / F5\u003c/td\u003e\n\u003ctd\u003e高性能（百万级），基于 IP + 端口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eL7 负载均衡\u003c/td\u003e\n\u003ctd\u003eNginx / HAProxy\u003c/td\u003e\n\u003ctd\u003e灵活（可按 URL、Header 路由），性能略低于 L4\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e常用调度算法\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e算法\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e轮询 / 加权轮询\u003c/td\u003e\n\u003ctd\u003e后端节点性能一致或差异已知\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e最少连接\u003c/td\u003e\n\u003ctd\u003e请求处理时间差异大\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一致性哈希\u003c/td\u003e\n\u003ctd\u003e需要会话亲和或缓存亲和\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e随机\u003c/td\u003e\n\u003ctd\u003e后端节点对等，实现最简单\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e四、容错层：保障系统韧性\u003c/h2\u003e\n\u003cp\u003e高并发场景下，系统组件出现故障的概率随节点数增长而增大。容错设计的目标是\u003cstrong\u003e局部故障不扩散为全局雪崩\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e4.1 熔断\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：当下游服务的错误率或响应时间超过阈值时，自动切断对该服务的调用，防止故障沿调用链向上蔓延。\u003c/p\u003e\n\u003cp\u003e熔断器借鉴了电路断路器的设计，有三个状态：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eClosed（关闭）→ 正常放行请求\n    ↓ 错误率超过阈值\nOpen（打开）→ 直接拒绝请求，返回降级结果\n    ↓ 超时后放行少量探测请求\nHalf-Open（半开）→ 探测成功则恢复，失败则重新打开\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e熔断阈值的设定需要区分\u003cstrong\u003e瞬时抖动\u003c/strong\u003e和\u003cstrong\u003e持续故障\u003c/strong\u003e。通常使用滑动窗口统计，避免单次超时就触发熔断\u003c/li\u003e\n\u003cli\u003e熔断后的降级策略需要提前设计：返回默认值、返回缓存数据、或返回友好提示\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.2 降级\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：在系统压力过大时，主动关闭非核心功能，将资源集中保障核心链路。\u003c/p\u003e\n\u003cp\u003e降级是一种\u003cstrong\u003e有策略的功能取舍\u003c/strong\u003e，核心思想是：宁可部分功能不可用，也不能让整个系统崩溃。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e降级层次\u003c/th\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e示例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e接口降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e关闭非核心接口\u003c/td\u003e\n\u003ctd\u003e大促期间关闭商品评论、推荐功能\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e返回简化/缓存数据\u003c/td\u003e\n\u003ctd\u003e库存查询降级为返回\u0026quot;有货\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e体验降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e降低功能质量\u003c/td\u003e\n\u003ctd\u003e图片返回低清版本、关闭个性化推荐\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e写降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e异步化写入\u003c/td\u003e\n\u003ctd\u003e日志、埋点异步落盘\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e降级开关应提前埋入代码，通过配置中心实时生效，而非临时发版\u003c/li\u003e\n\u003cli\u003e建立业务优先级分类（P0~P3），明确各级业务在压力场景下的降级策略\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.3 超时与重试\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：通过超时避免线程无限等待，通过重试应对瞬时故障。两者配合使用，在可靠性和资源效率之间取得平衡。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e关键参数\u003c/th\u003e\n\u003cth\u003e注意事项\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e超时\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e连接超时、读取超时\u003c/td\u003e\n\u003ctd\u003e超时时间应基于下游 P99 延迟设定，而非经验值\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e重试\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e最大重试次数、退避策略\u003c/td\u003e\n\u003ctd\u003e仅对\u003cstrong\u003e幂等\u003c/strong\u003e操作重试；使用指数退避避免重试风暴\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e重试的风险——重试风暴\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e正常情况：A → B → C，每层 1 次调用 = 1 次\n重试场景：A(重试3次) → B(重试3次) → C\n  C 的实际请求量 = 3 × 3 = 9 倍放大\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在调用链的\u003cstrong\u003e最外层\u003c/strong\u003e设置重试，中间层尽量不重试，避免指数级放大\u003c/li\u003e\n\u003cli\u003e重试需配合\u003cstrong\u003e熔断\u003c/strong\u003e使用：当下游已经熔断时，不应继续重试\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.4 隔离\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将不同业务或不同调用方的资源隔离开，防止某一个慢请求或故障请求耗尽全局资源。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e隔离方式\u003c/th\u003e\n\u003cth\u003e机制\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e线程池隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个下游调用使用独立线程池\u003c/td\u003e\n\u003ctd\u003e调用外部服务，需要严格隔离\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e信号量隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e限制某类请求的并发数\u003c/td\u003e\n\u003ctd\u003e轻量级隔离，开销比线程池小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e进程隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不同业务部署在独立进程/容器\u003c/td\u003e\n\u003ctd\u003e核心业务与非核心业务隔离\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e机房/泳道隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e流量按泳道划分到独立基础设施\u003c/td\u003e\n\u003ctd\u003eSET 化架构、灰度发布\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e五、验证层：建立量化基准\u003c/h2\u003e\n\u003cp\u003e以上所有策略的效果，最终都需要通过压力测试来验证。\u003c/p\u003e\n\u003ch3\u003e5.1 压力测试\u003c/h3\u003e\n\u003cp\u003e压测的目的不是\u0026quot;测试系统能抗多少\u0026quot;，而是\u003cstrong\u003e建立系统容量的量化认知\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e压测指标\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e目标\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eQPS/TPS\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每秒处理请求/事务数\u003c/td\u003e\n\u003ctd\u003e确定系统吞吐上限\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eP99 延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e99% 的请求响应时间\u003c/td\u003e\n\u003ctd\u003e确定延迟是否可接受\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e错误率\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e失败请求占比\u003c/td\u003e\n\u003ctd\u003e确定系统稳定性边界\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e资源利用率\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCPU、内存、网络、磁盘\u003c/td\u003e\n\u003ctd\u003e确定瓶颈所在\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e压测原则\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e全链路压测\u003c/strong\u003e：仅压测单个服务无法反映真实瓶颈，需要从入口到数据库全链路施压\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e梯度加压\u003c/strong\u003e：从低流量逐步增加，观察每个阶段的指标变化，而非直接打到目标流量\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e压测环境隔离\u003c/strong\u003e：避免压测流量影响线上数据，使用影子库/影子表隔离\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e5.2 容量规划\u003c/h3\u003e\n\u003cp\u003e基于压测数据建立容量模型：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e所需节点数 = 预估峰值 QPS / 单节点安全 QPS × 冗余系数\n\n示例：\n  预估峰值 QPS：10,000\n  单节点压测 QPS：2,000（P99 \u0026lt; 50ms 时）\n  冗余系数：1.5（预留 50% 余量应对突发）\n\n  所需节点数 = 10,000 / 2,000 × 1.5 = 7.5 → 8 个节点\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e容量规划以 \u003cstrong\u003eP99 延迟可接受时的 QPS\u003c/strong\u003e 为基准，而非极限 QPS\u003c/li\u003e\n\u003cli\u003e预留 30%~50% 的余量应对突发流量和非预期场景\u003c/li\u003e\n\u003cli\u003e建立常态化的容量巡检机制，而非仅在大促前才做压测\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e六、策略选择决策框架\u003c/h2\u003e\n\u003cp\u003e面对高并发问题时，不同策略的优先级和适用条件不同。以下是一个决策参考框架：\u003c/p\u003e\n\u003ch3\u003e按瓶颈类型选择策略\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e瓶颈类型\u003c/th\u003e\n\u003cth\u003e表现\u003c/th\u003e\n\u003cth\u003e优先策略\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eCPU 瓶颈\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCPU 利用率持续 \u0026gt; 80%\u003c/td\u003e\n\u003ctd\u003e水平扩展、异步化、算法优化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据库瓶颈（读）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e慢查询多、从库延迟高\u003c/td\u003e\n\u003ctd\u003e缓存、读写分离、索引优化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据库瓶颈（写）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e主库 TPS 到顶、锁等待严重\u003c/td\u003e\n\u003ctd\u003e分库分表、异步写入、批量合并\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e网络瓶颈\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e带宽打满、延迟升高\u003c/td\u003e\n\u003ctd\u003eCDN、数据压缩、减少调用次数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e连接数瓶颈\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003etoo many connections\u003c/td\u003e\n\u003ctd\u003e池化、读写分离、分库\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e按投入产出比排序\u003c/h3\u003e\n\u003cp\u003e高并发优化应遵循\u003cstrong\u003e先低成本高收益，再高成本高收益\u003c/strong\u003e的顺序：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e第一梯队（低成本、高收益）：\n  缓存 → 池化 → 索引优化 → CDN\n\n第二梯队（中等成本）：\n  读写分离 → 异步化 → 限流/熔断/降级\n\n第三梯队（高成本）：\n  分库分表 → 水平扩展 → 服务拆分 → SET 化\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e总结\u003c/h2\u003e\n\u003cp\u003e高并发系统设计不是某个单一技巧的应用，而是多种策略在不同层次的协同配合。核心原则可以归纳为三点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e先定位瓶颈，再选择策略\u003c/strong\u003e。不做盲目优化，压测数据是一切决策的基础\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e优先选择低成本方案\u003c/strong\u003e。缓存、池化、异步化往往能以最小代价解决 80% 的并发问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e容错比性能更重要\u003c/strong\u003e。系统在高并发下\u0026quot;不崩\u0026quot;比\u0026quot;更快\u0026quot;更关键——限流、熔断、降级是系统韧性的底线\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个成熟的高并发系统，不是在每个环节都做到极致，而是在每个环节都做出了正确的取舍。\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"19:T9547,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eAgent vs Workflow vs Automation: 选对抽象才是关键\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e系列第 03 篇。上一篇我们讲了\u0026quot;LLM 本身不是 Agent\u0026quot;，这一篇要回答一个更实际的问题：\u003cstrong\u003e你的问题，真的需要 Agent 吗？\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 开篇：Agent 万能论的陷阱\u003c/h2\u003e\n\u003cp\u003e2024 年以来，\u0026quot;Agent\u0026quot; 这个词已经被严重滥用。打开任何一篇技术文章，似乎所有系统都应该被重写为 Agent——客服要 Agent、ETL 要 Agent、运维要 Agent、审批要 Agent。\u003c/p\u003e\n\u003cp\u003e但现实是：\u003cstrong\u003e大部分生产系统中，80% 的任务用 if/else 和 DAG 就能解决，且解决得更好。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAgent 不是银弹。它是一种特定的执行范式，适用于特定的问题空间。盲目使用 Agent 的代价是：更高的 Token 成本、更长的延迟、更难的调试、更差的可预测性。\u003c/p\u003e\n\u003cp\u003e这篇文章的目标很简单：帮你建立一个清晰的选型框架。面对一个具体问题，你应该能在 30 秒内判断——\u003cstrong\u003e用 Automation、用 Workflow、还是用 Agent。\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 三种执行范式\u003c/h2\u003e\n\u003ch3\u003e2.1 Rule-based Automation\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：用预定义规则驱动的全自动执行。输入确定，规则确定，输出确定。\u003c/p\u003e\n\u003cp\u003e典型实现：if/else 逻辑、Rule Engine（Drools、Rete）、Cron Job、Event Trigger。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────┐\n│                 Rule-based Automation                    │\n│                                                         │\n│   Input ──→ [Rule Match] ──→ Action A                   │\n│                  │                                      │\n│                  ├──→ Action B                           │\n│                  │                                      │\n│                  └──→ Action C                           │\n│                                                         │\n│   特征：路径在编写时完全确定，运行时无决策               │\n│   类比：铁轨上的火车，轨道已铺好                         │\n└─────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e零运行时决策——所有分支在代码 / 规则编写时就已确定\u003c/li\u003e\n\u003cli\u003e确定性：相同输入永远产生相同输出\u003c/li\u003e\n\u003cli\u003e延迟极低（微秒到毫秒级）\u003c/li\u003e\n\u003cli\u003e可解释性最强——每一步都可以追溯到具体规则\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 典型的 Rule-based Automation\nclass AlertRule:\n    def __init__(self, metric: str, threshold: float, action: str):\n        self.metric = metric\n        self.threshold = threshold\n        self.action = action\n\nclass RuleEngine:\n    def __init__(self):\n        self.rules: list[AlertRule] = []\n\n    def add_rule(self, rule: AlertRule):\n        self.rules.append(rule)\n\n    def evaluate(self, metrics: dict[str, float]) -\u0026gt; list[str]:\n        \u0026quot;\u0026quot;\u0026quot;对每条指标做规则匹配，返回触发的动作列表\u0026quot;\u0026quot;\u0026quot;\n        actions = []\n        for rule in self.rules:\n            value = metrics.get(rule.metric)\n            if value is not None and value \u0026gt; rule.threshold:\n                actions.append(rule.action)\n        return actions\n\n# 使用\nengine = RuleEngine()\nengine.add_rule(AlertRule(\u0026quot;cpu_usage\u0026quot;, 90.0, \u0026quot;scale_up\u0026quot;))\nengine.add_rule(AlertRule(\u0026quot;error_rate\u0026quot;, 5.0, \u0026quot;page_oncall\u0026quot;))\nengine.add_rule(AlertRule(\u0026quot;disk_usage\u0026quot;, 85.0, \u0026quot;cleanup_logs\u0026quot;))\n\ntriggered = engine.evaluate({\u0026quot;cpu_usage\u0026quot;: 95.0, \u0026quot;error_rate\u0026quot;: 2.0})\n# → [\u0026quot;scale_up\u0026quot;]   — 完全确定，完全可预测\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.2 Workflow / DAG\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：预定义步骤的有序编排。步骤之间有依赖关系，可以有条件分支，但所有可能的路径在设计时已知。\u003c/p\u003e\n\u003cp\u003e典型实现：Airflow、Temporal、Prefect、Step Functions、BPMN Engine。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────┐\n│                    Workflow / DAG                        │\n│                                                         │\n│   Start ──→ [Step A] ──→ [Step B] ──┬──→ [Step C]      │\n│                                     │                   │\n│                                     └──→ [Step D]      │\n│                          │                    │         │\n│                          └────────┬───────────┘         │\n│                                   ▼                     │\n│                              [Step E] ──→ End           │\n│                                                         │\n│   特征：路径在设计时确定，运行时按条件选择分支           │\n│   类比：地铁线路图，站点和换乘规则预先设定               │\n└─────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e步骤预定义，依赖关系显式声明\u003c/li\u003e\n\u003cli\u003e有条件分支，但分支的数量和逻辑在设计时确定\u003c/li\u003e\n\u003cli\u003e支持重试、超时、补偿（Compensation）\u003c/li\u003e\n\u003cli\u003e可视化程度高——DAG 本身就是文档\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 典型的 Workflow / DAG 定义（伪代码，框架无关）\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, Callable\n\nclass StepStatus(Enum):\n    PENDING = \u0026quot;pending\u0026quot;\n    RUNNING = \u0026quot;running\u0026quot;\n    SUCCESS = \u0026quot;success\u0026quot;\n    FAILED = \u0026quot;failed\u0026quot;\n    SKIPPED = \u0026quot;skipped\u0026quot;\n\n@dataclass\nclass Step:\n    name: str\n    fn: Callable\n    depends_on: list[str] = field(default_factory=list)\n    condition: Callable | None = None  # 条件分支\n    retry_count: int = 3\n    timeout_seconds: int = 300\n\nclass DAGExecutor:\n    def __init__(self):\n        self.steps: dict[str, Step] = {}\n        self.results: dict[str, Any] = {}\n        self.status: dict[str, StepStatus] = {}\n\n    def add_step(self, step: Step):\n        self.steps[step.name] = step\n        self.status[step.name] = StepStatus.PENDING\n\n    def _can_run(self, step: Step) -\u0026gt; bool:\n        \u0026quot;\u0026quot;\u0026quot;检查依赖是否全部完成\u0026quot;\u0026quot;\u0026quot;\n        for dep in step.depends_on:\n            if self.status.get(dep) != StepStatus.SUCCESS:\n                return False\n        return True\n\n    def _should_run(self, step: Step) -\u0026gt; bool:\n        \u0026quot;\u0026quot;\u0026quot;检查条件分支\u0026quot;\u0026quot;\u0026quot;\n        if step.condition is None:\n            return True\n        return step.condition(self.results)\n\n    def run(self, initial_context: dict):\n        self.results.update(initial_context)\n        # 简化的拓扑排序执行（生产实现应支持并行）\n        remaining = set(self.steps.keys())\n        while remaining:\n            runnable = [\n                name for name in remaining\n                if self._can_run(self.steps[name])\n            ]\n            if not runnable:\n                raise RuntimeError(\u0026quot;DAG has unresolvable dependencies\u0026quot;)\n            for name in runnable:\n                step = self.steps[name]\n                remaining.remove(name)\n                if not self._should_run(step):\n                    self.status[name] = StepStatus.SKIPPED\n                    continue\n                self.status[name] = StepStatus.RUNNING\n                try:\n                    self.results[name] = step.fn(self.results)\n                    self.status[name] = StepStatus.SUCCESS\n                except Exception:\n                    self.status[name] = StepStatus.FAILED\n                    raise\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.3 Agent\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e定义\u003c/strong\u003e：LLM 驱动的动态决策执行。每一步做什么，由 LLM 在运行时根据当前状态决定。路径不确定，在执行前无法预知。\u003c/p\u003e\n\u003cp\u003e典型实现：ReAct Loop、LangGraph Agent、AutoGPT、自研 Agent Runtime。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────┐\n│                       Agent                             │\n│                                                         │\n│   Input ──→ [LLM: 观察+思考] ──→ [Tool A] ──┐          │\n│                     ▲                        │          │\n│                     │                        ▼          │\n│                     │            [LLM: 观察+思考]       │\n│                     │                  │     │          │\n│                     │         ┌────────┘     │          │\n│                     │         ▼              ▼          │\n│                     ├──── [Tool C]      [Tool B]        │\n│                     │         │              │          │\n│                     │         ▼              ▼          │\n│                     └── [LLM: 够了吗？] ──→ Output      │\n│                                                         │\n│   特征：路径在运行时动态生成，每一步由 LLM 决定         │\n│   类比：出租车司机，根据实时路况随时调整路线             │\n└─────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e运行时决策——下一步做什么由 LLM 在当前上下文中推理得出\u003c/li\u003e\n\u003cli\u003e非确定性：相同输入可能走不同路径（temperature \u0026gt; 0 时尤为明显）\u003c/li\u003e\n\u003cli\u003e能处理模糊、开放、未预见的输入\u003c/li\u003e\n\u003cli\u003e每一步决策都需要 LLM 推理，延迟和成本显著高于前两者\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 典型的 Agent Loop（极简实现）\nfrom typing import Any\n\nclass Tool:\n    def __init__(self, name: str, description: str, fn: callable):\n        self.name = name\n        self.description = description\n        self.fn = fn\n\nclass Agent:\n    def __init__(self, llm_client, tools: list[Tool], max_steps: int = 10):\n        self.llm = llm_client\n        self.tools = {t.name: t for t in tools}\n        self.max_steps = max_steps\n\n    def run(self, user_input: str) -\u0026gt; str:\n        messages = [{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_input}]\n        tool_descriptions = [\n            {\u0026quot;name\u0026quot;: t.name, \u0026quot;description\u0026quot;: t.description}\n            for t in self.tools.values()\n        ]\n\n        for step in range(self.max_steps):\n            # LLM 决定下一步：调用工具，还是直接回答\n            response = self.llm.chat(\n                messages=messages,\n                tools=tool_descriptions,\n            )\n\n            if response.is_final_answer:\n                return response.content\n\n            # LLM 选择了一个工具\n            tool_name = response.tool_call.name\n            tool_args = response.tool_call.arguments\n            tool_result = self.tools[tool_name].fn(**tool_args)\n\n            # 将工具结果加入上下文，进入下一轮循环\n            messages.append({\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: response.raw})\n            messages.append({\u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;, \u0026quot;content\u0026quot;: str(tool_result)})\n\n        return \u0026quot;达到最大步数限制，未能完成任务。\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意上面代码的关键区别：\u003cstrong\u003eAutomation 和 Workflow 的控制流是代码写死的，Agent 的控制流是 LLM 在运行时生成的。\u003c/strong\u003e 这是三者的本质差异。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. 决策维度分析\u003c/h2\u003e\n\u003ch3\u003e3.1 对比总览\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eRule-based Automation\u003c/th\u003e\n\u003cth\u003eWorkflow / DAG\u003c/th\u003e\n\u003cth\u003eAgent\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e确定性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e完全确定\u003c/td\u003e\n\u003ctd\u003e路径确定，结果依赖外部\u003c/td\u003e\n\u003ctd\u003e不确定\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e可解释性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e极强（规则可追溯）\u003c/td\u003e\n\u003ctd\u003e强（DAG 可视化）\u003c/td\u003e\n\u003ctd\u003e弱（LLM 是黑盒）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eμs - ms\u003c/td\u003e\n\u003ctd\u003ems - min（取决于步骤）\u003c/td\u003e\n\u003ctd\u003es - min（LLM 推理）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e单次成本\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e几乎为零\u003c/td\u003e\n\u003ctd\u003e低（计算资源）\u003c/td\u003e\n\u003ctd\u003e高（Token 费用）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e可靠性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e极高\u003c/td\u003e\n\u003ctd\u003e高（有重试/补偿）\u003c/td\u003e\n\u003ctd\u003e中等（LLM 可能幻觉）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e可观测性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e高（日志即文档）\u003c/td\u003e\n\u003ctd\u003e高（DAG 天然可视化）\u003c/td\u003e\n\u003ctd\u003e低（需要额外 Trace）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e灵活性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e低（新规则需改代码）\u003c/td\u003e\n\u003ctd\u003e中（新步骤需改 DAG）\u003c/td\u003e\n\u003ctd\u003e高（Prompt 即可调整）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e处理模糊输入\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不支持\u003c/td\u003e\n\u003ctd\u003e有限支持\u003c/td\u003e\n\u003ctd\u003e原生支持\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e开发复杂度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e3.2 逐维度展开\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e确定性 vs 不确定性\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是最重要的选型维度。问自己一个问题：\u003cstrong\u003e给定相同的输入，系统是否必须产生相同的输出？\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e如果答案是\u0026quot;必须\u0026quot;——不要用 Agent。Rule-based Automation 或 Workflow 是正确选择。\u003c/li\u003e\n\u003cli\u003e如果答案是\u0026quot;不一定，但结果需要在合理范围内\u0026quot;——Agent 可以考虑，但要加 Guardrail。\u003c/li\u003e\n\u003cli\u003e如果答案是\u0026quot;每次可以不同，只要合理就行\u0026quot;——Agent 是自然选择。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e金融交易、订单状态流转、计费逻辑——这些场景如果引入 Agent 的非确定性，后果不堪设想。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e可解释性\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e生产系统出了问题，你需要回答\u0026quot;为什么系统做了这个决策\u0026quot;。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRule Engine：直接查看匹配了哪条规则，一目了然。\u003c/li\u003e\n\u003cli\u003eWorkflow：查看 DAG 执行日志，哪个步骤走了哪个分支，完全透明。\u003c/li\u003e\n\u003cli\u003eAgent：LLM 的推理过程是一段自然语言（Chain of Thought），但它可能是事后合理化，并不一定反映真实的\u0026quot;推理过程\u0026quot;。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在合规要求高的领域（金融、医疗、法律），可解释性不是 nice-to-have，而是硬性要求。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e成本\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这一点经常被低估。以一个中等复杂度的任务为例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eRule Engine:  ~0 成本（CPU 时间可忽略）\nWorkflow:     ~$0.001（计算资源 + 存储）\nAgent:        ~$0.01 - $0.50（取决于步骤数和模型选择）\n              3 步 Agent × GPT-4 级别 ≈ 每次 $0.03-0.10\n              如果日调用量 100K，月成本 = $3,000 - $10,000\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e当你把 Agent 用在本该用 Rule Engine 解决的问题上，你是在用 100 倍的成本获得更差的可靠性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e可靠性\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRule Engine：只要规则正确，就永远正确。故障模式是规则覆盖不全。\u003c/li\u003e\n\u003cli\u003eWorkflow：支持重试、幂等、补偿事务。成熟的 Workflow Engine 可以做到 99.99% 可靠。\u003c/li\u003e\n\u003cli\u003eAgent：LLM 可能幻觉、可能选错工具、可能陷入循环。即使加了 Guardrail，端到端成功率通常在 85%-95%（复杂任务更低）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e可观测性\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRule Engine：每次执行记录匹配规则和动作，日志本身就是完整的审计轨迹。\u003c/li\u003e\n\u003cli\u003eWorkflow：DAG 执行引擎天然提供步骤级别的状态、耗时、输入输出。Airflow 的 UI 就是最好的例子。\u003c/li\u003e\n\u003cli\u003eAgent：你需要自己构建 Trace 系统——记录每一轮 LLM 的输入、输出、选择的工具、工具的返回值、Token 消耗。没有这些，Agent 在生产环境中就是一个黑盒。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e4. 场景分析\u003c/h2\u003e\n\u003cp\u003e抽象的对比不如具体场景有说服力。下面逐个分析。\u003c/p\u003e\n\u003ch3\u003e4.1 数据 ETL Pipeline → Workflow\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：每天从 3 个数据源抽取数据，清洗、转换、加载到数据仓库。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e选 Workflow 的理由\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e步骤完全确定：Extract → Transform → Load，不需要运行时决策\u003c/li\u003e\n\u003cli\u003e步骤间有明确的依赖关系：Transform 必须在 Extract 之后\u003c/li\u003e\n\u003cli\u003e需要精确的重试和失败补偿：某个数据源失败了，只重跑那个分支\u003c/li\u003e\n\u003cli\u003e需要调度：每天凌晨 3 点执行\u003c/li\u003e\n\u003cli\u003e需要回填（Backfill）：补跑历史数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e为什么不用 Agent\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003eETL 不需要\u0026quot;思考下一步做什么\u0026quot;——步骤是固定的。用 Agent 意味着每次运行都要花 Token 让 LLM \u0026quot;重新发现\u0026quot;这些固定步骤，纯属浪费。更危险的是，LLM 可能在某次运行中\u0026quot;创造性地\u0026quot;跳过某个步骤或改变转换逻辑。\u003c/p\u003e\n\u003ch3\u003e4.2 客服问答 → Agent\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：用户通过聊天窗口提问，系统需要理解意图、查询知识库、可能需要查订单、可能需要转人工。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e选 Agent 的理由\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e输入是自然语言，意图不确定，无法枚举所有可能\u003c/li\u003e\n\u003cli\u003e处理路径取决于用户说了什么——可能一步就能回答，也可能需要查 3 个系统\u003c/li\u003e\n\u003cli\u003e需要上下文理解和多轮对话能力\u003c/li\u003e\n\u003cli\u003e\u0026quot;足够好\u0026quot;的回答即可，不需要 100% 确定性\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e为什么不用 Workflow\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e你无法预定义所有可能的对话路径。用户可能问\u0026quot;我的订单到哪了\u0026quot;，也可能问\u0026quot;你们支持退款吗\u0026quot;，也可能在同一轮对话中先问订单再问退款政策。Workflow 的路径是编译期确定的，处理不了这种运行时的动态性。\u003c/p\u003e\n\u003ch3\u003e4.3 定时报表生成 → Automation\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：每周一早上 9 点，从数据库查询上周的销售数据，生成 Excel 报表，发送到指定邮箱。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e选 Automation 的理由\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e触发条件确定：Cron 定时\u003c/li\u003e\n\u003cli\u003e逻辑确定：SQL 查询 → 格式化 → 发送\u003c/li\u003e\n\u003cli\u003e不需要编排复杂依赖\u003c/li\u003e\n\u003cli\u003e不需要任何\u0026quot;智能\u0026quot;——SQL 和模板都是写死的\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e为什么不用 Workflow 或 Agent\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003eWorkflow 是大炮打蚊子——这里没有复杂的步骤依赖和分支。Agent 更是离谱——你不需要 LLM 来执行 \u003ccode\u003eSELECT SUM(amount) FROM orders WHERE date \u0026gt;= \u0026#39;2025-07-28\u0026#39;\u003c/code\u003e。\u003c/p\u003e\n\u003ch3\u003e4.4 代码审查助手 → Agent\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：PR 提交后，自动分析代码变更，给出审查意见：安全隐患、性能问题、风格建议。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e选 Agent 的理由\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e代码变更是非结构化的，无法穷举所有模式\u003c/li\u003e\n\u003cli\u003e需要\u0026quot;理解\u0026quot;代码语义，而非简单的模式匹配（静态分析工具已经覆盖了模式匹配的部分）\u003c/li\u003e\n\u003cli\u003e审查意见需要结合上下文（这个函数在项目中是怎么用的？改动会影响什么？）\u003c/li\u003e\n\u003cli\u003eAgent 可以调用多种工具：读取文件、运行测试、查看 Git 历史\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e为什么不用 Rule Engine\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003eRule Engine 只能匹配预定义模式（如\u0026quot;函数超过 100 行\u0026quot;），无法理解语义层面的问题（如\u0026quot;这个 API 调用没有处理超时\u0026quot;）。实际上，最好的方案是 \u003cstrong\u003eRule Engine + Agent\u003c/strong\u003e——先用 Linter/SAST 做确定性检查，再用 Agent 做语义级审查。\u003c/p\u003e\n\u003ch3\u003e4.5 订单状态流转 → Workflow\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：电商订单从创建到完成的状态机——待支付 → 已支付 → 拣货中 → 已发货 → 已签收 → 已完成。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e选 Workflow 的理由\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e状态和转换规则完全确定：已支付才能拣货，已发货才能签收\u003c/li\u003e\n\u003cli\u003e每个状态转换都有明确的触发条件（支付回调、物流推送）\u003c/li\u003e\n\u003cli\u003e需要事务保证：状态转换必须原子性，不能出现\u0026quot;钱扣了但订单还是待支付\u0026quot;\u003c/li\u003e\n\u003cli\u003e需要补偿机制：支付超时需要自动取消\u003c/li\u003e\n\u003cli\u003e0 容忍非确定性——用户的钱不能有任何模糊\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e为什么不用 Agent\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e这个问题需要反复强调：\u003cstrong\u003e涉及金钱和状态一致性的流程，绝对不能用 Agent。\u003c/strong\u003e LLM 的幻觉在这里不是\u0026quot;回答不太准确\u0026quot;，而是\u0026quot;用户的钱没了但订单没更新\u0026quot;。\u003c/p\u003e\n\u003ch3\u003e4.6 智能运维（AIOps）→ 混合架构\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：监控告警触发后，自动诊断根因并执行修复。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e为什么需要混合\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e这个场景天然分为确定性部分和不确定性部分——\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e确定性部分（Automation）：告警规则匹配、阈值判断、常见故障的自动修复（CPU 高 → 扩容，磁盘满 → 清理日志）\u003c/li\u003e\n\u003cli\u003e不确定性部分（Agent）：复杂故障的根因分析——Agent 可以查看日志、查询指标、检查最近的部署变更，综合判断根因\u003c/li\u003e\n\u003cli\u003e编排部分（Workflow）：整个处理流程的骨架——告警接收 → 去重 → 分级 → 自动修复 / 智能诊断 → 通知\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode\u003e告警触发\n   │\n   ▼\n[Automation: 告警去重 + 分级]\n   │\n   ├──→ P4/P3 已知模式 ──→ [Automation: 自动修复]\n   │                              │\n   │                              ▼\n   │                         [通知 Oncall]\n   │\n   └──→ P2/P1 或未知模式 ──→ [Agent: 根因分析]\n                                   │\n                                   ├──→ 找到根因 ──→ [Automation: 执行修复]\n                                   │\n                                   └──→ 无法确定 ──→ [升级到人工]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这才是 Agent 的正确用法——\u003cstrong\u003e只在真正需要\u0026quot;智能\u0026quot;的环节使用 Agent，其余部分用更可靠、更便宜的范式处理。\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 混合架构：三者如何共存\u003c/h2\u003e\n\u003cp\u003e真实的生产系统很少只用一种范式。更常见的模式是：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────────────┐\n│                    混合架构全景                                │\n│                                                              │\n│  ┌──────────────────────────────────────────────────┐        │\n│  │              Workflow / DAG（骨架层）              │        │\n│  │                                                  │        │\n│  │  Step 1          Step 2          Step 3          │        │\n│  │  ┌──────────┐   ┌──────────┐   ┌──────────┐     │        │\n│  │  │Automation│──→│  Agent   │──→│Automation│     │        │\n│  │  │数据预处理│   │语义分析  │   │结果写入  │     │        │\n│  │  └──────────┘   └──────────┘   └──────────┘     │        │\n│  │       │              │              │            │        │\n│  │       ▼              ▼              ▼            │        │\n│  │  确定性操作     LLM 推理       确定性操作        │        │\n│  │  延迟: 10ms    延迟: 2-5s     延迟: 50ms        │        │\n│  │  成本: ~0      成本: $0.02    成本: ~0           │        │\n│  └──────────────────────────────────────────────────┘        │\n│                                                              │\n│  设计原则：                                                  │\n│  1. Workflow 负责编排和容错（重试、超时、补偿）              │\n│  2. Automation 处理所有确定性步骤                            │\n│  3. Agent 只出现在需要\u0026quot;理解\u0026quot;和\u0026quot;推理\u0026quot;的节点                  │\n│  4. Agent 的输出经过验证后才进入下一步                       │\n└──────────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.1 设计原则\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原则一：Agent 是 Workflow 的节点，不是整个 Workflow\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个常见的错误是让 Agent 控制整个流程——从数据获取到处理到存储全部由 Agent 决定。正确的做法是：Workflow 定义骨架（步骤顺序、依赖关系、容错策略），Agent 只负责其中需要推理的那一步。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 错误做法：让 Agent 控制整个流程\nagent.run(\u0026quot;从数据库读取用户评论，分析情感，把结果写回数据库\u0026quot;)\n# Agent 可能：用错 SQL、忘记写回、写入格式错误...\n\n# 正确做法：Workflow 控制流程，Agent 只做推理\ndef step_1_extract(ctx):\n    \u0026quot;\u0026quot;\u0026quot;确定性步骤：用固定 SQL 读取数据\u0026quot;\u0026quot;\u0026quot;\n    return db.query(\u0026quot;SELECT id, comment FROM reviews WHERE date = %s\u0026quot;, ctx[\u0026quot;date\u0026quot;])\n\ndef step_2_analyze(ctx):\n    \u0026quot;\u0026quot;\u0026quot;Agent 步骤：对每条评论做情感分析\u0026quot;\u0026quot;\u0026quot;\n    results = []\n    for review in ctx[\u0026quot;step_1_extract\u0026quot;]:\n        sentiment = agent.run(\n            f\u0026quot;分析以下评论的情感倾向(positive/negative/neutral):\\n{review[\u0026#39;comment\u0026#39;]}\u0026quot;\n        )\n        results.append({\u0026quot;id\u0026quot;: review[\u0026quot;id\u0026quot;], \u0026quot;sentiment\u0026quot;: sentiment})\n    return results\n\ndef step_3_load(ctx):\n    \u0026quot;\u0026quot;\u0026quot;确定性步骤：用固定逻辑写回数据库\u0026quot;\u0026quot;\u0026quot;\n    for item in ctx[\u0026quot;step_2_analyze\u0026quot;]:\n        db.execute(\n            \u0026quot;UPDATE reviews SET sentiment = %s WHERE id = %s\u0026quot;,\n            (item[\u0026quot;sentiment\u0026quot;], item[\u0026quot;id\u0026quot;])\n        )\n\n# Workflow 定义\nworkflow.add_step(Step(\u0026quot;extract\u0026quot;, step_1_extract))\nworkflow.add_step(Step(\u0026quot;analyze\u0026quot;, step_2_analyze, depends_on=[\u0026quot;extract\u0026quot;]))\nworkflow.add_step(Step(\u0026quot;load\u0026quot;, step_3_load, depends_on=[\u0026quot;analyze\u0026quot;]))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e原则二：Agent 的输出必须经过验证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAgent 的输出是非确定性的。在混合架构中，Agent 节点和下游确定性节点之间，必须有一个验证层。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef step_2_analyze_with_validation(ctx):\n    \u0026quot;\u0026quot;\u0026quot;Agent 步骤 + 输出验证\u0026quot;\u0026quot;\u0026quot;\n    VALID_SENTIMENTS = {\u0026quot;positive\u0026quot;, \u0026quot;negative\u0026quot;, \u0026quot;neutral\u0026quot;}\n    results = []\n    for review in ctx[\u0026quot;step_1_extract\u0026quot;]:\n        sentiment = agent.run(f\u0026quot;分析情感倾向: {review[\u0026#39;comment\u0026#39;]}\u0026quot;)\n        # 验证 Agent 输出\n        sentiment = sentiment.strip().lower()\n        if sentiment not in VALID_SENTIMENTS:\n            sentiment = \u0026quot;neutral\u0026quot;  # fallback\n            log.warning(f\u0026quot;Agent 返回了无效的情感值，已 fallback: review_id={review[\u0026#39;id\u0026#39;]}\u0026quot;)\n        results.append({\u0026quot;id\u0026quot;: review[\u0026quot;id\u0026quot;], \u0026quot;sentiment\u0026quot;: sentiment})\n    return results\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e原则三：确定性部分永远优先用 Automation\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果一个步骤的输入输出可以完全预定义，就不要用 Agent。这不是技术保守，而是工程理性——用最简单的工具解决问题，把复杂性预算留给真正需要的地方。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. Agent 的隐性成本\u003c/h2\u003e\n\u003cp\u003e这一节讲的是大部分\u0026quot;Agent 教程\u0026quot;不会告诉你的东西。\u003c/p\u003e\n\u003ch3\u003e6.1 Token 成本\u003c/h3\u003e\n\u003cp\u003eAgent 的每一步决策都需要调用 LLM。一个 5 步 Agent 执行一次任务的 Token 消耗：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e第 1 步: System Prompt (500) + User Input (200) + Response (300)    = 1,000 tokens\n第 2 步: 上一轮上下文 (1,000) + Tool Result (500) + Response (400)  = 1,900 tokens\n第 3 步: 上一轮上下文 (1,900) + Tool Result (300) + Response (350)  = 2,550 tokens\n第 4 步: 上一轮上下文 (2,550) + Tool Result (800) + Response (400)  = 3,750 tokens\n第 5 步: 上一轮上下文 (3,750) + Tool Result (200) + Response (500)  = 4,450 tokens\n                                                          ─────────────────────\n                                                          总计: ~13,650 tokens\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意上下文是累积的——每一步都要重新发送之前所有的对话历史。这意味着 \u003cstrong\u003eToken 消耗是超线性增长的\u003c/strong\u003e。步骤越多，后期每一步的成本越高。\u003c/p\u003e\n\u003cp\u003e以 GPT-4o 为例（$2.5/1M input, $10/1M output），上面这个 5 步 Agent 单次执行成本约 $0.03-0.05。看似不多，但如果日调用量 10 万次，月成本就是 $90,000-$150,000。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e优化策略\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上下文压缩：每 N 步对历史做一次摘要\u003c/li\u003e\n\u003cli\u003e选择合适的模型：简单决策用小模型，关键决策用大模型\u003c/li\u003e\n\u003cli\u003e缓存：对相同输入的 Agent 结果做缓存（注意非确定性问题）\u003c/li\u003e\n\u003cli\u003e减少 Agent 步骤：通过更好的 Prompt 和工具设计，减少所需的推理轮次\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e6.2 延迟\u003c/h3\u003e\n\u003cp\u003eLLM 的推理延迟通常在 500ms-5s 之间（取决于模型和输出长度）。一个 5 步 Agent 的端到端延迟：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e5 步 × 平均 1.5s/步 = 7.5s\n\n加上工具调用时间（网络请求、数据库查询等），实际延迟可能在 10-15s。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e对比：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRule Engine 处理同样的逻辑：\u0026lt; 10ms\u003c/li\u003e\n\u003cli\u003eWorkflow 执行 5 个确定性步骤：\u0026lt; 500ms\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e在延迟敏感的场景（如支付、交易、实时推荐），Agent 的延迟是不可接受的。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003e6.3 不可预测性\u003c/h3\u003e\n\u003cp\u003e这是 Agent 最被低估的问题。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 同样的输入，Agent 可能走出完全不同的路径\n\n# 第一次运行\n# Step 1: 调用 search_database → 找到 3 条记录\n# Step 2: 调用 analyze_data → 生成分析\n# Step 3: 返回结果\n# 总计: 3 步, 耗时 4s, 成本 $0.02\n\n# 第二次运行（完全相同的输入）\n# Step 1: 调用 search_database → 找到 3 条记录\n# Step 2: 调用 search_web → 想找更多信息（为什么？LLM 这次觉得不够）\n# Step 3: 调用 search_database → 用新的关键词再查一次\n# Step 4: 调用 analyze_data → 生成分析\n# Step 5: 觉得分析不够好，调用 analyze_data → 重新生成\n# Step 6: 返回结果\n# 总计: 6 步, 耗时 10s, 成本 $0.06\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这意味着你\u003cstrong\u003e无法预测 Agent 的执行时间和成本\u003c/strong\u003e。在需要做容量规划和 SLA 承诺的生产系统中，这是一个严重的问题。\u003c/p\u003e\n\u003ch3\u003e6.4 调试困难\u003c/h3\u003e\n\u003cp\u003e确定性系统的 Bug 可以精确复现：相同的输入 + 相同的代码 = 相同的 Bug。\u003c/p\u003e\n\u003cp\u003eAgent 不行。因为：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eLLM 的输出本身带有随机性（即使 temperature=0，不同批次推理也可能有微小差异）\u003c/li\u003e\n\u003cli\u003e工具调用的结果可能随时间变化（数据库内容变了、API 返回变了）\u003c/li\u003e\n\u003cli\u003e上下文窗口中的信息累积，前几步的微小差异会被放大\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e调试 Agent 的正确做法\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e完整记录每一步的输入（包括完整的 messages 列表）和输出\u003c/li\u003e\n\u003cli\u003e记录每次工具调用的参数和返回值\u003c/li\u003e\n\u003cli\u003e记录 Token 使用量和延迟\u003c/li\u003e\n\u003cli\u003e支持\u0026quot;回放\u0026quot;——用记录的数据重新走一遍流程（但要注意，即使相同输入，LLM 也可能给出不同输出）\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 选型决策树\u003c/h2\u003e\n\u003cp\u003e面对一个具体需求，按以下流程判断：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                    你的任务需要\u0026quot;理解\u0026quot;自然语言\n                    或处理模糊/开放式输入吗？\n                           │\n                    ┌──────┴──────┐\n                    │             │\n                   Yes           No\n                    │             │\n                    ▼             ▼\n             结果需要 100%     任务步骤之间有\n             确定性吗？        复杂依赖关系吗？\n                │                    │\n          ┌─────┴─────┐        ┌─────┴─────┐\n          │           │        │           │\n         Yes         No       Yes         No\n          │           │        │           │\n          ▼           ▼        ▼           ▼\n      先用规则     ┌──────┐  Workflow    Automation\n      处理能处     │Agent │  / DAG      (Rule/Cron)\n      理的部分     └──┬───┘\n      用 Agent        │\n      处理剩余        ▼\n      (混合架构)   可以接受 $0.01-0.10/次\n                   的成本和 2-10s 的延迟吗？\n                          │\n                    ┌─────┴─────┐\n                    │           │\n                   Yes         No\n                    │           │\n                    ▼           ▼\n                  Agent     重新审视需求：\n                            能否拆分为\n                            确定性 + 模糊性部分？\n                            → 混合架构\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e速查表\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e如果你的任务是...\u003c/th\u003e\n\u003cth\u003e推荐范式\u003c/th\u003e\n\u003cth\u003e理由\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e固定逻辑 + 定时触发\u003c/td\u003e\n\u003ctd\u003eAutomation\u003c/td\u003e\n\u003ctd\u003e无需编排，无需推理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e多步骤 + 有依赖 + 确定性\u003c/td\u003e\n\u003ctd\u003eWorkflow\u003c/td\u003e\n\u003ctd\u003e需要编排，不需要推理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e理解自然语言 + 动态决策\u003c/td\u003e\n\u003ctd\u003eAgent\u003c/td\u003e\n\u003ctd\u003e需要推理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e大部分确定 + 少量模糊\u003c/td\u003e\n\u003ctd\u003eWorkflow + Agent 节点\u003c/td\u003e\n\u003ctd\u003e编排确定部分，推理模糊部分\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e简单触发 + 复杂诊断\u003c/td\u003e\n\u003ctd\u003eAutomation + Agent\u003c/td\u003e\n\u003ctd\u003e触发用规则，诊断用推理\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 常见误区\u003c/h2\u003e\n\u003cp\u003e在结束之前，总结几个我在实际项目中反复见到的选型错误。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e误区一：因为\u0026quot;想用 AI\u0026quot;而选 Agent\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e技术选型应该从问题出发，不是从解决方案出发。\u0026quot;我们想用 AI\u0026quot; 不是选 Agent 的理由，\u0026quot;用户输入是自然语言且意图不可穷举\u0026quot; 才是。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e误区二：用 Agent 替代状态机\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e订单流转、审批流程、工单生命周期——这些有限状态机（FSM）问题有成熟的解决方案。把它们交给 Agent 不会让系统更智能，只会让它更不可靠。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e误区三：Agent 做完所有事\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e让 Agent 既负责决策又负责执行。正确做法是：Agent 只负责\u0026quot;决定做什么\u0026quot;（What），具体的执行（How）交给确定性系统。例如 Agent 决定\u0026quot;需要给用户退款\u0026quot;，但实际调用退款 API 的逻辑是固定的代码，不是 Agent 自己拼 HTTP 请求。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e误区四：忽视 Agent 的失败模式\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAgent 会失败。它会幻觉、会陷入循环、会选错工具、会超时。你的系统设计必须考虑：Agent 失败了怎么办？有没有 Fallback？有没有人工兜底？最大重试次数是多少？\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 总结\u003c/h2\u003e\n\u003cp\u003e回到开篇的问题：你的问题，真的需要 Agent 吗？\u003c/p\u003e\n\u003cp\u003e三条准则：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e能用规则解决的，不要用 Workflow；能用 Workflow 解决的，不要用 Agent。\u003c/strong\u003e 选择复杂度最低的范式，降低的是长期维护成本。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAgent 的正确位置是\u0026quot;最后一英里的模糊性\u0026quot;。\u003c/strong\u003e 在混合架构中，让确定性系统处理 80% 的工作，Agent 只处理那 20% 需要\u0026quot;理解\u0026quot;和\u0026quot;推理\u0026quot;的部分。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAgent 是有代价的，而且代价比你想象的高。\u003c/strong\u003e Token 成本、延迟、不可预测性、调试难度——这些隐性成本在规模化后会成为真实的痛点。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e选对抽象，才是真正的技术判断力。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 03 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/02-From%20Prompt%20to%20Agent\"\u003e02 | From Prompt to Agent\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/04-The%20Agent%20Control%20Loop\"\u003e04 | The Agent Control Loop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"1a:Td4a2,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eTool Calling Deep Dive: 让 LLM 成为可编程接口\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这是 Agentic 系列的第 05 篇。在前几篇中我们建立了 Agent 的概念模型、控制循环、以及 Agent 与 Workflow 的边界。本篇聚焦于 Agent 能力的核心支点——Tool Calling。\u003c/p\u003e\n\u003cp\u003eTool Calling 不是\u0026quot;让 AI 调 API\u0026quot;这么简单。它是 LLM 从 \u003cstrong\u003eText-in/Text-out 的生成模型\u003c/strong\u003e 变成 \u003cstrong\u003e可编程接口\u003c/strong\u003e 的关键转折点。理解它的工作原理、设计约束和工程实践，是构建任何 Agentic 系统的前提。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么 Tool Calling 是关键转折点\u003c/h2\u003e\n\u003cp\u003e一个纯粹的 LLM 只能做一件事：接受文本，生成文本。它无法查询数据库、无法读取文件、无法发送邮件、无法获取实时天气。它的知识冻结在训练数据的截止日期，它的能力边界就是 token 序列的排列组合。\u003c/p\u003e\n\u003cp\u003eTool Calling 改变了这一切。\u003c/p\u003e\n\u003cp\u003e它的本质不是\u0026quot;让 LLM 调用工具\u0026quot;，而是 \u003cstrong\u003e让 LLM 生成结构化的调用意图，由外部运行时代为执行\u003c/strong\u003e。这个区分至关重要——LLM 从未真正\u0026quot;执行\u0026quot;过任何工具，它只是学会了在恰当的时机，输出一段符合约定格式的 JSON，表达\u0026quot;我需要调用某个工具，参数是这些\u0026quot;。\u003c/p\u003e\n\u003cp\u003e这意味着：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLM 变成了一个 \u003cstrong\u003e决策引擎\u003c/strong\u003e：决定调用什么、传什么参数\u003c/li\u003e\n\u003cli\u003eRuntime 变成了一个 \u003cstrong\u003e执行引擎\u003c/strong\u003e：负责真正的 I/O 操作\u003c/li\u003e\n\u003cli\u003e两者之间的契约是 \u003cstrong\u003eJSON Schema\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这种分离，让 LLM 从一个封闭的文本生成器，变成了一个可以与外部世界交互的可编程接口。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. Tool Calling 的工作原理\u003c/h2\u003e\n\u003ch3\u003e2.1 完整流程\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────────────────────┐\n│                    Tool Calling 完整序列图                            │\n└──────────────────────────────────────────────────────────────────────┘\n\n  User            LLM (API)          Runtime           Tool (Function)\n   │                 │                  │                     │\n   │  \u0026quot;北京今天天气\u0026quot;  │                  │                     │\n   ├────────────────\u0026gt;│                  │                     │\n   │                 │                  │                     │\n   │                 │  ┌─────────────┐ │                     │\n   │                 │  │ 推理:       │ │                     │\n   │                 │  │ 用户想查天气 │ │                     │\n   │                 │  │ 需要调用    │ │                     │\n   │                 │  │ get_weather │ │                     │\n   │                 │  └─────────────┘ │                     │\n   │                 │                  │                     │\n   │                 │  Tool Call JSON  │                     │\n   │                 │ ────────────────\u0026gt;│                     │\n   │                 │  {               │                     │\n   │                 │   \u0026quot;name\u0026quot;:        │                     │\n   │                 │    \u0026quot;get_weather\u0026quot; │                     │\n   │                 │   \u0026quot;arguments\u0026quot;:   │                     │\n   │                 │    {\u0026quot;city\u0026quot;:      │                     │\n   │                 │     \u0026quot;北京\u0026quot;}      │                     │\n   │                 │  }               │                     │\n   │                 │                  │  get_weather(\u0026quot;北京\u0026quot;) │\n   │                 │                  ├────────────────────\u0026gt;│\n   │                 │                  │                     │\n   │                 │                  │  {\u0026quot;temp\u0026quot;: 28,       │\n   │                 │                  │   \u0026quot;condition\u0026quot;:      │\n   │                 │                  │   \u0026quot;晴\u0026quot;}              │\n   │                 │                  │\u0026lt;────────────────────┤\n   │                 │                  │                     │\n   │                 │  Tool Result     │                     │\n   │                 │ \u0026lt;────────────────│                     │\n   │                 │                  │                     │\n   │                 │  ┌─────────────┐ │                     │\n   │                 │  │ 推理:       │ │                     │\n   │                 │  │ 根据工具返回 │ │                     │\n   │                 │  │ 组织回答    │ │                     │\n   │                 │  └─────────────┘ │                     │\n   │                 │                  │                     │\n   │ \u0026quot;北京今天28°C,晴\u0026quot;│                  │                     │\n   │\u0026lt;────────────────│                  │                     │\n   │                 │                  │                     │\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.2 关键洞察\u003c/h3\u003e\n\u003cp\u003e从上面的序列图中，可以提炼出几个核心事实：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLLM 发起两次推理\u003c/strong\u003e。第一次决定是否调用工具、调用哪个、传什么参数；第二次基于工具返回的结果生成最终回答。这意味着每次 Tool Calling 至少消耗两轮 LLM 调用的 token。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLLM 的输出不是自然语言，而是结构化 JSON\u003c/strong\u003e。这是模型经过专门训练（fine-tuning）才获得的能力。并非所有 LLM 都支持 Tool Calling——它需要模型在训练阶段就学会\u0026quot;在特定上下文下输出 JSON 而非自然语言\u0026quot;。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eRuntime 是不可或缺的中间层\u003c/strong\u003e。它负责：解析 LLM 返回的 Tool Call、校验参数、路由到正确的函数、执行函数、收集结果、将结果注入下一轮对话。没有 Runtime，Tool Calling 就是一段无人执行的 JSON。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e整个过程对用户透明\u003c/strong\u003e。用户看到的只是\u0026quot;问了一个问题，得到了回答\u0026quot;。中间的 Tool Call 调度过程完全由系统内部完成。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e3. JSON Schema 作为契约\u003c/h2\u003e\n\u003ch3\u003e3.1 工具定义的结构\u003c/h3\u003e\n\u003cp\u003e每个工具的定义由三部分组成：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003etool_definition = {\n    \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n    \u0026quot;function\u0026quot;: {\n        \u0026quot;name\u0026quot;: \u0026quot;get_weather\u0026quot;,          # 工具的唯一标识\n        \u0026quot;description\u0026quot;: \u0026quot;...\u0026quot;,           # 给 LLM 看的\u0026quot;接口文档\u0026quot;\n        \u0026quot;parameters\u0026quot;: {                 # JSON Schema 格式的参数约束\n            \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n            \u0026quot;properties\u0026quot;: {\n                \u0026quot;city\u0026quot;: {\n                    \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                    \u0026quot;description\u0026quot;: \u0026quot;城市名称，如 \u0026#39;北京\u0026#39;、\u0026#39;上海\u0026#39;\u0026quot;\n                }\n            },\n            \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;]\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这里的 \u003ccode\u003eparameters\u003c/code\u003e 遵循 JSON Schema 规范（Draft 2020-12 子集），它不仅定义了参数的类型，还定义了参数的约束、默认值、枚举范围等。JSON Schema 就是 LLM 与 Runtime 之间的 \u003cstrong\u003e契约\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e3.2 好的描述 vs 差的描述\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003edescription\u003c/code\u003e 是整个工具定义中最容易被低估的字段。它不是给人类看的注释，而是 \u003cstrong\u003e给 LLM 看的接口文档\u003c/strong\u003e。LLM 完全依赖 description 来决定是否调用这个工具、以及如何填充参数。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e差的描述：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e{\n    \u0026quot;name\u0026quot;: \u0026quot;query_db\u0026quot;,\n    \u0026quot;description\u0026quot;: \u0026quot;查询数据库\u0026quot;,          # 太模糊：查什么数据库？返回什么？\n    \u0026quot;parameters\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;q\u0026quot;: {                        # 参数名不直观\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\n            }\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e好的描述：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e{\n    \u0026quot;name\u0026quot;: \u0026quot;query_user_orders\u0026quot;,\n    \u0026quot;description\u0026quot;: (\n        \u0026quot;根据用户 ID 查询该用户的历史订单列表。\u0026quot;\n        \u0026quot;返回最近 30 天内的订单，包含订单号、金额、状态。\u0026quot;\n        \u0026quot;如果用户不存在，返回空列表。\u0026quot;\n        \u0026quot;不支持模糊查询，user_id 必须精确匹配。\u0026quot;\n    ),\n    \u0026quot;parameters\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;user_id\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;用户的唯一标识符，格式为 \u0026#39;U\u0026#39; + 8位数字，如 \u0026#39;U00012345\u0026#39;\u0026quot;\n            },\n            \u0026quot;status_filter\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;all\u0026quot;, \u0026quot;pending\u0026quot;, \u0026quot;completed\u0026quot;, \u0026quot;cancelled\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;按订单状态过滤，默认返回所有状态的订单\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;user_id\u0026quot;]\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e两者之间的差异在于：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e差的描述\u003c/th\u003e\n\u003cth\u003e好的描述\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e功能边界\u003c/td\u003e\n\u003ctd\u003e不清楚能做什么\u003c/td\u003e\n\u003ctd\u003e明确说明查询范围和返回内容\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e参数语义\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eq\u003c/code\u003e 是什么？\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003euser_id\u003c/code\u003e 含义清晰，且给出格式示例\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e约束条件\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e明确说明不支持模糊查询\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e异常行为\u003c/td\u003e\n\u003ctd\u003e未提及\u003c/td\u003e\n\u003ctd\u003e说明了用户不存在时的返回\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e枚举约束\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e用 \u003ccode\u003eenum\u003c/code\u003e 限定合法值\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e3.3 参数设计原则\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e简单优先\u003c/strong\u003e：参数数量尽量少。一个工具如果需要 10 个参数，说明它的职责太大，应该拆分。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e类型明确\u003c/strong\u003e：用 \u003ccode\u003eenum\u003c/code\u003e 约束离散值，用 \u003ccode\u003epattern\u003c/code\u003e 约束格式，用 \u003ccode\u003eminimum\u003c/code\u003e/\u003ccode\u003emaximum\u003c/code\u003e 约束数值范围。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e必选与可选分明\u003c/strong\u003e：\u003ccode\u003erequired\u003c/code\u003e 字段只放真正必须的参数，可选参数给默认值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e命名即文档\u003c/strong\u003e：\u003ccode\u003euser_id\u003c/code\u003e 比 \u003ccode\u003euid\u003c/code\u003e 好，\u003ccode\u003estart_date\u003c/code\u003e 比 \u003ccode\u003esd\u003c/code\u003e 好。LLM 会从参数名推断语义。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e避免嵌套过深\u003c/strong\u003e：LLM 生成深层嵌套 JSON 的准确率会显著下降。尽量用扁平结构。\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Structured Output vs Free-form Output\u003c/h2\u003e\n\u003ch3\u003e4.1 为什么结构化输出更可靠\u003c/h3\u003e\n\u003cp\u003e在 Tool Calling 出现之前，让 LLM 调用工具的常见做法是：在 Prompt 中要求 LLM \u0026quot;用特定格式输出\u0026quot;，然后用正则或字符串解析提取调用意图。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# 旧做法（Prompt Hacking）\n请用以下格式回答：\nAction: \u0026lt;工具名\u0026gt;\nAction Input: \u0026lt;参数 JSON\u0026gt;\n\n# LLM 可能的输出（不可靠）\n\u0026quot;我觉得应该查一下天气。Action: get_weather Action Input: {\u0026quot;city\u0026quot;: \u0026quot;北京\u0026quot;}\u0026quot;\n                       ^^ 前面混入了自然语言，解析会出错\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这种方式的根本问题是：LLM 的输出是 \u003cstrong\u003e非确定性的自由文本\u003c/strong\u003e，它可能在格式中混入自然语言、遗漏字段、搞错 JSON 语法。\u003c/p\u003e\n\u003cp\u003eStructured Output（结构化输出）通过 \u003cstrong\u003e约束解码（Constrained Decoding）\u003c/strong\u003e 从根本上解决了这个问题。模型在生成 token 时，解码器会强制输出符合预定义 JSON Schema 的 token 序列，从而保证输出 100% 可解析。\u003c/p\u003e\n\u003ch3\u003e4.2 三种机制的区别\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e机制\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e可靠性\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eJSON Mode\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e告诉模型\u0026quot;输出必须是合法 JSON\u0026quot;，但不约束 schema\u003c/td\u003e\n\u003ctd\u003e中等。JSON 语法正确，但字段可能不对\u003c/td\u003e\n\u003ctd\u003e简单的数据提取\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFunction Calling / Tool Use\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e模型经过 fine-tuning，能在特定上下文下输出 tool call 结构\u003c/td\u003e\n\u003ctd\u003e高。模型专门训练过\u003c/td\u003e\n\u003ctd\u003eAgent 工具调用\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eStructured Output\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e约束解码 + JSON Schema 验证，输出严格匹配 schema\u003c/td\u003e\n\u003ctd\u003e极高。解码层面保证\u003c/td\u003e\n\u003ctd\u003e需要严格 schema 的场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e4.3 各大模型的实现差异\u003c/h3\u003e\n\u003cp\u003e不同模型提供商对 Tool Calling 的 API 设计不尽相同，但核心思想一致：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e（GPT-4 系列）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 \u003ccode\u003etools\u003c/code\u003e 参数传递工具定义\u003c/li\u003e\n\u003cli\u003e返回 \u003ccode\u003etool_calls\u003c/code\u003e 数组，支持并行调用\u003c/li\u003e\n\u003cli\u003e支持 \u003ccode\u003estrict: true\u003c/code\u003e 开启 Structured Output 模式\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAnthropic\u003c/strong\u003e（Claude 系列）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 \u003ccode\u003etools\u003c/code\u003e 参数传递工具定义\u003c/li\u003e\n\u003cli\u003eTool Call 以 \u003ccode\u003etool_use\u003c/code\u003e content block 返回\u003c/li\u003e\n\u003cli\u003eTool 结果以 \u003ccode\u003etool_result\u003c/code\u003e content block 传回\u003c/li\u003e\n\u003cli\u003e原生支持并行工具调用\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eGoogle\u003c/strong\u003e（Gemini 系列）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 \u003ccode\u003etools\u003c/code\u003e + \u003ccode\u003efunction_declarations\u003c/code\u003e 结构\u003c/li\u003e\n\u003cli\u003e支持 \u003ccode\u003efunction_calling_config\u003c/code\u003e 控制调用模式（AUTO / ANY / NONE）\u003c/li\u003e\n\u003cli\u003e返回 \u003ccode\u003efunction_call\u003c/code\u003e part\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e虽然 API 格式不同，但抽象层面是一致的：\u003cstrong\u003e定义工具 → LLM 决定调用 → 返回结构化调用请求 → 外部执行 → 结果回传\u003c/strong\u003e。这也是为什么我们强调框架无关的原理理解——API 会变，原理不会。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 工具注册与发现（Tool Registry）\u003c/h2\u003e\n\u003ch3\u003e5.1 静态注册\u003c/h3\u003e\n\u003cp\u003e最简单的方式是在代码中硬编码工具列表：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eTOOLS = [\n    get_weather_tool,\n    query_db_tool,\n    send_email_tool,\n]\n\nresponse = client.chat.completions.create(\n    model=\u0026quot;gpt-4\u0026quot;,\n    messages=messages,\n    tools=TOOLS,\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e优点是简单直接，缺点是每次新增或修改工具都需要改代码、重新部署。适合工具数量少且稳定的场景。\u003c/p\u003e\n\u003ch3\u003e5.2 动态注册\u003c/h3\u003e\n\u003cp\u003e当工具数量增多或需要根据上下文动态调整时，需要一个 Tool Registry：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌────────────────────────────────────────────────┐\n│                Tool Registry                    │\n│                                                │\n│  ┌──────────┐  ┌──────────┐  ┌──────────┐     │\n│  │ weather  │  │ database │  │  email   │     │\n│  │  tool    │  │  tool    │  │  tool    │     │\n│  └──────────┘  └──────────┘  └──────────┘     │\n│  ┌──────────┐  ┌──────────┐                    │\n│  │  calc    │  │   file   │                    │\n│  │  tool    │  │  tool    │                    │\n│  └──────────┘  └──────────┘                    │\n│                                                │\n│  register(tool) / unregister(name)             │\n│  get_tools(filter?) -\u0026gt; List[Tool]              │\n│  get_tool(name) -\u0026gt; Tool                        │\n│  get_definitions() -\u0026gt; List[Dict]               │\n└────────────────────────────────────────────────┘\n         │\n         │  get_definitions()\n         ▼\n   ┌───────────┐     tools=[...]     ┌───────────┐\n   │  Runtime   │ ──────────────────\u0026gt; │  LLM API  │\n   └───────────┘                     └───────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.3 工具选择问题\u003c/h3\u003e\n\u003cp\u003e当工具数量超过一定阈值（经验值：15-20 个），LLM 的工具选择准确率会明显下降。原因有两个：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eContext 膨胀\u003c/strong\u003e：每个工具定义占用数百 token，20 个工具就是数千 token 的 system prompt，挤占了有效上下文空间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e选择困难\u003c/strong\u003e：工具越多，语义越可能重叠，LLM 越难区分应该调用哪个。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e5.4 Tool Selection 策略\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e策略一：全量传递\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e所有工具 ──全部传递──\u0026gt; LLM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e适用场景：工具少于 10 个。简单暴力，无额外开销。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e策略二：语义过滤\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e用户输入 ──Embedding──\u0026gt; 向量\n                          │\n工具描述 ──Embedding──\u0026gt; 向量库 ──Top-K 相似──\u0026gt; 候选工具 ──\u0026gt; LLM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e用 Embedding 计算用户输入与工具描述的语义相似度，只传递 Top-K 最相关的工具。缺点是可能漏掉正确工具。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e策略三：两阶段选择\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e阶段 1：所有工具名 + 简短描述 ──\u0026gt; LLM ──\u0026gt; 选出候选工具 (3-5 个)\n阶段 2：候选工具的完整定义     ──\u0026gt; LLM ──\u0026gt; 执行 Tool Call\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e第一阶段只传递工具名和一行描述（token 消耗少），让 LLM 先做粗筛；第二阶段只传递选中工具的完整定义。这种方式在工具数量 50+ 的场景下效果最好，代价是多一轮 LLM 调用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 完整代码示例\u003c/h2\u003e\n\u003ch3\u003e6.1 工具定义\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Any, Callable\n\n@dataclass\nclass Tool:\n    \u0026quot;\u0026quot;\u0026quot;工具的统一抽象\u0026quot;\u0026quot;\u0026quot;\n    name: str\n    description: str\n    parameters: dict          # JSON Schema\n    function: Callable        # 实际执行的函数\n    requires_confirmation: bool = False  # 是否需要用户确认\n\n    def to_openai_schema(self) -\u0026gt; dict:\n        \u0026quot;\u0026quot;\u0026quot;转换为 OpenAI API 格式\u0026quot;\u0026quot;\u0026quot;\n        return {\n            \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n            \u0026quot;function\u0026quot;: {\n                \u0026quot;name\u0026quot;: self.name,\n                \u0026quot;description\u0026quot;: self.description,\n                \u0026quot;parameters\u0026quot;: self.parameters,\n            }\n        }\n\n# ── 工具实现 ──────────────────────────────────────────────\n\ndef get_weather(city: str, unit: str = \u0026quot;celsius\u0026quot;) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;模拟天气查询\u0026quot;\u0026quot;\u0026quot;\n    # 实际场景中调用天气 API\n    mock_data = {\n        \u0026quot;北京\u0026quot;: {\u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;, \u0026quot;humidity\u0026quot;: 45},\n        \u0026quot;上海\u0026quot;: {\u0026quot;temp\u0026quot;: 32, \u0026quot;condition\u0026quot;: \u0026quot;多云\u0026quot;, \u0026quot;humidity\u0026quot;: 78},\n    }\n    data = mock_data.get(city, {\u0026quot;temp\u0026quot;: 20, \u0026quot;condition\u0026quot;: \u0026quot;未知\u0026quot;, \u0026quot;humidity\u0026quot;: 50})\n    if unit == \u0026quot;fahrenheit\u0026quot;:\n        data[\u0026quot;temp\u0026quot;] = data[\u0026quot;temp\u0026quot;] * 9 / 5 + 32\n    return {\u0026quot;city\u0026quot;: city, **data}\n\n\ndef query_database(sql: str, database: str = \u0026quot;default\u0026quot;) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;模拟数据库查询\u0026quot;\u0026quot;\u0026quot;\n    # 实际场景中执行 SQL\n    return {\n        \u0026quot;database\u0026quot;: database,\n        \u0026quot;query\u0026quot;: sql,\n        \u0026quot;rows\u0026quot;: [\n            {\u0026quot;id\u0026quot;: 1, \u0026quot;name\u0026quot;: \u0026quot;Alice\u0026quot;, \u0026quot;amount\u0026quot;: 100.0},\n            {\u0026quot;id\u0026quot;: 2, \u0026quot;name\u0026quot;: \u0026quot;Bob\u0026quot;, \u0026quot;amount\u0026quot;: 200.0},\n        ],\n        \u0026quot;row_count\u0026quot;: 2,\n    }\n\n\ndef calculate(expression: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;安全的数学计算\u0026quot;\u0026quot;\u0026quot;\n    allowed_chars = set(\u0026quot;0123456789+-*/.() \u0026quot;)\n    if not all(c in allowed_chars for c in expression):\n        return {\u0026quot;error\u0026quot;: \u0026quot;表达式包含非法字符\u0026quot;}\n    try:\n        result = eval(expression)  # 生产环境应使用 ast.literal_eval 或专用解析器\n        return {\u0026quot;expression\u0026quot;: expression, \u0026quot;result\u0026quot;: result}\n    except Exception as e:\n        return {\u0026quot;error\u0026quot;: str(e)}\n\n\ndef read_file(file_path: str, encoding: str = \u0026quot;utf-8\u0026quot;) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;读取文件内容\u0026quot;\u0026quot;\u0026quot;\n    try:\n        with open(file_path, \u0026quot;r\u0026quot;, encoding=encoding) as f:\n            content = f.read(10000)  # 限制读取大小\n        return {\u0026quot;path\u0026quot;: file_path, \u0026quot;content\u0026quot;: content, \u0026quot;size\u0026quot;: len(content)}\n    except FileNotFoundError:\n        return {\u0026quot;error\u0026quot;: f\u0026quot;文件不存在: {file_path}\u0026quot;}\n    except Exception as e:\n        return {\u0026quot;error\u0026quot;: str(e)}\n\n\ndef send_email(to: str, subject: str, body: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;模拟发送邮件\u0026quot;\u0026quot;\u0026quot;\n    # 实际场景中调用邮件服务\n    return {\u0026quot;status\u0026quot;: \u0026quot;sent\u0026quot;, \u0026quot;to\u0026quot;: to, \u0026quot;subject\u0026quot;: subject}\n\n\n# ── 工具注册 ──────────────────────────────────────────────\n\nweather_tool = Tool(\n    name=\u0026quot;get_weather\u0026quot;,\n    description=(\n        \u0026quot;查询指定城市的当前天气信息，包括温度、天气状况和湿度。\u0026quot;\n        \u0026quot;支持国内主要城市。如果城市不在数据库中，返回默认值。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;city\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;要查询的城市名称，如 \u0026#39;北京\u0026#39;、\u0026#39;上海\u0026#39;\u0026quot;\n            },\n            \u0026quot;unit\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;celsius\u0026quot;, \u0026quot;fahrenheit\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;温度单位，默认摄氏度\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;],\n    },\n    function=get_weather,\n)\n\ndatabase_tool = Tool(\n    name=\u0026quot;query_database\u0026quot;,\n    description=(\n        \u0026quot;执行 SQL 查询并返回结果。仅支持 SELECT 语句，\u0026quot;\n        \u0026quot;不允许执行 INSERT/UPDATE/DELETE 等写操作。\u0026quot;\n        \u0026quot;返回结果包含行数据和总行数。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;sql\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;要执行的 SQL SELECT 语句\u0026quot;\n            },\n            \u0026quot;database\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;default\u0026quot;, \u0026quot;analytics\u0026quot;, \u0026quot;users\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;目标数据库名称，默认为 \u0026#39;default\u0026#39;\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;sql\u0026quot;],\n    },\n    function=query_database,\n)\n\ncalculator_tool = Tool(\n    name=\u0026quot;calculate\u0026quot;,\n    description=(\n        \u0026quot;执行数学计算。支持加减乘除和括号。\u0026quot;\n        \u0026quot;输入为数学表达式字符串，如 \u0026#39;(3 + 5) * 2\u0026#39;。\u0026quot;\n        \u0026quot;不支持变量和函数调用，仅限纯数值运算。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;expression\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;数学表达式，如 \u0026#39;(3 + 5) * 2\u0026#39;\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;expression\u0026quot;],\n    },\n    function=calculate,\n)\n\nfile_tool = Tool(\n    name=\u0026quot;read_file\u0026quot;,\n    description=(\n        \u0026quot;读取指定路径的文本文件内容。最多读取 10000 字符。\u0026quot;\n        \u0026quot;仅支持文本文件，不支持二进制文件。\u0026quot;\n        \u0026quot;如果文件不存在，返回错误信息。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;file_path\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;文件的绝对路径或相对路径\u0026quot;\n            },\n            \u0026quot;encoding\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;文件编码，默认 utf-8\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;file_path\u0026quot;],\n    },\n    function=read_file,\n)\n\nemail_tool = Tool(\n    name=\u0026quot;send_email\u0026quot;,\n    description=(\n        \u0026quot;向指定收件人发送一封电子邮件。\u0026quot;\n        \u0026quot;需要提供收件人地址、邮件主题和正文。\u0026quot;\n        \u0026quot;正文支持纯文本格式。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;to\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;收件人邮箱地址\u0026quot;\n            },\n            \u0026quot;subject\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;邮件主题\u0026quot;\n            },\n            \u0026quot;body\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;邮件正文，纯文本格式\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;to\u0026quot;, \u0026quot;subject\u0026quot;, \u0026quot;body\u0026quot;],\n    },\n    function=send_email,\n    requires_confirmation=True,  # 发邮件需要用户确认\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.2 Tool Registry 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nfrom typing import Optional\n\nclass ToolRegistry:\n    \u0026quot;\u0026quot;\u0026quot;工具注册中心\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._tools: dict[str, Tool] = {}\n\n    def register(self, tool: Tool) -\u0026gt; None:\n        if tool.name in self._tools:\n            raise ValueError(f\u0026quot;工具 \u0026#39;{tool.name}\u0026#39; 已注册\u0026quot;)\n        self._tools[tool.name] = tool\n\n    def unregister(self, name: str) -\u0026gt; None:\n        self._tools.pop(name, None)\n\n    def get_tool(self, name: str) -\u0026gt; Optional[Tool]:\n        return self._tools.get(name)\n\n    def get_all_tools(self) -\u0026gt; list[Tool]:\n        return list(self._tools.values())\n\n    def get_definitions(self, names: list[str] | None = None) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;获取工具定义列表（用于传递给 LLM API）\u0026quot;\u0026quot;\u0026quot;\n        tools = self._tools.values()\n        if names:\n            tools = [t for t in tools if t.name in names]\n        return [t.to_openai_schema() for t in tools]\n\n    def get_summary(self) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;获取工具摘要（用于两阶段选择的第一阶段）\u0026quot;\u0026quot;\u0026quot;\n        lines = []\n        for tool in self._tools.values():\n            # 只取 description 的第一句\n            short_desc = tool.description.split(\u0026quot;。\u0026quot;)[0] + \u0026quot;。\u0026quot;\n            lines.append(f\u0026quot;- {tool.name}: {short_desc}\u0026quot;)\n        return \u0026quot;\\n\u0026quot;.join(lines)\n\n\n# 初始化 Registry\nregistry = ToolRegistry()\nfor tool in [weather_tool, database_tool, calculator_tool, file_tool, email_tool]:\n    registry.register(tool)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.3 Tool Dispatcher 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nclass ToolDispatcher:\n    \u0026quot;\u0026quot;\u0026quot;\n    工具调度器：解析 LLM 返回的 tool calls，执行对应工具，收集结果。\n    \u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, registry: ToolRegistry, max_parallel: int = 5):\n        self.registry = registry\n        self.max_parallel = max_parallel\n\n    def validate_arguments(self, tool: Tool, arguments: dict) -\u0026gt; list[str]:\n        \u0026quot;\u0026quot;\u0026quot;基础参数验证（生产环境建议使用 jsonschema 库）\u0026quot;\u0026quot;\u0026quot;\n        errors = []\n        schema = tool.parameters\n        required = schema.get(\u0026quot;required\u0026quot;, [])\n        properties = schema.get(\u0026quot;properties\u0026quot;, {})\n\n        # 检查必填参数\n        for param in required:\n            if param not in arguments:\n                errors.append(f\u0026quot;缺少必填参数: {param}\u0026quot;)\n\n        # 检查参数类型和枚举\n        for param, value in arguments.items():\n            if param not in properties:\n                errors.append(f\u0026quot;未知参数: {param}\u0026quot;)\n                continue\n            prop_schema = properties[param]\n            if \u0026quot;enum\u0026quot; in prop_schema and value not in prop_schema[\u0026quot;enum\u0026quot;]:\n                errors.append(\n                    f\u0026quot;参数 \u0026#39;{param}\u0026#39; 的值 \u0026#39;{value}\u0026#39; \u0026quot;\n                    f\u0026quot;不在允许范围内: {prop_schema[\u0026#39;enum\u0026#39;]}\u0026quot;\n                )\n\n        return errors\n\n    def execute_single(self, tool_call: dict) -\u0026gt; dict:\n        \u0026quot;\u0026quot;\u0026quot;执行单个工具调用\u0026quot;\u0026quot;\u0026quot;\n        name = tool_call[\u0026quot;function\u0026quot;][\u0026quot;name\u0026quot;]\n        raw_args = tool_call[\u0026quot;function\u0026quot;][\u0026quot;arguments\u0026quot;]\n        call_id = tool_call.get(\u0026quot;id\u0026quot;, \u0026quot;unknown\u0026quot;)\n\n        # 1. 查找工具\n        tool = self.registry.get_tool(name)\n        if not tool:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\u0026quot;error\u0026quot;: f\u0026quot;工具 \u0026#39;{name}\u0026#39; 不存在\u0026quot;}),\n            }\n\n        # 2. 解析参数\n        try:\n            arguments = json.loads(raw_args) if isinstance(raw_args, str) else raw_args\n        except json.JSONDecodeError as e:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\u0026quot;error\u0026quot;: f\u0026quot;参数 JSON 解析失败: {e}\u0026quot;}),\n            }\n\n        # 3. 验证参数\n        errors = self.validate_arguments(tool, arguments)\n        if errors:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\u0026quot;error\u0026quot;: \u0026quot;参数验证失败\u0026quot;, \u0026quot;details\u0026quot;: errors}),\n            }\n\n        # 4. 执行工具\n        try:\n            result = tool.function(**arguments)\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps(result, ensure_ascii=False),\n            }\n        except Exception as e:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\n                    \u0026quot;error\u0026quot;: f\u0026quot;工具执行失败: {type(e).__name__}: {e}\u0026quot;,\n                    \u0026quot;traceback\u0026quot;: traceback.format_exc()[-500:],  # 截断过长的堆栈\n                }),\n            }\n\n    def execute_parallel(self, tool_calls: list[dict]) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;并行执行多个工具调用\u0026quot;\u0026quot;\u0026quot;\n        if len(tool_calls) == 1:\n            return [self.execute_single(tool_calls[0])]\n\n        results = []\n        with ThreadPoolExecutor(max_workers=self.max_parallel) as executor:\n            future_to_call = {\n                executor.submit(self.execute_single, tc): tc\n                for tc in tool_calls\n            }\n            for future in as_completed(future_to_call):\n                results.append(future.result())\n\n        # 按原始顺序排列结果\n        id_to_result = {r[\u0026quot;tool_call_id\u0026quot;]: r for r in results}\n        ordered = []\n        for tc in tool_calls:\n            call_id = tc.get(\u0026quot;id\u0026quot;, \u0026quot;unknown\u0026quot;)\n            ordered.append(id_to_result.get(call_id, results.pop(0)))\n        return ordered\n\n\ndispatcher = ToolDispatcher(registry)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.4 完整对话循环\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom openai import OpenAI\n\ndef run_agent_loop(\n    client: OpenAI,\n    user_message: str,\n    registry: ToolRegistry,\n    dispatcher: ToolDispatcher,\n    max_iterations: int = 10,\n) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;\n    完整的 Agent 对话循环，支持多轮 Tool Calling。\n    \u0026quot;\u0026quot;\u0026quot;\n    messages = [\n        {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;你是一个有用的助手，可以使用工具来回答用户的问题。\u0026quot;},\n        {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_message},\n    ]\n    tools = registry.get_definitions()\n\n    for i in range(max_iterations):\n        response = client.chat.completions.create(\n            model=\u0026quot;gpt-4\u0026quot;,\n            messages=messages,\n            tools=tools if tools else None,\n        )\n        choice = response.choices[0]\n        message = choice.message\n\n        # 如果 LLM 没有调用工具，直接返回文本回答\n        if not message.tool_calls:\n            return message.content\n\n        # 将 LLM 的回复（含 tool_calls）加入消息历史\n        messages.append(message.model_dump())\n\n        # 执行所有工具调用（支持并行）\n        tool_calls = [tc.model_dump() for tc in message.tool_calls]\n        results = dispatcher.execute_parallel(tool_calls)\n\n        # 将工具执行结果加入消息历史\n        for result in results:\n            messages.append(result)\n\n        # 继续循环，让 LLM 基于工具结果做下一步决策\n\n    return \u0026quot;达到最大迭代次数，对话终止。\u0026quot;\n\n\n# 使用示例\n# client = OpenAI()\n# answer = run_agent_loop(client, \u0026quot;北京今天天气怎么样？然后帮我算一下 28 * 9/5 + 32\u0026quot;, registry, dispatcher)\n# print(answer)\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 错误处理与验证\u003c/h2\u003e\n\u003cp\u003eTool Calling 中的错误来源比常规 API 调用更多，因为链条更长：用户输入 → LLM 推理 → 参数生成 → 参数验证 → 工具执行 → 结果回传 → LLM 再推理。每一环都可能出错。\u003c/p\u003e\n\u003ch3\u003e7.1 参数验证\u003c/h3\u003e\n\u003cp\u003eLLM 生成的参数并不总是合法的。常见问题：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# LLM 可能生成的\u0026quot;有问题\u0026quot;的参数\n\n# 1. 类型错误：期望 string，给了 number\n{\u0026quot;city\u0026quot;: 123}\n\n# 2. 枚举越界：给了不在 enum 中的值\n{\u0026quot;unit\u0026quot;: \u0026quot;kelvin\u0026quot;}      # enum 里只有 celsius / fahrenheit\n\n# 3. 格式错误：JSON 语法不对\n\u0026#39;{\u0026quot;city\u0026quot;: \u0026quot;北京\u0026quot;,}\u0026#39;      # 尾部多余逗号（严格 JSON 不允许）\n\n# 4. 幻觉参数：编造了不存在的参数\n{\u0026quot;city\u0026quot;: \u0026quot;北京\u0026quot;, \u0026quot;forecast_days\u0026quot;: 7}  # 工具根本没有这个参数\n\n# 5. 语义错误：参数值表面合法但语义错误\n{\u0026quot;sql\u0026quot;: \u0026quot;DROP TABLE users\u0026quot;}  # 传了一条 DELETE 语句给 SELECT-only 工具\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e应对策略是 \u003cstrong\u003e分层验证\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef validate_and_execute(tool: Tool, raw_arguments: str) -\u0026gt; dict:\n    # 第一层：JSON 语法\n    try:\n        args = json.loads(raw_arguments)\n    except json.JSONDecodeError:\n        return {\u0026quot;error\u0026quot;: \u0026quot;参数不是合法的 JSON\u0026quot;}\n\n    # 第二层：Schema 验证（使用 jsonschema 库）\n    from jsonschema import validate, ValidationError\n    try:\n        validate(instance=args, schema=tool.parameters)\n    except ValidationError as e:\n        return {\u0026quot;error\u0026quot;: f\u0026quot;参数验证失败: {e.message}\u0026quot;}\n\n    # 第三层：业务规则验证\n    if tool.name == \u0026quot;query_database\u0026quot;:\n        sql = args.get(\u0026quot;sql\u0026quot;, \u0026quot;\u0026quot;).strip().upper()\n        if not sql.startswith(\u0026quot;SELECT\u0026quot;):\n            return {\u0026quot;error\u0026quot;: \u0026quot;仅支持 SELECT 查询\u0026quot;}\n\n    # 执行\n    return tool.function(**args)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.2 工具执行失败的反馈\u003c/h3\u003e\n\u003cp\u003e当工具执行失败时，最重要的原则是：\u003cstrong\u003e将错误信息回传给 LLM，让它决定下一步\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 不要这样做 —— 对用户抛出原始异常\nraise RuntimeError(\u0026quot;Connection timeout to weather API\u0026quot;)\n\n# 应该这样做 —— 将错误包装为工具结果，回传给 LLM\n{\n    \u0026quot;tool_call_id\u0026quot;: \u0026quot;call_abc123\u0026quot;,\n    \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n    \u0026quot;content\u0026quot;: json.dumps({\n        \u0026quot;error\u0026quot;: \u0026quot;天气 API 连接超时，请稍后重试或尝试查询其他城市\u0026quot;,\n        \u0026quot;error_type\u0026quot;: \u0026quot;timeout\u0026quot;,\n        \u0026quot;retryable\u0026quot;: True\n    })\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLLM 拿到这个错误信息后，可能会：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e换一种方式重试（比如换个参数）\u003c/li\u003e\n\u003cli\u003e告知用户当前无法完成\u003c/li\u003e\n\u003cli\u003e尝试用其他工具达成目标\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.3 重试策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                  ┌──────────────────────────┐\n                  │    Tool Call 失败         │\n                  └──────────┬───────────────┘\n                             │\n                   ┌─────────▼─────────┐\n                   │  错误类型判断       │\n                   └─────────┬─────────┘\n                             │\n              ┌──────────────┼──────────────┐\n              │              │              │\n        ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐\n        │ 可重试     │ │ 参数错误   │ │ 不可恢复   │\n        │(超时/限流) │ │(类型/格式) │ │(权限/404) │\n        └─────┬─────┘ └─────┬─────┘ └─────┬─────┘\n              │              │              │\n        ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐\n        │ Runtime    │ │ 回传 LLM  │ │ 回传 LLM  │\n        │ 自动重试   │ │ 让它修正   │ │ 让它放弃   │\n        │ (指数退避) │ │ 参数       │ │ 或换方案   │\n        └───────────┘ └───────────┘ └───────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e核心原则：\u003cstrong\u003e可重试的错误由 Runtime 处理，不可重试的错误交给 LLM 决策\u003c/strong\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e瞬时错误\u003c/strong\u003e（网络超时、限流）：Runtime 自动重试，设置退避策略和最大重试次数，不需要浪费 LLM 的 token。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e参数错误\u003c/strong\u003e：回传给 LLM，它可能会修正参数重新调用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e永久错误\u003c/strong\u003e（权限不足、资源不存在）：回传给 LLM，让它换一种方案或如实告知用户。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.4 幂等性考量\u003c/h3\u003e\n\u003cp\u003e当重试机制存在时，幂等性就变得至关重要。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 幂等操作 —— 重试安全\nget_weather(\u0026quot;北京\u0026quot;)           # 多次调用结果相同\nquery_database(\u0026quot;SELECT ...\u0026quot;)  # 只读查询，天然幂等\n\n# 非幂等操作 —— 重试危险\nsend_email(to=\u0026quot;a@b.com\u0026quot;, ...)  # 重试 = 发两封邮件\ncreate_order(item=\u0026quot;iPhone\u0026quot;)    # 重试 = 创建两个订单\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e对于非幂等操作，要么禁止自动重试，要么引入幂等 key：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef send_email_idempotent(to: str, subject: str, body: str, idempotency_key: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;带幂等 key 的邮件发送\u0026quot;\u0026quot;\u0026quot;\n    if is_already_sent(idempotency_key):\n        return {\u0026quot;status\u0026quot;: \u0026quot;already_sent\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;该请求已处理，跳过重复发送\u0026quot;}\n    result = _do_send_email(to, subject, body)\n    mark_as_sent(idempotency_key)\n    return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 安全性\u003c/h2\u003e\n\u003cp\u003eTool Calling 打开了 LLM 与外部世界的通道，也同时打开了攻击面。\u003c/p\u003e\n\u003ch3\u003e8.1 工具权限控制\u003c/h3\u003e\n\u003cp\u003e不是所有工具都应该对所有用户开放。一个合理的权限模型：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom enum import Enum\n\nclass ToolPermission(Enum):\n    READ = \u0026quot;read\u0026quot;        # 只读操作：查询天气、读文件\n    WRITE = \u0026quot;write\u0026quot;      # 写操作：发邮件、创建记录\n    ADMIN = \u0026quot;admin\u0026quot;      # 管理操作：删除数据、修改配置\n\nclass SecureToolRegistry(ToolRegistry):\n    \u0026quot;\u0026quot;\u0026quot;带权限控制的工具注册中心\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        super().__init__()\n        self._permissions: dict[str, ToolPermission] = {}\n\n    def register(self, tool: Tool, permission: ToolPermission = ToolPermission.READ):\n        super().register(tool)\n        self._permissions[tool.name] = permission\n\n    def get_definitions(\n        self,\n        names: list[str] | None = None,\n        max_permission: ToolPermission = ToolPermission.READ,\n    ) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;只返回用户权限范围内的工具\u0026quot;\u0026quot;\u0026quot;\n        permission_levels = {\n            ToolPermission.READ: 0,\n            ToolPermission.WRITE: 1,\n            ToolPermission.ADMIN: 2,\n        }\n        max_level = permission_levels[max_permission]\n        allowed = [\n            t for t in self._tools.values()\n            if permission_levels[self._permissions.get(t.name, ToolPermission.ADMIN)] \u0026lt;= max_level\n        ]\n        if names:\n            allowed = [t for t in allowed if t.name in names]\n        return [t.to_openai_schema() for t in allowed]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.2 参数注入风险\u003c/h3\u003e\n\u003cp\u003eLLM 的参数生成可以被 Prompt Injection 操纵。考虑以下场景：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e用户输入: \u0026quot;帮我查一下订单，user_id 是 U00012345; DROP TABLE orders; --\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e如果 \u003ccode\u003equery_database\u003c/code\u003e 工具直接拼接 SQL，这就变成了一次经典的 SQL 注入。防护措施：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e参数化查询\u003c/strong\u003e：工具内部必须使用参数化 SQL，绝不拼接。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e白名单校验\u003c/strong\u003e：用正则或枚举限制参数值的格式。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e最小权限原则\u003c/strong\u003e：数据库连接使用只读账号。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e8.3 Sandbox 执行\u003c/h3\u003e\n\u003cp\u003e对于高风险工具（如代码执行、文件操作），应在隔离环境中执行：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────┐\n│  Host Runtime                                 │\n│                                              │\n│   ┌─────────────┐     ┌──────────────────┐   │\n│   │  Safe Tools  │     │    Sandbox       │   │\n│   │  (天气/计算) │     │  ┌────────────┐  │   │\n│   │  直接执行    │     │  │ Risky Tools│  │   │\n│   └─────────────┘     │  │ (代码/文件) │  │   │\n│                       │  │ 隔离执行    │  │   │\n│                       │  └────────────┘  │   │\n│                       │  - 网络受限      │   │\n│                       │  - 文件系统隔离  │   │\n│                       │  - 执行时间限制  │   │\n│                       │  - 资源配额      │   │\n│                       └──────────────────┘   │\n└──────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSandbox 的实现方式取决于部署环境：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDocker 容器\u003c/strong\u003e：最常见，隔离性好\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003egVisor / Firecracker\u003c/strong\u003e：更强的隔离，适合多租户\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWASM\u003c/strong\u003e：轻量级沙箱，启动快\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e子进程 + seccomp\u003c/strong\u003e：Linux 下的轻量方案\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e9. Trade-off 分析\u003c/h2\u003e\n\u003ch3\u003e9.1 工具数量 vs 选择准确率\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e选择准确率\n  100% │ ****\n       │     ****\n   90% │         ****\n       │             ****\n   80% │                 ****\n       │                     ****\n   70% │                         ****\n       │                             ****\n   60% │                                 ****\n       ├───┬───┬───┬───┬───┬───┬───┬───┬───── 工具数量\n       0   5  10  15  20  25  30  35  40\n\n       |\u0026lt;-- 全量传递 --\u0026gt;|\u0026lt;- 需要过滤策略 -\u0026gt;|\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u0026lt; 10 个工具\u003c/strong\u003e：全量传递，不需要过滤。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e10-20 个工具\u003c/strong\u003e：准确率开始下降，可通过优化 description 缓解。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u0026gt; 20 个工具\u003c/strong\u003e：必须引入 Tool Selection 策略（语义过滤或两阶段选择）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u0026gt; 50 个工具\u003c/strong\u003e：两阶段选择几乎是唯一可行方案，或者按领域拆分为多个 Agent。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e9.2 工具描述详细度 vs Token 消耗\u003c/h3\u003e\n\u003cp\u003e每个工具定义大约占用 100-500 token（取决于描述长度和参数数量）。20 个工具就是 2000-10000 token 的系统开销，这是每次 API 调用都要付出的 \u003cstrong\u003e固定成本\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                        描述详细度\n                  低 ◄──────────────► 高\n                  │                    │\n  Token 消耗   低 │  ⚡ 省钱但模糊     │\n                  │  LLM 可能误选工具  │\n                  │                    │\n              高 │                    │  📖 精确但昂贵\n                  │                    │  LLM 选择更准确\n                  │                    │\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实践建议：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e工具 \u003ccode\u003ename\u003c/code\u003e 起好名字（零额外 token 成本，但信息量大）\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edescription\u003c/code\u003e 控制在 2-3 句话\u003c/li\u003e\n\u003cli\u003e参数的 \u003ccode\u003edescription\u003c/code\u003e 控制在 1 句话 + 1 个示例\u003c/li\u003e\n\u003cli\u003e用 \u003ccode\u003eenum\u003c/code\u003e 和 \u003ccode\u003erequired\u003c/code\u003e 代替冗长的文字约束\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e9.3 确定性执行 vs LLM 灵活性\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e确定性                                          灵活性\n  │                                              │\n  │  硬编码工作流           Agent Tool Calling     │\n  │  if/else 分支            LLM 自由选择工具     │\n  │  规则引擎                自动组合工具链        │\n  │                                              │\n  │  ✅ 可预测              ✅ 处理模糊意图        │\n  │  ✅ 可审计              ✅ 适应新场景          │\n  │  ✅ 低延迟              ✅ 用户体验自然        │\n  │  ❌ 不灵活              ❌ 不可预测            │\n  │  ❌ 维护成本高          ❌ 调试困难            │\n  │  ❌ 无法处理长尾        ❌ 成本高              │\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e决策框架：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景特征\u003c/th\u003e\n\u003cth\u003e推荐方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e流程固定、合规要求高\u003c/td\u003e\n\u003ctd\u003e硬编码工作流 + Tool Calling 作为执行层\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e意图模糊、工具组合多变\u003c/td\u003e\n\u003ctd\u003e完全由 LLM 驱动的 Tool Calling\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e核心路径固定、边缘场景多\u003c/td\u003e\n\u003ctd\u003e混合方案：主流程硬编码，长尾交给 LLM\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e关键洞察：Tool Calling 不是非此即彼的选择。你可以让 LLM 决定 \u003cstrong\u003e是否\u003c/strong\u003e 调用工具，但用代码控制 \u003cstrong\u003e调用后的流程\u003c/strong\u003e。比如 LLM 决定\u0026quot;需要查天气\u0026quot;，但查完天气后的处理逻辑是确定性的代码。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 常见陷阱\u003c/h2\u003e\n\u003cp\u003e在实际工程中，以下几个坑值得提前规避：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. 工具描述与实际行为不一致\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e工具描述说\u0026quot;返回最近 30 天的订单\u0026quot;，但实际实现返回所有订单。LLM 会基于描述做出错误假设，导致下游逻辑出错。\u003cstrong\u003e描述就是契约，必须与实现严格一致\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. 忽略工具结果的 Token 消耗\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e工具返回的结果会作为下一轮消息传给 LLM。如果一个数据库查询返回了 1000 行数据，这些数据全部变成 input token。务必在工具层面限制返回数据量。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef query_database(sql: str, database: str = \u0026quot;default\u0026quot;) -\u0026gt; dict:\n    results = _execute_query(sql, database)\n    # 限制返回行数，避免 token 爆炸\n    if len(results) \u0026gt; 50:\n        return {\n            \u0026quot;rows\u0026quot;: results[:50],\n            \u0026quot;total_count\u0026quot;: len(results),\n            \u0026quot;truncated\u0026quot;: True,\n            \u0026quot;message\u0026quot;: f\u0026quot;结果共 {len(results)} 行，仅返回前 50 行\u0026quot;\n        }\n    return {\u0026quot;rows\u0026quot;: results, \u0026quot;total_count\u0026quot;: len(results)}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. 缺少 stop condition\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果 LLM 反复调用同一个工具（比如因为错误一直重试），而没有最大迭代次数限制，系统会陷入无限循环。前面代码中的 \u003ccode\u003emax_iterations\u003c/code\u003e 参数就是为此设计的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. 并行调用的顺序依赖\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLLM 可能在一次回复中请求并行调用两个工具，但这两个工具之间有隐含的顺序依赖（比如先查用户 ID，再用这个 ID 查订单）。Runtime 需要能识别这种情况，或者在工具描述中引导 LLM 分步调用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e11. 总结与展望\u003c/h2\u003e\n\u003cp\u003eTool Calling 的本质是一个精心设计的 \u003cstrong\u003e协议\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌───────────┐    JSON Schema    ┌───────────┐    Function    ┌───────────┐\n│           │    (契约)          │           │    (执行)      │           │\n│    LLM    │ ◄───────────────► │  Runtime  │ ◄────────────► │   Tools   │\n│  (决策层) │   Tool Call JSON   │  (调度层) │   Function     │  (能力层) │\n│           │   Tool Result      │           │   Call/Return  │           │\n└───────────┘                   └───────────┘                └───────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLLM\u003c/strong\u003e 负责理解意图、选择工具、生成参数——它是决策者。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRuntime\u003c/strong\u003e 负责验证、路由、执行、错误处理——它是执行者。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTools\u003c/strong\u003e 是具体的能力——它们是能力的载体。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJSON Schema\u003c/strong\u003e 是三者之间的契约——它定义了什么可以做、怎么做。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e理解了这个架构，你就能在任何框架（LangChain、LlamaIndex、Semantic Kernel，或者自己写的 Runtime）上实现 Tool Calling，因为底层原理是相同的。\u003c/p\u003e\n\u003cp\u003e但 Tool Calling 只是让 Agent 有了\u0026quot;手\u0026quot;。要让 Agent 真正好用，还需要精心设计的 Prompt 来引导 LLM 的决策——什么时候该调工具、什么时候该直接回答、遇到错误该怎么处理、多个工具之间如何协调。这就是下一篇 \u003cstrong\u003ePrompt Engineering for Agents\u003c/strong\u003e 要深入讨论的主题。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 05 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/04-The%20Agent%20Control%20Loop\"\u003e04 | The Agent Control Loop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/06-Prompt%20Engineering%20for%20Agents\"\u003e06 | Prompt Engineering for Agents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"1b:T9c80,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eAgent Runtime from Scratch: 不依赖框架构建 Agent\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e框架是加速器，不是知识的替代品。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 07 篇，也是 Phase 2 的收官之作。我们将抛开所有框架，用纯 Python 从零构建一个功能完整的 Agent Runtime。这是系列中代码量最大的一篇——每一行代码都指向同一个目标：让你彻底理解 Agent 的运行本质。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么要自己写 Agent Runtime？\u003c/h2\u003e\n\u003cp\u003e前几篇我们理解了控制循环（第 04 篇）、Tool Calling（第 05 篇）、Prompt 工程（第 06 篇）。但这些还停留在概念层面。现在的问题是：\u003cstrong\u003e不用 LangChain、不用 LangGraph——你能写出一个 Agent 吗？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e自建 Runtime 的价值：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e透明性\u003c/strong\u003e：每一行代码你都清楚，出了问题知道往哪里看\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可控性\u003c/strong\u003e：精确控制重试策略、超时机制、消息压缩、工具调度，而不被框架的默认行为绑架\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e本质理解\u003c/strong\u003e：理解了 Runtime 本质，用任何框架时都能一眼看出它在做什么、哪里做得不好\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e更现实的原因：\u003cstrong\u003e生产环境中很多 Agent 系统最终都走向了自研\u003c/strong\u003e。框架在 PoC 阶段很方便，但到了需要精细控制 Token 成本、自定义 Observability、与内部基础设施深度集成时，框架往往成为障碍。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 架构设计\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e┌───────────────────────────────────────────────────┐\n│                   AgentRuntime                     │\n│                (Core Control Loop)                 │\n│                                                    │\n│  ┌────────────┐  ┌──────────────┐  ┌───────────┐ │\n│  │ LLMClient  │  │MessageManager│  │ StateStore │ │\n│  │ chat()     │  │ append()     │  │ save()     │ │\n│  │ stream()   │  │ compress()   │  │ load()     │ │\n│  │ retry()    │  │ count_tokens │  │ clear()    │ │\n│  └─────┬──────┘  └──────┬───────┘  └───────────┘ │\n│        │                │                          │\n│        ▼                ▼                          │\n│  ┌────────────────────────────────────┐            │\n│  │          Runtime Loop              │            │\n│  │  while not done and turns \u0026lt; max:   │            │\n│  │    response = llm.chat(messages)   │            │\n│  │    if tool_calls:                  │            │\n│  │      results = executor.run()      │            │\n│  │    else: done = True               │            │\n│  └──────────┬─────────────────────────┘            │\n│       ┌─────┴──────┐                               │\n│       ▼            ▼                                │\n│  ┌──────────┐ ┌────────────┐                       │\n│  │ToolRegist│ │ToolExecutor│                       │\n│  │ register │ │ execute()  │                       │\n│  │ schema() │ │ parallel() │                       │\n│  └──────────┘ └────────────┘                       │\n└───────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e核心设计原则——职责分离\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e模块\u003c/th\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003cth\u003e边界\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eLLMClient\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e封装模型调用，处理重试\u003c/td\u003e\n\u003ctd\u003e只管\u0026quot;调 API\u0026quot;，不管消息历史\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eToolRegistry\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e注册工具，生成 JSON Schema\u003c/td\u003e\n\u003ctd\u003e只管\u0026quot;有哪些工具\u0026quot;，不管怎么调\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eToolExecutor\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e解析 tool_calls，分发执行\u003c/td\u003e\n\u003ctd\u003e只管\u0026quot;执行工具\u0026quot;，不管谁触发的\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eMessageManager\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e管理消息列表，Token 计数和压缩\u003c/td\u003e\n\u003ctd\u003e只管\u0026quot;消息\u0026quot;，不管消息从哪来\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAgentRuntime\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e组装一切，驱动控制循环\u003c/td\u003e\n\u003ctd\u003e只管\u0026quot;编排\u0026quot;，不自己做具体事\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e任何模块可独立替换。换 Anthropic API？只改 \u003ccode\u003eLLMClient\u003c/code\u003e。状态存 Redis？只改 \u003ccode\u003eStateStore\u003c/code\u003e。Runtime 本身不需要变动。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. 逐步构建\u003c/h2\u003e\n\u003ch3\u003eStep 1: LLMClient — 封装模型调用\u003c/h3\u003e\n\u003cp\u003e封装 OpenAI 兼容接口，支持 \u003ccode\u003etools\u003c/code\u003e / \u003ccode\u003etool_choice\u003c/code\u003e，处理流式/非流式，实现指数退避重试。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# llm_client.py\nimport time, json, logging\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Generator\nfrom openai import OpenAI, APIError, RateLimitError, APITimeoutError\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass ToolCall:\n    id: str\n    name: str\n    arguments: dict\n\n@dataclass\nclass LLMResponse:\n    content: Optional[str] = None\n    tool_calls: list[ToolCall] = field(default_factory=list)\n    usage: dict = field(default_factory=dict)\n    finish_reason: str = \u0026quot;\u0026quot;\n\n    @property\n    def has_tool_calls(self) -\u0026gt; bool:\n        return len(self.tool_calls) \u0026gt; 0\n\nclass LLMClient:\n    RETRYABLE_ERRORS = (RateLimitError, APITimeoutError, APIError)\n\n    def __init__(self, model=\u0026quot;gpt-4o\u0026quot;, base_url=None, api_key=None,\n                 max_retries=3, retry_base_delay=1.0, timeout=60.0):\n        self.model = model\n        self.max_retries = max_retries\n        self.retry_base_delay = retry_base_delay\n        self.client = OpenAI(base_url=base_url, api_key=api_key, timeout=timeout)\n\n    def chat(self, messages, tools=None, tool_choice=\u0026quot;auto\u0026quot;, temperature=0.0):\n        kwargs = {\u0026quot;model\u0026quot;: self.model, \u0026quot;messages\u0026quot;: messages,\n                  \u0026quot;temperature\u0026quot;: temperature}\n        if tools:\n            kwargs[\u0026quot;tools\u0026quot;] = tools\n            kwargs[\u0026quot;tool_choice\u0026quot;] = tool_choice\n        raw = self._call_with_retry(**kwargs)\n        return self._parse_response(raw)\n\n    def stream(self, messages, tools=None, tool_choice=\u0026quot;auto\u0026quot;,\n               temperature=0.0) -\u0026gt; Generator[LLMResponse, None, None]:\n        kwargs = {\u0026quot;model\u0026quot;: self.model, \u0026quot;messages\u0026quot;: messages,\n                  \u0026quot;temperature\u0026quot;: temperature, \u0026quot;stream\u0026quot;: True}\n        if tools:\n            kwargs[\u0026quot;tools\u0026quot;] = tools\n            kwargs[\u0026quot;tool_choice\u0026quot;] = tool_choice\n\n        accumulated_tool_calls: dict[int, dict] = {}\n        for chunk in self._call_with_retry(**kwargs):\n            delta = chunk.choices[0].delta if chunk.choices else None\n            if not delta:\n                continue\n            if delta.content:\n                yield LLMResponse(content=delta.content)\n            # 流式下 tool_calls 分片到达，需要累积拼装\n            if delta.tool_calls:\n                for tc in delta.tool_calls:\n                    idx = tc.index\n                    if idx not in accumulated_tool_calls:\n                        accumulated_tool_calls[idx] = {\n                            \u0026quot;id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;arguments\u0026quot;: \u0026quot;\u0026quot;}\n                    if tc.id: accumulated_tool_calls[idx][\u0026quot;id\u0026quot;] = tc.id\n                    if tc.function.name:\n                        accumulated_tool_calls[idx][\u0026quot;name\u0026quot;] = tc.function.name\n                    if tc.function.arguments:\n                        accumulated_tool_calls[idx][\u0026quot;arguments\u0026quot;] += \\\n                            tc.function.arguments\n\n        if accumulated_tool_calls:\n            tool_calls = []\n            for d in accumulated_tool_calls.values():\n                args = json.loads(d[\u0026quot;arguments\u0026quot;]) if d[\u0026quot;arguments\u0026quot;] else {}\n                tool_calls.append(ToolCall(d[\u0026quot;id\u0026quot;], d[\u0026quot;name\u0026quot;], args))\n            yield LLMResponse(tool_calls=tool_calls)\n\n    def _call_with_retry(self, **kwargs):\n        last_error = None\n        for attempt in range(self.max_retries + 1):\n            try:\n                return self.client.chat.completions.create(**kwargs)\n            except self.RETRYABLE_ERRORS as e:\n                last_error = e\n                if attempt \u0026lt; self.max_retries:\n                    delay = self.retry_base_delay * (2 ** attempt)\n                    logger.warning(f\u0026quot;Retry {attempt+1} in {delay}s: {e}\u0026quot;)\n                    time.sleep(delay)\n        raise last_error\n\n    def _parse_response(self, raw) -\u0026gt; LLMResponse:\n        choice = raw.choices[0]\n        msg = choice.message\n        tool_calls = []\n        if msg.tool_calls:\n            for tc in msg.tool_calls:\n                args = json.loads(tc.function.arguments) \\\n                    if tc.function.arguments else {}\n                tool_calls.append(ToolCall(tc.id, tc.function.name, args))\n        return LLMResponse(\n            content=msg.content, tool_calls=tool_calls,\n            usage={\u0026quot;prompt_tokens\u0026quot;: raw.usage.prompt_tokens,\n                   \u0026quot;completion_tokens\u0026quot;: raw.usage.completion_tokens,\n                   \u0026quot;total_tokens\u0026quot;: raw.usage.total_tokens},\n            finish_reason=choice.finish_reason)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e关键设计决策\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e统一 \u003ccode\u003eLLMResponse\u003c/code\u003e\u003c/strong\u003e：无论底层用什么模型，Runtime 只看到同一结构——适配器模式。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e重试只针对可恢复错误\u003c/strong\u003e：\u003ccode\u003eRateLimitError\u003c/code\u003e 值得重试，\u003ccode\u003eAuthenticationError\u003c/code\u003e 重试一万次也没用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e流式 tool_calls 累积拼装\u003c/strong\u003e：OpenAI 把 tool_calls 拆成多个 chunk（先发 name，再逐步发 arguments），必须在客户端拼装。这是容易踩的坑。\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch3\u003eStep 2: ToolRegistry — 工具注册与发现\u003c/h3\u003e\n\u003cp\u003e用装饰器注册函数，通过 type hints 和 docstring 自动生成 OpenAI 格式的 JSON Schema。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# tool_registry.py\nimport inspect, json\nfrom typing import Any, Callable, Optional, get_type_hints\n\nTYPE_MAP = {str: \u0026quot;string\u0026quot;, int: \u0026quot;integer\u0026quot;, float: \u0026quot;number\u0026quot;,\n            bool: \u0026quot;boolean\u0026quot;, list: \u0026quot;array\u0026quot;, dict: \u0026quot;object\u0026quot;}\n\nclass ToolRegistry:\n    def __init__(self):\n        self._tools: dict[str, Callable] = {}\n        self._schemas: dict[str, dict] = {}\n\n    def tool(self, name=None, description=None):\n        \u0026quot;\u0026quot;\u0026quot;装饰器注册工具\u0026quot;\u0026quot;\u0026quot;\n        def decorator(func):\n            n = name or func.__name__\n            d = description or (func.__doc__ or \u0026quot;\u0026quot;).strip().split(\u0026quot;\\n\u0026quot;)[0]\n            self._tools[n] = func\n            self._schemas[n] = self._gen_schema(func, n, d)\n            return func\n        return decorator\n\n    def register(self, func, name=None, description=None):\n        \u0026quot;\u0026quot;\u0026quot;命令式注册（适用于无法加装饰器的场景）\u0026quot;\u0026quot;\u0026quot;\n        n = name or func.__name__\n        d = description or (func.__doc__ or \u0026quot;\u0026quot;).strip().split(\u0026quot;\\n\u0026quot;)[0]\n        self._tools[n] = func\n        self._schemas[n] = self._gen_schema(func, n, d)\n\n    def get_function(self, name): return self._tools.get(name)\n    def get_all_schemas(self): return list(self._schemas.values())\n    def list_tools(self): return list(self._tools.keys())\n\n    def _gen_schema(self, func, name, description):\n        sig = inspect.signature(func)\n        hints = get_type_hints(func)\n        properties, required = {}, []\n        for pname, param in sig.parameters.items():\n            if pname in (\u0026quot;self\u0026quot;, \u0026quot;cls\u0026quot;): continue\n            ptype = hints.get(pname, str)\n            prop = {\u0026quot;type\u0026quot;: TYPE_MAP.get(ptype, \u0026quot;string\u0026quot;)}\n            # 从 Google 风格 docstring 提取参数描述\n            pdesc = self._param_desc(func, pname)\n            if pdesc: prop[\u0026quot;description\u0026quot;] = pdesc\n            properties[pname] = prop\n            if param.default is inspect.Parameter.empty:\n                required.append(pname)\n        return {\u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;, \u0026quot;function\u0026quot;: {\n            \u0026quot;name\u0026quot;: name, \u0026quot;description\u0026quot;: description,\n            \u0026quot;parameters\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n                           \u0026quot;properties\u0026quot;: properties, \u0026quot;required\u0026quot;: required}}}\n\n    @staticmethod\n    def _param_desc(func, param_name):\n        doc = func.__doc__ or \u0026quot;\u0026quot;\n        in_args = False\n        for line in doc.split(\u0026quot;\\n\u0026quot;):\n            s = line.strip()\n            if s.lower().startswith(\u0026quot;args:\u0026quot;): in_args = True; continue\n            if in_args and param_name + \u0026quot;:\u0026quot; in s:\n                return s.split(\u0026quot;:\u0026quot;, 1)[1].strip()\n        return \u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e验证效果：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eregistry = ToolRegistry()\n\n@registry.tool()\ndef web_search(query: str, max_results: int = 5) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;搜索网页内容\n    Args:\n        query: 搜索关键词\n        max_results: 最大返回结果数量\n    \u0026quot;\u0026quot;\u0026quot;\n    return f\u0026quot;Results for: {query}\u0026quot;\n\n# 输出 OpenAI 格式的 tool schema\n# {\u0026quot;type\u0026quot;:\u0026quot;function\u0026quot;,\u0026quot;function\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;web_search\u0026quot;,\u0026quot;description\u0026quot;:\u0026quot;搜索网页内容\u0026quot;,\n#  \u0026quot;parameters\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;object\u0026quot;,\u0026quot;properties\u0026quot;:{\u0026quot;query\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;string\u0026quot;,\n#  \u0026quot;description\u0026quot;:\u0026quot;搜索关键词\u0026quot;},\u0026quot;max_results\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;integer\u0026quot;,\n#  \u0026quot;description\u0026quot;:\u0026quot;最大返回结果数量\u0026quot;}},\u0026quot;required\u0026quot;:[\u0026quot;query\u0026quot;]}}}\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch3\u003eStep 3: ToolExecutor — 工具执行与结果处理\u003c/h3\u003e\n\u003cp\u003e接收 LLM 返回的 \u003ccode\u003etool_calls\u003c/code\u003e，分发执行，收集结果，处理异常。支持串行和并行两种模式。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# tool_executor.py\nimport json, time, logging, traceback\nfrom concurrent.futures import ThreadPoolExecutor, TimeoutError as FTE\nfrom dataclasses import dataclass\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass ToolResult:\n    tool_call_id: str\n    name: str\n    result: str\n    success: bool\n    duration_ms: float = 0.0\n\nclass ToolExecutor:\n    def __init__(self, registry, default_timeout=30.0, max_workers=4):\n        self.registry = registry\n        self.default_timeout = default_timeout\n        self.max_workers = max_workers\n\n    def execute(self, tool_calls) -\u0026gt; list[ToolResult]:\n        \u0026quot;\u0026quot;\u0026quot;串行执行\u0026quot;\u0026quot;\u0026quot;\n        return [self._run_one(tc) for tc in tool_calls]\n\n    def execute_parallel(self, tool_calls) -\u0026gt; list[ToolResult]:\n        \u0026quot;\u0026quot;\u0026quot;并行执行（LLM 一次返回多个 tool_calls 时使用）\u0026quot;\u0026quot;\u0026quot;\n        if len(tool_calls) \u0026lt;= 1:\n            return self.execute(tool_calls)\n        results = []\n        with ThreadPoolExecutor(max_workers=self.max_workers) as pool:\n            futures = {pool.submit(self._run_one, tc): tc for tc in tool_calls}\n            for fut in futures:\n                try:\n                    results.append(fut.result(timeout=self.default_timeout))\n                except FTE:\n                    tc = futures[fut]\n                    results.append(ToolResult(\n                        tc.id, tc.name,\n                        f\u0026quot;Error: \u0026#39;{tc.name}\u0026#39; timed out after \u0026quot;\n                        f\u0026quot;{self.default_timeout}s\u0026quot;, False))\n        return results\n\n    def _run_one(self, tool_call) -\u0026gt; ToolResult:\n        start = time.monotonic()\n        func = self.registry.get_function(tool_call.name)\n        if not func:\n            return ToolResult(tool_call.id, tool_call.name,\n                f\u0026quot;Error: Unknown tool \u0026#39;{tool_call.name}\u0026#39;. \u0026quot;\n                f\u0026quot;Available: {self.registry.list_tools()}\u0026quot;, False)\n        try:\n            result = func(**tool_call.arguments)\n            if not isinstance(result, str):\n                result = json.dumps(result, ensure_ascii=False, default=str)\n            ms = (time.monotonic() - start) * 1000\n            logger.info(f\u0026quot;Tool \u0026#39;{tool_call.name}\u0026#39; OK in {ms:.0f}ms\u0026quot;)\n            return ToolResult(tool_call.id, tool_call.name, result, True, ms)\n        except Exception as e:\n            ms = (time.monotonic() - start) * 1000\n            msg = f\u0026quot;Error: {type(e).__name__}: {e}\u0026quot;\n            logger.error(f\u0026quot;{msg}\\n{traceback.format_exc()}\u0026quot;)\n            return ToolResult(tool_call.id, tool_call.name, msg, False, ms)\n\n    @staticmethod\n    def results_to_messages(results):\n        return [{\u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;, \u0026quot;tool_call_id\u0026quot;: r.tool_call_id,\n                 \u0026quot;content\u0026quot;: r.result} for r in results]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e串行 vs 并行的 Trade-off\u003c/strong\u003e：串行简单可调试；并行在 LLM 同时返回多个独立 tool_calls 时显著降低延迟。LLM 在一次响应中返回多个 tool_calls 本身就隐含了\u0026quot;它们之间无依赖\u0026quot;——否则它会分成多轮调用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eStep 4: MessageManager — 消息历史管理与压缩\u003c/h3\u003e\n\u003cp\u003e解决 Agent 长对话中最常遇到的问题：\u003cstrong\u003e消息越来越多，Context Window 不够用了\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# message_manager.py\nimport json, logging, tiktoken\nfrom typing import Optional\nfrom copy import deepcopy\n\nlogger = logging.getLogger(__name__)\n\nclass MessageManager:\n    def __init__(self, system_prompt=\u0026quot;\u0026quot;, model=\u0026quot;gpt-4o\u0026quot;,\n                 max_tokens=120000, compression_threshold=0.75):\n        self.system_prompt = system_prompt\n        self.max_tokens = max_tokens\n        self.compression_threshold = compression_threshold\n        try: self.enc = tiktoken.encoding_for_model(model)\n        except KeyError: self.enc = tiktoken.get_encoding(\u0026quot;cl100k_base\u0026quot;)\n        self._messages: list[dict] = []\n\n    def append(self, msg):\n        self._messages.append(msg)\n        self._maybe_compress()\n\n    def extend(self, msgs):\n        self._messages.extend(msgs)\n        self._maybe_compress()\n\n    def get_messages(self):\n        out = []\n        if self.system_prompt:\n            out.append({\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self.system_prompt})\n        out.extend(deepcopy(self._messages))\n        return out\n\n    def count_tokens(self, msgs=None):\n        msgs = msgs or self.get_messages()\n        total = 2  # priming tokens\n        for m in msgs:\n            total += 4  # per-message overhead\n            for v in m.values():\n                if isinstance(v, str): total += len(self.enc.encode(v))\n                elif isinstance(v, list):\n                    total += len(self.enc.encode(json.dumps(v)))\n        return total\n\n    def _maybe_compress(self):\n        threshold = int(self.max_tokens * self.compression_threshold)\n        if self.count_tokens() \u0026lt;= threshold: return\n        logger.info(\u0026quot;Token threshold exceeded, compressing...\u0026quot;)\n        self._sliding_window_compress(threshold)\n\n    def _sliding_window_compress(self, target):\n        \u0026quot;\u0026quot;\u0026quot;从最早的消息移除，保持 tool_call 对完整性。\n\n        关键约束：assistant(tool_calls) 后面的 tool(result) 消息必须\n        一起移除，否则 OpenAI API 会报错。\n        \u0026quot;\u0026quot;\u0026quot;\n        msgs, i = self._messages, 0\n        while i \u0026lt; len(msgs):\n            remaining = msgs[i:]\n            sys_msgs = ([{\u0026quot;role\u0026quot;:\u0026quot;system\u0026quot;,\u0026quot;content\u0026quot;:self.system_prompt}]\n                        if self.system_prompt else [])\n            if self.count_tokens(sys_msgs + remaining) \u0026lt;= target: break\n            i += 1\n            # 如果刚移除的是含 tool_calls 的 assistant，连续移除后续 tool 消息\n            if (i \u0026gt; 0 and msgs[i-1].get(\u0026quot;role\u0026quot;) == \u0026quot;assistant\u0026quot;\n                    and msgs[i-1].get(\u0026quot;tool_calls\u0026quot;)):\n                while i \u0026lt; len(msgs) and msgs[i].get(\u0026quot;role\u0026quot;) == \u0026quot;tool\u0026quot;:\n                    i += 1\n        if i \u0026gt; 0:\n            summary = {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;[{i} earlier messages removed to fit context window.]\u0026quot;}\n            self._messages = [summary] + msgs[i:]\n            logger.info(f\u0026quot;Removed {i} msgs, tokens: {self.count_tokens()}\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e三个关键点\u003c/strong\u003e：System Prompt 始终保留不参与压缩；tool_call 对必须保持完整（\u003ccode\u003eassistant\u003c/code\u003e + 后续 \u003ccode\u003etool\u003c/code\u003e 消息一起删或一起留）；在 75% 时就触发压缩，给回复留够空间。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eStep 5: StateStore — 状态持久化\u003c/h3\u003e\n\u003cp\u003e简单的键值存储，生产中替换为 Redis 或数据库即可。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# state_store.py\nimport json\nfrom typing import Any, Optional\nfrom pathlib import Path\n\nclass StateStore:\n    def __init__(self, store_dir=\u0026quot;.agent_state\u0026quot;):\n        self.dir = Path(store_dir)\n        self.dir.mkdir(parents=True, exist_ok=True)\n        self._cache: dict[str, Any] = {}\n\n    def save(self, key, value):\n        self._cache[key] = value\n        (self.dir / f\u0026quot;{key}.json\u0026quot;).write_text(\n            json.dumps(value, ensure_ascii=False, indent=2, default=str))\n\n    def load(self, key, default=None):\n        if key in self._cache: return self._cache[key]\n        f = self.dir / f\u0026quot;{key}.json\u0026quot;\n        if f.exists():\n            v = json.loads(f.read_text())\n            self._cache[key] = v\n            return v\n        return default\n\n    def clear(self, key=None):\n        if key:\n            self._cache.pop(key, None)\n            (self.dir / f\u0026quot;{key}.json\u0026quot;).unlink(missing_ok=True)\n        else:\n            self._cache.clear()\n            for f in self.dir.glob(\u0026quot;*.json\u0026quot;): f.unlink()\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e4. 核心 Runtime Loop\u003c/h2\u003e\n\u003cp\u003e所有模块就绪，组装成完整的 \u003ccode\u003eAgentRuntime\u003c/code\u003e。这是整篇文章的核心。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# agent_runtime.py\nimport json, time, logging\nfrom dataclasses import dataclass, field\nfrom typing import Optional, Callable\nfrom collections import Counter\n\nfrom llm_client import LLMClient, LLMResponse\nfrom tool_registry import ToolRegistry\nfrom tool_executor import ToolExecutor\nfrom message_manager import MessageManager\nfrom state_store import StateStore\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass RuntimeConfig:\n    max_turns: int = 20               # 最大循环轮次\n    max_total_time: float = 300.0     # 最大总执行时间（秒）\n    parallel_tool_calls: bool = True  # 是否并行执行工具\n    loop_detection_window: int = 4    # 死循环检测窗口\n    loop_detection_threshold: int = 3 # 相同调用出现次数阈值\n\n@dataclass\nclass AgentResult:\n    content: str\n    turns: int = 0\n    total_tokens: int = 0\n    tool_calls_made: list[dict] = field(default_factory=list)\n    duration_ms: float = 0.0\n    stopped_reason: str = \u0026quot;\u0026quot;\n\nclass AgentRuntime:\n    def __init__(self, llm: LLMClient, registry: ToolRegistry,\n                 system_prompt=\u0026quot;You are a helpful assistant.\u0026quot;,\n                 config: Optional[RuntimeConfig] = None):\n        self.llm = llm\n        self.registry = registry\n        self.executor = ToolExecutor(registry)\n        self.config = config or RuntimeConfig()\n        self.messages = MessageManager(system_prompt=system_prompt,\n                                       model=llm.model)\n        self.state = StateStore()\n        self.on_tool_start: Optional[Callable] = None\n        self.on_tool_end: Optional[Callable] = None\n\n    def run(self, user_input: str) -\u0026gt; AgentResult:\n        start_time = time.monotonic()\n        self.messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_input})\n        tools = self.registry.get_all_schemas() or None\n\n        turns, total_tokens, all_tc = 0, 0, []\n        tc_history: list[str] = []\n        final_content, stopped = \u0026quot;\u0026quot;, \u0026quot;completed\u0026quot;\n\n        while turns \u0026lt; self.config.max_turns:\n            turns += 1\n\n            # ── 全局超时检查 ─────────────────────────────\n            if time.monotonic() - start_time \u0026gt; self.config.max_total_time:\n                stopped = f\u0026quot;timeout ({self.config.max_total_time}s)\u0026quot;\n                break\n\n            # ── 调用 LLM ────────────────────────────────\n            logger.info(f\u0026quot;Turn {turns}: calling LLM...\u0026quot;)\n            resp = self.llm.chat(self.messages.get_messages(), tools=tools)\n            total_tokens += resp.usage.get(\u0026quot;total_tokens\u0026quot;, 0)\n\n            # ── 情况 1: 有 tool_calls → 执行工具 ────────\n            if resp.has_tool_calls:\n                # 构建 assistant 消息（必须包含 tool_calls 字段）\n                asst = {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: resp.content,\n                        \u0026quot;tool_calls\u0026quot;: [\n                    {\u0026quot;id\u0026quot;: tc.id, \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n                     \u0026quot;function\u0026quot;: {\u0026quot;name\u0026quot;: tc.name,\n                                  \u0026quot;arguments\u0026quot;: json.dumps(tc.arguments)}}\n                    for tc in resp.tool_calls]}\n                self.messages.append(asst)\n\n                # 死循环检测\n                sig = json.dumps([(tc.name, tc.arguments)\n                                  for tc in resp.tool_calls], sort_keys=True)\n                tc_history.append(sig)\n                if self._detect_loop(tc_history):\n                    stopped = \u0026quot;loop_detected\u0026quot;\n                    final_content = (\u0026quot;I\u0026#39;m repeating the same actions. \u0026quot;\n                                     \u0026quot;Stopping to summarize findings.\u0026quot;)\n                    break\n\n                # 执行\n                if self.on_tool_start: self.on_tool_start(resp.tool_calls)\n                if self.config.parallel_tool_calls and len(resp.tool_calls) \u0026gt; 1:\n                    results = self.executor.execute_parallel(resp.tool_calls)\n                else:\n                    results = self.executor.execute(resp.tool_calls)\n                if self.on_tool_end: self.on_tool_end(results)\n\n                for tc, r in zip(resp.tool_calls, results):\n                    all_tc.append({\u0026quot;turn\u0026quot;: turns, \u0026quot;name\u0026quot;: tc.name,\n                        \u0026quot;arguments\u0026quot;: tc.arguments,\n                        \u0026quot;success\u0026quot;: r.success, \u0026quot;duration_ms\u0026quot;: r.duration_ms})\n\n                self.messages.extend(ToolExecutor.results_to_messages(results))\n\n            # ── 情况 2: 纯文本 → 任务完成 ───────────────\n            else:\n                final_content = resp.content or \u0026quot;\u0026quot;\n                self.messages.append(\n                    {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: final_content})\n                break\n        else:\n            stopped = f\u0026quot;max_turns ({self.config.max_turns})\u0026quot;\n\n        return AgentResult(\n            content=final_content, turns=turns, total_tokens=total_tokens,\n            tool_calls_made=all_tc,\n            duration_ms=(time.monotonic() - start_time) * 1000,\n            stopped_reason=stopped)\n\n    def _detect_loop(self, history):\n        \u0026quot;\u0026quot;\u0026quot;滑动窗口 + 频次统计，同时捕获连续重复和交替重复\u0026quot;\u0026quot;\u0026quot;\n        w = self.config.loop_detection_window\n        t = self.config.loop_detection_threshold\n        if len(history) \u0026lt; t: return False\n        return any(c \u0026gt;= t for c in Counter(history[-w:]).values())\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e核心循环解读\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e两种退出路径\u003c/strong\u003e——这是 Agent 与 Workflow 的本质区别：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eresp.has_tool_calls == True   → 继续（还有事要做）\nresp.has_tool_calls == False  → break（LLM 认为任务完成了）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e为什么 assistant 消息必须包含 tool_calls 字段？\u003c/strong\u003e 这是 OpenAI API 的协议约束。消息流必须是：\u003ccode\u003euser\u003c/code\u003e → \u003ccode\u003eassistant(tool_calls)\u003c/code\u003e → \u003ccode\u003etool(result)\u003c/code\u003e → \u003ccode\u003eassistant(final)\u003c/code\u003e。打破这个顺序会报错。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e死循环检测\u003c/strong\u003e用滑动窗口而非简单的\u0026quot;连续 N 次相同\u0026quot;，因为 LLM 有时会在两个工具间交替调用（A→B→A→B→...），这也是死循环，但不是\u0026quot;连续相同\u0026quot;。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 高级特性\u003c/h2\u003e\n\u003ch3\u003e5.1 Streaming 支持\u003c/h3\u003e\n\u003cp\u003e流式模式下需要边输出文本、边判断是否有 tool_calls：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 添加到 AgentRuntime\ndef run_stream(self, user_input: str):\n    self.messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_input})\n    tools = self.registry.get_all_schemas() or None\n    turns = 0\n\n    while turns \u0026lt; self.config.max_turns:\n        turns += 1\n        content, final_tc = \u0026quot;\u0026quot;, None\n\n        for chunk in self.llm.stream(self.messages.get_messages(), tools=tools):\n            if chunk.content:\n                content += chunk.content\n                yield {\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;content\u0026quot;: chunk.content}\n            if chunk.tool_calls:\n                final_tc = chunk.tool_calls\n\n        if final_tc:\n            yield {\u0026quot;type\u0026quot;: \u0026quot;tool_start\u0026quot;,\n                   \u0026quot;calls\u0026quot;: [{\u0026quot;name\u0026quot;:tc.name} for tc in final_tc]}\n            asst = {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: content,\n                    \u0026quot;tool_calls\u0026quot;: [\n                {\u0026quot;id\u0026quot;:tc.id, \u0026quot;type\u0026quot;:\u0026quot;function\u0026quot;,\n                 \u0026quot;function\u0026quot;:{\u0026quot;name\u0026quot;:tc.name,\n                             \u0026quot;arguments\u0026quot;:json.dumps(tc.arguments)}}\n                for tc in final_tc]}\n            self.messages.append(asst)\n            results = self.executor.execute(final_tc)\n            self.messages.extend(ToolExecutor.results_to_messages(results))\n            yield {\u0026quot;type\u0026quot;: \u0026quot;tool_end\u0026quot;,\n                   \u0026quot;results\u0026quot;: [{\u0026quot;name\u0026quot;:r.name, \u0026quot;ok\u0026quot;:r.success} for r in results]}\n        else:\n            self.messages.append({\u0026quot;role\u0026quot;:\u0026quot;assistant\u0026quot;,\u0026quot;content\u0026quot;:content})\n            yield {\u0026quot;type\u0026quot;: \u0026quot;done\u0026quot;, \u0026quot;content\u0026quot;: content}\n            break\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.2 超时控制的两层设计\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────┐\n│ 全局超时 (max_total_time = 300s)     │\n│  ┌──────┐ ┌──────┐ ┌──────┐        │\n│  │Tool 1│ │Tool 2│ │Tool 3│        │\n│  │30s   │ │30s   │ │30s   │        │\n│  └──────┘ └──────┘ └──────┘        │\n│ 单工具超时 (default_timeout = 30s)   │\n└──────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e单工具超时在 \u003ccode\u003eToolExecutor\u003c/code\u003e 中通过 \u003ccode\u003eThreadPoolExecutor.result(timeout=30)\u003c/code\u003e 控制；全局超时在 Runtime 每轮循环开始时检查 elapsed time。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 完整示例：研究助手 Agent\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# research_agent.py\nimport json, os, logging\nfrom agent_runtime import AgentRuntime, RuntimeConfig\nfrom llm_client import LLMClient\nfrom tool_registry import ToolRegistry\n\nlogging.basicConfig(level=logging.INFO,\n    format=\u0026quot;%(asctime)s [%(levelname)s] %(name)s: %(message)s\u0026quot;)\n\nregistry = ToolRegistry()\n\n@registry.tool()\ndef web_search(query: str, max_results: int = 5) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;搜索网页内容\n    Args:\n        query: 搜索关键词\n        max_results: 最大返回数量\n    \u0026quot;\u0026quot;\u0026quot;\n    # 生产环境替换为 SerpAPI / Bing API\n    return json.dumps([{\u0026quot;title\u0026quot;: f\u0026quot;Result {i+1} for \u0026#39;{query}\u0026#39;\u0026quot;,\n        \u0026quot;url\u0026quot;: f\u0026quot;https://example.com/article-{i+1}\u0026quot;,\n        \u0026quot;snippet\u0026quot;: f\u0026quot;Detailed article about {query}, section {i+1}...\u0026quot;}\n        for i in range(min(max_results, 3))], ensure_ascii=False)\n\n@registry.tool()\ndef read_url(url: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;读取网页内容\n    Args:\n        url: 网页地址\n    \u0026quot;\u0026quot;\u0026quot;\n    # 生产环境替换为 requests + BeautifulSoup\n    return (f\u0026quot;[Content from {url}]\\n\u0026quot;\n            f\u0026quot;Key points: 1) Fundamental concepts 2) Best practices \u0026quot;\n            f\u0026quot;3) Common pitfalls 4) Case studies and benchmarks\u0026quot;)\n\n@registry.tool()\ndef write_file(filename: str, content: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;写入文件\n    Args:\n        filename: 文件名\n        content: 文本内容\n    \u0026quot;\u0026quot;\u0026quot;\n    os.makedirs(\u0026quot;output\u0026quot;, exist_ok=True)\n    path = os.path.join(\u0026quot;output\u0026quot;, os.path.basename(filename))\n    with open(path, \u0026quot;w\u0026quot;) as f: f.write(content)\n    return f\u0026quot;Wrote {len(content)} chars to {path}\u0026quot;\n\n@registry.tool()\ndef ask_user(question: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;向用户提问\n    Args:\n        question: 问题\n    \u0026quot;\u0026quot;\u0026quot;\n    print(f\u0026quot;\\nAgent asks: {question}\u0026quot;)\n    return input(\u0026quot;Your answer: \u0026quot;)\n\nSYSTEM_PROMPT = \u0026quot;\u0026quot;\u0026quot;You are a research assistant. Workflow:\n1. Search for information using web_search\n2. Read promising articles using read_url (at least 2 sources)\n3. Synthesize into a report and save with write_file\n4. Present a summary. Use ask_user if the topic is unclear.\u0026quot;\u0026quot;\u0026quot;\n\nagent = AgentRuntime(\n    llm=LLMClient(model=\u0026quot;gpt-4o\u0026quot;, api_key=os.environ.get(\u0026quot;OPENAI_API_KEY\u0026quot;)),\n    registry=registry,\n    system_prompt=SYSTEM_PROMPT,\n    config=RuntimeConfig(max_turns=15, max_total_time=120.0))\n\nif __name__ == \u0026quot;__main__\u0026quot;:\n    result = agent.run(\u0026quot;研究 Python asyncio 最佳实践，整理成技术报告并保存。\u0026quot;)\n    print(f\u0026quot;\\n{\u0026#39;=\u0026#39;*50}\\nTurns: {result.turns} | Tokens: {result.total_tokens} \u0026quot;\n          f\u0026quot;| {result.duration_ms:.0f}ms | {result.stopped_reason}\u0026quot;)\n    for tc in result.tool_calls_made:\n        print(f\u0026quot;  Turn {tc[\u0026#39;turn\u0026#39;]}: {tc[\u0026#39;name\u0026#39;]}() \u0026quot;\n              f\u0026quot;{\u0026#39;OK\u0026#39; if tc[\u0026#39;success\u0026#39;] else \u0026#39;FAIL\u0026#39;} {tc[\u0026#39;duration_ms\u0026#39;]:.0f}ms\u0026quot;)\n    print(f\u0026quot;\\n{result.content[:300]}\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e执行 Trace\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eTurn 1: calling LLM...  → web_search(\u0026quot;Python asyncio best practices\u0026quot;)\nTurn 2: calling LLM...  → read_url(url1) + read_url(url2)  [parallel]\nTurn 3: calling LLM...  → web_search(\u0026quot;asyncio common pitfalls\u0026quot;)\nTurn 4: calling LLM...  → read_url(url3)\nTurn 5: calling LLM...  → write_file(\u0026quot;asyncio-report.md\u0026quot;, ...)\nTurn 6: calling LLM...  → [no tool_calls] → Done\n\n==================================================\nTurns: 6 | Tokens: 8432 | 13245ms | completed\n  Turn 1: web_search() OK 45ms\n  Turn 2: read_url() OK 120ms\n  Turn 2: read_url() OK 135ms\n  Turn 3: web_search() OK 38ms\n  Turn 4: read_url() OK 110ms\n  Turn 5: write_file() OK 5ms\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意 Turn 2：LLM 返回了两个 \u003ccode\u003eread_url\u003c/code\u003e，Runtime 自动并行执行。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 与框架对比\u003c/h2\u003e\n\u003ch3\u003e自建 vs 框架\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e自建 Runtime\u003c/th\u003e\n\u003cth\u003e框架（LangChain 等）\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e透明性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e完全透明\u003c/td\u003e\n\u003ctd\u003e需要读框架源码\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e调试\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e直接 breakpoint\u003c/td\u003e\n\u003ctd\u003e需要理解框架抽象层\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e定制\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e任何行为可改\u003c/td\u003e\n\u003ctd\u003e受 API 设计约束\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e依赖\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eopenai\u003c/code\u003e + \u003ccode\u003etiktoken\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e几十个传递依赖\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e边界情况\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e自己发现和处理\u003c/td\u003e\n\u003ctd\u003e社区帮你踩过坑\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e生态集成\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个都要自己写\u003c/td\u003e\n\u003ctd\u003e现成的 VectorStore/Retriever\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e开发速度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e初期更慢\u003c/td\u003e\n\u003ctd\u003e有模板更快\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e决策建议\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e学习阶段\u003c/strong\u003e：一定要自建一次。不理解原理就用框架，永远无法判断框架是否在坑你。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePoC / Hackathon\u003c/strong\u003e：用框架，速度第一。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e生产系统\u003c/strong\u003e：自建核心 Runtime + 选择性使用框架组件（如只用 LangChain 的 Retriever）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e基础设施团队\u003c/strong\u003e：自建。你们的需求框架大概率满足不了。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 结语：Phase 2 完成\u003c/h2\u003e\n\u003cp\u003e到这里，Phase 2 四篇文章全部完成：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e第 04 篇\u003c/strong\u003e：理解控制循环 — Observe → Think → Act → Reflect\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 05 篇\u003c/strong\u003e：深入 Tool Calling — JSON Schema、Function Calling、Structured Output\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 06 篇\u003c/strong\u003e：Prompt Engineering — System Prompt 设计、工具选择引导、Reflection Prompt\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 07 篇（本篇）\u003c/strong\u003e：把以上所有知识组装成可运行的 Agent Runtime\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e此刻你有能力\u003cstrong\u003e不依赖任何框架，从零构建功能完整的 Agent 系统\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e但如果你运行过这个 Agent，会很快发现几个问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e没有记忆\u003c/strong\u003e：每次启动都是白纸，不记得上次的对话\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e不会计划\u003c/strong\u003e：面对复杂任务只是一步步试，没有全局规划\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e一个不够用\u003c/strong\u003e：有些任务需要不同角色的 Agent 协作\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这就是 Phase 3 要解决的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e第 08 篇\u003c/strong\u003e：Memory Architecture — Agent 的状态与记忆体系\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 09 篇\u003c/strong\u003e：RAG as Cognitive Memory — 检索增强生成的工程实践\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 10 篇\u003c/strong\u003e：Planning and Reflection — 从 ReAct 到分层规划\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 11 篇\u003c/strong\u003e：Multi-Agent Collaboration — 多 Agent 协作\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePhase 2 给了你造一把锤子的能力。Phase 3 将教你如何造一个工具箱。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 07 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/06-Prompt%20Engineering%20for%20Agents\"\u003e06 | Prompt Engineering for Agents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/08-Memory%20Architecture\"\u003e08 | Memory Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-1 text-sm mb-4\",\"children\":[[\"$\",\"$L13\",null,{\"href\":\"/blog/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"博客\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"Engineering\"}],[[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/agentic/page/1\",\"className\":\"text-blue-600 hover:text-blue-700 transition-colors\",\"children\":\"Agentic 系统\"}]]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center mb-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-4 h-4 mr-2 text-gray-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z\"}]}],[\"$\",\"time\",null,{\"dateTime\":\"2025-12-14\",\"children\":\"2025年12月14日\"}]]}]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-6 text-center\",\"children\":\"The Agent Control Loop: Agent 运行时的核心抽象\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6 justify-center\",\"children\":[[\"$\",\"$L13\",\"Agentic\",{\"href\":\"/blog/tag/Agentic/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Agentic\"}],[\"$\",\"$L13\",\"AI Engineering\",{\"href\":\"/blog/tag/AI%20Engineering/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"AI Engineering\"}],[\"$\",\"$L13\",\"Runtime\",{\"href\":\"/blog/tag/Runtime/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Runtime\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto\",\"children\":[\"$\",\"$L14\",null,{\"content\":\"$15\"}]}],[\"$\",\"$10\",null,{\"fallback\":[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":\"加载导航中...\"}],\"children\":[\"$\",\"$L16\",null,{\"globalNav\":{\"prev\":{\"slug\":\"engineering/architecture/微服务架构落地指南：从核心模式到技术选型\",\"title\":\"微服务架构落地指南：从核心模式到技术选型\",\"description\":\"系统性地探讨微服务架构设计的核心关注点，包括服务注册发现、API 网关、服务容错、基础设施选型、CI/CD 流水线和可观测性体系，帮助你从 0 到 1 构建一套完整的微服务技术栈。\",\"pubDate\":\"2025-12-12\",\"tags\":[\"架构设计\",\"微服务\",\"分布式系统\",\"技术选型\"],\"heroImage\":\"$undefined\",\"content\":\"$17\"},\"next\":{\"slug\":\"engineering/architecture/高并发系统设计：原理、策略与工程实践\",\"title\":\"高并发系统设计：原理、策略与工程实践\",\"description\":\"系统梳理高并发架构的核心设计策略，从计算层、数据层、流量层到容错层，逐一分析每种策略的适用原理、决策依据与工程实践，构建可落地的高并发设计知识体系。\",\"pubDate\":\"2025-12-15\",\"tags\":[\"高并发\",\"系统架构\",\"性能优化\",\"分布式系统\"],\"heroImage\":\"$undefined\",\"content\":\"$18\"}},\"tagNav\":{\"Agentic\":{\"prev\":{\"slug\":\"engineering/agentic/03-Agent vs Workflow vs Automation\",\"title\":\"Agent vs Workflow vs Automation: 选对抽象才是关键\",\"description\":\"不是所有问题都需要 Agent。本文系统比较 Rule-based Automation、Workflow/DAG、Agent 三种执行范式，从确定性、成本、可观测性等维度给出选型框架，帮助工程师在真实场景中选对抽象层次。\",\"pubDate\":\"2025-12-09\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Architecture\"],\"heroImage\":\"$undefined\",\"content\":\"$19\"},\"next\":{\"slug\":\"engineering/agentic/05-Tool Calling Deep Dive\",\"title\":\"Tool Calling Deep Dive: 让 LLM 成为可编程接口\",\"description\":\"Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。\",\"pubDate\":\"2025-12-18\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Tool Calling\"],\"heroImage\":\"$undefined\",\"content\":\"$1a\"}},\"AI Engineering\":{\"prev\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:prev\",\"next\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:next\"},\"Runtime\":{\"prev\":null,\"next\":{\"slug\":\"engineering/agentic/07-Agent Runtime from Scratch\",\"title\":\"Agent Runtime from Scratch: 不依赖框架构建 Agent\",\"description\":\"不依赖 LangChain 等框架，从零实现一个功能完整的 Agent Runtime。逐模块构建 LLMClient、ToolRegistry、ToolExecutor、MessageManager 和核心控制循环，包含并行工具调用、Streaming、超时控制、死循环检测等高级特性，附完整可运行代码。\",\"pubDate\":\"2025-12-28\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Runtime\"],\"heroImage\":\"$undefined\",\"content\":\"$1b\"}}}}]}],[\"$\",\"$L1c\",null,{}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"8:null\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"a:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"The Agent Control Loop: Agent 运行时的核心抽象 - Skyfalling Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"The Agent Control Loop: Agent 运行时的核心抽象\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"5\",{\"property\":\"article:published_time\",\"content\":\"2025-12-14\"}],[\"$\",\"meta\",\"6\",{\"property\":\"article:author\",\"content\":\"Skyfalling\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"The Agent Control Loop: Agent 运行时的核心抽象\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。\"}],[\"$\",\"link\",\"10\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"13\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":\"$a:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>