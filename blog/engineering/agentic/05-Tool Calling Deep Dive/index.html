<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/66b421ed9771e9de.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42d55485b4428e47.js"/><script src="/_next/static/chunks/4bd1b696-8ec333fca6b38e39.js" async=""></script><script src="/_next/static/chunks/1684-a2aac8a674e5d38c.js" async=""></script><script src="/_next/static/chunks/main-app-2791dc86ed05573e.js" async=""></script><script src="/_next/static/chunks/6874-7791217feaf05c17.js" async=""></script><script src="/_next/static/chunks/app/layout-142e67ac4336647c.js" async=""></script><script src="/_next/static/chunks/968-d7155a2506e36f1d.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js" async=""></script><meta name="next-size-adjust" content=""/><title>Tool Calling Deep Dive: 让 LLM 成为可编程接口 - Skyfalling Blog</title><meta name="description" content="Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。"/><meta property="og:title" content="Tool Calling Deep Dive: 让 LLM 成为可编程接口"/><meta property="og:description" content="Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-12-18"/><meta property="article:author" content="Skyfalling"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Tool Calling Deep Dive: 让 LLM 成为可编程接口"/><meta name="twitter:description" content="Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。"/><link rel="shortcut icon" href="/favicon.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/favicon.png"/><link rel="apple-touch-icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen flex flex-col"><header class="bg-[var(--background)]"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a class="-m-1.5 p-1.5" href="/"><span class="sr-only">Skyfalling Blog</span><span class="text-2xl font-bold text-gray-900">Skyfalling</span></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">打开主菜单</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/">首页</a><a class="text-base font-semibold leading-6 transition-colors text-blue-600 border-b-2 border-blue-600 pb-1" href="/blog/">博客</a><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/about/">关于</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"></div></nav></header><main class="flex-1"><article class="min-h-screen"><div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8"><div class="rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12"><header class="mb-8"><nav class="flex items-center gap-1 text-sm mb-4"><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/page/1/">博客</a><span class="text-gray-300">/</span><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/category/engineering/page/1/">Engineering</a><span class="text-gray-300">/</span><a class="text-blue-600 hover:text-blue-700 transition-colors" href="/blog/category/engineering/agentic/page/1/">Agentic 系统</a></nav><div class="flex items-center mb-6"><div class="inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal"><svg class="w-4 h-4 mr-2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2025-12-18">2025年12月18日</time></div></div><h1 class="text-4xl font-bold text-gray-900 mb-6 text-center">Tool Calling Deep Dive: 让 LLM 成为可编程接口</h1><div class="flex flex-wrap gap-2 mb-6 justify-center"><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Agentic/page/1/">Agentic</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/AI%20Engineering/page/1/">AI Engineering</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Tool%20Calling/page/1/">Tool Calling</a></div></header><div class="max-w-5xl mx-auto"><div class="prose prose-lg prose-gray mx-auto max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:text-blue-700 prose-strong:text-gray-900 prose-strong:font-semibold prose-li:text-gray-700 prose-hr:border-gray-300"><h1>Tool Calling Deep Dive: 让 LLM 成为可编程接口</h1>
<blockquote>
<p>这是 Agentic 系列的第 05 篇。在前几篇中我们建立了 Agent 的概念模型、控制循环、以及 Agent 与 Workflow 的边界。本篇聚焦于 Agent 能力的核心支点——Tool Calling。</p>
<p>Tool Calling 不是&quot;让 AI 调 API&quot;这么简单。它是 LLM 从 <strong>Text-in/Text-out 的生成模型</strong> 变成 <strong>可编程接口</strong> 的关键转折点。理解它的工作原理、设计约束和工程实践，是构建任何 Agentic 系统的前提。</p>
</blockquote>
<hr>
<h2>1. 为什么 Tool Calling 是关键转折点</h2>
<p>一个纯粹的 LLM 只能做一件事：接受文本，生成文本。它无法查询数据库、无法读取文件、无法发送邮件、无法获取实时天气。它的知识冻结在训练数据的截止日期，它的能力边界就是 token 序列的排列组合。</p>
<p>Tool Calling 改变了这一切。</p>
<p>它的本质不是&quot;让 LLM 调用工具&quot;，而是 <strong>让 LLM 生成结构化的调用意图，由外部运行时代为执行</strong>。这个区分至关重要——LLM 从未真正&quot;执行&quot;过任何工具，它只是学会了在恰当的时机，输出一段符合约定格式的 JSON，表达&quot;我需要调用某个工具，参数是这些&quot;。</p>
<p>这意味着：</p>
<ul>
<li>LLM 变成了一个 <strong>决策引擎</strong>：决定调用什么、传什么参数</li>
<li>Runtime 变成了一个 <strong>执行引擎</strong>：负责真正的 I/O 操作</li>
<li>两者之间的契约是 <strong>JSON Schema</strong></li>
</ul>
<p>这种分离，让 LLM 从一个封闭的文本生成器，变成了一个可以与外部世界交互的可编程接口。</p>
<hr>
<h2>2. Tool Calling 的工作原理</h2>
<h3>2.1 完整流程</h3>
<pre><code>┌──────────────────────────────────────────────────────────────────────┐
│                    Tool Calling 完整序列图                            │
└──────────────────────────────────────────────────────────────────────┘

  User            LLM (API)          Runtime           Tool (Function)
   │                 │                  │                     │
   │  &quot;北京今天天气&quot;  │                  │                     │
   ├────────────────&gt;│                  │                     │
   │                 │                  │                     │
   │                 │  ┌─────────────┐ │                     │
   │                 │  │ 推理:       │ │                     │
   │                 │  │ 用户想查天气 │ │                     │
   │                 │  │ 需要调用    │ │                     │
   │                 │  │ get_weather │ │                     │
   │                 │  └─────────────┘ │                     │
   │                 │                  │                     │
   │                 │  Tool Call JSON  │                     │
   │                 │ ────────────────&gt;│                     │
   │                 │  {               │                     │
   │                 │   &quot;name&quot;:        │                     │
   │                 │    &quot;get_weather&quot; │                     │
   │                 │   &quot;arguments&quot;:   │                     │
   │                 │    {&quot;city&quot;:      │                     │
   │                 │     &quot;北京&quot;}      │                     │
   │                 │  }               │                     │
   │                 │                  │  get_weather(&quot;北京&quot;) │
   │                 │                  ├────────────────────&gt;│
   │                 │                  │                     │
   │                 │                  │  {&quot;temp&quot;: 28,       │
   │                 │                  │   &quot;condition&quot;:      │
   │                 │                  │   &quot;晴&quot;}              │
   │                 │                  │&lt;────────────────────┤
   │                 │                  │                     │
   │                 │  Tool Result     │                     │
   │                 │ &lt;────────────────│                     │
   │                 │                  │                     │
   │                 │  ┌─────────────┐ │                     │
   │                 │  │ 推理:       │ │                     │
   │                 │  │ 根据工具返回 │ │                     │
   │                 │  │ 组织回答    │ │                     │
   │                 │  └─────────────┘ │                     │
   │                 │                  │                     │
   │ &quot;北京今天28°C,晴&quot;│                  │                     │
   │&lt;────────────────│                  │                     │
   │                 │                  │                     │
</code></pre>
<h3>2.2 关键洞察</h3>
<p>从上面的序列图中，可以提炼出几个核心事实：</p>
<ol>
<li><p><strong>LLM 发起两次推理</strong>。第一次决定是否调用工具、调用哪个、传什么参数；第二次基于工具返回的结果生成最终回答。这意味着每次 Tool Calling 至少消耗两轮 LLM 调用的 token。</p>
</li>
<li><p><strong>LLM 的输出不是自然语言，而是结构化 JSON</strong>。这是模型经过专门训练（fine-tuning）才获得的能力。并非所有 LLM 都支持 Tool Calling——它需要模型在训练阶段就学会&quot;在特定上下文下输出 JSON 而非自然语言&quot;。</p>
</li>
<li><p><strong>Runtime 是不可或缺的中间层</strong>。它负责：解析 LLM 返回的 Tool Call、校验参数、路由到正确的函数、执行函数、收集结果、将结果注入下一轮对话。没有 Runtime，Tool Calling 就是一段无人执行的 JSON。</p>
</li>
<li><p><strong>整个过程对用户透明</strong>。用户看到的只是&quot;问了一个问题，得到了回答&quot;。中间的 Tool Call 调度过程完全由系统内部完成。</p>
</li>
</ol>
<hr>
<h2>3. JSON Schema 作为契约</h2>
<h3>3.1 工具定义的结构</h3>
<p>每个工具的定义由三部分组成：</p>
<pre><code class="language-python">tool_definition = {
    &quot;type&quot;: &quot;function&quot;,
    &quot;function&quot;: {
        &quot;name&quot;: &quot;get_weather&quot;,          # 工具的唯一标识
        &quot;description&quot;: &quot;...&quot;,           # 给 LLM 看的&quot;接口文档&quot;
        &quot;parameters&quot;: {                 # JSON Schema 格式的参数约束
            &quot;type&quot;: &quot;object&quot;,
            &quot;properties&quot;: {
                &quot;city&quot;: {
                    &quot;type&quot;: &quot;string&quot;,
                    &quot;description&quot;: &quot;城市名称，如 &#39;北京&#39;、&#39;上海&#39;&quot;
                }
            },
            &quot;required&quot;: [&quot;city&quot;]
        }
    }
}
</code></pre>
<p>这里的 <code>parameters</code> 遵循 JSON Schema 规范（Draft 2020-12 子集），它不仅定义了参数的类型，还定义了参数的约束、默认值、枚举范围等。JSON Schema 就是 LLM 与 Runtime 之间的 <strong>契约</strong>。</p>
<h3>3.2 好的描述 vs 差的描述</h3>
<p><code>description</code> 是整个工具定义中最容易被低估的字段。它不是给人类看的注释，而是 <strong>给 LLM 看的接口文档</strong>。LLM 完全依赖 description 来决定是否调用这个工具、以及如何填充参数。</p>
<p><strong>差的描述：</strong></p>
<pre><code class="language-python">{
    &quot;name&quot;: &quot;query_db&quot;,
    &quot;description&quot;: &quot;查询数据库&quot;,          # 太模糊：查什么数据库？返回什么？
    &quot;parameters&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;q&quot;: {                        # 参数名不直观
                &quot;type&quot;: &quot;string&quot;
            }
        }
    }
}
</code></pre>
<p><strong>好的描述：</strong></p>
<pre><code class="language-python">{
    &quot;name&quot;: &quot;query_user_orders&quot;,
    &quot;description&quot;: (
        &quot;根据用户 ID 查询该用户的历史订单列表。&quot;
        &quot;返回最近 30 天内的订单，包含订单号、金额、状态。&quot;
        &quot;如果用户不存在，返回空列表。&quot;
        &quot;不支持模糊查询，user_id 必须精确匹配。&quot;
    ),
    &quot;parameters&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;user_id&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;用户的唯一标识符，格式为 &#39;U&#39; + 8位数字，如 &#39;U00012345&#39;&quot;
            },
            &quot;status_filter&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;enum&quot;: [&quot;all&quot;, &quot;pending&quot;, &quot;completed&quot;, &quot;cancelled&quot;],
                &quot;description&quot;: &quot;按订单状态过滤，默认返回所有状态的订单&quot;
            }
        },
        &quot;required&quot;: [&quot;user_id&quot;]
    }
}
</code></pre>
<p>两者之间的差异在于：</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>差的描述</th>
<th>好的描述</th>
</tr>
</thead>
<tbody><tr>
<td>功能边界</td>
<td>不清楚能做什么</td>
<td>明确说明查询范围和返回内容</td>
</tr>
<tr>
<td>参数语义</td>
<td><code>q</code> 是什么？</td>
<td><code>user_id</code> 含义清晰，且给出格式示例</td>
</tr>
<tr>
<td>约束条件</td>
<td>无</td>
<td>明确说明不支持模糊查询</td>
</tr>
<tr>
<td>异常行为</td>
<td>未提及</td>
<td>说明了用户不存在时的返回</td>
</tr>
<tr>
<td>枚举约束</td>
<td>无</td>
<td>用 <code>enum</code> 限定合法值</td>
</tr>
</tbody></table>
<h3>3.3 参数设计原则</h3>
<ol>
<li><strong>简单优先</strong>：参数数量尽量少。一个工具如果需要 10 个参数，说明它的职责太大，应该拆分。</li>
<li><strong>类型明确</strong>：用 <code>enum</code> 约束离散值，用 <code>pattern</code> 约束格式，用 <code>minimum</code>/<code>maximum</code> 约束数值范围。</li>
<li><strong>必选与可选分明</strong>：<code>required</code> 字段只放真正必须的参数，可选参数给默认值。</li>
<li><strong>命名即文档</strong>：<code>user_id</code> 比 <code>uid</code> 好，<code>start_date</code> 比 <code>sd</code> 好。LLM 会从参数名推断语义。</li>
<li><strong>避免嵌套过深</strong>：LLM 生成深层嵌套 JSON 的准确率会显著下降。尽量用扁平结构。</li>
</ol>
<hr>
<h2>4. Structured Output vs Free-form Output</h2>
<h3>4.1 为什么结构化输出更可靠</h3>
<p>在 Tool Calling 出现之前，让 LLM 调用工具的常见做法是：在 Prompt 中要求 LLM &quot;用特定格式输出&quot;，然后用正则或字符串解析提取调用意图。</p>
<pre><code># 旧做法（Prompt Hacking）
请用以下格式回答：
Action: &lt;工具名&gt;
Action Input: &lt;参数 JSON&gt;

# LLM 可能的输出（不可靠）
&quot;我觉得应该查一下天气。Action: get_weather Action Input: {&quot;city&quot;: &quot;北京&quot;}&quot;
                       ^^ 前面混入了自然语言，解析会出错
</code></pre>
<p>这种方式的根本问题是：LLM 的输出是 <strong>非确定性的自由文本</strong>，它可能在格式中混入自然语言、遗漏字段、搞错 JSON 语法。</p>
<p>Structured Output（结构化输出）通过 <strong>约束解码（Constrained Decoding）</strong> 从根本上解决了这个问题。模型在生成 token 时，解码器会强制输出符合预定义 JSON Schema 的 token 序列，从而保证输出 100% 可解析。</p>
<h3>4.2 三种机制的区别</h3>
<table>
<thead>
<tr>
<th>机制</th>
<th>原理</th>
<th>可靠性</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>JSON Mode</strong></td>
<td>告诉模型&quot;输出必须是合法 JSON&quot;，但不约束 schema</td>
<td>中等。JSON 语法正确，但字段可能不对</td>
<td>简单的数据提取</td>
</tr>
<tr>
<td><strong>Function Calling / Tool Use</strong></td>
<td>模型经过 fine-tuning，能在特定上下文下输出 tool call 结构</td>
<td>高。模型专门训练过</td>
<td>Agent 工具调用</td>
</tr>
<tr>
<td><strong>Structured Output</strong></td>
<td>约束解码 + JSON Schema 验证，输出严格匹配 schema</td>
<td>极高。解码层面保证</td>
<td>需要严格 schema 的场景</td>
</tr>
</tbody></table>
<h3>4.3 各大模型的实现差异</h3>
<p>不同模型提供商对 Tool Calling 的 API 设计不尽相同，但核心思想一致：</p>
<p><strong>OpenAI</strong>（GPT-4 系列）：</p>
<ul>
<li>使用 <code>tools</code> 参数传递工具定义</li>
<li>返回 <code>tool_calls</code> 数组，支持并行调用</li>
<li>支持 <code>strict: true</code> 开启 Structured Output 模式</li>
</ul>
<p><strong>Anthropic</strong>（Claude 系列）：</p>
<ul>
<li>使用 <code>tools</code> 参数传递工具定义</li>
<li>Tool Call 以 <code>tool_use</code> content block 返回</li>
<li>Tool 结果以 <code>tool_result</code> content block 传回</li>
<li>原生支持并行工具调用</li>
</ul>
<p><strong>Google</strong>（Gemini 系列）：</p>
<ul>
<li>使用 <code>tools</code> + <code>function_declarations</code> 结构</li>
<li>支持 <code>function_calling_config</code> 控制调用模式（AUTO / ANY / NONE）</li>
<li>返回 <code>function_call</code> part</li>
</ul>
<p>虽然 API 格式不同，但抽象层面是一致的：<strong>定义工具 → LLM 决定调用 → 返回结构化调用请求 → 外部执行 → 结果回传</strong>。这也是为什么我们强调框架无关的原理理解——API 会变，原理不会。</p>
<hr>
<h2>5. 工具注册与发现（Tool Registry）</h2>
<h3>5.1 静态注册</h3>
<p>最简单的方式是在代码中硬编码工具列表：</p>
<pre><code class="language-python">TOOLS = [
    get_weather_tool,
    query_db_tool,
    send_email_tool,
]

response = client.chat.completions.create(
    model=&quot;gpt-4&quot;,
    messages=messages,
    tools=TOOLS,
)
</code></pre>
<p>优点是简单直接，缺点是每次新增或修改工具都需要改代码、重新部署。适合工具数量少且稳定的场景。</p>
<h3>5.2 动态注册</h3>
<p>当工具数量增多或需要根据上下文动态调整时，需要一个 Tool Registry：</p>
<pre><code>┌────────────────────────────────────────────────┐
│                Tool Registry                    │
│                                                │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐     │
│  │ weather  │  │ database │  │  email   │     │
│  │  tool    │  │  tool    │  │  tool    │     │
│  └──────────┘  └──────────┘  └──────────┘     │
│  ┌──────────┐  ┌──────────┐                    │
│  │  calc    │  │   file   │                    │
│  │  tool    │  │  tool    │                    │
│  └──────────┘  └──────────┘                    │
│                                                │
│  register(tool) / unregister(name)             │
│  get_tools(filter?) -&gt; List[Tool]              │
│  get_tool(name) -&gt; Tool                        │
│  get_definitions() -&gt; List[Dict]               │
└────────────────────────────────────────────────┘
         │
         │  get_definitions()
         ▼
   ┌───────────┐     tools=[...]     ┌───────────┐
   │  Runtime   │ ──────────────────&gt; │  LLM API  │
   └───────────┘                     └───────────┘
</code></pre>
<h3>5.3 工具选择问题</h3>
<p>当工具数量超过一定阈值（经验值：15-20 个），LLM 的工具选择准确率会明显下降。原因有两个：</p>
<ol>
<li><strong>Context 膨胀</strong>：每个工具定义占用数百 token，20 个工具就是数千 token 的 system prompt，挤占了有效上下文空间。</li>
<li><strong>选择困难</strong>：工具越多，语义越可能重叠，LLM 越难区分应该调用哪个。</li>
</ol>
<h3>5.4 Tool Selection 策略</h3>
<p><strong>策略一：全量传递</strong></p>
<pre><code>所有工具 ──全部传递──&gt; LLM
</code></pre>
<p>适用场景：工具少于 10 个。简单暴力，无额外开销。</p>
<p><strong>策略二：语义过滤</strong></p>
<pre><code>用户输入 ──Embedding──&gt; 向量
                          │
工具描述 ──Embedding──&gt; 向量库 ──Top-K 相似──&gt; 候选工具 ──&gt; LLM
</code></pre>
<p>用 Embedding 计算用户输入与工具描述的语义相似度，只传递 Top-K 最相关的工具。缺点是可能漏掉正确工具。</p>
<p><strong>策略三：两阶段选择</strong></p>
<pre><code>阶段 1：所有工具名 + 简短描述 ──&gt; LLM ──&gt; 选出候选工具 (3-5 个)
阶段 2：候选工具的完整定义     ──&gt; LLM ──&gt; 执行 Tool Call
</code></pre>
<p>第一阶段只传递工具名和一行描述（token 消耗少），让 LLM 先做粗筛；第二阶段只传递选中工具的完整定义。这种方式在工具数量 50+ 的场景下效果最好，代价是多一轮 LLM 调用。</p>
<hr>
<h2>6. 完整代码示例</h2>
<h3>6.1 工具定义</h3>
<pre><code class="language-python">from dataclasses import dataclass, field
from typing import Any, Callable

@dataclass
class Tool:
    &quot;&quot;&quot;工具的统一抽象&quot;&quot;&quot;
    name: str
    description: str
    parameters: dict          # JSON Schema
    function: Callable        # 实际执行的函数
    requires_confirmation: bool = False  # 是否需要用户确认

    def to_openai_schema(self) -&gt; dict:
        &quot;&quot;&quot;转换为 OpenAI API 格式&quot;&quot;&quot;
        return {
            &quot;type&quot;: &quot;function&quot;,
            &quot;function&quot;: {
                &quot;name&quot;: self.name,
                &quot;description&quot;: self.description,
                &quot;parameters&quot;: self.parameters,
            }
        }

# ── 工具实现 ──────────────────────────────────────────────

def get_weather(city: str, unit: str = &quot;celsius&quot;) -&gt; dict:
    &quot;&quot;&quot;模拟天气查询&quot;&quot;&quot;
    # 实际场景中调用天气 API
    mock_data = {
        &quot;北京&quot;: {&quot;temp&quot;: 28, &quot;condition&quot;: &quot;晴&quot;, &quot;humidity&quot;: 45},
        &quot;上海&quot;: {&quot;temp&quot;: 32, &quot;condition&quot;: &quot;多云&quot;, &quot;humidity&quot;: 78},
    }
    data = mock_data.get(city, {&quot;temp&quot;: 20, &quot;condition&quot;: &quot;未知&quot;, &quot;humidity&quot;: 50})
    if unit == &quot;fahrenheit&quot;:
        data[&quot;temp&quot;] = data[&quot;temp&quot;] * 9 / 5 + 32
    return {&quot;city&quot;: city, **data}


def query_database(sql: str, database: str = &quot;default&quot;) -&gt; dict:
    &quot;&quot;&quot;模拟数据库查询&quot;&quot;&quot;
    # 实际场景中执行 SQL
    return {
        &quot;database&quot;: database,
        &quot;query&quot;: sql,
        &quot;rows&quot;: [
            {&quot;id&quot;: 1, &quot;name&quot;: &quot;Alice&quot;, &quot;amount&quot;: 100.0},
            {&quot;id&quot;: 2, &quot;name&quot;: &quot;Bob&quot;, &quot;amount&quot;: 200.0},
        ],
        &quot;row_count&quot;: 2,
    }


def calculate(expression: str) -&gt; dict:
    &quot;&quot;&quot;安全的数学计算&quot;&quot;&quot;
    allowed_chars = set(&quot;0123456789+-*/.() &quot;)
    if not all(c in allowed_chars for c in expression):
        return {&quot;error&quot;: &quot;表达式包含非法字符&quot;}
    try:
        result = eval(expression)  # 生产环境应使用 ast.literal_eval 或专用解析器
        return {&quot;expression&quot;: expression, &quot;result&quot;: result}
    except Exception as e:
        return {&quot;error&quot;: str(e)}


def read_file(file_path: str, encoding: str = &quot;utf-8&quot;) -&gt; dict:
    &quot;&quot;&quot;读取文件内容&quot;&quot;&quot;
    try:
        with open(file_path, &quot;r&quot;, encoding=encoding) as f:
            content = f.read(10000)  # 限制读取大小
        return {&quot;path&quot;: file_path, &quot;content&quot;: content, &quot;size&quot;: len(content)}
    except FileNotFoundError:
        return {&quot;error&quot;: f&quot;文件不存在: {file_path}&quot;}
    except Exception as e:
        return {&quot;error&quot;: str(e)}


def send_email(to: str, subject: str, body: str) -&gt; dict:
    &quot;&quot;&quot;模拟发送邮件&quot;&quot;&quot;
    # 实际场景中调用邮件服务
    return {&quot;status&quot;: &quot;sent&quot;, &quot;to&quot;: to, &quot;subject&quot;: subject}


# ── 工具注册 ──────────────────────────────────────────────

weather_tool = Tool(
    name=&quot;get_weather&quot;,
    description=(
        &quot;查询指定城市的当前天气信息，包括温度、天气状况和湿度。&quot;
        &quot;支持国内主要城市。如果城市不在数据库中，返回默认值。&quot;
    ),
    parameters={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;city&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;要查询的城市名称，如 &#39;北京&#39;、&#39;上海&#39;&quot;
            },
            &quot;unit&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;enum&quot;: [&quot;celsius&quot;, &quot;fahrenheit&quot;],
                &quot;description&quot;: &quot;温度单位，默认摄氏度&quot;
            }
        },
        &quot;required&quot;: [&quot;city&quot;],
    },
    function=get_weather,
)

database_tool = Tool(
    name=&quot;query_database&quot;,
    description=(
        &quot;执行 SQL 查询并返回结果。仅支持 SELECT 语句，&quot;
        &quot;不允许执行 INSERT/UPDATE/DELETE 等写操作。&quot;
        &quot;返回结果包含行数据和总行数。&quot;
    ),
    parameters={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;sql&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;要执行的 SQL SELECT 语句&quot;
            },
            &quot;database&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;enum&quot;: [&quot;default&quot;, &quot;analytics&quot;, &quot;users&quot;],
                &quot;description&quot;: &quot;目标数据库名称，默认为 &#39;default&#39;&quot;
            }
        },
        &quot;required&quot;: [&quot;sql&quot;],
    },
    function=query_database,
)

calculator_tool = Tool(
    name=&quot;calculate&quot;,
    description=(
        &quot;执行数学计算。支持加减乘除和括号。&quot;
        &quot;输入为数学表达式字符串，如 &#39;(3 + 5) * 2&#39;。&quot;
        &quot;不支持变量和函数调用，仅限纯数值运算。&quot;
    ),
    parameters={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;expression&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;数学表达式，如 &#39;(3 + 5) * 2&#39;&quot;
            }
        },
        &quot;required&quot;: [&quot;expression&quot;],
    },
    function=calculate,
)

file_tool = Tool(
    name=&quot;read_file&quot;,
    description=(
        &quot;读取指定路径的文本文件内容。最多读取 10000 字符。&quot;
        &quot;仅支持文本文件，不支持二进制文件。&quot;
        &quot;如果文件不存在，返回错误信息。&quot;
    ),
    parameters={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;file_path&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;文件的绝对路径或相对路径&quot;
            },
            &quot;encoding&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;文件编码，默认 utf-8&quot;
            }
        },
        &quot;required&quot;: [&quot;file_path&quot;],
    },
    function=read_file,
)

email_tool = Tool(
    name=&quot;send_email&quot;,
    description=(
        &quot;向指定收件人发送一封电子邮件。&quot;
        &quot;需要提供收件人地址、邮件主题和正文。&quot;
        &quot;正文支持纯文本格式。&quot;
    ),
    parameters={
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
            &quot;to&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;收件人邮箱地址&quot;
            },
            &quot;subject&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;邮件主题&quot;
            },
            &quot;body&quot;: {
                &quot;type&quot;: &quot;string&quot;,
                &quot;description&quot;: &quot;邮件正文，纯文本格式&quot;
            }
        },
        &quot;required&quot;: [&quot;to&quot;, &quot;subject&quot;, &quot;body&quot;],
    },
    function=send_email,
    requires_confirmation=True,  # 发邮件需要用户确认
)
</code></pre>
<h3>6.2 Tool Registry 实现</h3>
<pre><code class="language-python">import json
from typing import Optional

class ToolRegistry:
    &quot;&quot;&quot;工具注册中心&quot;&quot;&quot;

    def __init__(self):
        self._tools: dict[str, Tool] = {}

    def register(self, tool: Tool) -&gt; None:
        if tool.name in self._tools:
            raise ValueError(f&quot;工具 &#39;{tool.name}&#39; 已注册&quot;)
        self._tools[tool.name] = tool

    def unregister(self, name: str) -&gt; None:
        self._tools.pop(name, None)

    def get_tool(self, name: str) -&gt; Optional[Tool]:
        return self._tools.get(name)

    def get_all_tools(self) -&gt; list[Tool]:
        return list(self._tools.values())

    def get_definitions(self, names: list[str] | None = None) -&gt; list[dict]:
        &quot;&quot;&quot;获取工具定义列表（用于传递给 LLM API）&quot;&quot;&quot;
        tools = self._tools.values()
        if names:
            tools = [t for t in tools if t.name in names]
        return [t.to_openai_schema() for t in tools]

    def get_summary(self) -&gt; str:
        &quot;&quot;&quot;获取工具摘要（用于两阶段选择的第一阶段）&quot;&quot;&quot;
        lines = []
        for tool in self._tools.values():
            # 只取 description 的第一句
            short_desc = tool.description.split(&quot;。&quot;)[0] + &quot;。&quot;
            lines.append(f&quot;- {tool.name}: {short_desc}&quot;)
        return &quot;\n&quot;.join(lines)


# 初始化 Registry
registry = ToolRegistry()
for tool in [weather_tool, database_tool, calculator_tool, file_tool, email_tool]:
    registry.register(tool)
</code></pre>
<h3>6.3 Tool Dispatcher 实现</h3>
<pre><code class="language-python">import json
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed

class ToolDispatcher:
    &quot;&quot;&quot;
    工具调度器：解析 LLM 返回的 tool calls，执行对应工具，收集结果。
    &quot;&quot;&quot;

    def __init__(self, registry: ToolRegistry, max_parallel: int = 5):
        self.registry = registry
        self.max_parallel = max_parallel

    def validate_arguments(self, tool: Tool, arguments: dict) -&gt; list[str]:
        &quot;&quot;&quot;基础参数验证（生产环境建议使用 jsonschema 库）&quot;&quot;&quot;
        errors = []
        schema = tool.parameters
        required = schema.get(&quot;required&quot;, [])
        properties = schema.get(&quot;properties&quot;, {})

        # 检查必填参数
        for param in required:
            if param not in arguments:
                errors.append(f&quot;缺少必填参数: {param}&quot;)

        # 检查参数类型和枚举
        for param, value in arguments.items():
            if param not in properties:
                errors.append(f&quot;未知参数: {param}&quot;)
                continue
            prop_schema = properties[param]
            if &quot;enum&quot; in prop_schema and value not in prop_schema[&quot;enum&quot;]:
                errors.append(
                    f&quot;参数 &#39;{param}&#39; 的值 &#39;{value}&#39; &quot;
                    f&quot;不在允许范围内: {prop_schema[&#39;enum&#39;]}&quot;
                )

        return errors

    def execute_single(self, tool_call: dict) -&gt; dict:
        &quot;&quot;&quot;执行单个工具调用&quot;&quot;&quot;
        name = tool_call[&quot;function&quot;][&quot;name&quot;]
        raw_args = tool_call[&quot;function&quot;][&quot;arguments&quot;]
        call_id = tool_call.get(&quot;id&quot;, &quot;unknown&quot;)

        # 1. 查找工具
        tool = self.registry.get_tool(name)
        if not tool:
            return {
                &quot;tool_call_id&quot;: call_id,
                &quot;role&quot;: &quot;tool&quot;,
                &quot;content&quot;: json.dumps({&quot;error&quot;: f&quot;工具 &#39;{name}&#39; 不存在&quot;}),
            }

        # 2. 解析参数
        try:
            arguments = json.loads(raw_args) if isinstance(raw_args, str) else raw_args
        except json.JSONDecodeError as e:
            return {
                &quot;tool_call_id&quot;: call_id,
                &quot;role&quot;: &quot;tool&quot;,
                &quot;content&quot;: json.dumps({&quot;error&quot;: f&quot;参数 JSON 解析失败: {e}&quot;}),
            }

        # 3. 验证参数
        errors = self.validate_arguments(tool, arguments)
        if errors:
            return {
                &quot;tool_call_id&quot;: call_id,
                &quot;role&quot;: &quot;tool&quot;,
                &quot;content&quot;: json.dumps({&quot;error&quot;: &quot;参数验证失败&quot;, &quot;details&quot;: errors}),
            }

        # 4. 执行工具
        try:
            result = tool.function(**arguments)
            return {
                &quot;tool_call_id&quot;: call_id,
                &quot;role&quot;: &quot;tool&quot;,
                &quot;content&quot;: json.dumps(result, ensure_ascii=False),
            }
        except Exception as e:
            return {
                &quot;tool_call_id&quot;: call_id,
                &quot;role&quot;: &quot;tool&quot;,
                &quot;content&quot;: json.dumps({
                    &quot;error&quot;: f&quot;工具执行失败: {type(e).__name__}: {e}&quot;,
                    &quot;traceback&quot;: traceback.format_exc()[-500:],  # 截断过长的堆栈
                }),
            }

    def execute_parallel(self, tool_calls: list[dict]) -&gt; list[dict]:
        &quot;&quot;&quot;并行执行多个工具调用&quot;&quot;&quot;
        if len(tool_calls) == 1:
            return [self.execute_single(tool_calls[0])]

        results = []
        with ThreadPoolExecutor(max_workers=self.max_parallel) as executor:
            future_to_call = {
                executor.submit(self.execute_single, tc): tc
                for tc in tool_calls
            }
            for future in as_completed(future_to_call):
                results.append(future.result())

        # 按原始顺序排列结果
        id_to_result = {r[&quot;tool_call_id&quot;]: r for r in results}
        ordered = []
        for tc in tool_calls:
            call_id = tc.get(&quot;id&quot;, &quot;unknown&quot;)
            ordered.append(id_to_result.get(call_id, results.pop(0)))
        return ordered


dispatcher = ToolDispatcher(registry)
</code></pre>
<h3>6.4 完整对话循环</h3>
<pre><code class="language-python">from openai import OpenAI

def run_agent_loop(
    client: OpenAI,
    user_message: str,
    registry: ToolRegistry,
    dispatcher: ToolDispatcher,
    max_iterations: int = 10,
) -&gt; str:
    &quot;&quot;&quot;
    完整的 Agent 对话循环，支持多轮 Tool Calling。
    &quot;&quot;&quot;
    messages = [
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个有用的助手，可以使用工具来回答用户的问题。&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message},
    ]
    tools = registry.get_definitions()

    for i in range(max_iterations):
        response = client.chat.completions.create(
            model=&quot;gpt-4&quot;,
            messages=messages,
            tools=tools if tools else None,
        )
        choice = response.choices[0]
        message = choice.message

        # 如果 LLM 没有调用工具，直接返回文本回答
        if not message.tool_calls:
            return message.content

        # 将 LLM 的回复（含 tool_calls）加入消息历史
        messages.append(message.model_dump())

        # 执行所有工具调用（支持并行）
        tool_calls = [tc.model_dump() for tc in message.tool_calls]
        results = dispatcher.execute_parallel(tool_calls)

        # 将工具执行结果加入消息历史
        for result in results:
            messages.append(result)

        # 继续循环，让 LLM 基于工具结果做下一步决策

    return &quot;达到最大迭代次数，对话终止。&quot;


# 使用示例
# client = OpenAI()
# answer = run_agent_loop(client, &quot;北京今天天气怎么样？然后帮我算一下 28 * 9/5 + 32&quot;, registry, dispatcher)
# print(answer)
</code></pre>
<hr>
<h2>7. 错误处理与验证</h2>
<p>Tool Calling 中的错误来源比常规 API 调用更多，因为链条更长：用户输入 → LLM 推理 → 参数生成 → 参数验证 → 工具执行 → 结果回传 → LLM 再推理。每一环都可能出错。</p>
<h3>7.1 参数验证</h3>
<p>LLM 生成的参数并不总是合法的。常见问题：</p>
<pre><code class="language-python"># LLM 可能生成的&quot;有问题&quot;的参数

# 1. 类型错误：期望 string，给了 number
{&quot;city&quot;: 123}

# 2. 枚举越界：给了不在 enum 中的值
{&quot;unit&quot;: &quot;kelvin&quot;}      # enum 里只有 celsius / fahrenheit

# 3. 格式错误：JSON 语法不对
&#39;{&quot;city&quot;: &quot;北京&quot;,}&#39;      # 尾部多余逗号（严格 JSON 不允许）

# 4. 幻觉参数：编造了不存在的参数
{&quot;city&quot;: &quot;北京&quot;, &quot;forecast_days&quot;: 7}  # 工具根本没有这个参数

# 5. 语义错误：参数值表面合法但语义错误
{&quot;sql&quot;: &quot;DROP TABLE users&quot;}  # 传了一条 DELETE 语句给 SELECT-only 工具
</code></pre>
<p>应对策略是 <strong>分层验证</strong>：</p>
<pre><code class="language-python">def validate_and_execute(tool: Tool, raw_arguments: str) -&gt; dict:
    # 第一层：JSON 语法
    try:
        args = json.loads(raw_arguments)
    except json.JSONDecodeError:
        return {&quot;error&quot;: &quot;参数不是合法的 JSON&quot;}

    # 第二层：Schema 验证（使用 jsonschema 库）
    from jsonschema import validate, ValidationError
    try:
        validate(instance=args, schema=tool.parameters)
    except ValidationError as e:
        return {&quot;error&quot;: f&quot;参数验证失败: {e.message}&quot;}

    # 第三层：业务规则验证
    if tool.name == &quot;query_database&quot;:
        sql = args.get(&quot;sql&quot;, &quot;&quot;).strip().upper()
        if not sql.startswith(&quot;SELECT&quot;):
            return {&quot;error&quot;: &quot;仅支持 SELECT 查询&quot;}

    # 执行
    return tool.function(**args)
</code></pre>
<h3>7.2 工具执行失败的反馈</h3>
<p>当工具执行失败时，最重要的原则是：<strong>将错误信息回传给 LLM，让它决定下一步</strong>。</p>
<pre><code class="language-python"># 不要这样做 —— 对用户抛出原始异常
raise RuntimeError(&quot;Connection timeout to weather API&quot;)

# 应该这样做 —— 将错误包装为工具结果，回传给 LLM
{
    &quot;tool_call_id&quot;: &quot;call_abc123&quot;,
    &quot;role&quot;: &quot;tool&quot;,
    &quot;content&quot;: json.dumps({
        &quot;error&quot;: &quot;天气 API 连接超时，请稍后重试或尝试查询其他城市&quot;,
        &quot;error_type&quot;: &quot;timeout&quot;,
        &quot;retryable&quot;: True
    })
}
</code></pre>
<p>LLM 拿到这个错误信息后，可能会：</p>
<ul>
<li>换一种方式重试（比如换个参数）</li>
<li>告知用户当前无法完成</li>
<li>尝试用其他工具达成目标</li>
</ul>
<h3>7.3 重试策略</h3>
<pre><code>                  ┌──────────────────────────┐
                  │    Tool Call 失败         │
                  └──────────┬───────────────┘
                             │
                   ┌─────────▼─────────┐
                   │  错误类型判断       │
                   └─────────┬─────────┘
                             │
              ┌──────────────┼──────────────┐
              │              │              │
        ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐
        │ 可重试     │ │ 参数错误   │ │ 不可恢复   │
        │(超时/限流) │ │(类型/格式) │ │(权限/404) │
        └─────┬─────┘ └─────┬─────┘ └─────┬─────┘
              │              │              │
        ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐
        │ Runtime    │ │ 回传 LLM  │ │ 回传 LLM  │
        │ 自动重试   │ │ 让它修正   │ │ 让它放弃   │
        │ (指数退避) │ │ 参数       │ │ 或换方案   │
        └───────────┘ └───────────┘ └───────────┘
</code></pre>
<p>核心原则：<strong>可重试的错误由 Runtime 处理，不可重试的错误交给 LLM 决策</strong>。</p>
<ul>
<li><strong>瞬时错误</strong>（网络超时、限流）：Runtime 自动重试，设置退避策略和最大重试次数，不需要浪费 LLM 的 token。</li>
<li><strong>参数错误</strong>：回传给 LLM，它可能会修正参数重新调用。</li>
<li><strong>永久错误</strong>（权限不足、资源不存在）：回传给 LLM，让它换一种方案或如实告知用户。</li>
</ul>
<h3>7.4 幂等性考量</h3>
<p>当重试机制存在时，幂等性就变得至关重要。</p>
<pre><code class="language-python"># 幂等操作 —— 重试安全
get_weather(&quot;北京&quot;)           # 多次调用结果相同
query_database(&quot;SELECT ...&quot;)  # 只读查询，天然幂等

# 非幂等操作 —— 重试危险
send_email(to=&quot;a@b.com&quot;, ...)  # 重试 = 发两封邮件
create_order(item=&quot;iPhone&quot;)    # 重试 = 创建两个订单
</code></pre>
<p>对于非幂等操作，要么禁止自动重试，要么引入幂等 key：</p>
<pre><code class="language-python">def send_email_idempotent(to: str, subject: str, body: str, idempotency_key: str) -&gt; dict:
    &quot;&quot;&quot;带幂等 key 的邮件发送&quot;&quot;&quot;
    if is_already_sent(idempotency_key):
        return {&quot;status&quot;: &quot;already_sent&quot;, &quot;message&quot;: &quot;该请求已处理，跳过重复发送&quot;}
    result = _do_send_email(to, subject, body)
    mark_as_sent(idempotency_key)
    return result
</code></pre>
<hr>
<h2>8. 安全性</h2>
<p>Tool Calling 打开了 LLM 与外部世界的通道，也同时打开了攻击面。</p>
<h3>8.1 工具权限控制</h3>
<p>不是所有工具都应该对所有用户开放。一个合理的权限模型：</p>
<pre><code class="language-python">from enum import Enum

class ToolPermission(Enum):
    READ = &quot;read&quot;        # 只读操作：查询天气、读文件
    WRITE = &quot;write&quot;      # 写操作：发邮件、创建记录
    ADMIN = &quot;admin&quot;      # 管理操作：删除数据、修改配置

class SecureToolRegistry(ToolRegistry):
    &quot;&quot;&quot;带权限控制的工具注册中心&quot;&quot;&quot;

    def __init__(self):
        super().__init__()
        self._permissions: dict[str, ToolPermission] = {}

    def register(self, tool: Tool, permission: ToolPermission = ToolPermission.READ):
        super().register(tool)
        self._permissions[tool.name] = permission

    def get_definitions(
        self,
        names: list[str] | None = None,
        max_permission: ToolPermission = ToolPermission.READ,
    ) -&gt; list[dict]:
        &quot;&quot;&quot;只返回用户权限范围内的工具&quot;&quot;&quot;
        permission_levels = {
            ToolPermission.READ: 0,
            ToolPermission.WRITE: 1,
            ToolPermission.ADMIN: 2,
        }
        max_level = permission_levels[max_permission]
        allowed = [
            t for t in self._tools.values()
            if permission_levels[self._permissions.get(t.name, ToolPermission.ADMIN)] &lt;= max_level
        ]
        if names:
            allowed = [t for t in allowed if t.name in names]
        return [t.to_openai_schema() for t in allowed]
</code></pre>
<h3>8.2 参数注入风险</h3>
<p>LLM 的参数生成可以被 Prompt Injection 操纵。考虑以下场景：</p>
<pre><code>用户输入: &quot;帮我查一下订单，user_id 是 U00012345; DROP TABLE orders; --&quot;
</code></pre>
<p>如果 <code>query_database</code> 工具直接拼接 SQL，这就变成了一次经典的 SQL 注入。防护措施：</p>
<ol>
<li><strong>参数化查询</strong>：工具内部必须使用参数化 SQL，绝不拼接。</li>
<li><strong>白名单校验</strong>：用正则或枚举限制参数值的格式。</li>
<li><strong>最小权限原则</strong>：数据库连接使用只读账号。</li>
</ol>
<h3>8.3 Sandbox 执行</h3>
<p>对于高风险工具（如代码执行、文件操作），应在隔离环境中执行：</p>
<pre><code>┌──────────────────────────────────────────────┐
│  Host Runtime                                 │
│                                              │
│   ┌─────────────┐     ┌──────────────────┐   │
│   │  Safe Tools  │     │    Sandbox       │   │
│   │  (天气/计算) │     │  ┌────────────┐  │   │
│   │  直接执行    │     │  │ Risky Tools│  │   │
│   └─────────────┘     │  │ (代码/文件) │  │   │
│                       │  │ 隔离执行    │  │   │
│                       │  └────────────┘  │   │
│                       │  - 网络受限      │   │
│                       │  - 文件系统隔离  │   │
│                       │  - 执行时间限制  │   │
│                       │  - 资源配额      │   │
│                       └──────────────────┘   │
└──────────────────────────────────────────────┘
</code></pre>
<p>Sandbox 的实现方式取决于部署环境：</p>
<ul>
<li><strong>Docker 容器</strong>：最常见，隔离性好</li>
<li><strong>gVisor / Firecracker</strong>：更强的隔离，适合多租户</li>
<li><strong>WASM</strong>：轻量级沙箱，启动快</li>
<li><strong>子进程 + seccomp</strong>：Linux 下的轻量方案</li>
</ul>
<hr>
<h2>9. Trade-off 分析</h2>
<h3>9.1 工具数量 vs 选择准确率</h3>
<pre><code>选择准确率
  100% │ ****
       │     ****
   90% │         ****
       │             ****
   80% │                 ****
       │                     ****
   70% │                         ****
       │                             ****
   60% │                                 ****
       ├───┬───┬───┬───┬───┬───┬───┬───┬───── 工具数量
       0   5  10  15  20  25  30  35  40

       |&lt;-- 全量传递 --&gt;|&lt;- 需要过滤策略 -&gt;|
</code></pre>
<ul>
<li><strong>&lt; 10 个工具</strong>：全量传递，不需要过滤。</li>
<li><strong>10-20 个工具</strong>：准确率开始下降，可通过优化 description 缓解。</li>
<li><strong>&gt; 20 个工具</strong>：必须引入 Tool Selection 策略（语义过滤或两阶段选择）。</li>
<li><strong>&gt; 50 个工具</strong>：两阶段选择几乎是唯一可行方案，或者按领域拆分为多个 Agent。</li>
</ul>
<h3>9.2 工具描述详细度 vs Token 消耗</h3>
<p>每个工具定义大约占用 100-500 token（取决于描述长度和参数数量）。20 个工具就是 2000-10000 token 的系统开销，这是每次 API 调用都要付出的 <strong>固定成本</strong>。</p>
<pre><code>                        描述详细度
                  低 ◄──────────────► 高
                  │                    │
  Token 消耗   低 │  ⚡ 省钱但模糊     │
                  │  LLM 可能误选工具  │
                  │                    │
              高 │                    │  📖 精确但昂贵
                  │                    │  LLM 选择更准确
                  │                    │
</code></pre>
<p>实践建议：</p>
<ul>
<li>工具 <code>name</code> 起好名字（零额外 token 成本，但信息量大）</li>
<li><code>description</code> 控制在 2-3 句话</li>
<li>参数的 <code>description</code> 控制在 1 句话 + 1 个示例</li>
<li>用 <code>enum</code> 和 <code>required</code> 代替冗长的文字约束</li>
</ul>
<h3>9.3 确定性执行 vs LLM 灵活性</h3>
<pre><code>确定性                                          灵活性
  │                                              │
  │  硬编码工作流           Agent Tool Calling     │
  │  if/else 分支            LLM 自由选择工具     │
  │  规则引擎                自动组合工具链        │
  │                                              │
  │  ✅ 可预测              ✅ 处理模糊意图        │
  │  ✅ 可审计              ✅ 适应新场景          │
  │  ✅ 低延迟              ✅ 用户体验自然        │
  │  ❌ 不灵活              ❌ 不可预测            │
  │  ❌ 维护成本高          ❌ 调试困难            │
  │  ❌ 无法处理长尾        ❌ 成本高              │
</code></pre>
<p>决策框架：</p>
<table>
<thead>
<tr>
<th>场景特征</th>
<th>推荐方案</th>
</tr>
</thead>
<tbody><tr>
<td>流程固定、合规要求高</td>
<td>硬编码工作流 + Tool Calling 作为执行层</td>
</tr>
<tr>
<td>意图模糊、工具组合多变</td>
<td>完全由 LLM 驱动的 Tool Calling</td>
</tr>
<tr>
<td>核心路径固定、边缘场景多</td>
<td>混合方案：主流程硬编码，长尾交给 LLM</td>
</tr>
</tbody></table>
<p>关键洞察：Tool Calling 不是非此即彼的选择。你可以让 LLM 决定 <strong>是否</strong> 调用工具，但用代码控制 <strong>调用后的流程</strong>。比如 LLM 决定&quot;需要查天气&quot;，但查完天气后的处理逻辑是确定性的代码。</p>
<hr>
<h2>10. 常见陷阱</h2>
<p>在实际工程中，以下几个坑值得提前规避：</p>
<p><strong>1. 工具描述与实际行为不一致</strong></p>
<p>工具描述说&quot;返回最近 30 天的订单&quot;，但实际实现返回所有订单。LLM 会基于描述做出错误假设，导致下游逻辑出错。<strong>描述就是契约，必须与实现严格一致</strong>。</p>
<p><strong>2. 忽略工具结果的 Token 消耗</strong></p>
<p>工具返回的结果会作为下一轮消息传给 LLM。如果一个数据库查询返回了 1000 行数据，这些数据全部变成 input token。务必在工具层面限制返回数据量。</p>
<pre><code class="language-python">def query_database(sql: str, database: str = &quot;default&quot;) -&gt; dict:
    results = _execute_query(sql, database)
    # 限制返回行数，避免 token 爆炸
    if len(results) &gt; 50:
        return {
            &quot;rows&quot;: results[:50],
            &quot;total_count&quot;: len(results),
            &quot;truncated&quot;: True,
            &quot;message&quot;: f&quot;结果共 {len(results)} 行，仅返回前 50 行&quot;
        }
    return {&quot;rows&quot;: results, &quot;total_count&quot;: len(results)}
</code></pre>
<p><strong>3. 缺少 stop condition</strong></p>
<p>如果 LLM 反复调用同一个工具（比如因为错误一直重试），而没有最大迭代次数限制，系统会陷入无限循环。前面代码中的 <code>max_iterations</code> 参数就是为此设计的。</p>
<p><strong>4. 并行调用的顺序依赖</strong></p>
<p>LLM 可能在一次回复中请求并行调用两个工具，但这两个工具之间有隐含的顺序依赖（比如先查用户 ID，再用这个 ID 查订单）。Runtime 需要能识别这种情况，或者在工具描述中引导 LLM 分步调用。</p>
<hr>
<h2>11. 总结与展望</h2>
<p>Tool Calling 的本质是一个精心设计的 <strong>协议</strong>：</p>
<pre><code>┌───────────┐    JSON Schema    ┌───────────┐    Function    ┌───────────┐
│           │    (契约)          │           │    (执行)      │           │
│    LLM    │ ◄───────────────► │  Runtime  │ ◄────────────► │   Tools   │
│  (决策层) │   Tool Call JSON   │  (调度层) │   Function     │  (能力层) │
│           │   Tool Result      │           │   Call/Return  │           │
└───────────┘                   └───────────┘                └───────────┘
</code></pre>
<ul>
<li><strong>LLM</strong> 负责理解意图、选择工具、生成参数——它是决策者。</li>
<li><strong>Runtime</strong> 负责验证、路由、执行、错误处理——它是执行者。</li>
<li><strong>Tools</strong> 是具体的能力——它们是能力的载体。</li>
<li><strong>JSON Schema</strong> 是三者之间的契约——它定义了什么可以做、怎么做。</li>
</ul>
<p>理解了这个架构，你就能在任何框架（LangChain、LlamaIndex、Semantic Kernel，或者自己写的 Runtime）上实现 Tool Calling，因为底层原理是相同的。</p>
<p>但 Tool Calling 只是让 Agent 有了&quot;手&quot;。要让 Agent 真正好用，还需要精心设计的 Prompt 来引导 LLM 的决策——什么时候该调工具、什么时候该直接回答、遇到错误该怎么处理、多个工具之间如何协调。这就是下一篇 <strong>Prompt Engineering for Agents</strong> 要深入讨论的主题。</p>
<hr>
<blockquote>
<p><strong>系列导航</strong>：本文是 Agentic 系列的第 05 篇。</p>
<ul>
<li>上一篇：<a href="/blog/engineering/agentic/04-The%20Agent%20Control%20Loop">04 | The Agent Control Loop</a></li>
<li>下一篇：<a href="/blog/engineering/agentic/06-Prompt%20Engineering%20for%20Agents">06 | Prompt Engineering for Agents</a></li>
<li>完整目录：<a href="/blog/engineering/agentic/01-From%20LLM%20to%20Agent">01 | From LLM to Agent</a></li>
</ul>
</blockquote>
</div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="mt-12 pt-8 border-t border-gray-200">加载导航中...</div><!--/$--><div class="mt-16 border-t border-gray-200 pt-8"><div class="mx-auto max-w-3xl"><h3 class="text-2xl font-bold text-gray-900 mb-8">评论</h3></div></div></div></div></article><!--$--><!--/$--></main><footer class="bg-[var(--background)]"><div class="mx-auto max-w-7xl px-6 py-12 lg:px-8"><p class="text-center text-xs leading-5 text-gray-400">© <!-- -->2026<!-- --> Skyfalling</p></div></footer></div><script src="/_next/static/chunks/webpack-42d55485b4428e47.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[10616,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"7177\",\"static/chunks/app/layout-142e67ac4336647c.js\"],\"default\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n6:I[59665,[],\"OutletBoundary\"]\n9:I[74911,[],\"AsyncMetadataOutlet\"]\nb:I[59665,[],\"ViewportBoundary\"]\nd:I[59665,[],\"MetadataBoundary\"]\nf:I[26614,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/66b421ed9771e9de.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"C33gYo3klV3feVWcJcf5W\",\"p\":\"\",\"c\":[\"\",\"blog\",\"engineering\",\"agentic\",\"05-Tool%20Calling%20Deep%20Dive\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"engineering/agentic/05-Tool%20Calling%20Deep%20Dive\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/66b421ed9771e9de.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-[var(--background)]\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-6 py-12 lg:px-8\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs leading-5 text-gray-400\",\"children\":[\"© \",2026,\" Skyfalling\"]}]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"engineering/agentic/05-Tool%20Calling%20Deep%20Dive\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",null,[\"$\",\"$L6\",null,{\"children\":[\"$L7\",\"$L8\",[\"$\",\"$L9\",null,{\"promise\":\"$@a\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"9hGANGeh0-C5nHQ6_2xZkv\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:\"$Sreact.suspense\"\n11:I[74911,[],\"AsyncMetadata\"]\n13:I[6874,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"\"]\n14:I[32923,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n16:I[40780,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n1b:I[85300,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\ne:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]}]}]\n15:Td4a2,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eTool Calling Deep Dive: 让 LLM 成为可编程接口\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这是 Agentic 系列的第 05 篇。在前几篇中我们建立了 Agent 的概念模型、控制循环、以及 Agent 与 Workflow 的边界。本篇聚焦于 Agent 能力的核心支点——Tool Calling。\u003c/p\u003e\n\u003cp\u003eTool Calling 不是\u0026quot;让 AI 调 API\u0026quot;这么简单。它是 LLM 从 \u003cstrong\u003eText-in/Text-out 的生成模型\u003c/strong\u003e 变成 \u003cstrong\u003e可编程接口\u003c/strong\u003e 的关键转折点。理解它的工作原理、设计约束和工程实践，是构建任何 Agentic 系统的前提。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么 Tool Calling 是关键转折点\u003c/h2\u003e\n\u003cp\u003e一个纯粹的 LLM 只能做一件事：接受文本，生成文本。它无法查询数据库、无法读取文件、无法发送邮件、无法获取实时天气。它的知识冻结在训练数据的截止日期，它的能力边界就是 token 序列的排列组合。\u003c/p\u003e\n\u003cp\u003eTool Calling 改变了这一切。\u003c/p\u003e\n\u003cp\u003e它的本质不是\u0026quot;让 LLM 调用工具\u0026quot;，而是 \u003cstrong\u003e让 LLM 生成结构化的调用意图，由外部运行时代为执行\u003c/strong\u003e。这个区分至关重要——LLM 从未真正\u0026quot;执行\u0026quot;过任何工具，它只是学会了在恰当的时机，输出一段符合约定格式的 JSON，表达\u0026quot;我需要调用某个工具，参数是这些\u0026quot;。\u003c/p\u003e\n\u003cp\u003e这意味着：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLM 变成了一个 \u003cstrong\u003e决策引擎\u003c/strong\u003e：决定调用什么、传什么参数\u003c/li\u003e\n\u003cli\u003eRuntime 变成了一个 \u003cstrong\u003e执行引擎\u003c/strong\u003e：负责真正的 I/O 操作\u003c/li\u003e\n\u003cli\u003e两者之间的契约是 \u003cstrong\u003eJSON Schema\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这种分离，让 LLM 从一个封闭的文本生成器，变成了一个可以与外部世界交互的可编程接口。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. Tool Calling 的工作原理\u003c/h2\u003e\n\u003ch3\u003e2.1 完整流程\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────────────────────┐\n│                    Tool Calling 完整序列图                            │\n└──────────────────────────────────────────────────────────────────────┘\n\n  User            LLM (API)          Runtime           Tool (Function)\n   │                 │                  │                     │\n   │  \u0026quot;北京今天天气\u0026quot;  │                  │                     │\n   ├────────────────\u0026gt;│                  │                     │\n   │                 │                  │                     │\n   │                 │  ┌─────────────┐ │                     │\n   │                 │  │ 推理:       │ │                     │\n   │                 │  │ 用户想查天气 │ │                     │\n   │                 │  │ 需要调用    │ │                     │\n   │                 │  │ get_weather │ │                     │\n   │                 │  └─────────────┘ │                     │\n   │                 │                  │                     │\n   │                 │  Tool Call JSON  │                     │\n   │                 │ ────────────────\u0026gt;│                     │\n   │                 │  {               │                     │\n   │                 │   \u0026quot;name\u0026quot;:        │                     │\n   │                 │    \u0026quot;get_weather\u0026quot; │                     │\n   │                 │   \u0026quot;arguments\u0026quot;:   │                     │\n   │                 │    {\u0026quot;city\u0026quot;:      │                     │\n   │                 │     \u0026quot;北京\u0026quot;}      │                     │\n   │                 │  }               │                     │\n   │                 │                  │  get_weather(\u0026quot;北京\u0026quot;) │\n   │                 │                  ├────────────────────\u0026gt;│\n   │                 │                  │                     │\n   │                 │                  │  {\u0026quot;temp\u0026quot;: 28,       │\n   │                 │                  │   \u0026quot;condition\u0026quot;:      │\n   │                 │                  │   \u0026quot;晴\u0026quot;}              │\n   │                 │                  │\u0026lt;────────────────────┤\n   │                 │                  │                     │\n   │                 │  Tool Result     │                     │\n   │                 │ \u0026lt;────────────────│                     │\n   │                 │                  │                     │\n   │                 │  ┌─────────────┐ │                     │\n   │                 │  │ 推理:       │ │                     │\n   │                 │  │ 根据工具返回 │ │                     │\n   │                 │  │ 组织回答    │ │                     │\n   │                 │  └─────────────┘ │                     │\n   │                 │                  │                     │\n   │ \u0026quot;北京今天28°C,晴\u0026quot;│                  │                     │\n   │\u0026lt;────────────────│                  │                     │\n   │                 │                  │                     │\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.2 关键洞察\u003c/h3\u003e\n\u003cp\u003e从上面的序列图中，可以提炼出几个核心事实：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLLM 发起两次推理\u003c/strong\u003e。第一次决定是否调用工具、调用哪个、传什么参数；第二次基于工具返回的结果生成最终回答。这意味着每次 Tool Calling 至少消耗两轮 LLM 调用的 token。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLLM 的输出不是自然语言，而是结构化 JSON\u003c/strong\u003e。这是模型经过专门训练（fine-tuning）才获得的能力。并非所有 LLM 都支持 Tool Calling——它需要模型在训练阶段就学会\u0026quot;在特定上下文下输出 JSON 而非自然语言\u0026quot;。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eRuntime 是不可或缺的中间层\u003c/strong\u003e。它负责：解析 LLM 返回的 Tool Call、校验参数、路由到正确的函数、执行函数、收集结果、将结果注入下一轮对话。没有 Runtime，Tool Calling 就是一段无人执行的 JSON。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e整个过程对用户透明\u003c/strong\u003e。用户看到的只是\u0026quot;问了一个问题，得到了回答\u0026quot;。中间的 Tool Call 调度过程完全由系统内部完成。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e3. JSON Schema 作为契约\u003c/h2\u003e\n\u003ch3\u003e3.1 工具定义的结构\u003c/h3\u003e\n\u003cp\u003e每个工具的定义由三部分组成：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003etool_definition = {\n    \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n    \u0026quot;function\u0026quot;: {\n        \u0026quot;name\u0026quot;: \u0026quot;get_weather\u0026quot;,          # 工具的唯一标识\n        \u0026quot;description\u0026quot;: \u0026quot;...\u0026quot;,           # 给 LLM 看的\u0026quot;接口文档\u0026quot;\n        \u0026quot;parameters\u0026quot;: {                 # JSON Schema 格式的参数约束\n            \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n            \u0026quot;properties\u0026quot;: {\n                \u0026quot;city\u0026quot;: {\n                    \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                    \u0026quot;description\u0026quot;: \u0026quot;城市名称，如 \u0026#39;北京\u0026#39;、\u0026#39;上海\u0026#39;\u0026quot;\n                }\n            },\n            \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;]\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这里的 \u003ccode\u003eparameters\u003c/code\u003e 遵循 JSON Schema 规范（Draft 2020-12 子集），它不仅定义了参数的类型，还定义了参数的约束、默认值、枚举范围等。JSON Schema 就是 LLM 与 Runtime 之间的 \u003cstrong\u003e契约\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e3.2 好的描述 vs 差的描述\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003edescription\u003c/code\u003e 是整个工具定义中最容易被低估的字段。它不是给人类看的注释，而是 \u003cstrong\u003e给 LLM 看的接口文档\u003c/strong\u003e。LLM 完全依赖 description 来决定是否调用这个工具、以及如何填充参数。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e差的描述：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e{\n    \u0026quot;name\u0026quot;: \u0026quot;query_db\u0026quot;,\n    \u0026quot;description\u0026quot;: \u0026quot;查询数据库\u0026quot;,          # 太模糊：查什么数据库？返回什么？\n    \u0026quot;parameters\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;q\u0026quot;: {                        # 参数名不直观\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\n            }\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e好的描述：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e{\n    \u0026quot;name\u0026quot;: \u0026quot;query_user_orders\u0026quot;,\n    \u0026quot;description\u0026quot;: (\n        \u0026quot;根据用户 ID 查询该用户的历史订单列表。\u0026quot;\n        \u0026quot;返回最近 30 天内的订单，包含订单号、金额、状态。\u0026quot;\n        \u0026quot;如果用户不存在，返回空列表。\u0026quot;\n        \u0026quot;不支持模糊查询，user_id 必须精确匹配。\u0026quot;\n    ),\n    \u0026quot;parameters\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;user_id\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;用户的唯一标识符，格式为 \u0026#39;U\u0026#39; + 8位数字，如 \u0026#39;U00012345\u0026#39;\u0026quot;\n            },\n            \u0026quot;status_filter\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;all\u0026quot;, \u0026quot;pending\u0026quot;, \u0026quot;completed\u0026quot;, \u0026quot;cancelled\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;按订单状态过滤，默认返回所有状态的订单\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;user_id\u0026quot;]\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e两者之间的差异在于：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e差的描述\u003c/th\u003e\n\u003cth\u003e好的描述\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e功能边界\u003c/td\u003e\n\u003ctd\u003e不清楚能做什么\u003c/td\u003e\n\u003ctd\u003e明确说明查询范围和返回内容\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e参数语义\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eq\u003c/code\u003e 是什么？\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003euser_id\u003c/code\u003e 含义清晰，且给出格式示例\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e约束条件\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e明确说明不支持模糊查询\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e异常行为\u003c/td\u003e\n\u003ctd\u003e未提及\u003c/td\u003e\n\u003ctd\u003e说明了用户不存在时的返回\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e枚举约束\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e用 \u003ccode\u003eenum\u003c/code\u003e 限定合法值\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e3.3 参数设计原则\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e简单优先\u003c/strong\u003e：参数数量尽量少。一个工具如果需要 10 个参数，说明它的职责太大，应该拆分。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e类型明确\u003c/strong\u003e：用 \u003ccode\u003eenum\u003c/code\u003e 约束离散值，用 \u003ccode\u003epattern\u003c/code\u003e 约束格式，用 \u003ccode\u003eminimum\u003c/code\u003e/\u003ccode\u003emaximum\u003c/code\u003e 约束数值范围。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e必选与可选分明\u003c/strong\u003e：\u003ccode\u003erequired\u003c/code\u003e 字段只放真正必须的参数，可选参数给默认值。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e命名即文档\u003c/strong\u003e：\u003ccode\u003euser_id\u003c/code\u003e 比 \u003ccode\u003euid\u003c/code\u003e 好，\u003ccode\u003estart_date\u003c/code\u003e 比 \u003ccode\u003esd\u003c/code\u003e 好。LLM 会从参数名推断语义。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e避免嵌套过深\u003c/strong\u003e：LLM 生成深层嵌套 JSON 的准确率会显著下降。尽量用扁平结构。\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Structured Output vs Free-form Output\u003c/h2\u003e\n\u003ch3\u003e4.1 为什么结构化输出更可靠\u003c/h3\u003e\n\u003cp\u003e在 Tool Calling 出现之前，让 LLM 调用工具的常见做法是：在 Prompt 中要求 LLM \u0026quot;用特定格式输出\u0026quot;，然后用正则或字符串解析提取调用意图。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# 旧做法（Prompt Hacking）\n请用以下格式回答：\nAction: \u0026lt;工具名\u0026gt;\nAction Input: \u0026lt;参数 JSON\u0026gt;\n\n# LLM 可能的输出（不可靠）\n\u0026quot;我觉得应该查一下天气。Action: get_weather Action Input: {\u0026quot;city\u0026quot;: \u0026quot;北京\u0026quot;}\u0026quot;\n                       ^^ 前面混入了自然语言，解析会出错\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这种方式的根本问题是：LLM 的输出是 \u003cstrong\u003e非确定性的自由文本\u003c/strong\u003e，它可能在格式中混入自然语言、遗漏字段、搞错 JSON 语法。\u003c/p\u003e\n\u003cp\u003eStructured Output（结构化输出）通过 \u003cstrong\u003e约束解码（Constrained Decoding）\u003c/strong\u003e 从根本上解决了这个问题。模型在生成 token 时，解码器会强制输出符合预定义 JSON Schema 的 token 序列，从而保证输出 100% 可解析。\u003c/p\u003e\n\u003ch3\u003e4.2 三种机制的区别\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e机制\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e可靠性\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eJSON Mode\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e告诉模型\u0026quot;输出必须是合法 JSON\u0026quot;，但不约束 schema\u003c/td\u003e\n\u003ctd\u003e中等。JSON 语法正确，但字段可能不对\u003c/td\u003e\n\u003ctd\u003e简单的数据提取\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFunction Calling / Tool Use\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e模型经过 fine-tuning，能在特定上下文下输出 tool call 结构\u003c/td\u003e\n\u003ctd\u003e高。模型专门训练过\u003c/td\u003e\n\u003ctd\u003eAgent 工具调用\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eStructured Output\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e约束解码 + JSON Schema 验证，输出严格匹配 schema\u003c/td\u003e\n\u003ctd\u003e极高。解码层面保证\u003c/td\u003e\n\u003ctd\u003e需要严格 schema 的场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e4.3 各大模型的实现差异\u003c/h3\u003e\n\u003cp\u003e不同模型提供商对 Tool Calling 的 API 设计不尽相同，但核心思想一致：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e（GPT-4 系列）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 \u003ccode\u003etools\u003c/code\u003e 参数传递工具定义\u003c/li\u003e\n\u003cli\u003e返回 \u003ccode\u003etool_calls\u003c/code\u003e 数组，支持并行调用\u003c/li\u003e\n\u003cli\u003e支持 \u003ccode\u003estrict: true\u003c/code\u003e 开启 Structured Output 模式\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAnthropic\u003c/strong\u003e（Claude 系列）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 \u003ccode\u003etools\u003c/code\u003e 参数传递工具定义\u003c/li\u003e\n\u003cli\u003eTool Call 以 \u003ccode\u003etool_use\u003c/code\u003e content block 返回\u003c/li\u003e\n\u003cli\u003eTool 结果以 \u003ccode\u003etool_result\u003c/code\u003e content block 传回\u003c/li\u003e\n\u003cli\u003e原生支持并行工具调用\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eGoogle\u003c/strong\u003e（Gemini 系列）：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e使用 \u003ccode\u003etools\u003c/code\u003e + \u003ccode\u003efunction_declarations\u003c/code\u003e 结构\u003c/li\u003e\n\u003cli\u003e支持 \u003ccode\u003efunction_calling_config\u003c/code\u003e 控制调用模式（AUTO / ANY / NONE）\u003c/li\u003e\n\u003cli\u003e返回 \u003ccode\u003efunction_call\u003c/code\u003e part\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e虽然 API 格式不同，但抽象层面是一致的：\u003cstrong\u003e定义工具 → LLM 决定调用 → 返回结构化调用请求 → 外部执行 → 结果回传\u003c/strong\u003e。这也是为什么我们强调框架无关的原理理解——API 会变，原理不会。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 工具注册与发现（Tool Registry）\u003c/h2\u003e\n\u003ch3\u003e5.1 静态注册\u003c/h3\u003e\n\u003cp\u003e最简单的方式是在代码中硬编码工具列表：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eTOOLS = [\n    get_weather_tool,\n    query_db_tool,\n    send_email_tool,\n]\n\nresponse = client.chat.completions.create(\n    model=\u0026quot;gpt-4\u0026quot;,\n    messages=messages,\n    tools=TOOLS,\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e优点是简单直接，缺点是每次新增或修改工具都需要改代码、重新部署。适合工具数量少且稳定的场景。\u003c/p\u003e\n\u003ch3\u003e5.2 动态注册\u003c/h3\u003e\n\u003cp\u003e当工具数量增多或需要根据上下文动态调整时，需要一个 Tool Registry：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌────────────────────────────────────────────────┐\n│                Tool Registry                    │\n│                                                │\n│  ┌──────────┐  ┌──────────┐  ┌──────────┐     │\n│  │ weather  │  │ database │  │  email   │     │\n│  │  tool    │  │  tool    │  │  tool    │     │\n│  └──────────┘  └──────────┘  └──────────┘     │\n│  ┌──────────┐  ┌──────────┐                    │\n│  │  calc    │  │   file   │                    │\n│  │  tool    │  │  tool    │                    │\n│  └──────────┘  └──────────┘                    │\n│                                                │\n│  register(tool) / unregister(name)             │\n│  get_tools(filter?) -\u0026gt; List[Tool]              │\n│  get_tool(name) -\u0026gt; Tool                        │\n│  get_definitions() -\u0026gt; List[Dict]               │\n└────────────────────────────────────────────────┘\n         │\n         │  get_definitions()\n         ▼\n   ┌───────────┐     tools=[...]     ┌───────────┐\n   │  Runtime   │ ──────────────────\u0026gt; │  LLM API  │\n   └───────────┘                     └───────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.3 工具选择问题\u003c/h3\u003e\n\u003cp\u003e当工具数量超过一定阈值（经验值：15-20 个），LLM 的工具选择准确率会明显下降。原因有两个：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eContext 膨胀\u003c/strong\u003e：每个工具定义占用数百 token，20 个工具就是数千 token 的 system prompt，挤占了有效上下文空间。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e选择困难\u003c/strong\u003e：工具越多，语义越可能重叠，LLM 越难区分应该调用哪个。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e5.4 Tool Selection 策略\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e策略一：全量传递\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e所有工具 ──全部传递──\u0026gt; LLM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e适用场景：工具少于 10 个。简单暴力，无额外开销。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e策略二：语义过滤\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e用户输入 ──Embedding──\u0026gt; 向量\n                          │\n工具描述 ──Embedding──\u0026gt; 向量库 ──Top-K 相似──\u0026gt; 候选工具 ──\u0026gt; LLM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e用 Embedding 计算用户输入与工具描述的语义相似度，只传递 Top-K 最相关的工具。缺点是可能漏掉正确工具。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e策略三：两阶段选择\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e阶段 1：所有工具名 + 简短描述 ──\u0026gt; LLM ──\u0026gt; 选出候选工具 (3-5 个)\n阶段 2：候选工具的完整定义     ──\u0026gt; LLM ──\u0026gt; 执行 Tool Call\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e第一阶段只传递工具名和一行描述（token 消耗少），让 LLM 先做粗筛；第二阶段只传递选中工具的完整定义。这种方式在工具数量 50+ 的场景下效果最好，代价是多一轮 LLM 调用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 完整代码示例\u003c/h2\u003e\n\u003ch3\u003e6.1 工具定义\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Any, Callable\n\n@dataclass\nclass Tool:\n    \u0026quot;\u0026quot;\u0026quot;工具的统一抽象\u0026quot;\u0026quot;\u0026quot;\n    name: str\n    description: str\n    parameters: dict          # JSON Schema\n    function: Callable        # 实际执行的函数\n    requires_confirmation: bool = False  # 是否需要用户确认\n\n    def to_openai_schema(self) -\u0026gt; dict:\n        \u0026quot;\u0026quot;\u0026quot;转换为 OpenAI API 格式\u0026quot;\u0026quot;\u0026quot;\n        return {\n            \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n            \u0026quot;function\u0026quot;: {\n                \u0026quot;name\u0026quot;: self.name,\n                \u0026quot;description\u0026quot;: self.description,\n                \u0026quot;parameters\u0026quot;: self.parameters,\n            }\n        }\n\n# ── 工具实现 ──────────────────────────────────────────────\n\ndef get_weather(city: str, unit: str = \u0026quot;celsius\u0026quot;) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;模拟天气查询\u0026quot;\u0026quot;\u0026quot;\n    # 实际场景中调用天气 API\n    mock_data = {\n        \u0026quot;北京\u0026quot;: {\u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;, \u0026quot;humidity\u0026quot;: 45},\n        \u0026quot;上海\u0026quot;: {\u0026quot;temp\u0026quot;: 32, \u0026quot;condition\u0026quot;: \u0026quot;多云\u0026quot;, \u0026quot;humidity\u0026quot;: 78},\n    }\n    data = mock_data.get(city, {\u0026quot;temp\u0026quot;: 20, \u0026quot;condition\u0026quot;: \u0026quot;未知\u0026quot;, \u0026quot;humidity\u0026quot;: 50})\n    if unit == \u0026quot;fahrenheit\u0026quot;:\n        data[\u0026quot;temp\u0026quot;] = data[\u0026quot;temp\u0026quot;] * 9 / 5 + 32\n    return {\u0026quot;city\u0026quot;: city, **data}\n\n\ndef query_database(sql: str, database: str = \u0026quot;default\u0026quot;) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;模拟数据库查询\u0026quot;\u0026quot;\u0026quot;\n    # 实际场景中执行 SQL\n    return {\n        \u0026quot;database\u0026quot;: database,\n        \u0026quot;query\u0026quot;: sql,\n        \u0026quot;rows\u0026quot;: [\n            {\u0026quot;id\u0026quot;: 1, \u0026quot;name\u0026quot;: \u0026quot;Alice\u0026quot;, \u0026quot;amount\u0026quot;: 100.0},\n            {\u0026quot;id\u0026quot;: 2, \u0026quot;name\u0026quot;: \u0026quot;Bob\u0026quot;, \u0026quot;amount\u0026quot;: 200.0},\n        ],\n        \u0026quot;row_count\u0026quot;: 2,\n    }\n\n\ndef calculate(expression: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;安全的数学计算\u0026quot;\u0026quot;\u0026quot;\n    allowed_chars = set(\u0026quot;0123456789+-*/.() \u0026quot;)\n    if not all(c in allowed_chars for c in expression):\n        return {\u0026quot;error\u0026quot;: \u0026quot;表达式包含非法字符\u0026quot;}\n    try:\n        result = eval(expression)  # 生产环境应使用 ast.literal_eval 或专用解析器\n        return {\u0026quot;expression\u0026quot;: expression, \u0026quot;result\u0026quot;: result}\n    except Exception as e:\n        return {\u0026quot;error\u0026quot;: str(e)}\n\n\ndef read_file(file_path: str, encoding: str = \u0026quot;utf-8\u0026quot;) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;读取文件内容\u0026quot;\u0026quot;\u0026quot;\n    try:\n        with open(file_path, \u0026quot;r\u0026quot;, encoding=encoding) as f:\n            content = f.read(10000)  # 限制读取大小\n        return {\u0026quot;path\u0026quot;: file_path, \u0026quot;content\u0026quot;: content, \u0026quot;size\u0026quot;: len(content)}\n    except FileNotFoundError:\n        return {\u0026quot;error\u0026quot;: f\u0026quot;文件不存在: {file_path}\u0026quot;}\n    except Exception as e:\n        return {\u0026quot;error\u0026quot;: str(e)}\n\n\ndef send_email(to: str, subject: str, body: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;模拟发送邮件\u0026quot;\u0026quot;\u0026quot;\n    # 实际场景中调用邮件服务\n    return {\u0026quot;status\u0026quot;: \u0026quot;sent\u0026quot;, \u0026quot;to\u0026quot;: to, \u0026quot;subject\u0026quot;: subject}\n\n\n# ── 工具注册 ──────────────────────────────────────────────\n\nweather_tool = Tool(\n    name=\u0026quot;get_weather\u0026quot;,\n    description=(\n        \u0026quot;查询指定城市的当前天气信息，包括温度、天气状况和湿度。\u0026quot;\n        \u0026quot;支持国内主要城市。如果城市不在数据库中，返回默认值。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;city\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;要查询的城市名称，如 \u0026#39;北京\u0026#39;、\u0026#39;上海\u0026#39;\u0026quot;\n            },\n            \u0026quot;unit\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;celsius\u0026quot;, \u0026quot;fahrenheit\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;温度单位，默认摄氏度\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;],\n    },\n    function=get_weather,\n)\n\ndatabase_tool = Tool(\n    name=\u0026quot;query_database\u0026quot;,\n    description=(\n        \u0026quot;执行 SQL 查询并返回结果。仅支持 SELECT 语句，\u0026quot;\n        \u0026quot;不允许执行 INSERT/UPDATE/DELETE 等写操作。\u0026quot;\n        \u0026quot;返回结果包含行数据和总行数。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;sql\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;要执行的 SQL SELECT 语句\u0026quot;\n            },\n            \u0026quot;database\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;default\u0026quot;, \u0026quot;analytics\u0026quot;, \u0026quot;users\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;目标数据库名称，默认为 \u0026#39;default\u0026#39;\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;sql\u0026quot;],\n    },\n    function=query_database,\n)\n\ncalculator_tool = Tool(\n    name=\u0026quot;calculate\u0026quot;,\n    description=(\n        \u0026quot;执行数学计算。支持加减乘除和括号。\u0026quot;\n        \u0026quot;输入为数学表达式字符串，如 \u0026#39;(3 + 5) * 2\u0026#39;。\u0026quot;\n        \u0026quot;不支持变量和函数调用，仅限纯数值运算。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;expression\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;数学表达式，如 \u0026#39;(3 + 5) * 2\u0026#39;\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;expression\u0026quot;],\n    },\n    function=calculate,\n)\n\nfile_tool = Tool(\n    name=\u0026quot;read_file\u0026quot;,\n    description=(\n        \u0026quot;读取指定路径的文本文件内容。最多读取 10000 字符。\u0026quot;\n        \u0026quot;仅支持文本文件，不支持二进制文件。\u0026quot;\n        \u0026quot;如果文件不存在，返回错误信息。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;file_path\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;文件的绝对路径或相对路径\u0026quot;\n            },\n            \u0026quot;encoding\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;文件编码，默认 utf-8\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;file_path\u0026quot;],\n    },\n    function=read_file,\n)\n\nemail_tool = Tool(\n    name=\u0026quot;send_email\u0026quot;,\n    description=(\n        \u0026quot;向指定收件人发送一封电子邮件。\u0026quot;\n        \u0026quot;需要提供收件人地址、邮件主题和正文。\u0026quot;\n        \u0026quot;正文支持纯文本格式。\u0026quot;\n    ),\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;to\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;收件人邮箱地址\u0026quot;\n            },\n            \u0026quot;subject\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;邮件主题\u0026quot;\n            },\n            \u0026quot;body\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;description\u0026quot;: \u0026quot;邮件正文，纯文本格式\u0026quot;\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;to\u0026quot;, \u0026quot;subject\u0026quot;, \u0026quot;body\u0026quot;],\n    },\n    function=send_email,\n    requires_confirmation=True,  # 发邮件需要用户确认\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.2 Tool Registry 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nfrom typing import Optional\n\nclass ToolRegistry:\n    \u0026quot;\u0026quot;\u0026quot;工具注册中心\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._tools: dict[str, Tool] = {}\n\n    def register(self, tool: Tool) -\u0026gt; None:\n        if tool.name in self._tools:\n            raise ValueError(f\u0026quot;工具 \u0026#39;{tool.name}\u0026#39; 已注册\u0026quot;)\n        self._tools[tool.name] = tool\n\n    def unregister(self, name: str) -\u0026gt; None:\n        self._tools.pop(name, None)\n\n    def get_tool(self, name: str) -\u0026gt; Optional[Tool]:\n        return self._tools.get(name)\n\n    def get_all_tools(self) -\u0026gt; list[Tool]:\n        return list(self._tools.values())\n\n    def get_definitions(self, names: list[str] | None = None) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;获取工具定义列表（用于传递给 LLM API）\u0026quot;\u0026quot;\u0026quot;\n        tools = self._tools.values()\n        if names:\n            tools = [t for t in tools if t.name in names]\n        return [t.to_openai_schema() for t in tools]\n\n    def get_summary(self) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;获取工具摘要（用于两阶段选择的第一阶段）\u0026quot;\u0026quot;\u0026quot;\n        lines = []\n        for tool in self._tools.values():\n            # 只取 description 的第一句\n            short_desc = tool.description.split(\u0026quot;。\u0026quot;)[0] + \u0026quot;。\u0026quot;\n            lines.append(f\u0026quot;- {tool.name}: {short_desc}\u0026quot;)\n        return \u0026quot;\\n\u0026quot;.join(lines)\n\n\n# 初始化 Registry\nregistry = ToolRegistry()\nfor tool in [weather_tool, database_tool, calculator_tool, file_tool, email_tool]:\n    registry.register(tool)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.3 Tool Dispatcher 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nclass ToolDispatcher:\n    \u0026quot;\u0026quot;\u0026quot;\n    工具调度器：解析 LLM 返回的 tool calls，执行对应工具，收集结果。\n    \u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, registry: ToolRegistry, max_parallel: int = 5):\n        self.registry = registry\n        self.max_parallel = max_parallel\n\n    def validate_arguments(self, tool: Tool, arguments: dict) -\u0026gt; list[str]:\n        \u0026quot;\u0026quot;\u0026quot;基础参数验证（生产环境建议使用 jsonschema 库）\u0026quot;\u0026quot;\u0026quot;\n        errors = []\n        schema = tool.parameters\n        required = schema.get(\u0026quot;required\u0026quot;, [])\n        properties = schema.get(\u0026quot;properties\u0026quot;, {})\n\n        # 检查必填参数\n        for param in required:\n            if param not in arguments:\n                errors.append(f\u0026quot;缺少必填参数: {param}\u0026quot;)\n\n        # 检查参数类型和枚举\n        for param, value in arguments.items():\n            if param not in properties:\n                errors.append(f\u0026quot;未知参数: {param}\u0026quot;)\n                continue\n            prop_schema = properties[param]\n            if \u0026quot;enum\u0026quot; in prop_schema and value not in prop_schema[\u0026quot;enum\u0026quot;]:\n                errors.append(\n                    f\u0026quot;参数 \u0026#39;{param}\u0026#39; 的值 \u0026#39;{value}\u0026#39; \u0026quot;\n                    f\u0026quot;不在允许范围内: {prop_schema[\u0026#39;enum\u0026#39;]}\u0026quot;\n                )\n\n        return errors\n\n    def execute_single(self, tool_call: dict) -\u0026gt; dict:\n        \u0026quot;\u0026quot;\u0026quot;执行单个工具调用\u0026quot;\u0026quot;\u0026quot;\n        name = tool_call[\u0026quot;function\u0026quot;][\u0026quot;name\u0026quot;]\n        raw_args = tool_call[\u0026quot;function\u0026quot;][\u0026quot;arguments\u0026quot;]\n        call_id = tool_call.get(\u0026quot;id\u0026quot;, \u0026quot;unknown\u0026quot;)\n\n        # 1. 查找工具\n        tool = self.registry.get_tool(name)\n        if not tool:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\u0026quot;error\u0026quot;: f\u0026quot;工具 \u0026#39;{name}\u0026#39; 不存在\u0026quot;}),\n            }\n\n        # 2. 解析参数\n        try:\n            arguments = json.loads(raw_args) if isinstance(raw_args, str) else raw_args\n        except json.JSONDecodeError as e:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\u0026quot;error\u0026quot;: f\u0026quot;参数 JSON 解析失败: {e}\u0026quot;}),\n            }\n\n        # 3. 验证参数\n        errors = self.validate_arguments(tool, arguments)\n        if errors:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\u0026quot;error\u0026quot;: \u0026quot;参数验证失败\u0026quot;, \u0026quot;details\u0026quot;: errors}),\n            }\n\n        # 4. 执行工具\n        try:\n            result = tool.function(**arguments)\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps(result, ensure_ascii=False),\n            }\n        except Exception as e:\n            return {\n                \u0026quot;tool_call_id\u0026quot;: call_id,\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;content\u0026quot;: json.dumps({\n                    \u0026quot;error\u0026quot;: f\u0026quot;工具执行失败: {type(e).__name__}: {e}\u0026quot;,\n                    \u0026quot;traceback\u0026quot;: traceback.format_exc()[-500:],  # 截断过长的堆栈\n                }),\n            }\n\n    def execute_parallel(self, tool_calls: list[dict]) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;并行执行多个工具调用\u0026quot;\u0026quot;\u0026quot;\n        if len(tool_calls) == 1:\n            return [self.execute_single(tool_calls[0])]\n\n        results = []\n        with ThreadPoolExecutor(max_workers=self.max_parallel) as executor:\n            future_to_call = {\n                executor.submit(self.execute_single, tc): tc\n                for tc in tool_calls\n            }\n            for future in as_completed(future_to_call):\n                results.append(future.result())\n\n        # 按原始顺序排列结果\n        id_to_result = {r[\u0026quot;tool_call_id\u0026quot;]: r for r in results}\n        ordered = []\n        for tc in tool_calls:\n            call_id = tc.get(\u0026quot;id\u0026quot;, \u0026quot;unknown\u0026quot;)\n            ordered.append(id_to_result.get(call_id, results.pop(0)))\n        return ordered\n\n\ndispatcher = ToolDispatcher(registry)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.4 完整对话循环\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom openai import OpenAI\n\ndef run_agent_loop(\n    client: OpenAI,\n    user_message: str,\n    registry: ToolRegistry,\n    dispatcher: ToolDispatcher,\n    max_iterations: int = 10,\n) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;\n    完整的 Agent 对话循环，支持多轮 Tool Calling。\n    \u0026quot;\u0026quot;\u0026quot;\n    messages = [\n        {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;你是一个有用的助手，可以使用工具来回答用户的问题。\u0026quot;},\n        {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_message},\n    ]\n    tools = registry.get_definitions()\n\n    for i in range(max_iterations):\n        response = client.chat.completions.create(\n            model=\u0026quot;gpt-4\u0026quot;,\n            messages=messages,\n            tools=tools if tools else None,\n        )\n        choice = response.choices[0]\n        message = choice.message\n\n        # 如果 LLM 没有调用工具，直接返回文本回答\n        if not message.tool_calls:\n            return message.content\n\n        # 将 LLM 的回复（含 tool_calls）加入消息历史\n        messages.append(message.model_dump())\n\n        # 执行所有工具调用（支持并行）\n        tool_calls = [tc.model_dump() for tc in message.tool_calls]\n        results = dispatcher.execute_parallel(tool_calls)\n\n        # 将工具执行结果加入消息历史\n        for result in results:\n            messages.append(result)\n\n        # 继续循环，让 LLM 基于工具结果做下一步决策\n\n    return \u0026quot;达到最大迭代次数，对话终止。\u0026quot;\n\n\n# 使用示例\n# client = OpenAI()\n# answer = run_agent_loop(client, \u0026quot;北京今天天气怎么样？然后帮我算一下 28 * 9/5 + 32\u0026quot;, registry, dispatcher)\n# print(answer)\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 错误处理与验证\u003c/h2\u003e\n\u003cp\u003eTool Calling 中的错误来源比常规 API 调用更多，因为链条更长：用户输入 → LLM 推理 → 参数生成 → 参数验证 → 工具执行 → 结果回传 → LLM 再推理。每一环都可能出错。\u003c/p\u003e\n\u003ch3\u003e7.1 参数验证\u003c/h3\u003e\n\u003cp\u003eLLM 生成的参数并不总是合法的。常见问题：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# LLM 可能生成的\u0026quot;有问题\u0026quot;的参数\n\n# 1. 类型错误：期望 string，给了 number\n{\u0026quot;city\u0026quot;: 123}\n\n# 2. 枚举越界：给了不在 enum 中的值\n{\u0026quot;unit\u0026quot;: \u0026quot;kelvin\u0026quot;}      # enum 里只有 celsius / fahrenheit\n\n# 3. 格式错误：JSON 语法不对\n\u0026#39;{\u0026quot;city\u0026quot;: \u0026quot;北京\u0026quot;,}\u0026#39;      # 尾部多余逗号（严格 JSON 不允许）\n\n# 4. 幻觉参数：编造了不存在的参数\n{\u0026quot;city\u0026quot;: \u0026quot;北京\u0026quot;, \u0026quot;forecast_days\u0026quot;: 7}  # 工具根本没有这个参数\n\n# 5. 语义错误：参数值表面合法但语义错误\n{\u0026quot;sql\u0026quot;: \u0026quot;DROP TABLE users\u0026quot;}  # 传了一条 DELETE 语句给 SELECT-only 工具\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e应对策略是 \u003cstrong\u003e分层验证\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef validate_and_execute(tool: Tool, raw_arguments: str) -\u0026gt; dict:\n    # 第一层：JSON 语法\n    try:\n        args = json.loads(raw_arguments)\n    except json.JSONDecodeError:\n        return {\u0026quot;error\u0026quot;: \u0026quot;参数不是合法的 JSON\u0026quot;}\n\n    # 第二层：Schema 验证（使用 jsonschema 库）\n    from jsonschema import validate, ValidationError\n    try:\n        validate(instance=args, schema=tool.parameters)\n    except ValidationError as e:\n        return {\u0026quot;error\u0026quot;: f\u0026quot;参数验证失败: {e.message}\u0026quot;}\n\n    # 第三层：业务规则验证\n    if tool.name == \u0026quot;query_database\u0026quot;:\n        sql = args.get(\u0026quot;sql\u0026quot;, \u0026quot;\u0026quot;).strip().upper()\n        if not sql.startswith(\u0026quot;SELECT\u0026quot;):\n            return {\u0026quot;error\u0026quot;: \u0026quot;仅支持 SELECT 查询\u0026quot;}\n\n    # 执行\n    return tool.function(**args)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.2 工具执行失败的反馈\u003c/h3\u003e\n\u003cp\u003e当工具执行失败时，最重要的原则是：\u003cstrong\u003e将错误信息回传给 LLM，让它决定下一步\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 不要这样做 —— 对用户抛出原始异常\nraise RuntimeError(\u0026quot;Connection timeout to weather API\u0026quot;)\n\n# 应该这样做 —— 将错误包装为工具结果，回传给 LLM\n{\n    \u0026quot;tool_call_id\u0026quot;: \u0026quot;call_abc123\u0026quot;,\n    \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n    \u0026quot;content\u0026quot;: json.dumps({\n        \u0026quot;error\u0026quot;: \u0026quot;天气 API 连接超时，请稍后重试或尝试查询其他城市\u0026quot;,\n        \u0026quot;error_type\u0026quot;: \u0026quot;timeout\u0026quot;,\n        \u0026quot;retryable\u0026quot;: True\n    })\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLLM 拿到这个错误信息后，可能会：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e换一种方式重试（比如换个参数）\u003c/li\u003e\n\u003cli\u003e告知用户当前无法完成\u003c/li\u003e\n\u003cli\u003e尝试用其他工具达成目标\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.3 重试策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                  ┌──────────────────────────┐\n                  │    Tool Call 失败         │\n                  └──────────┬───────────────┘\n                             │\n                   ┌─────────▼─────────┐\n                   │  错误类型判断       │\n                   └─────────┬─────────┘\n                             │\n              ┌──────────────┼──────────────┐\n              │              │              │\n        ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐\n        │ 可重试     │ │ 参数错误   │ │ 不可恢复   │\n        │(超时/限流) │ │(类型/格式) │ │(权限/404) │\n        └─────┬─────┘ └─────┬─────┘ └─────┬─────┘\n              │              │              │\n        ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐\n        │ Runtime    │ │ 回传 LLM  │ │ 回传 LLM  │\n        │ 自动重试   │ │ 让它修正   │ │ 让它放弃   │\n        │ (指数退避) │ │ 参数       │ │ 或换方案   │\n        └───────────┘ └───────────┘ └───────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e核心原则：\u003cstrong\u003e可重试的错误由 Runtime 处理，不可重试的错误交给 LLM 决策\u003c/strong\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e瞬时错误\u003c/strong\u003e（网络超时、限流）：Runtime 自动重试，设置退避策略和最大重试次数，不需要浪费 LLM 的 token。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e参数错误\u003c/strong\u003e：回传给 LLM，它可能会修正参数重新调用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e永久错误\u003c/strong\u003e（权限不足、资源不存在）：回传给 LLM，让它换一种方案或如实告知用户。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.4 幂等性考量\u003c/h3\u003e\n\u003cp\u003e当重试机制存在时，幂等性就变得至关重要。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 幂等操作 —— 重试安全\nget_weather(\u0026quot;北京\u0026quot;)           # 多次调用结果相同\nquery_database(\u0026quot;SELECT ...\u0026quot;)  # 只读查询，天然幂等\n\n# 非幂等操作 —— 重试危险\nsend_email(to=\u0026quot;a@b.com\u0026quot;, ...)  # 重试 = 发两封邮件\ncreate_order(item=\u0026quot;iPhone\u0026quot;)    # 重试 = 创建两个订单\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e对于非幂等操作，要么禁止自动重试，要么引入幂等 key：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef send_email_idempotent(to: str, subject: str, body: str, idempotency_key: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;带幂等 key 的邮件发送\u0026quot;\u0026quot;\u0026quot;\n    if is_already_sent(idempotency_key):\n        return {\u0026quot;status\u0026quot;: \u0026quot;already_sent\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;该请求已处理，跳过重复发送\u0026quot;}\n    result = _do_send_email(to, subject, body)\n    mark_as_sent(idempotency_key)\n    return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 安全性\u003c/h2\u003e\n\u003cp\u003eTool Calling 打开了 LLM 与外部世界的通道，也同时打开了攻击面。\u003c/p\u003e\n\u003ch3\u003e8.1 工具权限控制\u003c/h3\u003e\n\u003cp\u003e不是所有工具都应该对所有用户开放。一个合理的权限模型：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom enum import Enum\n\nclass ToolPermission(Enum):\n    READ = \u0026quot;read\u0026quot;        # 只读操作：查询天气、读文件\n    WRITE = \u0026quot;write\u0026quot;      # 写操作：发邮件、创建记录\n    ADMIN = \u0026quot;admin\u0026quot;      # 管理操作：删除数据、修改配置\n\nclass SecureToolRegistry(ToolRegistry):\n    \u0026quot;\u0026quot;\u0026quot;带权限控制的工具注册中心\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        super().__init__()\n        self._permissions: dict[str, ToolPermission] = {}\n\n    def register(self, tool: Tool, permission: ToolPermission = ToolPermission.READ):\n        super().register(tool)\n        self._permissions[tool.name] = permission\n\n    def get_definitions(\n        self,\n        names: list[str] | None = None,\n        max_permission: ToolPermission = ToolPermission.READ,\n    ) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;只返回用户权限范围内的工具\u0026quot;\u0026quot;\u0026quot;\n        permission_levels = {\n            ToolPermission.READ: 0,\n            ToolPermission.WRITE: 1,\n            ToolPermission.ADMIN: 2,\n        }\n        max_level = permission_levels[max_permission]\n        allowed = [\n            t for t in self._tools.values()\n            if permission_levels[self._permissions.get(t.name, ToolPermission.ADMIN)] \u0026lt;= max_level\n        ]\n        if names:\n            allowed = [t for t in allowed if t.name in names]\n        return [t.to_openai_schema() for t in allowed]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.2 参数注入风险\u003c/h3\u003e\n\u003cp\u003eLLM 的参数生成可以被 Prompt Injection 操纵。考虑以下场景：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e用户输入: \u0026quot;帮我查一下订单，user_id 是 U00012345; DROP TABLE orders; --\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e如果 \u003ccode\u003equery_database\u003c/code\u003e 工具直接拼接 SQL，这就变成了一次经典的 SQL 注入。防护措施：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e参数化查询\u003c/strong\u003e：工具内部必须使用参数化 SQL，绝不拼接。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e白名单校验\u003c/strong\u003e：用正则或枚举限制参数值的格式。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e最小权限原则\u003c/strong\u003e：数据库连接使用只读账号。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e8.3 Sandbox 执行\u003c/h3\u003e\n\u003cp\u003e对于高风险工具（如代码执行、文件操作），应在隔离环境中执行：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────┐\n│  Host Runtime                                 │\n│                                              │\n│   ┌─────────────┐     ┌──────────────────┐   │\n│   │  Safe Tools  │     │    Sandbox       │   │\n│   │  (天气/计算) │     │  ┌────────────┐  │   │\n│   │  直接执行    │     │  │ Risky Tools│  │   │\n│   └─────────────┘     │  │ (代码/文件) │  │   │\n│                       │  │ 隔离执行    │  │   │\n│                       │  └────────────┘  │   │\n│                       │  - 网络受限      │   │\n│                       │  - 文件系统隔离  │   │\n│                       │  - 执行时间限制  │   │\n│                       │  - 资源配额      │   │\n│                       └──────────────────┘   │\n└──────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSandbox 的实现方式取决于部署环境：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDocker 容器\u003c/strong\u003e：最常见，隔离性好\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003egVisor / Firecracker\u003c/strong\u003e：更强的隔离，适合多租户\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWASM\u003c/strong\u003e：轻量级沙箱，启动快\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e子进程 + seccomp\u003c/strong\u003e：Linux 下的轻量方案\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e9. Trade-off 分析\u003c/h2\u003e\n\u003ch3\u003e9.1 工具数量 vs 选择准确率\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e选择准确率\n  100% │ ****\n       │     ****\n   90% │         ****\n       │             ****\n   80% │                 ****\n       │                     ****\n   70% │                         ****\n       │                             ****\n   60% │                                 ****\n       ├───┬───┬───┬───┬───┬───┬───┬───┬───── 工具数量\n       0   5  10  15  20  25  30  35  40\n\n       |\u0026lt;-- 全量传递 --\u0026gt;|\u0026lt;- 需要过滤策略 -\u0026gt;|\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u0026lt; 10 个工具\u003c/strong\u003e：全量传递，不需要过滤。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e10-20 个工具\u003c/strong\u003e：准确率开始下降，可通过优化 description 缓解。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u0026gt; 20 个工具\u003c/strong\u003e：必须引入 Tool Selection 策略（语义过滤或两阶段选择）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u0026gt; 50 个工具\u003c/strong\u003e：两阶段选择几乎是唯一可行方案，或者按领域拆分为多个 Agent。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e9.2 工具描述详细度 vs Token 消耗\u003c/h3\u003e\n\u003cp\u003e每个工具定义大约占用 100-500 token（取决于描述长度和参数数量）。20 个工具就是 2000-10000 token 的系统开销，这是每次 API 调用都要付出的 \u003cstrong\u003e固定成本\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                        描述详细度\n                  低 ◄──────────────► 高\n                  │                    │\n  Token 消耗   低 │  ⚡ 省钱但模糊     │\n                  │  LLM 可能误选工具  │\n                  │                    │\n              高 │                    │  📖 精确但昂贵\n                  │                    │  LLM 选择更准确\n                  │                    │\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实践建议：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e工具 \u003ccode\u003ename\u003c/code\u003e 起好名字（零额外 token 成本，但信息量大）\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edescription\u003c/code\u003e 控制在 2-3 句话\u003c/li\u003e\n\u003cli\u003e参数的 \u003ccode\u003edescription\u003c/code\u003e 控制在 1 句话 + 1 个示例\u003c/li\u003e\n\u003cli\u003e用 \u003ccode\u003eenum\u003c/code\u003e 和 \u003ccode\u003erequired\u003c/code\u003e 代替冗长的文字约束\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e9.3 确定性执行 vs LLM 灵活性\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e确定性                                          灵活性\n  │                                              │\n  │  硬编码工作流           Agent Tool Calling     │\n  │  if/else 分支            LLM 自由选择工具     │\n  │  规则引擎                自动组合工具链        │\n  │                                              │\n  │  ✅ 可预测              ✅ 处理模糊意图        │\n  │  ✅ 可审计              ✅ 适应新场景          │\n  │  ✅ 低延迟              ✅ 用户体验自然        │\n  │  ❌ 不灵活              ❌ 不可预测            │\n  │  ❌ 维护成本高          ❌ 调试困难            │\n  │  ❌ 无法处理长尾        ❌ 成本高              │\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e决策框架：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景特征\u003c/th\u003e\n\u003cth\u003e推荐方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e流程固定、合规要求高\u003c/td\u003e\n\u003ctd\u003e硬编码工作流 + Tool Calling 作为执行层\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e意图模糊、工具组合多变\u003c/td\u003e\n\u003ctd\u003e完全由 LLM 驱动的 Tool Calling\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e核心路径固定、边缘场景多\u003c/td\u003e\n\u003ctd\u003e混合方案：主流程硬编码，长尾交给 LLM\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e关键洞察：Tool Calling 不是非此即彼的选择。你可以让 LLM 决定 \u003cstrong\u003e是否\u003c/strong\u003e 调用工具，但用代码控制 \u003cstrong\u003e调用后的流程\u003c/strong\u003e。比如 LLM 决定\u0026quot;需要查天气\u0026quot;，但查完天气后的处理逻辑是确定性的代码。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 常见陷阱\u003c/h2\u003e\n\u003cp\u003e在实际工程中，以下几个坑值得提前规避：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. 工具描述与实际行为不一致\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e工具描述说\u0026quot;返回最近 30 天的订单\u0026quot;，但实际实现返回所有订单。LLM 会基于描述做出错误假设，导致下游逻辑出错。\u003cstrong\u003e描述就是契约，必须与实现严格一致\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. 忽略工具结果的 Token 消耗\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e工具返回的结果会作为下一轮消息传给 LLM。如果一个数据库查询返回了 1000 行数据，这些数据全部变成 input token。务必在工具层面限制返回数据量。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef query_database(sql: str, database: str = \u0026quot;default\u0026quot;) -\u0026gt; dict:\n    results = _execute_query(sql, database)\n    # 限制返回行数，避免 token 爆炸\n    if len(results) \u0026gt; 50:\n        return {\n            \u0026quot;rows\u0026quot;: results[:50],\n            \u0026quot;total_count\u0026quot;: len(results),\n            \u0026quot;truncated\u0026quot;: True,\n            \u0026quot;message\u0026quot;: f\u0026quot;结果共 {len(results)} 行，仅返回前 50 行\u0026quot;\n        }\n    return {\u0026quot;rows\u0026quot;: results, \u0026quot;total_count\u0026quot;: len(results)}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. 缺少 stop condition\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果 LLM 反复调用同一个工具（比如因为错误一直重试），而没有最大迭代次数限制，系统会陷入无限循环。前面代码中的 \u003ccode\u003emax_iterations\u003c/code\u003e 参数就是为此设计的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. 并行调用的顺序依赖\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLLM 可能在一次回复中请求并行调用两个工具，但这两个工具之间有隐含的顺序依赖（比如先查用户 ID，再用这个 ID 查订单）。Runtime 需要能识别这种情况，或者在工具描述中引导 LLM 分步调用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e11. 总结与展望\u003c/h2\u003e\n\u003cp\u003eTool Calling 的本质是一个精心设计的 \u003cstrong\u003e协议\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌───────────┐    JSON Schema    ┌───────────┐    Function    ┌───────────┐\n│           │    (契约)          │           │    (执行)      │           │\n│    LLM    │ ◄───────────────► │  Runtime  │ ◄────────────► │   Tools   │\n│  (决策层) │   Tool Call JSON   │  (调度层) │   Function     │  (能力层) │\n│           │   Tool Result      │           │   Call/Return  │           │\n└───────────┘                   └───────────┘                └───────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLLM\u003c/strong\u003e 负责理解意图、选择工具、生成参数——它是决策者。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRuntime\u003c/strong\u003e 负责验证、路由、执行、错误处理——它是执行者。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTools\u003c/strong\u003e 是具体的能力——它们是能力的载体。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJSON Schema\u003c/strong\u003e 是三者之间的契约——它定义了什么可以做、怎么做。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e理解了这个架构，你就能在任何框架（LangChain、LlamaIndex、Semantic Kernel，或者自己写的 Runtime）上实现 Tool Calling，因为底层原理是相同的。\u003c/p\u003e\n\u003cp\u003e但 Tool Calling 只是让 Agent 有了\u0026quot;手\u0026quot;。要让 Agent 真正好用，还需要精心设计的 Prompt 来引导 LLM 的决策——什么时候该调工具、什么时候该直接回答、遇到错误该怎么处理、多个工具之间如何协调。这就是下一篇 \u003cstrong\u003ePrompt Engineering for Agents\u003c/strong\u003e 要深入讨论的主题。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 05 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/04-The%20Agent%20Control%20Loop\"\u003e04 | The Agent Control Loop\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/06-Prompt%20Engineering%20for%20Agents\"\u003e06 | Prompt Engineering for Agents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"17:T602d,"])</script><script>self.__next_f.push([1,"\u003ch1\u003e高并发系统设计：原理、策略与工程实践\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e高并发不是一个单点问题，而是一个系统性工程。它要求在计算、存储、网络、容错等多个维度协同设计，在吞吐量、延迟、一致性、可用性之间做出精确的权衡。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e高并发系统的本质目标是：\u003cstrong\u003e在保证系统整体可用的前提下，最大化单位时间内的请求处理能力\u003c/strong\u003e。这涉及两个核心指标——\u003cstrong\u003e吞吐量\u003c/strong\u003e（TPS/QPS）和\u003cstrong\u003e响应延迟\u003c/strong\u003e（Latency），以及一个隐含约束——\u003cstrong\u003e资源成本\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e本文将高并发设计策略按作用层次分为四大类，逐一分析每种策略的底层原理、适用场景与决策依据。\u003c/p\u003e\n\u003ch2\u003e一、计算层：提升处理能力\u003c/h2\u003e\n\u003cp\u003e计算层的核心矛盾是\u003cstrong\u003e单节点处理能力有限\u003c/strong\u003e。解决思路有两条：纵向压榨单机性能，横向扩展节点数量。\u003c/p\u003e\n\u003ch3\u003e1.1 水平扩展\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将请求分散到多个对等节点并行处理，系统吞吐量随节点数近线性增长。\u003c/p\u003e\n\u003cp\u003e水平扩展是高并发的第一性原理——当单机无法承载时，加机器是最直接的手段。但前提是系统必须具备\u003cstrong\u003e无状态性\u003c/strong\u003e，否则扩展只是增加复杂度。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e条件\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e无状态服务\u003c/td\u003e\n\u003ctd\u003e请求可被任意节点处理，不依赖本地状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e负载均衡\u003c/td\u003e\n\u003ctd\u003e流量均匀分配到各节点（轮询、加权、一致性哈希）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e服务发现\u003c/td\u003e\n\u003ctd\u003e新增/下线节点时自动感知\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e水平扩展的收益存在拐点。当瓶颈不在计算层（如数据库连接数耗尽），加应用节点无法提升吞吐\u003c/li\u003e\n\u003cli\u003e扩展前先确认瓶颈位置：CPU 密集型看计算节点数，I/O 密集型看下游容量\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e1.2 服务拆分\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将单体应用按业务域拆分为独立服务，每个服务独立部署、独立扩展，使资源投放更精准。\u003c/p\u003e\n\u003cp\u003e服务拆分的高并发价值不在于\u0026quot;拆\u0026quot;本身，而在于\u003cstrong\u003e差异化扩展\u003c/strong\u003e——热点服务可以单独扩容，而不必整体扩展。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e单体应用：所有模块共享资源池\n  → 商品查询 QPS 暴涨时，订单、支付模块的资源也被占用\n\n服务拆分后：\n  → 商品服务独立扩容 10 倍，订单服务保持不变\n  → 资源利用率提升，扩容成本下降\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e拆分粒度不是越细越好。过度拆分导致服务间调用链路变长，网络开销和故障概率增加\u003c/li\u003e\n\u003cli\u003e拆分的依据是\u003cstrong\u003e业务边界\u003c/strong\u003e和\u003cstrong\u003e扩展需求\u003c/strong\u003e，而非代码量\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e1.3 异步化\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将同步阻塞调用转为异步非阻塞，释放线程资源去处理更多请求，从而提升单位时间内的吞吐量。\u003c/p\u003e\n\u003cp\u003e同步模型下，线程在等待下游响应期间处于阻塞状态，无法处理新请求。异步化的本质是\u003cstrong\u003e把等待时间转化为处理能力\u003c/strong\u003e。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e异步方式\u003c/th\u003e\n\u003cth\u003e机制\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e消息队列\u003c/td\u003e\n\u003ctd\u003e请求写入 MQ 后立即返回，消费者异步处理\u003c/td\u003e\n\u003ctd\u003e非实时性业务（通知、日志、数据同步）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e异步 I/O\u003c/td\u003e\n\u003ctd\u003eNIO / Reactor 模型\u003c/td\u003e\n\u003ctd\u003e高并发网络通信（Netty、WebFlux）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并行调用\u003c/td\u003e\n\u003ctd\u003eCompletableFuture / 协程\u003c/td\u003e\n\u003ctd\u003e多个独立下游调用并行执行\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e事件驱动\u003c/td\u003e\n\u003ctd\u003e发布-订阅模式\u003c/td\u003e\n\u003ctd\u003e服务间解耦\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e异步化的前提是业务允许\u003cstrong\u003e延迟处理\u003c/strong\u003e。对于实时性要求高的链路（如支付扣款），不宜异步\u003c/li\u003e\n\u003cli\u003e引入异步后需要处理\u003cstrong\u003e结果通知\u003c/strong\u003e（回调、轮询）和\u003cstrong\u003e失败重试\u003c/strong\u003e，系统复杂度会上升\u003c/li\u003e\n\u003cli\u003e消息队列的削峰价值：瞬时 5000 QPS 的流量冲击，系统处理能力 2000 QPS，MQ 作为缓冲区，将超出部分排队处理，避免系统过载\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e1.4 池化\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：预先创建并复用昂贵资源（连接、线程、对象），避免频繁创建/销毁带来的开销。\u003c/p\u003e\n\u003cp\u003e每次创建数据库连接需要 TCP 三次握手 + 认证，耗时通常在毫秒级。在高并发场景下，这些开销会被放大数百倍。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e池化类型\u003c/th\u003e\n\u003cth\u003e复用的资源\u003c/th\u003e\n\u003cth\u003e关键参数\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e数据库连接池\u003c/td\u003e\n\u003ctd\u003eTCP 连接 + 认证会话\u003c/td\u003e\n\u003ctd\u003e最大连接数、最小空闲数、获取超时\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHTTP 连接池\u003c/td\u003e\n\u003ctd\u003eTCP 连接（Keep-Alive）\u003c/td\u003e\n\u003ctd\u003e最大连接数、每路由最大连接数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e线程池\u003c/td\u003e\n\u003ctd\u003e线程\u003c/td\u003e\n\u003ctd\u003e核心线程数、最大线程数、队列长度、拒绝策略\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e对象池\u003c/td\u003e\n\u003ctd\u003e重量级对象（如序列化器）\u003c/td\u003e\n\u003ctd\u003e池大小、借出超时\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e连接池大小不是越大越好。过多连接会导致数据库端线程竞争加剧，反而降低性能。PostgreSQL 官方建议的公式：\u003ccode\u003e连接数 = ((核心数 * 2) + 有效磁盘数)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e线程池的队列策略直接影响系统行为：无界队列可能导致 OOM，有界队列需要配合合理的拒绝策略\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e二、数据层：突破存储瓶颈\u003c/h2\u003e\n\u003cp\u003e高并发系统中，数据库通常是第一个到达瓶颈的组件。数据层优化的核心思路是\u003cstrong\u003e减少对数据库的直接访问\u003c/strong\u003e和\u003cstrong\u003e提升数据库本身的承载能力\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e2.1 缓存\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将热点数据存储在访问速度更快的介质中（内存），减少对慢速存储（磁盘数据库）的访问。\u003c/p\u003e\n\u003cp\u003e缓存是高并发系统中 ROI 最高的优化手段。一次 Redis 查询耗时约 0.5ms，一次 MySQL 查询耗时约 5\u003cdel\u003e50ms，性能差距在 10\u003c/del\u003e100 倍。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e多级缓存架构\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e请求 → L1 本地缓存（Caffeine）    命中率 ~60%\n     → L2 分布式缓存（Redis）      命中率 ~95%\n     → L3 数据库（MySQL）          兜底查询\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e每一层拦截掉大部分请求，最终到达数据库的流量可能不到总量的 5%。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缓存三大问题及应对\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e问题\u003c/th\u003e\n\u003cth\u003e成因\u003c/th\u003e\n\u003cth\u003e解决方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e穿透\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e查询不存在的 Key，每次都打到 DB\u003c/td\u003e\n\u003ctd\u003e布隆过滤器拦截；空值缓存（TTL 设短）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e击穿\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e热点 Key 过期瞬间，大量请求涌入 DB\u003c/td\u003e\n\u003ctd\u003e互斥锁重建；逻辑过期 + 异步刷新\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e雪崩\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e大批 Key 同时过期\u003c/td\u003e\n\u003ctd\u003e过期时间加随机偏移；多级缓存兜底\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e缓存适用于\u003cstrong\u003e读多写少\u003c/strong\u003e的场景。写频繁的数据缓存命中率低，且一致性维护成本高\u003c/li\u003e\n\u003cli\u003e缓存与数据库的一致性没有完美方案。常用策略是\u003cstrong\u003eCache Aside（旁路缓存）\u003c/strong\u003e：读时先查缓存，miss 则查 DB 并回填；写时先更新 DB，再删除缓存\u003c/li\u003e\n\u003cli\u003e本地缓存适合体积小、变化少、一致性要求低的数据（如配置信息）；分布式缓存适合体积大、需要跨节点共享的数据\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.2 读写分离\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将数据库的读写流量分离到不同实例，主库承担写操作，从库承担读操作，利用数据复制实现读能力的水平扩展。\u003c/p\u003e\n\u003cp\u003e大多数业务系统的读写比在 7:3 到 9:1 之间。读写分离的本质是\u003cstrong\u003e用廉价的从库分担主库的读压力\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e写请求 → 主库（Master）\n                ↓ Binlog 复制\n读请求 → 从库 1 / 从库 2 / 从库 N\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e需要处理的关键问题\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e问题\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003cth\u003e解决方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e主从延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e从库数据滞后于主库（通常 ms~s 级）\u003c/td\u003e\n\u003ctd\u003e强一致读走主库；半同步复制减少延迟\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e延迟感知\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e刚写入的数据立即读取可能读到旧值\u003c/td\u003e\n\u003ctd\u003e写后读强制路由到主库（Session 级别）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e从库故障\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e某个从库不可用\u003c/td\u003e\n\u003ctd\u003e负载均衡自动摘除；从库集群冗余\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e读写分离能解决读瓶颈，但无法解决写瓶颈。如果写 QPS 过高，需要考虑分库\u003c/li\u003e\n\u003cli\u003e对于实时性要求高的读操作（如支付后查询订单状态），必须路由到主库\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.3 分库分表\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将数据分散到多个数据库实例（分库）或多张表（分表），突破单实例的存储容量和连接数限制。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e解决的问题\u003c/th\u003e\n\u003cth\u003e拆分维度\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e垂直分库\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不同业务的数据隔离\u003c/td\u003e\n\u003ctd\u003e按业务域拆分（用户库、订单库、商品库）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e水平分库\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单库连接数/写入能力不足\u003c/td\u003e\n\u003ctd\u003e按路由键分片到多个库实例\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e水平分表\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单表数据量过大导致查询变慢\u003c/td\u003e\n\u003ctd\u003e按路由键分片到多张表\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e分片策略对比\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eHash 取模\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eshardId = hash(key) % N\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e数据分布均匀\u003c/td\u003e\n\u003ctd\u003e扩容需要数据迁移\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e范围分片\u003c/td\u003e\n\u003ctd\u003e按 ID 或时间范围划分\u003c/td\u003e\n\u003ctd\u003e扩容简单，支持范围查询\u003c/td\u003e\n\u003ctd\u003e可能出现热点分片\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一致性哈希\u003c/td\u003e\n\u003ctd\u003e哈希环 + 虚拟节点\u003c/td\u003e\n\u003ctd\u003e扩容仅迁移部分数据\u003c/td\u003e\n\u003ctd\u003e实现复杂度较高\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e单表数据量超过 \u003cstrong\u003e1000 万~2000 万行\u003c/strong\u003e时，B+ 树索引层级增加，查询性能开始下降，应考虑分表\u003c/li\u003e\n\u003cli\u003e分库分表会引入\u003cstrong\u003e分布式事务\u003c/strong\u003e和\u003cstrong\u003e跨分片查询\u003c/strong\u003e两大难题，在决策前需评估这些成本是否可接受\u003c/li\u003e\n\u003cli\u003e路由键的选择至关重要：选择查询最频繁的字段（通常是用户 ID），避免绝大多数查询变成跨分片查询\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.4 搜索引擎分流\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将搜索、模糊查询、聚合统计等对关系型数据库不友好的查询，分流到专用搜索引擎（Elasticsearch），减轻数据库压力。\u003c/p\u003e\n\u003cp\u003eMySQL 的 \u003ccode\u003eLIKE \u0026#39;%keyword%\u0026#39;\u003c/code\u003e 无法走索引，在大数据量下性能急剧下降。Elasticsearch 基于倒排索引，天然支持全文检索和聚合查询，且具备水平扩展能力。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e适合搜索引擎的场景\u003c/th\u003e\n\u003cth\u003e不适合的场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e全文搜索、模糊匹配\u003c/td\u003e\n\u003ctd\u003e强事务性写入\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e多维度组合筛选\u003c/td\u003e\n\u003ctd\u003e实时一致性要求高的读取\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e聚合统计分析\u003c/td\u003e\n\u003ctd\u003e频繁更新的热点数据\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eES 的数据来源于数据库同步（Binlog 订阅或双写），存在秒级延迟，不适合作为事务性读取的主存储\u003c/li\u003e\n\u003cli\u003eES 集群的运维成本较高（分片管理、索引优化、GC 调优），引入前需评估团队的运维能力\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e三、流量层：控制入口压力\u003c/h2\u003e\n\u003cp\u003e当流量超过系统承载能力时，需要在入口层进行管控，避免系统被打垮。\u003c/p\u003e\n\u003ch3\u003e3.1 CDN 静态加速\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将静态资源（图片、CSS、JS）分发到离用户最近的边缘节点，用户就近访问，减少源站压力和网络延迟。\u003c/p\u003e\n\u003cp\u003eCDN 的价值不仅是加速，更是\u003cstrong\u003e将静态请求从应用服务器完全卸载\u003c/strong\u003e。一个电商页面中，静态资源请求可能占总请求量的 80% 以上。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e无 CDN：  用户（深圳） → 源站（北京）   RTT ~40ms\n有 CDN：  用户（深圳） → CDN 节点（深圳）  RTT ~5ms\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e静态资源使用独立域名，避免携带不必要的 Cookie\u003c/li\u003e\n\u003cli\u003e文件名带内容哈希（如 \u003ccode\u003eapp.a3b2c1.js\u003c/code\u003e），配合长缓存策略，既保证缓存命中率又支持即时更新\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.2 限流\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：当入口流量超过系统容量时，主动丢弃超出部分的请求，保证系统在承载范围内正常服务。\u003c/p\u003e\n\u003cp\u003e限流是\u003cstrong\u003e保护系统不被打垮的最后一道防线\u003c/strong\u003e。它的前提假设是：服务部分用户优于服务零用户。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e主流限流算法对比\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e算法\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e固定窗口\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e固定时间窗口内计数\u003c/td\u003e\n\u003ctd\u003e实现简单\u003c/td\u003e\n\u003ctd\u003e存在窗口边界突发问题\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e滑动窗口\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e滑动时间窗口内计数\u003c/td\u003e\n\u003ctd\u003e平滑度优于固定窗口\u003c/td\u003e\n\u003ctd\u003e内存占用略高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e漏桶\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e请求以固定速率流出\u003c/td\u003e\n\u003ctd\u003e流量绝对平滑\u003c/td\u003e\n\u003ctd\u003e无法应对合理的突发流量\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e令牌桶\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e令牌以固定速率生成，请求消耗令牌\u003c/td\u003e\n\u003ctd\u003e允许一定突发流量\u003c/td\u003e\n\u003ctd\u003e参数调优有一定复杂度\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e限流的层次\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e接入层限流（Nginx / API Gateway）   → 粗粒度，按 IP 或接口\n应用层限流（Sentinel / Guava）      → 细粒度，按用户、业务维度\n数据层限流（连接池 / 信号量）         → 保护下游资源\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e限流阈值必须基于\u003cstrong\u003e压测数据\u003c/strong\u003e设定，而非拍脑袋。先压测确定系统容量，再按容量的 70%~80% 设置限流阈值\u003c/li\u003e\n\u003cli\u003e被限流的请求应返回明确的状态码（如 HTTP 429）和友好的提示，而非超时或错误\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.3 负载均衡\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将入口流量按策略分配到多个后端节点，避免单节点过载，同时实现故障自动摘除。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e层级\u003c/th\u003e\n\u003cth\u003e实现\u003c/th\u003e\n\u003cth\u003e特点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eDNS 负载均衡\u003c/td\u003e\n\u003ctd\u003eDNS 多 A 记录\u003c/td\u003e\n\u003ctd\u003e粗粒度，无法感知后端状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eL4 负载均衡\u003c/td\u003e\n\u003ctd\u003eLVS / F5\u003c/td\u003e\n\u003ctd\u003e高性能（百万级），基于 IP + 端口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eL7 负载均衡\u003c/td\u003e\n\u003ctd\u003eNginx / HAProxy\u003c/td\u003e\n\u003ctd\u003e灵活（可按 URL、Header 路由），性能略低于 L4\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e常用调度算法\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e算法\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e轮询 / 加权轮询\u003c/td\u003e\n\u003ctd\u003e后端节点性能一致或差异已知\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e最少连接\u003c/td\u003e\n\u003ctd\u003e请求处理时间差异大\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一致性哈希\u003c/td\u003e\n\u003ctd\u003e需要会话亲和或缓存亲和\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e随机\u003c/td\u003e\n\u003ctd\u003e后端节点对等，实现最简单\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e四、容错层：保障系统韧性\u003c/h2\u003e\n\u003cp\u003e高并发场景下，系统组件出现故障的概率随节点数增长而增大。容错设计的目标是\u003cstrong\u003e局部故障不扩散为全局雪崩\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e4.1 熔断\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：当下游服务的错误率或响应时间超过阈值时，自动切断对该服务的调用，防止故障沿调用链向上蔓延。\u003c/p\u003e\n\u003cp\u003e熔断器借鉴了电路断路器的设计，有三个状态：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eClosed（关闭）→ 正常放行请求\n    ↓ 错误率超过阈值\nOpen（打开）→ 直接拒绝请求，返回降级结果\n    ↓ 超时后放行少量探测请求\nHalf-Open（半开）→ 探测成功则恢复，失败则重新打开\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e熔断阈值的设定需要区分\u003cstrong\u003e瞬时抖动\u003c/strong\u003e和\u003cstrong\u003e持续故障\u003c/strong\u003e。通常使用滑动窗口统计，避免单次超时就触发熔断\u003c/li\u003e\n\u003cli\u003e熔断后的降级策略需要提前设计：返回默认值、返回缓存数据、或返回友好提示\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.2 降级\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：在系统压力过大时，主动关闭非核心功能，将资源集中保障核心链路。\u003c/p\u003e\n\u003cp\u003e降级是一种\u003cstrong\u003e有策略的功能取舍\u003c/strong\u003e，核心思想是：宁可部分功能不可用，也不能让整个系统崩溃。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e降级层次\u003c/th\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e示例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e接口降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e关闭非核心接口\u003c/td\u003e\n\u003ctd\u003e大促期间关闭商品评论、推荐功能\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e返回简化/缓存数据\u003c/td\u003e\n\u003ctd\u003e库存查询降级为返回\u0026quot;有货\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e体验降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e降低功能质量\u003c/td\u003e\n\u003ctd\u003e图片返回低清版本、关闭个性化推荐\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e写降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e异步化写入\u003c/td\u003e\n\u003ctd\u003e日志、埋点异步落盘\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e降级开关应提前埋入代码，通过配置中心实时生效，而非临时发版\u003c/li\u003e\n\u003cli\u003e建立业务优先级分类（P0~P3），明确各级业务在压力场景下的降级策略\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.3 超时与重试\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：通过超时避免线程无限等待，通过重试应对瞬时故障。两者配合使用，在可靠性和资源效率之间取得平衡。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e关键参数\u003c/th\u003e\n\u003cth\u003e注意事项\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e超时\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e连接超时、读取超时\u003c/td\u003e\n\u003ctd\u003e超时时间应基于下游 P99 延迟设定，而非经验值\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e重试\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e最大重试次数、退避策略\u003c/td\u003e\n\u003ctd\u003e仅对\u003cstrong\u003e幂等\u003c/strong\u003e操作重试；使用指数退避避免重试风暴\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e重试的风险——重试风暴\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e正常情况：A → B → C，每层 1 次调用 = 1 次\n重试场景：A(重试3次) → B(重试3次) → C\n  C 的实际请求量 = 3 × 3 = 9 倍放大\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在调用链的\u003cstrong\u003e最外层\u003c/strong\u003e设置重试，中间层尽量不重试，避免指数级放大\u003c/li\u003e\n\u003cli\u003e重试需配合\u003cstrong\u003e熔断\u003c/strong\u003e使用：当下游已经熔断时，不应继续重试\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.4 隔离\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e原理\u003c/strong\u003e：将不同业务或不同调用方的资源隔离开，防止某一个慢请求或故障请求耗尽全局资源。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e隔离方式\u003c/th\u003e\n\u003cth\u003e机制\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e线程池隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个下游调用使用独立线程池\u003c/td\u003e\n\u003ctd\u003e调用外部服务，需要严格隔离\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e信号量隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e限制某类请求的并发数\u003c/td\u003e\n\u003ctd\u003e轻量级隔离，开销比线程池小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e进程隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不同业务部署在独立进程/容器\u003c/td\u003e\n\u003ctd\u003e核心业务与非核心业务隔离\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e机房/泳道隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e流量按泳道划分到独立基础设施\u003c/td\u003e\n\u003ctd\u003eSET 化架构、灰度发布\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e五、验证层：建立量化基准\u003c/h2\u003e\n\u003cp\u003e以上所有策略的效果，最终都需要通过压力测试来验证。\u003c/p\u003e\n\u003ch3\u003e5.1 压力测试\u003c/h3\u003e\n\u003cp\u003e压测的目的不是\u0026quot;测试系统能抗多少\u0026quot;，而是\u003cstrong\u003e建立系统容量的量化认知\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e压测指标\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e目标\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eQPS/TPS\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每秒处理请求/事务数\u003c/td\u003e\n\u003ctd\u003e确定系统吞吐上限\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eP99 延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e99% 的请求响应时间\u003c/td\u003e\n\u003ctd\u003e确定延迟是否可接受\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e错误率\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e失败请求占比\u003c/td\u003e\n\u003ctd\u003e确定系统稳定性边界\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e资源利用率\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCPU、内存、网络、磁盘\u003c/td\u003e\n\u003ctd\u003e确定瓶颈所在\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e压测原则\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e全链路压测\u003c/strong\u003e：仅压测单个服务无法反映真实瓶颈，需要从入口到数据库全链路施压\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e梯度加压\u003c/strong\u003e：从低流量逐步增加，观察每个阶段的指标变化，而非直接打到目标流量\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e压测环境隔离\u003c/strong\u003e：避免压测流量影响线上数据，使用影子库/影子表隔离\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e5.2 容量规划\u003c/h3\u003e\n\u003cp\u003e基于压测数据建立容量模型：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e所需节点数 = 预估峰值 QPS / 单节点安全 QPS × 冗余系数\n\n示例：\n  预估峰值 QPS：10,000\n  单节点压测 QPS：2,000（P99 \u0026lt; 50ms 时）\n  冗余系数：1.5（预留 50% 余量应对突发）\n\n  所需节点数 = 10,000 / 2,000 × 1.5 = 7.5 → 8 个节点\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e最佳实践\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e容量规划以 \u003cstrong\u003eP99 延迟可接受时的 QPS\u003c/strong\u003e 为基准，而非极限 QPS\u003c/li\u003e\n\u003cli\u003e预留 30%~50% 的余量应对突发流量和非预期场景\u003c/li\u003e\n\u003cli\u003e建立常态化的容量巡检机制，而非仅在大促前才做压测\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e六、策略选择决策框架\u003c/h2\u003e\n\u003cp\u003e面对高并发问题时，不同策略的优先级和适用条件不同。以下是一个决策参考框架：\u003c/p\u003e\n\u003ch3\u003e按瓶颈类型选择策略\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e瓶颈类型\u003c/th\u003e\n\u003cth\u003e表现\u003c/th\u003e\n\u003cth\u003e优先策略\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eCPU 瓶颈\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCPU 利用率持续 \u0026gt; 80%\u003c/td\u003e\n\u003ctd\u003e水平扩展、异步化、算法优化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据库瓶颈（读）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e慢查询多、从库延迟高\u003c/td\u003e\n\u003ctd\u003e缓存、读写分离、索引优化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据库瓶颈（写）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e主库 TPS 到顶、锁等待严重\u003c/td\u003e\n\u003ctd\u003e分库分表、异步写入、批量合并\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e网络瓶颈\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e带宽打满、延迟升高\u003c/td\u003e\n\u003ctd\u003eCDN、数据压缩、减少调用次数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e连接数瓶颈\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003etoo many connections\u003c/td\u003e\n\u003ctd\u003e池化、读写分离、分库\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e按投入产出比排序\u003c/h3\u003e\n\u003cp\u003e高并发优化应遵循\u003cstrong\u003e先低成本高收益，再高成本高收益\u003c/strong\u003e的顺序：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e第一梯队（低成本、高收益）：\n  缓存 → 池化 → 索引优化 → CDN\n\n第二梯队（中等成本）：\n  读写分离 → 异步化 → 限流/熔断/降级\n\n第三梯队（高成本）：\n  分库分表 → 水平扩展 → 服务拆分 → SET 化\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e总结\u003c/h2\u003e\n\u003cp\u003e高并发系统设计不是某个单一技巧的应用，而是多种策略在不同层次的协同配合。核心原则可以归纳为三点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e先定位瓶颈，再选择策略\u003c/strong\u003e。不做盲目优化，压测数据是一切决策的基础\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e优先选择低成本方案\u003c/strong\u003e。缓存、池化、异步化往往能以最小代价解决 80% 的并发问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e容错比性能更重要\u003c/strong\u003e。系统在高并发下\u0026quot;不崩\u0026quot;比\u0026quot;更快\u0026quot;更关键——限流、熔断、降级是系统韧性的底线\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个成熟的高并发系统，不是在每个环节都做到极致，而是在每个环节都做出了正确的取舍。\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"18:T7a49,"])</script><script>self.__next_f.push([1,"\u003ch1\u003e架构师的认知升级：从技术深度到系统决策能力\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e架构的本质不是技术选型，而是在约束条件下做出最合理的决策。架构师的成长不是一蹴而就的技能习得，而是从\u0026quot;解决问题\u0026quot;到\u0026quot;定义问题\u0026quot;的思维蜕变。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e技术人的职业发展中，\u0026quot;架构师\u0026quot;是一个绕不开的里程碑。但很多人对架构师的认知停留在\u0026quot;画架构图\u0026quot;或\u0026quot;选技术栈\u0026quot;的层面，这远远不够。真正的架构能力是一种系统化的思维方式——它要求你既能深入技术细节，又能站在全局视角做出取舍。\u003c/p\u003e\n\u003cp\u003e本文将从架构的本质定义出发，系统梳理架构师的能力模型、知识体系、设计方法论与成长路径，为技术人提供一份可落地的架构认知框架。\u003c/p\u003e\n\u003ch2\u003e什么是架构？\u003c/h2\u003e\n\u003ch3\u003e从定义到本质\u003c/h3\u003e\n\u003cp\u003eIEEE 1471 对软件架构的定义是：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e软件架构是一个系统的基本组织，由其组件、组件之间的关系以及与环境之间的关系，还有指导其设计和演化的原则所体现。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e这个定义包含三个关键要素：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e要素\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e举例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e组件（Components）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e系统的构成单元\u003c/td\u003e\n\u003ctd\u003e服务、模块、数据库、消息队列\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e关系（Relationships）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e组件之间的交互方式\u003c/td\u003e\n\u003ctd\u003e同步调用、异步消息、事件驱动\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e原则（Principles）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e指导设计决策的约束\u003c/td\u003e\n\u003ctd\u003e高内聚低耦合、最终一致性、服务自治\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e架构的本质可以用一句话概括：\u003cstrong\u003e架构 = 结构 + 决策 + 演进\u003c/strong\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e结构\u003c/strong\u003e是系统的静态组织方式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e决策\u003c/strong\u003e是在多种方案中做出的关键取舍\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e演进\u003c/strong\u003e是架构随业务发展持续适应的能力\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e架构的四个层次\u003c/h3\u003e\n\u003cp\u003e在企业级系统中，架构通常分为四个层次，每一层关注的维度不同：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e层次\u003c/th\u003e\n\u003cth\u003e关注点\u003c/th\u003e\n\u003cth\u003e核心问题\u003c/th\u003e\n\u003cth\u003e典型产出\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e业务架构\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e业务域、能力、流程\u003c/td\u003e\n\u003ctd\u003e业务边界在哪？核心能力是什么？\u003c/td\u003e\n\u003ctd\u003e业务能力地图、流程图\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e应用架构\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e系统边界、服务划分\u003c/td\u003e\n\u003ctd\u003e系统如何拆分？服务如何协作？\u003c/td\u003e\n\u003ctd\u003e应用全景图、服务依赖图\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e技术架构\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e技术选型、基础设施\u003c/td\u003e\n\u003ctd\u003e用什么技术实现？如何部署？\u003c/td\u003e\n\u003ctd\u003e技术栈选型、部署架构图\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据架构\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e数据模型、流转、存储\u003c/td\u003e\n\u003ctd\u003e数据如何组织？如何流转？\u003c/td\u003e\n\u003ctd\u003e数据模型、数据流图\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e四个层次之间的关系是\u003cstrong\u003e自上而下驱动、自下而上支撑\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e业务架构（WHY）\n    ↓ 驱动\n应用架构（WHAT）\n    ↓ 驱动\n技术架构 + 数据架构（HOW）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e很多技术人在做架构设计时直接跳到\u0026quot;用什么技术\u0026quot;，忽略了业务架构和应用架构的推导过程。\u003cstrong\u003e脱离业务的架构设计就是空中楼阁。\u003c/strong\u003e\u003c/p\u003e\n\u003ch2\u003e架构师的核心能力模型\u003c/h2\u003e\n\u003cp\u003e架构师不是一个纯技术角色，而是技术与业务之间的桥梁。一个合格的架构师需要具备以下六个维度的能力：\u003c/p\u003e\n\u003ch3\u003e能力雷达图\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e能力维度\u003c/th\u003e\n\u003cth\u003e定义\u003c/th\u003e\n\u003cth\u003e初级要求\u003c/th\u003e\n\u003cth\u003e高级要求\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e技术深度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e对核心技术的原理级理解\u003c/td\u003e\n\u003ctd\u003e掌握主力技术栈源码\u003c/td\u003e\n\u003ctd\u003e能从原理推导解决方案\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e技术广度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e对多领域技术的了解\u003c/td\u003e\n\u003ctd\u003e熟悉 3+ 技术领域\u003c/td\u003e\n\u003ctd\u003e能做跨领域技术整合\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e抽象能力\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e从具象中提炼本质的能力\u003c/td\u003e\n\u003ctd\u003e能做模块抽象\u003c/td\u003e\n\u003ctd\u003e能做业务域建模\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e业务理解\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e对业务本质和商业逻辑的洞察\u003c/td\u003e\n\u003ctd\u003e理解业务流程\u003c/td\u003e\n\u003ctd\u003e能用技术语言翻译业务战略\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e系统思维\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e全局视角和权衡取舍的能力\u003c/td\u003e\n\u003ctd\u003e能做技术方案对比\u003c/td\u003e\n\u003ctd\u003e能在复杂约束下做最优决策\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e沟通影响\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e跨团队协调和技术布道的能力\u003c/td\u003e\n\u003ctd\u003e能清晰表达方案\u003c/td\u003e\n\u003ctd\u003e能影响组织技术方向\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e架构思维的三个核心\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e1. 抽象思维\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e抽象是架构师最重要的思维能力。抽象不是简单的\u0026quot;去掉细节\u0026quot;，而是\u003cstrong\u003e识别事物的本质特征，忽略非本质差异\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e具体问题: 订单超时未支付需要自动取消\n    ↓ 抽象\n通用问题: 延时任务调度\n    ↓ 进一步抽象\n核心模型: 时间驱动的状态机\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e好的抽象应该是\u003cstrong\u003e稳定的\u003c/strong\u003e——业务在变，但抽象出的模型不轻易变化。比如\u0026quot;购物车\u0026quot;的业务形态千差万别，但抽象到本质就是\u0026quot;临时容器 + 商品列表 + 计价规则\u0026quot;。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. 分解思维\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e复杂系统必须被分解才能被理解和管理。分解的关键是找到\u003cstrong\u003e正确的切面\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e分解方式\u003c/th\u003e\n\u003cth\u003e切面\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e水平分层\u003c/td\u003e\n\u003ctd\u003e职责层次\u003c/td\u003e\n\u003ctd\u003e展示层 / 业务层 / 数据层\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e垂直切分\u003c/td\u003e\n\u003ctd\u003e业务域\u003c/td\u003e\n\u003ctd\u003e按业务领域拆分微服务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e功能分解\u003c/td\u003e\n\u003ctd\u003e能力单元\u003c/td\u003e\n\u003ctd\u003e将系统拆分为可独立部署的功能模块\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e流程分解\u003c/td\u003e\n\u003ctd\u003e时间序列\u003c/td\u003e\n\u003ctd\u003e将长流程拆分为异步编排的子流程\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e3. 权衡思维\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e架构设计没有银弹，只有 Trade-off。架构师需要在以下维度中不断权衡：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e一致性 vs 可用性\u003c/strong\u003e（CAP 定理）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e性能 vs 可维护性\u003c/strong\u003e（内联 vs 抽象）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e灵活性 vs 复杂度\u003c/strong\u003e（配置化 vs 硬编码）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e当前成本 vs 未来成本\u003c/strong\u003e（快速交付 vs 技术债务）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e理想方案 vs 资源约束\u003c/strong\u003e（完美设计 vs 现实落地）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e架构师的价值不在于设计出最优方案，而在于在给定约束下设计出最合理的方案。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e架构设计三原则\u003c/h2\u003e\n\u003cp\u003e在做架构决策时，有三条根本性原则需要遵循：\u003c/p\u003e\n\u003ch3\u003e合适原则\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e合适优于先进。\u003c/strong\u003e 没有最好的架构，只有最合适的架构。\u003c/p\u003e\n\u003cp\u003e一个日活 1000 的内部管理系统不需要微服务架构；一个创业期产品不需要分布式事务框架。架构的选择必须匹配：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e业务阶段\u003c/strong\u003e：0→1 阶段优先快速验证，1→N 阶段优先可扩展性\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e团队能力\u003c/strong\u003e：团队驾驭不了的架构就是最差的架构\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e资源约束\u003c/strong\u003e：时间、人力、基础设施的现实限制\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e简单原则\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e简单优于复杂。\u003c/strong\u003e 如果两个方案能达到相同效果，选更简单的那个。\u003c/p\u003e\n\u003cp\u003e复杂度是软件系统的头号杀手。每引入一个组件、一层抽象、一种模式，都要问自己：\u003cstrong\u003e这个复杂度带来的收益，是否大于它引入的成本？\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e单体应用能解决的问题 → 不要用微服务\n本地缓存能解决的问题 → 不要用分布式缓存\n同步调用能解决的问题 → 不要用消息队列\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e演化原则\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e演化优于一步到位。\u003c/strong\u003e 架构不是一次性设计出来的，而是演化出来的。\u003c/p\u003e\n\u003cp\u003e优秀的架构师不会试图在第一天就设计出\u0026quot;完美架构\u0026quot;，而是：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e识别当前最关键的架构决策，做出合理选择\u003c/li\u003e\n\u003cli\u003e为未来的变化预留扩展点（而不是过度设计）\u003c/li\u003e\n\u003cli\u003e建立持续演进的机制（架构治理、技术债务管理）\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e技术知识体系全景\u003c/h2\u003e\n\u003cp\u003e架构师需要具备广泛而有深度的技术知识。以下是一个体系化的技术知识地图：\u003c/p\u003e\n\u003ch3\u003e编程基础与语言\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e领域\u003c/th\u003e\n\u003cth\u003e核心知识点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e数据结构与算法\u003c/td\u003e\n\u003ctd\u003e树、图、哈希、排序、动态规划、时间/空间复杂度分析\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e设计模式\u003c/td\u003e\n\u003ctd\u003e创建型、结构型、行为型模式；反模式识别\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e编程范式\u003c/td\u003e\n\u003ctd\u003eOOP、函数式编程、响应式编程\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eJVM 体系\u003c/td\u003e\n\u003ctd\u003e内存模型、GC 算法、类加载机制、JIT 编译、性能调优\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并发编程\u003c/td\u003e\n\u003ctd\u003e线程模型、锁机制、AQS、并发容器、线程池、协程\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e框架与中间件\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e领域\u003c/th\u003e\n\u003cth\u003e核心技术\u003c/th\u003e\n\u003cth\u003e需要理解的深度\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eWeb 框架\u003c/td\u003e\n\u003ctd\u003eSpring Boot / Spring MVC\u003c/td\u003e\n\u003ctd\u003eIoC 容器原理、AOP 实现、自动配置机制\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eORM 框架\u003c/td\u003e\n\u003ctd\u003eMyBatis / JPA\u003c/td\u003e\n\u003ctd\u003eSQL 映射原理、缓存机制、N+1 问题\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRPC 框架\u003c/td\u003e\n\u003ctd\u003eDubbo / gRPC\u003c/td\u003e\n\u003ctd\u003e序列化协议、服务发现、负载均衡策略\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e消息队列\u003c/td\u003e\n\u003ctd\u003eKafka / RocketMQ / RabbitMQ\u003c/td\u003e\n\u003ctd\u003e消息模型、持久化机制、顺序性保证、事务消息\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e缓存系统\u003c/td\u003e\n\u003ctd\u003eRedis / Caffeine\u003c/td\u003e\n\u003ctd\u003e数据结构、持久化、集群方案、缓存一致性\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e搜索引擎\u003c/td\u003e\n\u003ctd\u003eElasticsearch\u003c/td\u003e\n\u003ctd\u003e倒排索引、分词、相关性评分、集群管理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据库\u003c/td\u003e\n\u003ctd\u003eMySQL / PostgreSQL\u003c/td\u003e\n\u003ctd\u003e索引原理（B+ 树）、事务隔离级别、锁机制、主从复制\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e分布式与云原生\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e领域\u003c/th\u003e\n\u003cth\u003e核心知识点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e分布式理论\u003c/td\u003e\n\u003ctd\u003eCAP 定理、BASE 理论、FLP 不可能定理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一致性协议\u003c/td\u003e\n\u003ctd\u003ePaxos、Raft、ZAB、Gossip\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e分布式事务\u003c/td\u003e\n\u003ctd\u003e2PC、3PC、TCC、Saga、本地消息表\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e服务治理\u003c/td\u003e\n\u003ctd\u003e服务发现、负载均衡、熔断降级、限流、灰度发布\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e容器与编排\u003c/td\u003e\n\u003ctd\u003eDocker、Kubernetes、Service Mesh（Istio）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDevOps\u003c/td\u003e\n\u003ctd\u003eCI/CD、GitOps、IaC、可观测性（Metrics/Logging/Tracing）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e架构设计能力\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e领域\u003c/th\u003e\n\u003cth\u003e核心知识点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e架构模式\u003c/td\u003e\n\u003ctd\u003e分层架构、微服务、事件驱动、CQRS、六边形架构\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e高可用设计\u003c/td\u003e\n\u003ctd\u003e冗余、故障转移、限流降级、异地多活\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e高性能设计\u003c/td\u003e\n\u003ctd\u003e缓存策略、异步化、并行化、池化、零拷贝\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可扩展设计\u003c/td\u003e\n\u003ctd\u003e水平扩展、分库分表、读写分离、弹性伸缩\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e安全设计\u003c/td\u003e\n\u003ctd\u003e认证授权、数据加密、SQL 注入防御、OWASP Top 10\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e分布式系统核心理论\u003c/h2\u003e\n\u003cp\u003e分布式系统是现代架构的基石，理解其核心理论是架构师的必修课。\u003c/p\u003e\n\u003ch3\u003eCAP 定理\u003c/h3\u003e\n\u003cp\u003e分布式系统不可能同时满足以下三个特性：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eC（Consistency）一致性\u003c/strong\u003e：所有节点在同一时刻看到的数据一致\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eA（Availability）可用性\u003c/strong\u003e：每个请求都能收到非错误响应\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eP（Partition Tolerance）分区容错性\u003c/strong\u003e：网络分区时系统仍能继续运行\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e由于网络分区在分布式环境中不可避免，实际上的选择是在 \u003cstrong\u003eCP\u003c/strong\u003e 和 \u003cstrong\u003eAP\u003c/strong\u003e 之间做取舍：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e选择\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e典型场景\u003c/th\u003e\n\u003cth\u003e代表系统\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eCP\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e牺牲可用性保一致性\u003c/td\u003e\n\u003ctd\u003e金融交易、库存扣减\u003c/td\u003e\n\u003ctd\u003eZooKeeper、etcd、HBase\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAP\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e牺牲一致性保可用性\u003c/td\u003e\n\u003ctd\u003e商品展示、用户动态\u003c/td\u003e\n\u003ctd\u003eCassandra、DynamoDB、Eureka\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003eBASE 理论\u003c/h3\u003e\n\u003cp\u003eBASE 是对 CAP 中 AP 方案的延伸，是大规模互联网系统的实践指导：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBA（Basically Available）基本可用\u003c/strong\u003e：允许部分功能降级，保证核心功能可用\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eS（Soft State）软状态\u003c/strong\u003e：允许中间状态存在，不要求实时一致\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eE（Eventually Consistent）最终一致性\u003c/strong\u003e：经过一段时间后，数据最终达到一致\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e一致性协议\u003c/h3\u003e\n\u003cp\u003e分布式共识是解决多节点数据一致性的核心手段：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e协议\u003c/th\u003e\n\u003cth\u003e核心思想\u003c/th\u003e\n\u003cth\u003e复杂度\u003c/th\u003e\n\u003cth\u003e典型应用\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ePaxos\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e提案-承诺-接受三阶段\u003c/td\u003e\n\u003ctd\u003e高，难以工程实现\u003c/td\u003e\n\u003ctd\u003eGoogle Chubby\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRaft\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eLeader 选举 + 日志复制\u003c/td\u003e\n\u003ctd\u003e中，易于理解和实现\u003c/td\u003e\n\u003ctd\u003eetcd、Consul\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eZAB\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e崩溃恢复 + 消息广播\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003eZooKeeper\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eGossip\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e去中心化的信息传播\u003c/td\u003e\n\u003ctd\u003e低，最终一致\u003c/td\u003e\n\u003ctd\u003eRedis Cluster、Consul（成员管理）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e分布式事务\u003c/h3\u003e\n\u003cp\u003e跨服务的数据一致性是分布式系统最具挑战性的问题之一：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e方案\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e一致性\u003c/th\u003e\n\u003cth\u003e性能\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e2PC\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e准备-提交两阶段\u003c/td\u003e\n\u003ctd\u003e强一致\u003c/td\u003e\n\u003ctd\u003e低（同步阻塞）\u003c/td\u003e\n\u003ctd\u003e数据库层面的跨库事务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eTCC\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eTry-Confirm-Cancel\u003c/td\u003e\n\u003ctd\u003e强一致\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e资金类高一致性业务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSaga\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e正向操作 + 补偿操作\u003c/td\u003e\n\u003ctd\u003e最终一致\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e长流程业务编排\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e本地消息表\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e本地事务 + 异步消息\u003c/td\u003e\n\u003ctd\u003e最终一致\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e跨服务异步通知\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e事务消息\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e半消息 + 确认机制\u003c/td\u003e\n\u003ctd\u003e最终一致\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e基于 MQ 的数据同步\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e实践建议\u003c/strong\u003e：绝大多数业务场景不需要强一致性。优先考虑最终一致性方案（Saga、本地消息表），只有在资金、库存等核心场景才使用 TCC。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e架构演进：从单体到云原生\u003c/h2\u003e\n\u003cp\u003e架构不是一成不变的，它随着业务规模和技术发展不断演进。理解每个阶段的特征和驱动力，比记住具体方案更重要。\u003c/p\u003e\n\u003ch3\u003e演进路线\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e单体架构 → 垂直拆分 → SOA → 微服务 → 云原生 → Serverless\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e各阶段特征对比\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e阶段\u003c/th\u003e\n\u003cth\u003e核心特征\u003c/th\u003e\n\u003cth\u003e解决的问题\u003c/th\u003e\n\u003cth\u003e引入的问题\u003c/th\u003e\n\u003cth\u003e适用规模\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e单体架构\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e所有功能在一个进程\u003c/td\u003e\n\u003ctd\u003e开发部署简单\u003c/td\u003e\n\u003ctd\u003e扩展困难、技术栈锁定\u003c/td\u003e\n\u003ctd\u003e初创期、小团队\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e垂直拆分\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e按业务线拆分独立应用\u003c/td\u003e\n\u003ctd\u003e业务隔离、独立扩展\u003c/td\u003e\n\u003ctd\u003e公共功能重复、数据冗余\u003c/td\u003e\n\u003ctd\u003e多业务线\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSOA\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e服务化 + ESB 集中治理\u003c/td\u003e\n\u003ctd\u003e服务复用、统一治理\u003c/td\u003e\n\u003ctd\u003eESB 单点瓶颈、治理复杂\u003c/td\u003e\n\u003ctd\u003e中大型企业\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e微服务\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e细粒度服务 + 去中心化\u003c/td\u003e\n\u003ctd\u003e独立部署、技术异构\u003c/td\u003e\n\u003ctd\u003e运维复杂度、分布式事务\u003c/td\u003e\n\u003ctd\u003e大型互联网\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e云原生\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e容器化 + 编排 + 服务网格\u003c/td\u003e\n\u003ctd\u003e弹性伸缩、基础设施抽象\u003c/td\u003e\n\u003ctd\u003e技术栈门槛高、学习曲线陡\u003c/td\u003e\n\u003ctd\u003e规模化互联网\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eServerless\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e函数计算 + 事件驱动\u003c/td\u003e\n\u003ctd\u003e零运维、按需付费\u003c/td\u003e\n\u003ctd\u003e冷启动、厂商锁定\u003c/td\u003e\n\u003ctd\u003e事件驱动型业务\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e演进的驱动力\u003c/h3\u003e\n\u003cp\u003e架构演进不是为了追新，而是被以下力量推动的：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e业务复杂度增长\u003c/strong\u003e：单体无法承载越来越复杂的业务逻辑\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e团队规模扩大\u003c/strong\u003e：多团队并行开发需要服务边界隔离\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e流量规模变化\u003c/strong\u003e：从百级到亿级 QPS 需要不同的架构模式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e交付效率要求\u003c/strong\u003e：从月级发布到日级发布需要服务独立部署\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e技术生态成熟\u003c/strong\u003e：容器、服务网格等基础设施的成熟降低了架构升级的门槛\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e关键认知\u003c/strong\u003e：架构演进应该是业务驱动的、渐进式的。不要因为\u0026quot;微服务很火\u0026quot;就拆分单体，也不要因为\u0026quot;Kubernetes 很酷\u0026quot;就上云原生。每次架构升级都应该有明确的业务收益支撑。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e架构设计方法论\u003c/h2\u003e\n\u003cp\u003e光有知识储备还不够，架构师需要一套系统化的方法论来指导架构设计过程。\u003c/p\u003e\n\u003ch3\u003eTOGAF：企业架构框架\u003c/h3\u003e\n\u003cp\u003eTOGAF（The Open Group Architecture Framework）是最广泛采用的企业架构框架，其核心是 \u003cstrong\u003eADM（Architecture Development Method）\u003c/strong\u003e 架构开发方法：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e预备阶段 → 架构愿景 → 业务架构 → 信息系统架构 → 技术架构\n    → 机会和解决方案 → 迁移规划 → 实施治理 → 架构变更管理\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTOGAF 的核心价值在于提供了一套\u003cstrong\u003e从业务到技术的推导过程\u003c/strong\u003e，避免架构设计的随意性。\u003c/p\u003e\n\u003ch3\u003e架构设计的四步法\u003c/h3\u003e\n\u003cp\u003e在实际工作中，可以将架构设计简化为四个步骤：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e第一步：需求分析与约束识别\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e功能需求 → 系统需要做什么？\n质量需求 → 性能、可用性、安全性指标是什么？\n约束条件 → 时间、人力、技术栈、合规要求有哪些？\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e第二步：关键决策与方案选型\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e识别架构中的关键决策点（通常是那些一旦确定就难以更改的决策），然后对每个决策点做方案对比：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e决策点\u003c/th\u003e\n\u003cth\u003e方案 A\u003c/th\u003e\n\u003cth\u003e方案 B\u003c/th\u003e\n\u003cth\u003e选择依据\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e服务通信\u003c/td\u003e\n\u003ctd\u003eREST\u003c/td\u003e\n\u003ctd\u003egRPC\u003c/td\u003e\n\u003ctd\u003e内部服务间高频调用选 gRPC\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据存储\u003c/td\u003e\n\u003ctd\u003eMySQL\u003c/td\u003e\n\u003ctd\u003eMongoDB\u003c/td\u003e\n\u003ctd\u003e结构化数据 + 事务需求选 MySQL\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e消息队列\u003c/td\u003e\n\u003ctd\u003eKafka\u003c/td\u003e\n\u003ctd\u003eRocketMQ\u003c/td\u003e\n\u003ctd\u003e需要事务消息选 RocketMQ\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e第三步：架构方案设计\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e从全局到局部，分层输出架构方案：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e系统上下文图（C4 Level 1）：系统与外部的关系\u003c/li\u003e\n\u003cli\u003e容器图（C4 Level 2）：系统内部的主要构件\u003c/li\u003e\n\u003cli\u003e组件图（C4 Level 3）：关键服务的内部结构\u003c/li\u003e\n\u003cli\u003e关键流程的时序图\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e第四步：架构评审与验证\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e使用 \u003cstrong\u003eATAM（Architecture Tradeoff Analysis Method）\u003c/strong\u003e 对架构方案进行评审：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e识别架构中的风险点\u003c/li\u003e\n\u003cli\u003e验证方案是否满足质量属性需求\u003c/li\u003e\n\u003cli\u003e确认 Trade-off 是否被利益相关者接受\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e架构决策记录（ADR）\u003c/h3\u003e\n\u003cp\u003e每个重要的架构决策都应该被记录下来，格式可以采用 ADR：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# ADR-001: 采用事件驱动架构处理订单状态变更\n\n## 状态\n已采纳\n\n## 背景\n订单状态变更需要通知下游 10+ 个系统，同步调用导致耦合严重且响应时间过长。\n\n## 决策\n采用事件驱动架构，订单状态变更时发布领域事件，下游系统订阅事件自行处理。\n\n## 影响\n- 正面：服务解耦、响应时间降低、可扩展性增强\n- 负面：引入最终一致性、增加消息中间件运维成本、需要处理消息幂等\n\n## 备选方案\n1. 同步 HTTP 调用（被否：耦合度高、链路过长）\n2. 数据库轮询（被否：实时性差、数据库压力大）\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e高可用架构设计\u003c/h2\u003e\n\u003cp\u003e高可用是架构设计中最核心的质量属性之一。它的本质是\u003cstrong\u003e通过冗余和自动化来对抗故障的不确定性\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e可用性度量\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e可用性等级\u003c/th\u003e\n\u003cth\u003e年度不可用时间\u003c/th\u003e\n\u003cth\u003e典型场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e99%（2 个 9）\u003c/td\u003e\n\u003ctd\u003e3.65 天\u003c/td\u003e\n\u003ctd\u003e内部管理系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e99.9%（3 个 9）\u003c/td\u003e\n\u003ctd\u003e8.76 小时\u003c/td\u003e\n\u003ctd\u003e一般业务系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e99.99%（4 个 9）\u003c/td\u003e\n\u003ctd\u003e52.56 分钟\u003c/td\u003e\n\u003ctd\u003e核心交易系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e99.999%（5 个 9）\u003c/td\u003e\n\u003ctd\u003e5.26 分钟\u003c/td\u003e\n\u003ctd\u003e金融核心系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e高可用设计策略\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e冗余策略\u003c/strong\u003e：消除单点故障\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e单点             →  冗余方案\n单台应用服务器    →  集群 + 负载均衡\n单个数据库实例    →  主从复制 + 自动切换\n单个机房          →  同城双活 / 异地多活\n单个注册中心      →  集群部署 + 多节点\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e容错策略\u003c/strong\u003e：优雅应对局部故障\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e实现\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e超时控制\u003c/td\u003e\n\u003ctd\u003e避免无限等待\u003c/td\u003e\n\u003ctd\u003e设置合理的超时时间\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e重试机制\u003c/td\u003e\n\u003ctd\u003e应对瞬时故障\u003c/td\u003e\n\u003ctd\u003e指数退避 + 最大重试次数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e熔断器\u003c/td\u003e\n\u003ctd\u003e防止故障蔓延\u003c/td\u003e\n\u003ctd\u003eHystrix / Sentinel / Resilience4j\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e降级策略\u003c/td\u003e\n\u003ctd\u003e保核心弃非核心\u003c/td\u003e\n\u003ctd\u003e返回默认值、关闭非关键功能\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e限流控制\u003c/td\u003e\n\u003ctd\u003e保护系统容量\u003c/td\u003e\n\u003ctd\u003e令牌桶、滑动窗口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e隔离机制\u003c/td\u003e\n\u003ctd\u003e故障域隔离\u003c/td\u003e\n\u003ctd\u003e线程池隔离、信号量隔离、泳道隔离\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e发布策略\u003c/strong\u003e：变更是故障的主要来源\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e风险\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e蓝绿部署\u003c/td\u003e\n\u003ctd\u003e两套环境瞬间切换\u003c/td\u003e\n\u003ctd\u003e资源成本翻倍\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e滚动发布\u003c/td\u003e\n\u003ctd\u003e逐步替换旧实例\u003c/td\u003e\n\u003ctd\u003e新旧版本短暂共存\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e金丝雀发布\u003c/td\u003e\n\u003ctd\u003e小流量验证后全量\u003c/td\u003e\n\u003ctd\u003e需要流量分配能力\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eFeature Flag\u003c/td\u003e\n\u003ctd\u003e功能开关控制上线\u003c/td\u003e\n\u003ctd\u003e代码分支复杂度增加\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e高性能架构设计\u003c/h2\u003e\n\u003cp\u003e高性能不是\u0026quot;用最快的技术\u0026quot;，而是\u0026quot;在每个环节消除不必要的等待和浪费\u0026quot;。\u003c/p\u003e\n\u003ch3\u003e性能优化的分层思路\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户端 → CDN/静态资源优化 → 接入层(负载均衡/连接池)\n    → 应用层(缓存/异步/并行) → 数据层(索引/分库分表/读写分离)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e核心优化策略\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e典型实践\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e缓存\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e用空间换时间\u003c/td\u003e\n\u003ctd\u003e多级缓存（L1 本地 → L2 分布式 → DB）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e异步化\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e将串行变并行\u003c/td\u003e\n\u003ctd\u003e消息队列异步处理非关键路径\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e并行化\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e充分利用多核\u003c/td\u003e\n\u003ctd\u003eCompletableFuture 并行调用多个下游\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e池化\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e复用昂贵资源\u003c/td\u003e\n\u003ctd\u003e连接池、线程池、对象池\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e批量化\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e减少 I/O 次数\u003c/td\u003e\n\u003ctd\u003e批量查询、批量写入、Pipeline\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e预计算\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e提前计算结果\u003c/td\u003e\n\u003ctd\u003e离线计算报表、预生成推荐结果\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e压缩\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e减少传输量\u003c/td\u003e\n\u003ctd\u003eGzip 压缩、Protocol Buffers\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e缓存设计的三大问题\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e问题\u003c/th\u003e\n\u003cth\u003e描述\u003c/th\u003e\n\u003cth\u003e解决方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e缓存穿透\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e查询不存在的数据\u003c/td\u003e\n\u003ctd\u003e布隆过滤器、空值缓存\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e缓存击穿\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e热点 Key 过期瞬间\u003c/td\u003e\n\u003ctd\u003e互斥锁、永不过期 + 异步更新\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e缓存雪崩\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e大量 Key 同时过期\u003c/td\u003e\n\u003ctd\u003e过期时间加随机值、多级缓存\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e架构师的软实力\u003c/h2\u003e\n\u003cp\u003e技术能力是架构师的基础，但真正决定架构师高度的是软实力。\u003c/p\u003e\n\u003ch3\u003e决策能力：在不确定性中做选择\u003c/h3\u003e\n\u003cp\u003e架构决策往往发生在信息不完全的情况下。优秀的架构师需要：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e识别关键决策与次要决策\u003c/strong\u003e：不是每个技术选择都需要深度分析，把精力放在不可逆的关键决策上\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e设定决策框架\u003c/strong\u003e：明确评估维度和权重，避免拍脑袋决策\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e接受\u0026quot;足够好\u0026quot;而非\u0026quot;最优\u0026quot;\u003c/strong\u003e：在时间压力下，80% 的正确比 100% 的犹豫更有价值\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e沟通能力：让技术方案\u0026quot;被买单\u0026quot;\u003c/h3\u003e\n\u003cp\u003e架构师的方案再好，如果不能被团队理解和接受，就等于零。有效的技术沟通需要：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e面向不同听众调整表达\u003c/strong\u003e：给 CEO 讲业务价值，给研发讲技术方案，给运维讲部署方案\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e用图说话\u003c/strong\u003e：一张好的架构图胜过千字描述\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e讲清\u0026quot;为什么不选 B\u0026quot;\u003c/strong\u003e：决策的说服力不在于方案 A 有多好，而在于你对备选方案的分析有多透彻\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e平衡能力：在理想与现实之间\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e理想主义\u003c/th\u003e\n\u003cth\u003e务实主义\u003c/th\u003e\n\u003cth\u003e平衡点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e代码质量\u003c/td\u003e\n\u003ctd\u003e完美的代码\u003c/td\u003e\n\u003ctd\u003e能跑就行\u003c/td\u003e\n\u003ctd\u003e核心模块高质量，边缘模块可接受\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e技术债务\u003c/td\u003e\n\u003ctd\u003e零债务\u003c/td\u003e\n\u003ctd\u003e先上线\u003c/td\u003e\n\u003ctd\u003e有计划地管理技术债务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e架构设计\u003c/td\u003e\n\u003ctd\u003e一步到位\u003c/td\u003e\n\u003ctd\u003e走一步算一步\u003c/td\u003e\n\u003ctd\u003e关键决策前瞻设计 + 渐进演化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e新技术\u003c/td\u003e\n\u003ctd\u003e全面拥抱\u003c/td\u003e\n\u003ctd\u003e保守不动\u003c/td\u003e\n\u003ctd\u003e在非核心场景试点验证\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e架构师成长路径\u003c/h2\u003e\n\u003ch3\u003e成长阶段\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e初级开发 → 高级开发 → 技术主管 → 架构师 → 首席架构师/CTO\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e每个阶段的核心差异在于\u003cstrong\u003e视野的宽度和决策的影响范围\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e阶段\u003c/th\u003e\n\u003cth\u003e关注范围\u003c/th\u003e\n\u003cth\u003e核心能力\u003c/th\u003e\n\u003cth\u003e时间分配\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e初级开发\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单个功能模块\u003c/td\u003e\n\u003ctd\u003e编码能力、调试能力\u003c/td\u003e\n\u003ctd\u003e80% 编码 + 20% 设计\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e高级开发\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单个系统/服务\u003c/td\u003e\n\u003ctd\u003e系统设计、性能优化\u003c/td\u003e\n\u003ctd\u003e60% 编码 + 40% 设计\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e技术主管\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e多个系统/团队\u003c/td\u003e\n\u003ctd\u003e技术决策、团队管理\u003c/td\u003e\n\u003ctd\u003e30% 编码 + 50% 设计 + 20% 管理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e架构师\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e技术体系全局\u003c/td\u003e\n\u003ctd\u003e架构设计、技术战略\u003c/td\u003e\n\u003ctd\u003e10% 编码 + 60% 设计 + 30% 沟通\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e首席架构师\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e技术 + 业务全局\u003c/td\u003e\n\u003ctd\u003e技术愿景、组织影响\u003c/td\u003e\n\u003ctd\u003e70% 战略 + 30% 关键问题攻坚\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e从开发到架构师的关键跨越\u003c/h3\u003e\n\u003cp\u003e很多优秀的开发者在向架构师转型时会遇到瓶颈。核心原因在于需要完成三个关键跨越：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e跨越一：从\u0026quot;怎么做\u0026quot;到\u0026quot;做不做\u0026quot;\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e开发者关注的是\u0026quot;如何实现一个功能\u0026quot;，架构师关注的是\u0026quot;这个功能应不应该做，用什么方式做最合理\u0026quot;。这是从执行思维到决策思维的跨越。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e跨越二：从\u0026quot;局部最优\u0026quot;到\u0026quot;全局最优\u0026quot;\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e开发者追求单个模块的代码质量，架构师追求整个系统的平衡。有时候某个模块的\u0026quot;不完美\u0026quot;恰恰是全局最优的选择。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e跨越三：从\u0026quot;技术驱动\u0026quot;到\u0026quot;业务驱动\u0026quot;\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e开发者用技术解决问题，架构师用技术创造业务价值。如果不理解业务，就无法做出正确的架构决策。\u003c/p\u003e\n\u003ch3\u003e持续成长的方法\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e深度学习\u003c/strong\u003e：选 2-3 个核心技术领域，深入到源码级别理解\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e广度拓展\u003c/strong\u003e：关注技术趋势，了解不同领域的架构模式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e实践总结\u003c/strong\u003e：每个项目结束后做架构复盘，记录 ADR\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e输出分享\u003c/strong\u003e：写技术博客、做技术分享，输出倒逼输入\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e跨界学习\u003c/strong\u003e：了解业务、产品、运营，建立全局视角\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e总结\u003c/h2\u003e\n\u003cp\u003e架构师的成长是一条从\u0026quot;技术专精\u0026quot;到\u0026quot;架构思维\u0026quot;的蜕变之路。这条路上有几个核心认知需要建立：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e架构是决策，不是画图\u003c/strong\u003e。架构师的核心价值在于在复杂约束条件下做出合理的技术决策\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e业务是根基，技术是手段\u003c/strong\u003e。脱离业务的架构设计没有意义，技术选型必须服务于业务目标\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e简单是终极的复杂\u003c/strong\u003e。能用简单方案解决的问题，不要用复杂方案；能不引入的组件，就不引入\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e演化优于完美\u003c/strong\u003e。不要追求一步到位的架构设计，建立持续演进的能力比设计完美的架构更重要\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTrade-off 是永恒的主题\u003c/strong\u003e。没有银弹，只有在给定约束下的最佳平衡\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e一个架构师的成熟度，不在于他掌握了多少种技术，而在于他知道什么时候不该用某种技术。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"19:Tc7d3,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eThe Agent Control Loop: Agent 运行时的核心抽象\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e如果说 LLM 是 Agent 的大脑，那么 Control Loop 就是 Agent 的心跳。\u003c/p\u003e\n\u003cp\u003e大多数教程在讲 Agent 时，上来就接框架、调 API、跑 demo。但如果你不理解 Agent 运行时的核心抽象——控制循环——你永远只是在用别人的黑盒。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 04 篇，整个系列的技术基石。我们会从状态机模型出发，逐层拆解 Agent Control Loop 的每一个阶段，给出完整的 Python 实现，并深入分析实际工程中的 trade-off。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. Agent 的本质：可中断的控制循环\u003c/h2\u003e\n\u003cp\u003e一个常见的误解是把 Agent 等同于\u0026quot;一次 LLM 调用\u0026quot;。实际上，Agent 和 LLM 的关系，类似于操作系统和 CPU 的关系——LLM 是执行推理的计算单元，而 Agent 是管理整个执行生命周期的运行时系统。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLLM 是一个函数：\u003c/strong\u003e \u003ccode\u003ef(prompt) -\u0026gt; completion\u003c/code\u003e，输入文本，输出文本，调用一次就结束。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAgent 是一个循环：\u003c/strong\u003e 它持续运行，在每一轮中观察环境、调用 LLM 进行推理、执行动作、评估结果，然后决定是否继续。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eLLM:    Input ──→ Output            (一次调用)\n\nAgent:  Input ──→ [Observe → Think → Act → Reflect] ──→ ... ──→ Output\n                  └──────── 循环 N 次 ────────────┘     (多轮控制)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这个循环有几个关键特性：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e可中断\u003c/strong\u003e：循环可以在任何阶段暂停，等待外部输入（用户确认、异步工具返回）后恢复\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有状态\u003c/strong\u003e：循环维护上下文信息，每一轮的输出影响下一轮的输入\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e有终止条件\u003c/strong\u003e：循环不会无限运行，它在满足特定条件时停止\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可观测\u003c/strong\u003e：循环的每一步都应该是可追踪、可回溯的\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e理解了这一点，Agent 编程的核心问题就变成了：\u003cstrong\u003e如何设计和实现这个控制循环？\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 状态机模型：形式化定义\u003c/h2\u003e\n\u003cp\u003e要严谨地描述 Control Loop，最自然的方式是用\u003cstrong\u003e有限状态机（FSM）\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e2.1 状态定义\u003c/h3\u003e\n\u003cp\u003e一个 Agent Control Loop 可以用以下状态集合描述：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom enum import Enum\n\nclass AgentState(Enum):\n    OBSERVE  = \u0026quot;observe\u0026quot;   # 接收并归一化输入\n    THINK    = \u0026quot;think\u0026quot;     # LLM 推理，决定下一步行动\n    ACT      = \u0026quot;act\u0026quot;       # 执行工具调用或产出结果\n    REFLECT  = \u0026quot;reflect\u0026quot;   # 评估执行结果，决定是否继续\n    DONE     = \u0026quot;done\u0026quot;      # 终止：任务完成\n    ERROR    = \u0026quot;error\u0026quot;     # 终止：不可恢复错误\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.2 状态转移图\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌─────────────────────────────────────────┐\n                    │                                         │\n                    ▼                                         │\n              ┌──────────┐                                    │\n   Input ───→│ OBSERVE  │                                    │\n              └────┬─────┘                                    │\n                   │                                         │\n                   ▼                                         │\n              ┌──────────┐    need_action    ┌──────────┐    │\n              │  THINK   │ ───────────────→ │   ACT    │    │\n              └────┬─────┘                   └────┬─────┘    │\n                   │                              │          │\n                   │ has_answer                   │          │\n                   │                              ▼          │\n                   │                        ┌──────────┐     │\n                   │                        │ REFLECT  │ ────┘\n                   │                        └────┬─────┘  continue\n                   │                             │\n                   ▼                             ▼\n              ┌──────────┐                  ┌──────────┐\n              │   DONE   │                  │  ERROR   │\n              └──────────┘                  └──────────┘\n                                       (max_retries exceeded\n                                        / unrecoverable)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e状态转移规则：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e当前状态\u003c/th\u003e\n\u003cth\u003e条件\u003c/th\u003e\n\u003cth\u003e下一状态\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eOBSERVE\u003c/td\u003e\n\u003ctd\u003e输入就绪\u003c/td\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003ctd\u003eLLM 返回 tool_call\u003c/td\u003e\n\u003ctd\u003eACT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003ctd\u003eLLM 返回最终回答\u003c/td\u003e\n\u003ctd\u003eDONE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTHINK\u003c/td\u003e\n\u003ctd\u003eLLM 调用异常\u003c/td\u003e\n\u003ctd\u003eERROR\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eACT\u003c/td\u003e\n\u003ctd\u003e工具执行完成\u003c/td\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eACT\u003c/td\u003e\n\u003ctd\u003e工具执行失败\u003c/td\u003e\n\u003ctd\u003eREFLECT (带错误信息)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003ctd\u003e需要继续\u003c/td\u003e\n\u003ctd\u003eOBSERVE (将结果作为新输入)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003ctd\u003e任务完成\u003c/td\u003e\n\u003ctd\u003eDONE\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eREFLECT\u003c/td\u003e\n\u003ctd\u003e超过重试上限\u003c/td\u003e\n\u003ctd\u003eERROR\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e2.3 与 OODA Loop 的对比\u003c/h3\u003e\n\u003cp\u003eAgent Control Loop 并不是凭空发明的，它和军事决策理论中的 \u003cstrong\u003eOODA Loop（Observe-Orient-Decide-Act）\u003c/strong\u003e 有深层的结构对应：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eOODA Loop:          Agent Control Loop:\n┌─────────┐         ┌─────────┐\n│ Observe │ ──────→ │ OBSERVE │  感知环境\n├─────────┤         ├─────────┤\n│ Orient  │ ──────→ │ THINK   │  理解上下文，形成判断\n├─────────┤         │         │\n│ Decide  │ ──────→ │         │  (LLM 在 THINK 中同时完成 Orient+Decide)\n├─────────┤         ├─────────┤\n│  Act    │ ──────→ │  ACT    │  执行行动\n└─────────┘         ├─────────┤\n                    │ REFLECT │  OODA 中没有显式的反思阶段\n                    └─────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键区别在于 \u003cstrong\u003eREFLECT 阶段\u003c/strong\u003e。传统 OODA Loop 假设决策者能实时感知行动效果并自然融入下一轮 Observe。但 LLM Agent 不具备这种连续感知能力——它需要一个显式的反思步骤来评估工具返回值、判断是否需要修正。这是 Agent Control Loop 相对于经典决策循环的重要改进。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. 循环中每个阶段的深入分析\u003c/h2\u003e\n\u003ch3\u003e3.1 OBSERVE：输入归一化\u003c/h3\u003e\n\u003cp\u003eOBSERVE 阶段的职责是\u003cstrong\u003e收集并归一化各种来源的输入\u003c/strong\u003e，将它们统一为 LLM 可理解的格式。\u003c/p\u003e\n\u003cp\u003e输入来源远不止\u0026quot;用户消息\u0026quot;一种：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e输入来源                    归一化后\n┌─────────────────┐       ┌──────────────────────┐\n│ 用户消息         │ ────→ │ {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,     │\n│ 工具返回值       │ ────→ │  \u0026quot;content\u0026quot;: \u0026quot;...\u0026quot;}   │\n│ 系统事件         │ ────→ │                      │\n│ 定时触发         │ ────→ │ {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,   │\n│ 外部 Webhook    │ ────→ │  \u0026quot;content\u0026quot;: \u0026quot;...\u0026quot;}   │\n│ 上一轮反思结果   │ ────→ │                      │\n└─────────────────┘       └──────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e输入归一化的核心原则：\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e所有输入都必须序列化为 message 格式\u003c/strong\u003e。不管来源是什么，最终都要变成 \u003ccode\u003e{\u0026quot;role\u0026quot;: ..., \u0026quot;content\u0026quot;: ...}\u003c/code\u003e 的形式，因为 LLM 只理解 message 序列。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e工具返回值需要结构化包装\u003c/strong\u003e。不要直接把原始 JSON 甩给 LLM，要附上工具名称、执行状态和必要的摘要信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e输入需要截断和优先级排序\u003c/strong\u003e。当多个输入同时到达时，需要决定哪些放进当前轮次的 Context Window，哪些缓存到下一轮。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef observe(self, raw_inputs: list[dict]) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;将原始输入归一化为 LLM message 格式\u0026quot;\u0026quot;\u0026quot;\n    messages = []\n    for inp in raw_inputs:\n        match inp[\u0026quot;type\u0026quot;]:\n            case \u0026quot;user_message\u0026quot;:\n                messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: inp[\u0026quot;text\u0026quot;]})\n            case \u0026quot;tool_result\u0026quot;:\n                messages.append({\n                    \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                    \u0026quot;tool_call_id\u0026quot;: inp[\u0026quot;call_id\u0026quot;],\n                    \u0026quot;content\u0026quot;: self._format_tool_result(inp),\n                })\n            case \u0026quot;system_event\u0026quot;:\n                messages.append({\n                    \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                    \u0026quot;content\u0026quot;: f\u0026quot;[System Event] {inp[\u0026#39;event\u0026#39;]}\u0026quot;,\n                })\n    return messages\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.2 THINK：LLM 推理\u003c/h3\u003e\n\u003cp\u003eTHINK 阶段是控制循环中最核心的一环——调用 LLM，让它基于当前上下文做出决策。\u003c/p\u003e\n\u003cp\u003e这个阶段要解决三个问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题一：Context Window 构建\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLLM 的输入不是当前轮次的消息，而是\u003cstrong\u003e从任务开始到现在的完整上下文\u003c/strong\u003e。构建 Context Window 的典型结构：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────┐\n│ System Prompt                               │  固定不变\n│ (角色定义 + 能力边界 + 输出格式要求)           │\n├─────────────────────────────────────────────┤\n│ Tool Definitions                            │  固定不变\n│ (可用工具的 JSON Schema 定义)                │\n├─────────────────────────────────────────────┤\n│ Message History                             │  随轮次增长\n│ (user → assistant → tool → assistant → ...) │\n├─────────────────────────────────────────────┤\n│ Current Turn Input                          │  当前轮次\n│ (本轮 OBSERVE 阶段归一化的输入)              │\n└─────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e问题二：Token 预算控制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eContext Window 有上限（4K / 8K / 128K / 200K），而每一轮循环都会增加 message history。如果不加控制，几轮之后就会超限。\u003c/p\u003e\n\u003cp\u003e常见的预算控制策略：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e实现方式\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e硬截断\u003c/td\u003e\n\u003ctd\u003e只保留最近 N 条消息\u003c/td\u003e\n\u003ctd\u003e简单场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e滑动窗口\u003c/td\u003e\n\u003ctd\u003eSystem Prompt 固定 + 最近 K 轮对话\u003c/td\u003e\n\u003ctd\u003e工具调用场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e摘要压缩\u003c/td\u003e\n\u003ctd\u003e将早期对话用 LLM 生成摘要后替换\u003c/td\u003e\n\u003ctd\u003e长对话场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e优先级保留\u003c/td\u003e\n\u003ctd\u003e按消息重要性排序，低优先级先丢弃\u003c/td\u003e\n\u003ctd\u003e复杂多步任务\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _build_context(self, new_messages: list[dict]) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;构建符合 Token 预算的 Context Window\u0026quot;\u0026quot;\u0026quot;\n    self.message_history.extend(new_messages)\n\n    context = [self.system_prompt] + self.tool_definitions\n    remaining_budget = self.max_tokens - self._count_tokens(context)\n\n    # 从最新消息开始向前填充，直到预算耗尽\n    selected = []\n    for msg in reversed(self.message_history):\n        msg_tokens = self._count_tokens([msg])\n        if msg_tokens \u0026gt; remaining_budget:\n            break\n        selected.insert(0, msg)\n        remaining_budget -= msg_tokens\n\n    return context + selected\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e问题三：LLM 输出解析\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLLM 的返回可能是纯文本回答（任务完成），也可能是工具调用请求。需要根据返回类型决定下一步状态转移：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef think(self, context: list[dict]) -\u0026gt; ThinkResult:\n    \u0026quot;\u0026quot;\u0026quot;调用 LLM 进行推理\u0026quot;\u0026quot;\u0026quot;\n    response = self.client.chat.completions.create(\n        model=self.model,\n        messages=context,\n        tools=self.tool_schemas,\n    )\n    choice = response.choices[0]\n\n    if choice.finish_reason == \u0026quot;tool_calls\u0026quot;:\n        return ThinkResult(\n            action=\u0026quot;tool_call\u0026quot;,\n            tool_calls=choice.message.tool_calls,\n            raw_message=choice.message,\n        )\n    else:\n        return ThinkResult(\n            action=\u0026quot;answer\u0026quot;,\n            content=choice.message.content,\n            raw_message=choice.message,\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.3 ACT：执行层\u003c/h3\u003e\n\u003cp\u003eACT 阶段负责\u003cstrong\u003e执行 THINK 阶段决定的动作\u003c/strong\u003e——通常是调用工具（Tool Calling）。\u003c/p\u003e\n\u003cp\u003e执行层的核心挑战不是\u0026quot;调用工具\u0026quot;本身，而是以下几个工程问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e同步 vs 异步执行\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e同步执行（Simple）：\n  think → call_tool_1 → wait → call_tool_2 → wait → reflect\n  延迟 = T1 + T2\n\n异步 / 并行执行（Optimized）：\n  think → call_tool_1 ─┬─→ reflect\n        → call_tool_2 ─┘\n  延迟 = max(T1, T2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e当 LLM 在一次返回中请求多个工具调用（parallel tool calling）时，应该并行执行以降低延迟：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport asyncio\n\nasync def act(self, tool_calls: list[ToolCall]) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;并行执行多个工具调用\u0026quot;\u0026quot;\u0026quot;\n    tasks = [self._execute_tool(tc) for tc in tool_calls]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    tool_results = []\n    for tc, result in zip(tool_calls, results):\n        if isinstance(result, Exception):\n            tool_results.append({\n                \u0026quot;type\u0026quot;: \u0026quot;tool_result\u0026quot;,\n                \u0026quot;call_id\u0026quot;: tc.id,\n                \u0026quot;status\u0026quot;: \u0026quot;error\u0026quot;,\n                \u0026quot;content\u0026quot;: f\u0026quot;Tool \u0026#39;{tc.function.name}\u0026#39; failed: {result}\u0026quot;,\n            })\n        else:\n            tool_results.append({\n                \u0026quot;type\u0026quot;: \u0026quot;tool_result\u0026quot;,\n                \u0026quot;call_id\u0026quot;: tc.id,\n                \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;,\n                \u0026quot;content\u0026quot;: str(result),\n            })\n    return tool_results\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e执行安全\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e工具执行不是无条件信任的。需要考虑：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e超时控制\u003c/strong\u003e：每个工具调用必须有 timeout，防止阻塞整个循环\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e结果大小限制\u003c/strong\u003e：工具返回值可能非常大（比如查数据库返回 10 万行），需要截断\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e权限校验\u003c/strong\u003e：某些工具（文件写入、网络请求、代码执行）需要额外的权限检查\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e沙箱执行\u003c/strong\u003e：代码执行类工具应该在沙箱中运行\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.4 REFLECT：输出质量评估\u003c/h3\u003e\n\u003cp\u003eREFLECT 阶段回答一个关键问题：\u003cstrong\u003e上一步的执行结果是否满意？是继续、重试还是停止？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这个阶段有两种实现方式：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方式一：隐式反思——让 LLM 在下一轮 THINK 中自行判断\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是最简单的方式。把工具返回值直接送进下一轮 THINK，让 LLM 自己决定是否需要修正。大多数框架（如 OpenAI Assistants API）默认采用这种方式。\u003c/p\u003e\n\u003cp\u003e优点：实现简单，不增加额外的 LLM 调用。\u003c/p\u003e\n\u003cp\u003e缺点：LLM 可能\u0026quot;自信地\u0026quot;忽略错误，特别是在返回值看起来合理但语义错误的情况下。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e方式二：显式反思——用独立的 LLM 调用进行自我评估\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef reflect(self, action_result: dict, task_goal: str) -\u0026gt; ReflectResult:\n    \u0026quot;\u0026quot;\u0026quot;显式反思：评估执行结果\u0026quot;\u0026quot;\u0026quot;\n    prompt = f\u0026quot;\u0026quot;\u0026quot;评估以下工具执行结果是否达成了任务目标。\n\n任务目标: {task_goal}\n执行结果: {json.dumps(action_result, ensure_ascii=False)}\n\n请回答：\n1. 结果是否正确？(yes/no)\n2. 是否需要进一步行动？(yes/no)\n3. 如果需要，下一步应该做什么？\n\u0026quot;\u0026quot;\u0026quot;\n    response = self.client.chat.completions.create(\n        model=self.model,\n        messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: prompt}],\n    )\n    # 解析反思结果...\n    return ReflectResult(\n        is_correct=...,\n        needs_more_action=...,\n        next_step_hint=...,\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off 分析：\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e隐式反思\u003c/th\u003e\n\u003cth\u003e显式反思\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eToken 消耗\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e高（额外一次 LLM 调用）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e质量把控\u003c/td\u003e\n\u003ctd\u003e依赖 LLM 自觉\u003c/td\u003e\n\u003ctd\u003e有独立的质量评估\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e延迟\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e增加一轮 LLM 延迟\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用场景\u003c/td\u003e\n\u003ctd\u003e简单工具调用\u003c/td\u003e\n\u003ctd\u003e复杂推理链、高准确性要求\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e实际工程中，常用的折中方案是：\u003cstrong\u003e对关键步骤用显式反思，对常规步骤用隐式反思\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e3.5 终止条件：什么时候停下来？\u003c/h3\u003e\n\u003cp\u003e一个 Agent 如果不知道什么时候停，就是一个烧钱的死循环。终止条件的设计是 Control Loop 中最容易被忽视、但对生产环境最重要的部分。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef should_stop(self, state: LoopState) -\u0026gt; tuple[bool, str]:\n    \u0026quot;\u0026quot;\u0026quot;判断是否应该终止循环\u0026quot;\u0026quot;\u0026quot;\n    # 1. LLM 认为任务完成\n    if state.last_think_result.action == \u0026quot;answer\u0026quot;:\n        return True, \u0026quot;task_completed\u0026quot;\n\n    # 2. 达到最大轮次\n    if state.turn_count \u0026gt;= self.max_turns:\n        return True, \u0026quot;max_turns_exceeded\u0026quot;\n\n    # 3. Token 预算耗尽\n    if state.total_tokens \u0026gt;= self.token_budget:\n        return True, \u0026quot;token_budget_exceeded\u0026quot;\n\n    # 4. 连续错误过多\n    if state.consecutive_errors \u0026gt;= self.max_consecutive_errors:\n        return True, \u0026quot;too_many_errors\u0026quot;\n\n    # 5. 死循环检测（重复输出相同内容）\n    if self._detect_loop(state.recent_outputs):\n        return True, \u0026quot;loop_detected\u0026quot;\n\n    return False, \u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e各终止条件的设计考量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003emax_turns\u003c/strong\u003e：硬上限，防止失控。一般设 10-30 轮。过小会导致复杂任务被截断，过大会导致 Token 浪费\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003etoken_budget\u003c/strong\u003e：成本控制。根据业务场景设定每次交互的 Token 上限\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003econsecutive_errors\u003c/strong\u003e：容错阈值。工具偶尔失败是正常的，但连续 3 次以上通常意味着系统性问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eloop_detected\u003c/strong\u003e：死循环检测。如果 Agent 连续 N 轮输出相同或高度相似的内容，说明它陷入了无效循环\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e4. 两种主流 Loop 模式对比\u003c/h2\u003e\n\u003ch3\u003e4.1 ReAct 模式\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eReAct（Reason + Act）\u003c/strong\u003e 是目前最主流的 Agent Loop 模式，由 Yao et al. 2022 提出。其核心思想是让 LLM 交替进行推理和行动：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────┐\n│                   ReAct Loop                         │\n│                                                      │\n│  ┌─────────┐    ┌─────────┐    ┌─────────────────┐  │\n│  │ Thought │ →  │ Action  │ →  │  Observation    │  │\n│  │(LLM推理)│    │(工具调用)│    │(工具返回值)      │  │\n│  └─────────┘    └─────────┘    └────────┬────────┘  │\n│       ▲                                  │          │\n│       └──────────────────────────────────┘          │\n│                  循环直到完成                         │\n└──────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e一个典型的 ReAct 执行轨迹（Trace）：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eThought: 用户想知道北京今天的天气。我需要调用天气 API。\nAction:  get_weather(city=\u0026quot;北京\u0026quot;)\nObservation: {\u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;, \u0026quot;humidity\u0026quot;: 45}\n\nThought: 已经获取到天气数据，我可以直接回答用户。\nAnswer:  北京今天晴天，气温 28°C，湿度 45%。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eReAct 的优势：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每一步都基于最新的观察结果做决策，\u003cstrong\u003e适应性强\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eThought 过程可见，\u003cstrong\u003e可解释性好\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e实现简单，与 Tool Calling API 天然契合\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eReAct 的劣势：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e逐步决策，无法全局优化执行顺序\u003c/li\u003e\n\u003cli\u003e每一步都需要一次 LLM 调用，\u003cstrong\u003e延迟累积\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e对于需要协调多个子任务的复杂场景，容易陷入局部最优\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.2 Plan-then-Execute 模式\u003c/h3\u003e\n\u003cp\u003e与 ReAct 的\u0026quot;走一步看一步\u0026quot;不同，Plan-then-Execute 先生成一个\u003cstrong\u003e完整的执行计划\u003c/strong\u003e，然后按计划依次执行：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌──────────────────────────────────────────────────────────┐\n│              Plan-then-Execute Loop                       │\n│                                                          │\n│  ┌──────────────────────────────────────┐                │\n│  │           Planning Phase             │                │\n│  │  Input → LLM → [Step1, Step2, ...]   │                │\n│  └───────────────┬──────────────────────┘                │\n│                  │                                        │\n│                  ▼                                        │\n│  ┌──────────────────────────────────────┐                │\n│  │         Execution Phase              │                │\n│  │  Step1 → Execute → Result1           │                │\n│  │  Step2 → Execute → Result2           │                │\n│  │  ...                                 │                │\n│  └───────────────┬──────────────────────┘                │\n│                  │                                        │\n│                  ▼                                        │\n│  ┌──────────────────────────────────────┐                │\n│  │    Replan (if needed)                │                │\n│  │  检查是否需要调整计划                   │                │\n│  └──────────────────────────────────────┘                │\n└──────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e执行轨迹示例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePlan:\n  1. 查询北京天气\n  2. 查询上海天气\n  3. 对比两地天气差异\n  4. 生成出行建议\n\nExecute Step 1: get_weather(city=\u0026quot;北京\u0026quot;) → {\u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;}\nExecute Step 2: get_weather(city=\u0026quot;上海\u0026quot;) → {\u0026quot;temp\u0026quot;: 32, \u0026quot;condition\u0026quot;: \u0026quot;多云\u0026quot;}\nExecute Step 3: (LLM 对比分析)\nExecute Step 4: (LLM 生成建议)\n\nAnswer: ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.3 Trade-off 分析\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                        灵活性\n                          ▲\n                          │\n                 ReAct ●  │\n                          │\n                          │        ● Hybrid\n                          │          (ReAct + Plan)\n                          │\n              Plan-then   │\n              -Execute ●  │\n                          │\n                          └──────────────────→ 效率\n                                          (LLM 调用次数)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eReAct\u003c/th\u003e\n\u003cth\u003ePlan-then-Execute\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e灵活性\u003c/td\u003e\n\u003ctd\u003e高。每步实时调整\u003c/td\u003e\n\u003ctd\u003e低。偏离计划时需要 Replan\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLLM 调用次数\u003c/td\u003e\n\u003ctd\u003e多（每步一次推理）\u003c/td\u003e\n\u003ctd\u003e少（规划一次 + 执行时可能不需要 LLM）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可控性\u003c/td\u003e\n\u003ctd\u003e低。难以预测执行路径\u003c/td\u003e\n\u003ctd\u003e高。计划可审核、可修改\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适合场景\u003c/td\u003e\n\u003ctd\u003e工具调用为主、步骤不确定\u003c/td\u003e\n\u003ctd\u003e多步骤、有依赖关系、需要全局协调\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e错误恢复\u003c/td\u003e\n\u003ctd\u003e自然。下一步可以直接修正\u003c/td\u003e\n\u003ctd\u003e需要 Replan 机制\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e人类干预\u003c/td\u003e\n\u003ctd\u003e难以在中途插入\u003c/td\u003e\n\u003ctd\u003e容易。可以审核和修改计划\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e实际工程建议：\u003c/strong\u003e 大多数场景从 ReAct 开始。当你发现 Agent 频繁在多步任务中\u0026quot;迷路\u0026quot;或做出低效的工具调用序列时，再考虑引入 Plan-then-Execute 或混合模式。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 状态管理\u003c/h2\u003e\n\u003cp\u003eControl Loop 的状态管理决定了 Agent 的\u003cstrong\u003e持久性\u003c/strong\u003e和\u003cstrong\u003e可恢复性\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e5.1 Stateless Agent\u003c/h3\u003e\n\u003cp\u003eStateless Agent 不维护执行状态，所有上下文通过 \u003cstrong\u003emessage history\u003c/strong\u003e 传递。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eRequest 1:  [system, user_msg_1]                     → response_1\nRequest 2:  [system, user_msg_1, response_1, user_2] → response_2\nRequest 3:  [system, user_msg_1, response_1, user_2, response_2, user_3] → response_3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e特点：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e实现最简单，无需持久化\u003c/li\u003e\n\u003cli\u003e每次请求都是自包含的\u003c/li\u003e\n\u003cli\u003emessage history 不断膨胀，最终超过 Context Window\u003c/li\u003e\n\u003cli\u003e不支持暂停/恢复\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这是大多数 \u0026quot;chat completion\u0026quot; 应用的工作方式。适合单轮或短对话场景。\u003c/p\u003e\n\u003ch3\u003e5.2 Stateful Agent\u003c/h3\u003e\n\u003cp\u003eStateful Agent 维护一个独立的 \u003cstrong\u003eexecution state\u003c/strong\u003e，它不仅包含 message history，还包含任务进度、中间结果、工具状态等信息。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ExecutionState:\n    \u0026quot;\u0026quot;\u0026quot;Agent 执行状态\u0026quot;\u0026quot;\u0026quot;\n    session_id: str\n    status: AgentState\n    turn_count: int\n    message_history: list[dict]\n\n    # 任务状态\n    task_goal: str\n    current_plan: list[str] | None\n    completed_steps: list[str]\n\n    # 资源消耗\n    total_input_tokens: int\n    total_output_tokens: int\n\n    # 错误追踪\n    consecutive_errors: int\n    error_log: list[dict]\n\n    # 时间戳\n    created_at: float\n    updated_at: float\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.3 状态持久化方案\u003c/h3\u003e\n\u003cp\u003e当 Agent 需要支持暂停/恢复、跨进程执行、或长时间运行时，执行状态必须持久化。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────┐     ┌──────────────┐     ┌──────────────┐\n│   In-Memory  │     │    Redis     │     │   Database   │\n│  (dict/obj)  │     │  (KV Store)  │     │ (PostgreSQL) │\n├─────────────┤     ├──────────────┤     ├──────────────┤\n│ 最快         │     │ 快，支持 TTL  │     │ 持久可靠     │\n│ 进程重启丢失  │     │ 跨进程共享    │     │ 支持查询分析  │\n│ 单进程使用    │     │ 重启后可保留  │     │ 适合生产环境  │\n│ 适合开发/测试 │     │ 适合 session  │     │ 适合审计追溯  │\n└─────────────┘     └──────────────┘     └──────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eCheckpoint 与恢复\u003c/strong\u003e 是 Stateful Agent 的核心能力。思路很直接：在每轮循环的关键节点保存一次快照，异常恢复时从最近的快照重新开始。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass CheckpointManager:\n    def save(self, state: ExecutionState) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;保存 checkpoint，返回 checkpoint_id\u0026quot;\u0026quot;\u0026quot;\n        snapshot = {\n            \u0026quot;state\u0026quot;: asdict(state),\n            \u0026quot;timestamp\u0026quot;: time.time(),\n        }\n        checkpoint_id = f\u0026quot;{state.session_id}:{state.turn_count}\u0026quot;\n        self.store.set(checkpoint_id, json.dumps(snapshot))\n        return checkpoint_id\n\n    def restore(self, checkpoint_id: str) -\u0026gt; ExecutionState:\n        \u0026quot;\u0026quot;\u0026quot;从 checkpoint 恢复执行状态\u0026quot;\u0026quot;\u0026quot;\n        snapshot = json.loads(self.store.get(checkpoint_id))\n        return ExecutionState(**snapshot[\u0026quot;state\u0026quot;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实际系统中，checkpoint 的保存频率需要权衡：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e每轮都保存\u003c/strong\u003e：恢复粒度最细，但写入开销大\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e关键节点保存\u003c/strong\u003e（如每次工具调用前后）：开销适中，覆盖最重要的故障场景\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e定时保存\u003c/strong\u003e：实现简单，但可能丢失最近几轮的状态\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 完整代码实现\u003c/h2\u003e\n\u003cp\u003e下面是一个最小但完整的 Agent Control Loop 实现。不依赖任何框架，仅使用 Python 标准库 + OpenAI SDK。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e\u0026quot;\u0026quot;\u0026quot;\nMinimal Agent Control Loop\n不依赖任何框架，纯 Python + OpenAI SDK\n\u0026quot;\u0026quot;\u0026quot;\nimport json\nimport time\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom openai import OpenAI\n\n\nclass State(Enum):\n    OBSERVE = \u0026quot;observe\u0026quot;\n    THINK = \u0026quot;think\u0026quot;\n    ACT = \u0026quot;act\u0026quot;\n    REFLECT = \u0026quot;reflect\u0026quot;\n    DONE = \u0026quot;done\u0026quot;\n    ERROR = \u0026quot;error\u0026quot;\n\n\n@dataclass\nclass LoopContext:\n    messages: list[dict] = field(default_factory=list)\n    turn: int = 0\n    total_tokens: int = 0\n    consecutive_errors: int = 0\n    recent_outputs: list[str] = field(default_factory=list)\n\n\n# ── Tool Registry ────────────────────────────────────\n\nTOOL_FUNCTIONS = {}\n\ndef register_tool(name: str, description: str, parameters: dict):\n    \u0026quot;\u0026quot;\u0026quot;装饰器：注册工具函数及其 schema\u0026quot;\u0026quot;\u0026quot;\n    def decorator(fn):\n        TOOL_FUNCTIONS[name] = {\n            \u0026quot;fn\u0026quot;: fn,\n            \u0026quot;schema\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n                \u0026quot;function\u0026quot;: {\n                    \u0026quot;name\u0026quot;: name,\n                    \u0026quot;description\u0026quot;: description,\n                    \u0026quot;parameters\u0026quot;: parameters,\n                },\n            },\n        }\n        return fn\n    return decorator\n\n\n@register_tool(\n    name=\u0026quot;get_weather\u0026quot;,\n    description=\u0026quot;获取指定城市的当前天气\u0026quot;,\n    parameters={\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;city\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;城市名称\u0026quot;},\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;],\n    },\n)\ndef get_weather(city: str) -\u0026gt; str:\n    # 示例实现，实际中调用真实 API\n    return json.dumps({\u0026quot;city\u0026quot;: city, \u0026quot;temp\u0026quot;: 28, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;})\n\n\n# ── Agent Control Loop ───────────────────────────────\n\nclass Agent:\n    def __init__(\n        self,\n        system_prompt: str,\n        model: str = \u0026quot;gpt-4o\u0026quot;,\n        max_turns: int = 15,\n        token_budget: int = 50_000,\n        max_consecutive_errors: int = 3,\n    ):\n        self.client = OpenAI()\n        self.model = model\n        self.system_prompt = system_prompt\n        self.max_turns = max_turns\n        self.token_budget = token_budget\n        self.max_errors = max_consecutive_errors\n        self.tool_schemas = [t[\u0026quot;schema\u0026quot;] for t in TOOL_FUNCTIONS.values()]\n\n    def run(self, user_input: str) -\u0026gt; str:\n        ctx = LoopContext()\n        ctx.messages = [\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self.system_prompt},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_input},\n        ]\n        state = State.THINK  # 首轮输入已就绪，直接进入 THINK\n\n        while state not in (State.DONE, State.ERROR):\n            match state:\n                case State.THINK:\n                    state, ctx = self._think(ctx)\n                case State.ACT:\n                    state, ctx = self._act(ctx)\n                case State.REFLECT:\n                    state, ctx = self._reflect(ctx)\n            ctx.turn += 1\n\n        # 提取最终回答\n        for msg in reversed(ctx.messages):\n            if msg[\u0026quot;role\u0026quot;] == \u0026quot;assistant\u0026quot; and msg.get(\u0026quot;content\u0026quot;):\n                return msg[\u0026quot;content\u0026quot;]\n        return \u0026quot;[Agent finished without a final answer]\u0026quot;\n\n    def _think(self, ctx: LoopContext) -\u0026gt; tuple[State, LoopContext]:\n        \u0026quot;\u0026quot;\u0026quot;调用 LLM 推理\u0026quot;\u0026quot;\u0026quot;\n        try:\n            response = self.client.chat.completions.create(\n                model=self.model,\n                messages=ctx.messages,\n                tools=self.tool_schemas or None,\n            )\n        except Exception as e:\n            ctx.consecutive_errors += 1\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: f\u0026quot;[LLM Error] {e}\u0026quot;,\n            })\n            if ctx.consecutive_errors \u0026gt;= self.max_errors:\n                return State.ERROR, ctx\n            return State.THINK, ctx  # 重试\n\n        # 记录 token 消耗\n        usage = response.usage\n        ctx.total_tokens += (usage.prompt_tokens + usage.completion_tokens)\n        ctx.consecutive_errors = 0\n\n        choice = response.choices[0]\n        assistant_msg = choice.message.model_dump()\n        ctx.messages.append(assistant_msg)\n\n        # 决定下一状态\n        if choice.message.tool_calls:\n            return State.ACT, ctx\n        else:\n            return State.DONE, ctx\n\n    def _act(self, ctx: LoopContext) -\u0026gt; tuple[State, LoopContext]:\n        \u0026quot;\u0026quot;\u0026quot;执行工具调用\u0026quot;\u0026quot;\u0026quot;\n        assistant_msg = ctx.messages[-1]\n        tool_calls = assistant_msg.get(\u0026quot;tool_calls\u0026quot;, [])\n\n        for tc in tool_calls:\n            fn_name = tc[\u0026quot;function\u0026quot;][\u0026quot;name\u0026quot;]\n            fn_args = json.loads(tc[\u0026quot;function\u0026quot;][\u0026quot;arguments\u0026quot;])\n\n            tool_entry = TOOL_FUNCTIONS.get(fn_name)\n            if not tool_entry:\n                result = f\u0026quot;Error: unknown tool \u0026#39;{fn_name}\u0026#39;\u0026quot;\n            else:\n                try:\n                    result = tool_entry[\u0026quot;fn\u0026quot;](**fn_args)\n                except Exception as e:\n                    result = f\u0026quot;Error: tool \u0026#39;{fn_name}\u0026#39; raised {type(e).__name__}: {e}\u0026quot;\n                    ctx.consecutive_errors += 1\n\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;tool_call_id\u0026quot;: tc[\u0026quot;id\u0026quot;],\n                \u0026quot;content\u0026quot;: str(result),\n            })\n\n        return State.REFLECT, ctx\n\n    def _reflect(self, ctx: LoopContext) -\u0026gt; tuple[State, LoopContext]:\n        \u0026quot;\u0026quot;\u0026quot;反思：检查终止条件\u0026quot;\u0026quot;\u0026quot;\n        # 最大轮次\n        if ctx.turn \u0026gt;= self.max_turns:\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: \u0026quot;[Agent stopped: max turns exceeded]\u0026quot;,\n            })\n            return State.ERROR, ctx\n\n        # Token 预算\n        if ctx.total_tokens \u0026gt;= self.token_budget:\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: \u0026quot;[Agent stopped: token budget exceeded]\u0026quot;,\n            })\n            return State.ERROR, ctx\n\n        # 连续错误\n        if ctx.consecutive_errors \u0026gt;= self.max_errors:\n            return State.ERROR, ctx\n\n        # 死循环检测：最近 3 次输出相同\n        tool_results = [\n            m[\u0026quot;content\u0026quot;] for m in ctx.messages[-6:]\n            if m.get(\u0026quot;role\u0026quot;) == \u0026quot;tool\u0026quot;\n        ]\n        if len(tool_results) \u0026gt;= 3 and len(set(tool_results[-3:])) == 1:\n            ctx.messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;,\n                \u0026quot;content\u0026quot;: \u0026quot;[Agent stopped: loop detected]\u0026quot;,\n            })\n            return State.ERROR, ctx\n\n        # 继续下一轮推理\n        return State.THINK, ctx\n\n\n# ── 使用示例 ─────────────────────────────────────────\n\nif __name__ == \u0026quot;__main__\u0026quot;:\n    agent = Agent(\n        system_prompt=\u0026quot;你是一个天气助手。使用 get_weather 工具回答天气问题。\u0026quot;,\n        max_turns=10,\n    )\n    answer = agent.run(\u0026quot;北京今天天气怎么样？\u0026quot;)\n    print(answer)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码约 130 行，涵盖了 Control Loop 的所有核心要素：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e状态机驱动的循环控制\u003c/li\u003e\n\u003cli\u003e工具注册与动态调用\u003c/li\u003e\n\u003cli\u003eLLM 异常重试\u003c/li\u003e\n\u003cli\u003eToken 消耗追踪\u003c/li\u003e\n\u003cli\u003e多种终止条件（max_turns / token_budget / consecutive_errors / loop_detected）\u003c/li\u003e\n\u003cli\u003e工具执行错误处理\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e它不是生产级代码，但足以说明 Control Loop 的核心机制。在此基础上增加异步执行、状态持久化、日志追踪，就能逐步演进为生产级实现。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 错误处理策略\u003c/h2\u003e\n\u003cp\u003e生产环境中，Agent Control Loop 最常遇到的四类错误：\u003c/p\u003e\n\u003ch3\u003e7.1 Tool 调用失败\u003c/h3\u003e\n\u003cp\u003e工具调用失败是最高频的错误。正确的处理方式不是抛异常终止，而是\u003cstrong\u003e将错误信息作为 Observation 返回给 LLM\u003c/strong\u003e，让它决定如何应对。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 错误的做法：直接终止\ntry:\n    result = call_tool(name, args)\nexcept Exception:\n    raise  # Agent 直接崩溃\n\n# 正确的做法：将错误反馈给 LLM\ntry:\n    result = call_tool(name, args)\nexcept TimeoutError:\n    result = \u0026quot;Tool timed out after 30s. Consider using different parameters.\u0026quot;\nexcept ValueError as e:\n    result = f\u0026quot;Invalid arguments: {e}. Please check parameter types.\u0026quot;\nexcept Exception as e:\n    result = f\u0026quot;Tool failed: {type(e).__name__}: {e}\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLLM 在收到错误信息后，通常能自主修正——换一组参数重试、换一个工具、或者告知用户当前无法完成任务。\u003c/p\u003e\n\u003ch3\u003e7.2 LLM 返回格式异常\u003c/h3\u003e\n\u003cp\u003eLLM 偶尔会返回不符合预期的格式：JSON 不合法、tool_call 参数缺失、content 为空等。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _parse_tool_call_safe(self, tool_call) -\u0026gt; tuple[str, dict]:\n    \u0026quot;\u0026quot;\u0026quot;安全解析工具调用参数\u0026quot;\u0026quot;\u0026quot;\n    name = tool_call.function.name\n    try:\n        args = json.loads(tool_call.function.arguments)\n    except json.JSONDecodeError:\n        # LLM 返回了非法 JSON，尝试修复或跳过\n        args = {}\n        self.logger.warning(\n            f\u0026quot;Invalid JSON in tool_call arguments: \u0026quot;\n            f\u0026quot;{tool_call.function.arguments}\u0026quot;\n        )\n    return name, args\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.3 超时处理\u003c/h3\u003e\n\u003cp\u003e整个 Agent 执行需要有全局超时，防止无限挂起：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport signal\n\nclass TimeoutError(Exception):\n    pass\n\ndef run_with_timeout(fn, timeout_seconds: int, *args, **kwargs):\n    \u0026quot;\u0026quot;\u0026quot;为函数执行添加超时限制\u0026quot;\u0026quot;\u0026quot;\n    def handler(signum, frame):\n        raise TimeoutError(f\u0026quot;Execution timed out after {timeout_seconds}s\u0026quot;)\n\n    old_handler = signal.signal(signal.SIGALRM, handler)\n    signal.alarm(timeout_seconds)\n    try:\n        return fn(*args, **kwargs)\n    finally:\n        signal.alarm(0)\n        signal.signal(signal.SIGALRM, old_handler)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.4 死循环检测\u003c/h3\u003e\n\u003cp\u003e当 Agent 陷入死循环时，它会反复执行相同的操作序列。检测策略：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _detect_loop(self, messages: list[dict], window: int = 6) -\u0026gt; bool:\n    \u0026quot;\u0026quot;\u0026quot;检测 Agent 是否陷入重复循环\u0026quot;\u0026quot;\u0026quot;\n    recent = messages[-window:]\n\n    # 策略 1：完全重复检测\n    contents = [m.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;) for m in recent if m[\u0026quot;role\u0026quot;] == \u0026quot;assistant\u0026quot;]\n    if len(contents) \u0026gt;= 3 and len(set(contents[-3:])) == 1:\n        return True\n\n    # 策略 2：工具调用序列重复检测\n    tool_calls = []\n    for m in recent:\n        if m.get(\u0026quot;tool_calls\u0026quot;):\n            for tc in m[\u0026quot;tool_calls\u0026quot;]:\n                tool_calls.append(f\u0026quot;{tc[\u0026#39;function\u0026#39;][\u0026#39;name\u0026#39;]}:{tc[\u0026#39;function\u0026#39;][\u0026#39;arguments\u0026#39;]}\u0026quot;)\n\n    if len(tool_calls) \u0026gt;= 4:\n        half = len(tool_calls) // 2\n        if tool_calls[:half] == tool_calls[half:2*half]:\n            return True\n\n    return False\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 性能考量\u003c/h2\u003e\n\u003ch3\u003e8.1 Token 消耗与循环次数的关系\u003c/h3\u003e\n\u003cp\u003eAgent Control Loop 的 Token 消耗不是线性增长，而是\u003cstrong\u003e二次增长\u003c/strong\u003e——因为每一轮都要携带之前所有轮次的 message history。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e轮次    新增消息 Token    累计 Context Token    本轮总消耗\n1       T               S + T                S + T\n2       T               S + 2T               S + 2T\n3       T               S + 3T               S + 3T\n...\nN       T               S + NT               S + NT\n\n总消耗 = N*S + T*(1+2+...+N) = N*S + T*N*(N+1)/2\n\n其中 S = System Prompt Token 数，T = 平均每轮消息 Token 数\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这意味着 \u003cstrong\u003e10 轮的 Agent 消耗的 Token 不是 1 轮的 10 倍，而可能是 55 倍\u003c/strong\u003e。这对成本控制至关重要。\u003c/p\u003e\n\u003ch3\u003e8.2 Context Window 膨胀问题\u003c/h3\u003e\n\u003cp\u003e随着轮次增加，Context Window 持续膨胀，导致：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e延迟增加\u003c/strong\u003e：LLM 推理时间与输入 Token 数正相关\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成本增加\u003c/strong\u003e：按 Token 计费，输入越长越贵\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e质量下降\u003c/strong\u003e：过长的 Context 会导致 LLM \u0026quot;注意力分散\u0026quot;，关键信息被淹没（lost in the middle 问题）\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e8.3 消息压缩/摘要策略\u003c/h3\u003e\n\u003cp\u003e应对 Context Window 膨胀的核心策略：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e策略一：滑动窗口\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e只保留最近 K 轮对话，丢弃更早的历史。简单粗暴但有效。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _sliding_window(self, messages: list[dict], keep_last: int = 10) -\u0026gt; list[dict]:\n    system_msgs = [m for m in messages if m[\u0026quot;role\u0026quot;] == \u0026quot;system\u0026quot;]\n    non_system = [m for m in messages if m[\u0026quot;role\u0026quot;] != \u0026quot;system\u0026quot;]\n    return system_msgs + non_system[-keep_last:]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e策略二：摘要压缩\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e当 message history 超过阈值时，用 LLM 对早期对话生成摘要，替换原始消息。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _compress_history(self, messages: list[dict], threshold: int = 20) -\u0026gt; list[dict]:\n    if len(messages) \u0026lt;= threshold:\n        return messages\n\n    # 将早期消息压缩为摘要\n    early = messages[1:-threshold]  # 跳过 system prompt，保留最近的\n    summary_prompt = (\n        \u0026quot;请用 3-5 句话总结以下对话的关键信息和已完成的操作：\\n\u0026quot;\n        + \u0026quot;\\n\u0026quot;.join(m.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;) for m in early if m.get(\u0026quot;content\u0026quot;))\n    )\n\n    summary = self.client.chat.completions.create(\n        model=\u0026quot;gpt-4o-mini\u0026quot;,  # 用小模型做摘要，节省成本\n        messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: summary_prompt}],\n    ).choices[0].message.content\n\n    return (\n        [messages[0]]  # system prompt\n        + [{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;[Earlier conversation summary] {summary}\u0026quot;}]\n        + messages[-threshold:]\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e策略三：选择性保留\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e不是所有消息都同等重要。工具的原始返回值（可能非常长）通常可以只保留摘要：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef _trim_tool_results(self, messages: list[dict], max_len: int = 500) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;截断过长的工具返回值\u0026quot;\u0026quot;\u0026quot;\n    trimmed = []\n    for m in messages:\n        if m[\u0026quot;role\u0026quot;] == \u0026quot;tool\u0026quot; and len(m.get(\u0026quot;content\u0026quot;, \u0026quot;\u0026quot;)) \u0026gt; max_len:\n            m = {**m, \u0026quot;content\u0026quot;: m[\u0026quot;content\u0026quot;][:max_len] + \u0026quot;\\n...[truncated]\u0026quot;}\n        trimmed.append(m)\n    return trimmed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e三种策略的对比：\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e信息保留\u003c/th\u003e\n\u003cth\u003e实现成本\u003c/th\u003e\n\u003cth\u003eToken 节省\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e滑动窗口\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e极低\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e短对话、工具调用为主\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e摘要压缩\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e中（需要额外 LLM 调用）\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e长对话、需要历史上下文\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e选择性保留\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e工具返回值较大的场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e实际工程中，通常\u003cstrong\u003e组合使用\u003c/strong\u003e：先用选择性保留截断大结果，再用滑动窗口控制总长度，在关键节点用摘要压缩保留全局上下文。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 小结与进一步思考\u003c/h2\u003e\n\u003cp\u003e本文从状态机模型出发，完整地拆解了 Agent Control Loop 的核心抽象：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOBSERVE\u003c/strong\u003e 负责输入归一化——将各种来源的信息统一为 LLM 可理解的 message 格式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTHINK\u003c/strong\u003e 是核心推理阶段——管理 Context Window、控制 Token 预算、解析 LLM 输出\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eACT\u003c/strong\u003e 是执行层——处理工具调用的同步/异步执行、超时控制、安全隔离\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eREFLECT\u003c/strong\u003e 负责质量评估——决定是继续、重试还是终止\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e终止条件\u003c/strong\u003e是成本和安全的兜底——max_turns、token_budget、error_threshold、loop_detection\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e我们对比了 ReAct 和 Plan-then-Execute 两种主流模式，分析了 Stateless 与 Stateful 两种状态管理策略，并实现了一个不依赖任何框架的完整 Control Loop。\u003c/p\u003e\n\u003cp\u003e但控制循环只是 Agent 运行时的骨架。它的灵魂在于 \u003cstrong\u003eTool Calling\u003c/strong\u003e——正是工具让 Agent 从\u0026quot;能说会道的语言模型\u0026quot;变成\u0026quot;能做事的智能体\u0026quot;。\u003c/p\u003e\n\u003cp\u003e在下一篇 \u003cstrong\u003e《Tool Calling Deep Dive: 让 LLM 成为可编程接口》\u003c/strong\u003e 中，我们会深入工具调用的设计哲学：JSON Schema 作为契约、Tool Registry 的实现、参数校验、错误传播，以及 Structured Output 为什么优于自由文本。\u003c/p\u003e\n\u003cp\u003e留几个值得进一步思考的问题：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eControl Loop 的嵌套\u003c/strong\u003e：当一个 Agent 的工具是另一个 Agent 时，控制循环如何嵌套？外层循环和内层循环的终止条件如何协调？\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e人机协作中的循环\u003c/strong\u003e：如何在 Control Loop 中优雅地插入人类审批节点？这和 Stateful Agent 的 checkpoint 机制有什么关系？\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e流式输出与控制循环\u003c/strong\u003e：当 Agent 需要边思考边输出（streaming）时，状态机模型还适用吗？需要做哪些调整？\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多模态输入的归一化\u003c/strong\u003e：当 OBSERVE 阶段接收的不只是文本，还有图片、音频、视频时，输入归一化策略如何演化？\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 04 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/03-Agent%20vs%20Workflow%20vs%20Automation\"\u003e03 | Agent vs Workflow vs Automation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/05-Tool%20Calling%20Deep%20Dive\"\u003e05 | Tool Calling Deep Dive\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"1a:Td28a,"])</script><script>self.__next_f.push([1,"\u003ch1\u003ePrompt Engineering for Agents: 面向 Agent 的提示词工程\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAgentic 系列第 06 篇。前文我们讨论了 Tool Calling 的设计哲学与工程实践，LLM 已经具备了\u0026quot;使用工具\u0026quot;的能力。但工具只是 Agent 的四肢，Prompt 才是 Agent 的大脑皮层——它定义了 Agent 如何感知、如何推理、如何决策、如何行动。\u003c/p\u003e\n\u003cp\u003e本文的核心观点：\u003cstrong\u003eAgent 的 Prompt 不是\u0026quot;聊天提示词\u0026quot;，而是\u0026quot;系统接口规范\u0026quot;。\u003c/strong\u003e Chatbot 的 Prompt 追求对话自然，Agent 的 Prompt 追求行为可控。这两者的设计哲学截然不同。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 从\u0026quot;对话技巧\u0026quot;到\u0026quot;接口规范\u0026quot;\u003c/h2\u003e\n\u003cp\u003e大多数人对 Prompt Engineering 的印象停留在\u0026quot;写好提示词让 AI 回答更好\u0026quot;的阶段。这在 Chatbot 场景下基本成立——你调整措辞、给几个例子、加一句\u0026quot;请一步一步思考\u0026quot;，模型输出的质量就会改善。\u003c/p\u003e\n\u003cp\u003e但 Agent 场景完全不同。\u003c/p\u003e\n\u003cp\u003eAgent 的 Prompt 不是写给\u0026quot;一个聊天助手\u0026quot;的，而是写给\u0026quot;一个程序运行时\u0026quot;的。它的目的不是让输出\u0026quot;看起来更好\u0026quot;，而是让输出\u003cstrong\u003e可解析、可路由、可执行\u003c/strong\u003e。一个 Agent Prompt 的失败，不是\u0026quot;回答不够好\u0026quot;，而是\u003cstrong\u003e系统崩溃\u003c/strong\u003e——JSON 解析失败、工具调用参数错误、无限循环、状态机卡死。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eChatbot Prompt\u003c/th\u003e\n\u003cth\u003eAgent Prompt\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e目标\u003c/td\u003e\n\u003ctd\u003e自然、有帮助的回复\u003c/td\u003e\n\u003ctd\u003e可解析、可执行的结构化输出\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e消费者\u003c/td\u003e\n\u003ctd\u003e人类用户\u003c/td\u003e\n\u003ctd\u003e程序代码（Parser / Router / Executor）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e失败模式\u003c/td\u003e\n\u003ctd\u003e回答质量下降\u003c/td\u003e\n\u003ctd\u003e系统崩溃、无限循环、安全漏洞\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e格式要求\u003c/td\u003e\n\u003ctd\u003e宽松，Markdown 即可\u003c/td\u003e\n\u003ctd\u003e严格，JSON / XML / 特定 Schema\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可测试性\u003c/td\u003e\n\u003ctd\u003e主观评估\u003c/td\u003e\n\u003ctd\u003e可自动化断言\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e版本管理\u003c/td\u003e\n\u003ctd\u003e通常不管理\u003c/td\u003e\n\u003ctd\u003e必须版本控制，等同于代码\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e这意味着，\u003cstrong\u003eAgent 的 Prompt Engineering 本质上是一种接口设计（Interface Design）\u003c/strong\u003e，而不是文案写作。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. Agent Prompt 的分层架构\u003c/h2\u003e\n\u003cp\u003e一个成熟的 Agent 系统，发送给 LLM 的 Prompt 不是一坨字符串，而是多个层次动态组装的结果。\u003c/p\u003e\n\u003ch3\u003e2.1 四层结构\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────┐\n│                   Final Prompt                       │\n│  ┌───────────────────────────────────────────────┐  │\n│  │  Layer 1: System Prompt (静态)                 │  │\n│  │  - 身份定义（你是谁，你的职责是什么）            │  │\n│  │  - 行为约束（必须做什么，禁止做什么）            │  │\n│  │  - 输出格式规范（JSON Schema / XML 模板）       │  │\n│  ├───────────────────────────────────────────────┤  │\n│  │  Layer 2: Context Injection (动态)             │  │\n│  │  - 可用工具列表及其描述                         │  │\n│  │  - 历史对话摘要 / 关键事实                      │  │\n│  │  - 当前系统状态（已完成步骤、中间结果）           │  │\n│  │  - 检索到的外部知识（RAG 结果）                  │  │\n│  ├───────────────────────────────────────────────┤  │\n│  │  Layer 3: User Input (外部)                    │  │\n│  │  - 用户的原始请求                               │  │\n│  │  - 或上一步 Agent 的输出（在 Multi-Agent 中）    │  │\n│  ├───────────────────────────────────────────────┤  │\n│  │  Layer 4: Constraints \u0026amp; Guardrails (静态+动态)  │  │\n│  │  - 安全边界（禁止调用的工具、禁止访问的数据）     │  │\n│  │  - 输出限制（最大步骤数、Token 预算）            │  │\n│  │  - 当前 Turn 的特殊指令                         │  │\n│  └───────────────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2.2 组装过程\u003c/h3\u003e\n\u003cp\u003ePrompt 组装不是简单的字符串拼接，而是一个有优先级、有裁剪策略的构建过程：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                  Token Budget: 8000\n                       │\n      ┌────────────────┼────────────────┐\n      │                │                │\n      ▼                ▼                ▼\n System Prompt    Context Injection   User Input\n (固定预算:2000)  (弹性预算:4500)    (固定预算:1500)\n      │                │                │\n      │          ┌─────┴─────┐          │\n      │          │           │          │\n      │      Tool Descs   History       │\n      │      (1500 max)  (3000 max)     │\n      │          │           │          │\n      │          │     [若超预算]        │\n      │          │     → 压缩/截断      │\n      │          │           │          │\n      ▼          ▼           ▼          ▼\n     ┌──────────────────────────────────┐\n     │      Prompt Assembler            │\n     │  1. 拼装各层                      │\n     │  2. 计算总 Token                  │\n     │  3. 若超预算 → 压缩 Context 层    │\n     │  4. 注入 Constraints              │\n     └──────────────────────────────────┘\n                    │\n                    ▼\n              Final Prompt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键设计决策：\u003cstrong\u003eSystem Prompt 和 User Input 的预算是固定的，Context Injection 的预算是弹性的。\u003c/strong\u003e 当总 Token 超出预算时，优先压缩 Context 层（截断历史、精简工具描述），而非删减 System Prompt 中的行为约束。因为行为约束一旦丢失，Agent 的行为就不可控了。\u003c/p\u003e\n\u003ch3\u003e2.3 Python 示例：Prompt 组装器\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\n\n@dataclass\nclass PromptLayer:\n    content: str\n    priority: int        # 越高越不容易被裁剪\n    max_tokens: int\n    compressible: bool   # 是否允许被压缩\n\n@dataclass\nclass PromptAssembler:\n    total_budget: int = 8000\n    layers: list[PromptLayer] = field(default_factory=list)\n\n    def add_layer(self, layer: PromptLayer):\n        self.layers.append(layer)\n\n    def assemble(self) -\u0026gt; str:\n        # 按优先级排序：高优先级最后处理（最不容易被裁剪）\n        sorted_layers = sorted(self.layers, key=lambda l: l.priority)\n\n        total_used = sum(estimate_tokens(l.content) for l in self.layers)\n\n        if total_used \u0026gt; self.total_budget:\n            overflow = total_used - self.total_budget\n            # 从低优先级开始压缩\n            for layer in sorted_layers:\n                if not layer.compressible:\n                    continue\n                available_cut = estimate_tokens(layer.content) - 100  # 至少保留 100 token\n                cut = min(overflow, available_cut)\n                layer.content = truncate_to_tokens(layer.content,\n                                                    estimate_tokens(layer.content) - cut)\n                overflow -= cut\n                if overflow \u0026lt;= 0:\n                    break\n\n        # 按原始顺序拼装\n        return \u0026quot;\\n\\n\u0026quot;.join(l.content for l in self.layers)\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e3. 四种关键 Agent Prompt 设计模式\u003c/h2\u003e\n\u003cp\u003eAgent 系统中，不同角色的 Agent 需要不同风格的 Prompt。以下是四种最核心的设计模式，每种都给出完整可用的 Prompt 示例。\u003c/p\u003e\n\u003ch3\u003e3.1 Router Prompt：意图路由\u003c/h3\u003e\n\u003cp\u003eRouter 的职责是根据用户输入\u003cstrong\u003e选择正确的工具或子流程\u003c/strong\u003e，而不是自己去执行任务。它是 Agent 系统的\u0026quot;交通警察\u0026quot;。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eROUTER_PROMPT = \u0026quot;\u0026quot;\u0026quot;You are a request router. Your ONLY job is to analyze the user\u0026#39;s\nrequest and select the appropriate tool. Do NOT attempt to answer the question yourself.\n\n## Available Tools\n{tool_descriptions}\n\n## Routing Rules\n1. If the request involves real-time data (weather, stock prices, news) → use `web_search`\n2. If the request involves the user\u0026#39;s own data (files, emails, calendar) → use `data_query`\n3. If the request involves code generation or debugging → use `code_assistant`\n4. If the request involves image generation or editing → use `image_tool`\n5. If the request is ambiguous, ask a clarifying question instead of guessing.\n6. If NO tool matches, respond with tool_name: \u0026quot;none\u0026quot; and explain why.\n\n## Output Format (strict JSON, no markdown fence)\n{{\n  \u0026quot;reasoning\u0026quot;: \u0026quot;\u0026lt;one sentence explaining your routing decision\u0026gt;\u0026quot;,\n  \u0026quot;tool_name\u0026quot;: \u0026quot;\u0026lt;exact tool name from the list above, or \u0026#39;none\u0026#39;\u0026gt;\u0026quot;,\n  \u0026quot;tool_input\u0026quot;: {{\u0026lt;parameters to pass to the selected tool\u0026gt;}},\n  \u0026quot;confidence\u0026quot;: \u0026lt;float between 0.0 and 1.0\u0026gt;\n}}\n\n## Critical Constraints\n- NEVER fabricate a tool name not in the list.\n- NEVER return free-form text. ALWAYS return valid JSON.\n- If confidence \u0026lt; 0.6, set tool_name to \u0026quot;none\u0026quot; and ask for clarification.\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e设计要点：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e明确告诉 LLM \u0026quot;你不负责回答问题\u0026quot;，避免它自作主张直接回答\u003c/li\u003e\n\u003cli\u003e提供确定性的路由规则（if-then），减少 LLM 的自由裁量空间\u003c/li\u003e\n\u003cli\u003e要求输出 confidence 分数，让调用方可以做二次判断\u003c/li\u003e\n\u003cli\u003e兜底规则：没有匹配的工具时，显式输出 \u0026quot;none\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.2 Planner Prompt：任务规划\u003c/h3\u003e\n\u003cp\u003ePlanner 的职责是将一个复杂请求\u003cstrong\u003e分解为可执行的子任务列表\u003c/strong\u003e。它是 Agent 的\u0026quot;项目经理\u0026quot;。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ePLANNER_PROMPT = \u0026quot;\u0026quot;\u0026quot;You are a task planner. Given a complex user request, decompose it\ninto a sequence of concrete, executable sub-tasks.\n\n## Planning Principles\n1. Each sub-task must be independently executable by a single tool call.\n2. Sub-tasks should be ordered by dependency — a task can only depend on tasks before it.\n3. Minimize the number of steps. Do NOT over-decompose simple requests.\n4. If a request can be done in ONE tool call, return a plan with ONE step.\n\n## Available Tools\n{tool_descriptions}\n\n## Output Format (strict JSON)\n{{\n  \u0026quot;analysis\u0026quot;: \u0026quot;\u0026lt;brief analysis of the request\u0026#39;s complexity and required resources\u0026gt;\u0026quot;,\n  \u0026quot;plan\u0026quot;: [\n    {{\n      \u0026quot;step_id\u0026quot;: 1,\n      \u0026quot;description\u0026quot;: \u0026quot;\u0026lt;what this step does\u0026gt;\u0026quot;,\n      \u0026quot;tool_name\u0026quot;: \u0026quot;\u0026lt;tool to use\u0026gt;\u0026quot;,\n      \u0026quot;tool_input\u0026quot;: {{\u0026lt;parameters\u0026gt;}},\n      \u0026quot;depends_on\u0026quot;: []\n    }},\n    {{\n      \u0026quot;step_id\u0026quot;: 2,\n      \u0026quot;description\u0026quot;: \u0026quot;\u0026lt;what this step does\u0026gt;\u0026quot;,\n      \u0026quot;tool_name\u0026quot;: \u0026quot;\u0026lt;tool to use\u0026gt;\u0026quot;,\n      \u0026quot;tool_input\u0026quot;: {{\u0026lt;parameters, can reference $step_1_result\u0026gt;}},\n      \u0026quot;depends_on\u0026quot;: [1]\n    }}\n  ],\n  \u0026quot;estimated_steps\u0026quot;: \u0026lt;int\u0026gt;,\n  \u0026quot;can_parallelize\u0026quot;: [\u0026lt;list of step_id groups that can run concurrently\u0026gt;]\n}}\n\n## Constraints\n- Maximum 8 steps. If the task seems to need more, simplify or ask the user to narrow scope.\n- NEVER include steps like \u0026quot;verify result\u0026quot; or \u0026quot;report to user\u0026quot; — those are handled by the system.\n- Use $step_N_result to reference the output of a previous step.\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e设计要点：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026quot;最小化步骤数\u0026quot;原则防止 LLM 过度分解（这是规划器最常见的问题）\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edepends_on\u003c/code\u003e 字段使得执行引擎可以识别并行机会\u003c/li\u003e\n\u003cli\u003e明确设置步骤上限（8 步），避免 LLM 生成无休止的计划\u003c/li\u003e\n\u003cli\u003e禁止 LLM 添加\u0026quot;元步骤\u0026quot;（验证、汇报），这些是系统层的职责\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.3 Executor Prompt：执行操作\u003c/h3\u003e\n\u003cp\u003eExecutor 的职责是\u003cstrong\u003e执行单个具体操作\u003c/strong\u003e，并以严格的格式返回结果。它是 Agent 的\u0026quot;操作工\u0026quot;。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eEXECUTOR_PROMPT = \u0026quot;\u0026quot;\u0026quot;You are a task executor. You will receive a specific sub-task and\nmust execute it using the provided tool.\n\n## Current Task\n{task_description}\n\n## Tool to Use\nName: {tool_name}\nSchema: {tool_schema}\n\n## Context from Previous Steps\n{previous_results}\n\n## Execution Rules\n1. Call the tool EXACTLY ONCE with the correct parameters.\n2. Do NOT deviate from the task description.\n3. Do NOT call tools not specified for this task.\n4. If the tool call fails, report the error — do NOT retry or improvise.\n\n## Output Format (strict JSON)\n{{\n  \u0026quot;tool_call\u0026quot;: {{\n    \u0026quot;name\u0026quot;: \u0026quot;{tool_name}\u0026quot;,\n    \u0026quot;arguments\u0026quot;: {{\u0026lt;filled parameters\u0026gt;}}\n  }},\n  \u0026quot;explanation\u0026quot;: \u0026quot;\u0026lt;one sentence on why these parameters were chosen\u0026gt;\u0026quot;\n}}\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e设计要点：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExecutor 的设计哲学是\u0026quot;最小权限\u0026quot;——只做被告知的事\u003c/li\u003e\n\u003cli\u003e严禁 Executor 自主决策，发现错误只能上报，不能自行重试\u003c/li\u003e\n\u003cli\u003e这种设计让 Executor 成为一个确定性单元，便于测试和审计\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.4 Reflector Prompt：结果反思\u003c/h3\u003e\n\u003cp\u003eReflector 的职责是\u003cstrong\u003e评估执行结果\u003c/strong\u003e，判断是否达成目标，如果未达成则提出修正方案。它是 Agent 的\u0026quot;质量检查员\u0026quot;。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eREFLECTOR_PROMPT = \u0026quot;\u0026quot;\u0026quot;You are a result evaluator. Given the original user request and the\nexecution result, determine whether the task has been completed successfully.\n\n## Original Request\n{user_request}\n\n## Execution Plan\n{plan}\n\n## Execution Results\n{results}\n\n## Evaluation Criteria\n1. Completeness: Does the result fully address the user\u0026#39;s request?\n2. Correctness: Is the result factually and logically correct?\n3. Format: Is the result in the expected format?\n\n## Output Format (strict JSON)\n{{\n  \u0026quot;evaluation\u0026quot;: {{\n    \u0026quot;completeness\u0026quot;: {{\u0026quot;score\u0026quot;: \u0026lt;1-5\u0026gt;, \u0026quot;reason\u0026quot;: \u0026quot;\u0026lt;explanation\u0026gt;\u0026quot;}},\n    \u0026quot;correctness\u0026quot;: {{\u0026quot;score\u0026quot;: \u0026lt;1-5\u0026gt;, \u0026quot;reason\u0026quot;: \u0026quot;\u0026lt;explanation\u0026gt;\u0026quot;}},\n    \u0026quot;format\u0026quot;: {{\u0026quot;score\u0026quot;: \u0026lt;1-5\u0026gt;, \u0026quot;reason\u0026quot;: \u0026quot;\u0026lt;explanation\u0026gt;\u0026quot;}}\n  }},\n  \u0026quot;overall_pass\u0026quot;: \u0026lt;true|false\u0026gt;,\n  \u0026quot;action\u0026quot;: \u0026quot;\u0026lt;one of: \u0026#39;accept\u0026#39;, \u0026#39;retry_step\u0026#39;, \u0026#39;replan\u0026#39;, \u0026#39;escalate\u0026#39;\u0026gt;\u0026quot;,\n  \u0026quot;retry_details\u0026quot;: {{\n    \u0026quot;step_id\u0026quot;: \u0026lt;which step to retry, if applicable\u0026gt;,\n    \u0026quot;modification\u0026quot;: \u0026quot;\u0026lt;what to change in the retry\u0026gt;\u0026quot;\n  }}\n}}\n\n## Decision Rules\n- If all scores \u0026gt;= 4: action = \u0026quot;accept\u0026quot;\n- If any score \u0026lt;= 2 and retry_count \u0026lt; 3: action = \u0026quot;retry_step\u0026quot; or \u0026quot;replan\u0026quot;\n- If retry_count \u0026gt;= 3: action = \u0026quot;escalate\u0026quot; (ask user for help)\n- NEVER accept a result with correctness score \u0026lt;= 2.\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e设计要点：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e多维度评估（完整性、正确性、格式）而非简单的 pass/fail\u003c/li\u003e\n\u003cli\u003e明确的决策规则，减少 LLM 判断的主观性\u003c/li\u003e\n\u003cli\u003eretry_count 上限防止无限重试循环\u003c/li\u003e\n\u003cli\u003e\u0026quot;escalate\u0026quot; 作为最终兜底——承认失败比无限循环好得多\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3.5 四种模式的协作\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eUser Request\n     │\n     ▼\n ┌────────┐     tool_name + input     ┌──────────┐\n │ Router │ ──── (简单请求直接执行) ───→│ Executor │──→ Result\n └────┬───┘                           └──────────┘\n      │ (复杂请求)                          ▲\n      ▼                                    │\n ┌─────────┐    plan[step_1..N]     ┌──────┴───┐\n │ Planner │ ─────────────────────→│ Executor  │\n └─────────┘                       │ (per step)│\n                                   └──────┬───┘\n                                          │ results\n                                          ▼\n                                   ┌───────────┐\n                                   │ Reflector  │\n                                   └─────┬─────┘\n                                         │\n                              ┌──────────┼──────────┐\n                              │          │          │\n                           accept    retry_step   replan\n                              │          │          │\n                              ▼          ▼          ▼\n                           Return    Executor    Planner\n                           to User  (重试该步)   (重新规划)\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Chain-of-Thought 在 Agent 中的应用\u003c/h2\u003e\n\u003ch3\u003e4.1 标准 CoT vs Agent CoT\u003c/h3\u003e\n\u003cp\u003e标准的 Chain-of-Thought（CoT）是一种推理增强技术——\u0026quot;Let\u0026#39;s think step by step\u0026quot;。但在 Agent 中，CoT 的用途和形式有本质不同：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e标准 CoT\u003c/th\u003e\n\u003cth\u003eAgent CoT\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e目的\u003c/td\u003e\n\u003ctd\u003e提高推理准确性\u003c/td\u003e\n\u003ctd\u003e让中间推理过程可审计、可路由\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e消费者\u003c/td\u003e\n\u003ctd\u003e最终输出的一部分\u003c/td\u003e\n\u003ctd\u003eAgent Runtime 的中间状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e格式\u003c/td\u003e\n\u003ctd\u003e自然语言\u003c/td\u003e\n\u003ctd\u003e结构化（通常嵌入 JSON 的某个字段）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e是否返回用户\u003c/td\u003e\n\u003ctd\u003e通常是\u003c/td\u003e\n\u003ctd\u003e通常不是（内部消费）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003eAgent 的 CoT 更像是一个\u003cstrong\u003e内部日志\u003c/strong\u003e，而非用户可见的推理过程。它的首要目标是让系统（而非人类）能够理解和利用中间推理。\u003c/p\u003e\n\u003ch3\u003e4.2 Scratchpad 模式\u003c/h3\u003e\n\u003cp\u003eScratchpad 模式是 Agent CoT 的典型实现——在 Prompt 中显式开辟一个\u0026quot;草稿区\u0026quot;，让 LLM 在其中进行中间推理，然后输出最终决策。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eSCRATCHPAD_PROMPT = \u0026quot;\u0026quot;\u0026quot;Analyze the user\u0026#39;s request and decide on an action.\n\n## User Request\n{user_request}\n\n## Available Tools\n{tools}\n\n## Instructions\nUse the \u0026lt;scratchpad\u0026gt; section to think through your decision. This section will NOT be\nshown to the user. Then provide your final action in the \u0026lt;action\u0026gt; section.\n\n\u0026lt;scratchpad\u0026gt;\nThink through:\n1. What is the user actually asking for?\n2. Which tools could help? What are the pros/cons of each?\n3. What information am I missing?\n4. What\u0026#39;s the simplest approach that works?\n\u0026lt;/scratchpad\u0026gt;\n\n\u0026lt;action\u0026gt;\nReturn strict JSON here:\n{{\u0026quot;tool_name\u0026quot;: \u0026quot;...\u0026quot;, \u0026quot;tool_input\u0026quot;: {{...}}, \u0026quot;reasoning_summary\u0026quot;: \u0026quot;...\u0026quot;}}\n\u0026lt;/action\u0026gt;\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRuntime 解析时，只提取 \u003ccode\u003e\u0026lt;action\u0026gt;\u003c/code\u003e 标签中的内容作为执行指令，\u003ccode\u003e\u0026lt;scratchpad\u0026gt;\u003c/code\u003e 的内容记录到日志中用于调试和审计。\u003c/p\u003e\n\u003ch3\u003e4.3 显式推理 vs 隐式推理的 Trade-off\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e显式推理（Explicit Reasoning）：\u003c/strong\u003e 在 Prompt 中要求 LLM 输出推理过程。\u003c/p\u003e\n\u003cp\u003e优势：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e可审计，出了问题能追溯\u0026quot;为什么做了这个决策\u0026quot;\u003c/li\u003e\n\u003cli\u003e推理质量通常更高（CoT 效应）\u003c/li\u003e\n\u003cli\u003e便于调试\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e劣势：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e消耗更多 Token（推理内容可能占输出的 50%+）\u003c/li\u003e\n\u003cli\u003e增加延迟\u003c/li\u003e\n\u003cli\u003e推理内容可能包含敏感的内部逻辑\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e隐式推理（Implicit Reasoning）：\u003c/strong\u003e 直接要求 LLM 输出最终决策，不要求中间过程。\u003c/p\u003e\n\u003cp\u003e优势：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eToken 用量更低，延迟更短\u003c/li\u003e\n\u003cli\u003e输出更简洁，解析更简单\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e劣势：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e黑盒，无法理解决策过程\u003c/li\u003e\n\u003cli\u003e在复杂场景下准确率下降明显\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e工程决策建议：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRouter 和 Executor（简单、确定性高）：倾向隐式推理，追求速度\u003c/li\u003e\n\u003cli\u003ePlanner 和 Reflector（复杂、需要判断）：必须显式推理，追求准确性和可审计性\u003c/li\u003e\n\u003cli\u003e在系统稳定后，可以通过 A/B 测试逐步将显式推理切换为隐式推理以降低成本\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e5. Few-shot vs Zero-shot 在 Agent 场景的选择\u003c/h2\u003e\n\u003cp\u003e这是 Agent Prompt 设计中一个重要但常被忽视的决策点。\u003c/p\u003e\n\u003ch3\u003e5.1 决策矩阵\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    输出结构化程度\n                 低 ◄──────────► 高\n                 │                │\n  任务复杂度  高  │  Few-shot      │  Zero-shot + Schema\n                 │  (复杂规划)     │  (结构化反思)\n                 │                │\n              低  │  Zero-shot     │  Zero-shot + Schema\n                 │  (简单对话)     │  (工具调用)\n                 │                │\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5.2 工具调用：Zero-shot 优先\u003c/h3\u003e\n\u003cp\u003e工具调用场景天然适合 Zero-shot。原因是 \u003cstrong\u003eJSON Schema 本身就是最好的\u0026quot;示例\u0026quot;\u003c/strong\u003e——它精确定义了每个参数的名称、类型、描述和约束，比任何 Few-shot 示例都更完整。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 工具调用不需要 few-shot，Schema 就是最好的约束\ntool_schema = {\n    \u0026quot;name\u0026quot;: \u0026quot;search_database\u0026quot;,\n    \u0026quot;description\u0026quot;: \u0026quot;Search the product database with filters\u0026quot;,\n    \u0026quot;parameters\u0026quot;: {\n        \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n        \u0026quot;properties\u0026quot;: {\n            \u0026quot;query\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;Search keywords\u0026quot;},\n            \u0026quot;category\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;,\n                \u0026quot;enum\u0026quot;: [\u0026quot;electronics\u0026quot;, \u0026quot;clothing\u0026quot;, \u0026quot;books\u0026quot;],\n                \u0026quot;description\u0026quot;: \u0026quot;Product category filter\u0026quot;\n            },\n            \u0026quot;max_results\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot;,\n                \u0026quot;default\u0026quot;: 10,\n                \u0026quot;minimum\u0026quot;: 1,\n                \u0026quot;maximum\u0026quot;: 100\n            }\n        },\n        \u0026quot;required\u0026quot;: [\u0026quot;query\u0026quot;]\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e加 Few-shot 反而可能引入问题：LLM 可能过度拟合示例中的具体值，而不是理解 Schema 的通用约束。\u003c/p\u003e\n\u003ch3\u003e5.3 复杂规划：Few-shot 有价值\u003c/h3\u003e\n\u003cp\u003e规划场景是 Few-shot 真正发挥价值的地方。因为\u0026quot;好的计划\u0026quot;是一个模糊的概念——仅凭输出格式定义不足以引导 LLM 产出高质量的计划。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ePLANNER_WITH_EXAMPLES = \u0026quot;\u0026quot;\u0026quot;You are a task planner.\n\n## Example 1: Multi-step data analysis\nUser: \u0026quot;Compare last month\u0026#39;s sales with the same period last year and visualize the trend\u0026quot;\nPlan:\n[\n  {{\u0026quot;step_id\u0026quot;: 1, \u0026quot;tool\u0026quot;: \u0026quot;data_query\u0026quot;, \u0026quot;input\u0026quot;: \u0026quot;sales data for 2025-07\u0026quot;, \u0026quot;depends_on\u0026quot;: []}},\n  {{\u0026quot;step_id\u0026quot;: 2, \u0026quot;tool\u0026quot;: \u0026quot;data_query\u0026quot;, \u0026quot;input\u0026quot;: \u0026quot;sales data for 2024-07\u0026quot;, \u0026quot;depends_on\u0026quot;: []}},\n  {{\u0026quot;step_id\u0026quot;: 3, \u0026quot;tool\u0026quot;: \u0026quot;data_compare\u0026quot;, \u0026quot;input\u0026quot;: \u0026quot;$step_1_result, $step_2_result\u0026quot;, \u0026quot;depends_on\u0026quot;: [1, 2]}},\n  {{\u0026quot;step_id\u0026quot;: 4, \u0026quot;tool\u0026quot;: \u0026quot;chart_gen\u0026quot;, \u0026quot;input\u0026quot;: \u0026quot;$step_3_result, type=line\u0026quot;, \u0026quot;depends_on\u0026quot;: [3]}}\n]\nNote: Steps 1 and 2 can run in parallel since they have no dependencies.\n\n## Example 2: Simple single-step task\nUser: \u0026quot;What\u0026#39;s the weather in Tokyo?\u0026quot;\nPlan:\n[\n  {{\u0026quot;step_id\u0026quot;: 1, \u0026quot;tool\u0026quot;: \u0026quot;weather_api\u0026quot;, \u0026quot;input\u0026quot;: \u0026quot;Tokyo\u0026quot;, \u0026quot;depends_on\u0026quot;: []}}\n]\nNote: Simple requests should NOT be over-decomposed.\n\n## Now plan for:\nUser: \u0026quot;{user_request}\u0026quot;\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFew-shot 示例在这里传递了两个关键信息：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e粒度标准\u003c/strong\u003e——什么程度的分解是合适的\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e并行意识\u003c/strong\u003e——独立步骤应该标记为可并行\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e5.4 反思评估：Zero-shot + 结构化输出\u003c/h3\u003e\n\u003cp\u003e反思（Reflection）场景适合 Zero-shot + 结构化输出。原因是反思本质上是\u0026quot;评判\u0026quot;，而评判标准已经通过评估维度（completeness / correctness / format）和评分规则完整定义了。给出 Few-shot 示例反而可能让 LLM 锚定在示例的评分上，而不是独立评估当前结果。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e总结决策原则：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e格式约束充分（JSON Schema / 评分规则）→ Zero-shot\u003c/li\u003e\n\u003cli\u003e需要传递\u0026quot;风格\u0026quot;或\u0026quot;粒度标准\u0026quot; → Few-shot\u003c/li\u003e\n\u003cli\u003e两者都可以时 → 优先 Zero-shot（更省 Token，更不容易过拟合）\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e6. Prompt 工程化实践\u003c/h2\u003e\n\u003cp\u003e当 Agent 系统超过原型阶段，Prompt 管理就变成了一个严肃的工程问题。\u003c/p\u003e\n\u003ch3\u003e6.1 Prompt 模板化\u003c/h3\u003e\n\u003cp\u003e核心思想：\u003cstrong\u003e分离静态结构和动态内容\u003c/strong\u003e。静态部分（身份定义、行为规则、输出格式）是模板，动态部分（工具列表、历史消息、当前状态）通过变量注入。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom typing import Any\nfrom string import Template\nimport hashlib\nimport json\nfrom datetime import datetime\n\n\nclass PromptTemplate:\n    \u0026quot;\u0026quot;\u0026quot;可管理、可版本化、可测试的 Prompt 模板\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, name: str, template: str, version: str,\n                 required_vars: list[str], metadata: dict | None = None):\n        self.name = name\n        self.template = template\n        self.version = version\n        self.required_vars = required_vars\n        self.metadata = metadata or {}\n        self._hash = hashlib.sha256(template.encode()).hexdigest()[:12]\n\n    def render(self, **kwargs) -\u0026gt; str:\n        # 校验所有必需变量都已提供\n        missing = set(self.required_vars) - set(kwargs.keys())\n        if missing:\n            raise ValueError(f\u0026quot;Missing required variables: {missing}\u0026quot;)\n\n        # 渲染模板\n        rendered = self.template\n        for key, value in kwargs.items():\n            placeholder = \u0026quot;{\u0026quot; + key + \u0026quot;}\u0026quot;\n            if isinstance(value, (dict, list)):\n                value = json.dumps(value, indent=2, ensure_ascii=False)\n            rendered = rendered.replace(placeholder, str(value))\n\n        return rendered\n\n    def fingerprint(self) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;返回模板内容的哈希指纹，用于版本追踪\u0026quot;\u0026quot;\u0026quot;\n        return f\u0026quot;{self.name}@{self.version}#{self._hash}\u0026quot;\n\n\nclass PromptRegistry:\n    \u0026quot;\u0026quot;\u0026quot;Prompt 模板注册中心：集中管理所有 Agent 使用的 Prompt\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._templates: dict[str, dict[str, PromptTemplate]] = {}  # name -\u0026gt; {version -\u0026gt; template}\n\n    def register(self, template: PromptTemplate):\n        if template.name not in self._templates:\n            self._templates[template.name] = {}\n        self._templates[template.name][template.version] = template\n\n    def get(self, name: str, version: str = \u0026quot;latest\u0026quot;) -\u0026gt; PromptTemplate:\n        if name not in self._templates:\n            raise KeyError(f\u0026quot;Template \u0026#39;{name}\u0026#39; not found\u0026quot;)\n\n        versions = self._templates[name]\n        if version == \u0026quot;latest\u0026quot;:\n            latest_version = sorted(versions.keys())[-1]\n            return versions[latest_version]\n\n        if version not in versions:\n            raise KeyError(f\u0026quot;Version \u0026#39;{version}\u0026#39; not found for template \u0026#39;{name}\u0026#39;\u0026quot;)\n        return versions[version]\n\n    def list_all(self) -\u0026gt; dict[str, list[str]]:\n        return {name: sorted(vers.keys()) for name, vers in self._templates.items()}\n\n\n# ── 使用示例 ──\n\nregistry = PromptRegistry()\n\n# 注册 Router Prompt v1\nregistry.register(PromptTemplate(\n    name=\u0026quot;router\u0026quot;,\n    version=\u0026quot;1.0\u0026quot;,\n    template=\u0026quot;\u0026quot;\u0026quot;You are a request router.\nAvailable tools: {tool_descriptions}\nRoute the following request: {user_input}\nOutput JSON: {{\u0026quot;tool_name\u0026quot;: \u0026quot;...\u0026quot;, \u0026quot;tool_input\u0026quot;: {{...}}}}\u0026quot;\u0026quot;\u0026quot;,\n    required_vars=[\u0026quot;tool_descriptions\u0026quot;, \u0026quot;user_input\u0026quot;],\n    metadata={\u0026quot;author\u0026quot;: \u0026quot;agent-team\u0026quot;, \u0026quot;last_tested\u0026quot;: \u0026quot;2025-08-10\u0026quot;}\n))\n\n# 注册 Router Prompt v2（增加了 confidence 字段）\nregistry.register(PromptTemplate(\n    name=\u0026quot;router\u0026quot;,\n    version=\u0026quot;2.0\u0026quot;,\n    template=\u0026quot;\u0026quot;\u0026quot;You are a request router. Your ONLY job is to route, not to answer.\nAvailable tools: {tool_descriptions}\nRoute the following request: {user_input}\nOutput JSON: {{\u0026quot;tool_name\u0026quot;: \u0026quot;...\u0026quot;, \u0026quot;tool_input\u0026quot;: {{...}}, \u0026quot;confidence\u0026quot;: \u0026lt;0.0-1.0\u0026gt;}}\u0026quot;\u0026quot;\u0026quot;,\n    required_vars=[\u0026quot;tool_descriptions\u0026quot;, \u0026quot;user_input\u0026quot;],\n    metadata={\u0026quot;author\u0026quot;: \u0026quot;agent-team\u0026quot;, \u0026quot;last_tested\u0026quot;: \u0026quot;2025-08-13\u0026quot;}\n))\n\n# 获取并渲染\nrouter_prompt = registry.get(\u0026quot;router\u0026quot;, version=\u0026quot;2.0\u0026quot;)\nfinal_prompt = router_prompt.render(\n    tool_descriptions=\u0026quot;1. web_search: Search the web\\n2. calculator: Do math\u0026quot;,\n    user_input=\u0026quot;What is 42 * 17?\u0026quot;\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.2 Prompt 版本控制\u003c/h3\u003e\n\u003cp\u003e为什么 Prompt 需要版本控制？因为 \u003cstrong\u003ePrompt 是 Agent 行为的源代码\u003c/strong\u003e。改一个词可能导致 Agent 行为的巨大变化——从正确路由变成错误路由，从结构化输出变成自由文本。\u003c/p\u003e\n\u003cp\u003e版本控制策略：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eprompts/\n├── router/\n│   ├── v1.0.txt          # 初始版本\n│   ├── v1.1.txt          # 修复：低 confidence 时的行为\n│   ├── v2.0.txt          # 重大变更：新增 confidence 字段\n│   └── changelog.md      # 变更记录\n├── planner/\n│   ├── v1.0.txt\n│   └── v1.1.txt\n├── executor/\n│   └── v1.0.txt\n└── reflector/\n    └── v1.0.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键实践：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e每次 Prompt 变更都有对应的测试结果\u003c/strong\u003e（下面会详述）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e生产环境使用固定版本号\u003c/strong\u003e，而非 \u0026quot;latest\u0026quot;\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e支持灰度发布\u003c/strong\u003e：新版 Prompt 可以先对 10% 的流量生效\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e保留回滚能力\u003c/strong\u003e：发现新版 Prompt 导致问题时，立即切回旧版\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e6.3 Prompt 测试\u003c/h3\u003e\n\u003cp\u003ePrompt 测试的核心挑战是 LLM 输出的非确定性。我们不能像测试普通函数那样做精确断言，但可以做\u003cstrong\u003e结构化断言\u003c/strong\u003e和\u003cstrong\u003e统计性断言\u003c/strong\u003e。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass\n\n@dataclass\nclass PromptTestCase:\n    name: str\n    input_vars: dict[str, Any]       # 模板变量\n    assertions: list[dict]            # 断言列表\n\n    # 断言类型：\n    # {\u0026quot;type\u0026quot;: \u0026quot;json_valid\u0026quot;}                           → 输出是合法 JSON\n    # {\u0026quot;type\u0026quot;: \u0026quot;has_field\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;tool_name\u0026quot;}      → JSON 中包含指定字段\n    # {\u0026quot;type\u0026quot;: \u0026quot;field_in\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;tool_name\u0026quot;, \u0026quot;values\u0026quot;: [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;]} → 字段值在范围内\n    # {\u0026quot;type\u0026quot;: \u0026quot;no_field\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;apology\u0026quot;}         → 不包含某字段（防止 LLM 废话）\n    # {\u0026quot;type\u0026quot;: \u0026quot;max_tokens\u0026quot;, \u0026quot;limit\u0026quot;: 200}             → 输出长度不超过限制\n\n\nclass PromptTestRunner:\n    def __init__(self, llm_client, template: PromptTemplate):\n        self.llm = llm_client\n        self.template = template\n\n    def run_test(self, test_case: PromptTestCase, n_runs: int = 5) -\u0026gt; dict:\n        \u0026quot;\u0026quot;\u0026quot;对同一个测试用例运行 N 次，统计通过率\u0026quot;\u0026quot;\u0026quot;\n        prompt = self.template.render(**test_case.input_vars)\n        results = []\n\n        for _ in range(n_runs):\n            output = self.llm.generate(prompt)\n            pass_all = True\n            details = []\n\n            for assertion in test_case.assertions:\n                passed = self._check_assertion(output, assertion)\n                details.append({\u0026quot;assertion\u0026quot;: assertion, \u0026quot;passed\u0026quot;: passed})\n                if not passed:\n                    pass_all = False\n\n            results.append({\u0026quot;output\u0026quot;: output, \u0026quot;passed\u0026quot;: pass_all, \u0026quot;details\u0026quot;: details})\n\n        pass_rate = sum(1 for r in results if r[\u0026quot;passed\u0026quot;]) / n_runs\n        return {\n            \u0026quot;test_case\u0026quot;: test_case.name,\n            \u0026quot;template\u0026quot;: self.template.fingerprint(),\n            \u0026quot;n_runs\u0026quot;: n_runs,\n            \u0026quot;pass_rate\u0026quot;: pass_rate,\n            \u0026quot;results\u0026quot;: results\n        }\n\n    def _check_assertion(self, output: str, assertion: dict) -\u0026gt; bool:\n        if assertion[\u0026quot;type\u0026quot;] == \u0026quot;json_valid\u0026quot;:\n            try:\n                json.loads(output)\n                return True\n            except json.JSONDecodeError:\n                return False\n\n        if assertion[\u0026quot;type\u0026quot;] == \u0026quot;has_field\u0026quot;:\n            try:\n                data = json.loads(output)\n                return assertion[\u0026quot;field\u0026quot;] in data\n            except (json.JSONDecodeError, TypeError):\n                return False\n\n        if assertion[\u0026quot;type\u0026quot;] == \u0026quot;field_in\u0026quot;:\n            try:\n                data = json.loads(output)\n                return data.get(assertion[\u0026quot;field\u0026quot;]) in assertion[\u0026quot;values\u0026quot;]\n            except (json.JSONDecodeError, TypeError):\n                return False\n\n        return False  # 未知断言类型\n\n\n# ── 测试用例示例 ──\n\ntest_cases = [\n    PromptTestCase(\n        name=\u0026quot;math_request_should_route_to_calculator\u0026quot;,\n        input_vars={\n            \u0026quot;tool_descriptions\u0026quot;: \u0026quot;1. web_search: Search the web\\n2. calculator: Do math\u0026quot;,\n            \u0026quot;user_input\u0026quot;: \u0026quot;What is 1024 * 768?\u0026quot;\n        },\n        assertions=[\n            {\u0026quot;type\u0026quot;: \u0026quot;json_valid\u0026quot;},\n            {\u0026quot;type\u0026quot;: \u0026quot;has_field\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;tool_name\u0026quot;},\n            {\u0026quot;type\u0026quot;: \u0026quot;field_in\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;tool_name\u0026quot;, \u0026quot;values\u0026quot;: [\u0026quot;calculator\u0026quot;]},\n        ]\n    ),\n    PromptTestCase(\n        name=\u0026quot;ambiguous_request_should_not_guess\u0026quot;,\n        input_vars={\n            \u0026quot;tool_descriptions\u0026quot;: \u0026quot;1. web_search: Search the web\\n2. calculator: Do math\u0026quot;,\n            \u0026quot;user_input\u0026quot;: \u0026quot;Help me with my project\u0026quot;\n        },\n        assertions=[\n            {\u0026quot;type\u0026quot;: \u0026quot;json_valid\u0026quot;},\n            {\u0026quot;type\u0026quot;: \u0026quot;has_field\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;tool_name\u0026quot;},\n            {\u0026quot;type\u0026quot;: \u0026quot;field_in\u0026quot;, \u0026quot;field\u0026quot;: \u0026quot;tool_name\u0026quot;, \u0026quot;values\u0026quot;: [\u0026quot;none\u0026quot;]},\n        ]\n    ),\n]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e测试策略建议：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每个 Prompt 版本至少 10 个测试用例，覆盖正常路径、边界情况和对抗输入\u003c/li\u003e\n\u003cli\u003e每个测试用例运行 5-10 次，要求通过率 \u0026gt;= 90%（而非 100%，因为 LLM 输出非确定性）\u003c/li\u003e\n\u003cli\u003e将测试集纳入 CI，每次 Prompt 变更触发回归测试\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e6.4 Prompt 组合：模块化拼装\u003c/h3\u003e\n\u003cp\u003e复杂 Agent 的 Prompt 往往由多个模块组合而成。与其维护一个巨大的单体 Prompt，不如将其拆分为可复用的模块：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass PromptComposer:\n    \u0026quot;\u0026quot;\u0026quot;将多个 Prompt 模块按顺序组合\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._modules: list[tuple[str, PromptTemplate]] = []\n\n    def add(self, section_name: str, template: PromptTemplate):\n        self._modules.append((section_name, template))\n        return self  # 支持链式调用\n\n    def compose(self, **all_vars) -\u0026gt; str:\n        sections = []\n        for section_name, template in self._modules:\n            # 每个模块只取自己需要的变量\n            relevant_vars = {k: v for k, v in all_vars.items()\n                           if k in template.required_vars}\n            rendered = template.render(**relevant_vars)\n            sections.append(f\u0026quot;## {section_name}\\n{rendered}\u0026quot;)\n        return \u0026quot;\\n\\n\u0026quot;.join(sections)\n\n\n# 使用方式\nidentity_module = PromptTemplate(\n    name=\u0026quot;identity\u0026quot;, version=\u0026quot;1.0\u0026quot;,\n    template=\u0026quot;You are {agent_role}. {agent_description}\u0026quot;,\n    required_vars=[\u0026quot;agent_role\u0026quot;, \u0026quot;agent_description\u0026quot;]\n)\n\ntools_module = PromptTemplate(\n    name=\u0026quot;tools\u0026quot;, version=\u0026quot;1.0\u0026quot;,\n    template=\u0026quot;Available tools:\\n{tool_descriptions}\u0026quot;,\n    required_vars=[\u0026quot;tool_descriptions\u0026quot;]\n)\n\noutput_format_module = PromptTemplate(\n    name=\u0026quot;output_format\u0026quot;, version=\u0026quot;1.0\u0026quot;,\n    template=\u0026quot;You MUST respond in the following JSON format:\\n{json_schema}\u0026quot;,\n    required_vars=[\u0026quot;json_schema\u0026quot;]\n)\n\nconstraints_module = PromptTemplate(\n    name=\u0026quot;constraints\u0026quot;, version=\u0026quot;1.0\u0026quot;,\n    template=\u0026quot;Constraints:\\n{constraint_list}\u0026quot;,\n    required_vars=[\u0026quot;constraint_list\u0026quot;]\n)\n\n# 组合\ncomposer = PromptComposer()\ncomposer.add(\u0026quot;Identity\u0026quot;, identity_module) \\\n        .add(\u0026quot;Tools\u0026quot;, tools_module) \\\n        .add(\u0026quot;Output Format\u0026quot;, output_format_module) \\\n        .add(\u0026quot;Constraints\u0026quot;, constraints_module)\n\nfinal_prompt = composer.compose(\n    agent_role=\u0026quot;a task router\u0026quot;,\n    agent_description=\u0026quot;You route user requests to the appropriate tool.\u0026quot;,\n    tool_descriptions=\u0026quot;1. search: web search\\n2. calc: calculator\u0026quot;,\n    json_schema=\u0026#39;{\u0026quot;tool_name\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;tool_input\u0026quot;: \u0026quot;object\u0026quot;}\u0026#39;,\n    constraint_list=\u0026quot;- Never fabricate tool names\\n- Always return valid JSON\u0026quot;\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e模块化的好处：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e同一个 \u003ccode\u003eoutput_format_module\u003c/code\u003e 可以被 Router、Planner、Executor 共享\u003c/li\u003e\n\u003cli\u003e修改 constraints 不需要触碰 identity 和 tools 部分\u003c/li\u003e\n\u003cli\u003e每个模块可以独立测试和版本控制\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Context Window 管理\u003c/h2\u003e\n\u003cp\u003eAgent 的 Context Window 管理是一个独特且关键的工程挑战。与 Chatbot 的\u0026quot;对话越长体验越差\u0026quot;不同，Agent 的 context 膨胀会直接导致\u003cstrong\u003e系统性故障\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e7.1 Agent 的 Context 膨胀问题\u003c/h3\u003e\n\u003cp\u003eAgent 的 context 会从三个维度快速膨胀：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTurn 1:  System(2000) + User(200) + Response(500)              = 2,700 tokens\nTurn 2:  + Tool_Result(3000) + Response(800)                   = 6,500 tokens\nTurn 3:  + Tool_Result(5000) + Error_Msg(1000) + Response(600) = 13,100 tokens\nTurn 4:  + Tool_Result(2000) + Response(400)                   = 15,500 tokens\nTurn 5:  + RAG_Context(4000) + Response(1000)                  = 20,500 tokens\n  ...\nTurn 10: 很容易突破 50,000 tokens\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e三大膨胀源：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e工具返回值\u003c/strong\u003e：一次数据库查询可能返回几千 token 的 JSON，一次网页抓取可能返回上万 token\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e历史消息积累\u003c/strong\u003e：每一轮的 user message + assistant response + tool calls 都在累积\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e错误信息\u003c/strong\u003e：工具调用失败的 traceback、重试过程中的冗余信息\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e7.2 消息压缩策略\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e策略 1：摘要压缩（Summarization）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将早期的对话历史压缩为摘要，只保留关键事实和决策结果。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef compress_history(messages: list[dict], llm_client,\n                     keep_recent: int = 4) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;将早期历史压缩为摘要，保留最近 N 轮完整消息\u0026quot;\u0026quot;\u0026quot;\n    if len(messages) \u0026lt;= keep_recent:\n        return messages\n\n    old_messages = messages[:-keep_recent]\n    recent_messages = messages[-keep_recent:]\n\n    # 用 LLM 生成摘要\n    summary_prompt = f\u0026quot;\u0026quot;\u0026quot;Summarize the following conversation history into key facts\nand decisions. Keep only information that might be needed for future steps.\nBe concise — maximum 200 words.\n\n{format_messages(old_messages)}\u0026quot;\u0026quot;\u0026quot;\n\n    summary = llm_client.generate(summary_prompt)\n\n    # 将摘要作为一条 system message 注入\n    summary_message = {\n        \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n        \u0026quot;content\u0026quot;: f\u0026quot;[Conversation Summary]\\n{summary}\u0026quot;\n    }\n\n    return [summary_message] + recent_messages\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e策略 2：滑动窗口（Sliding Window）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e更简单粗暴——只保留最近 N 条消息，丢弃更早的消息。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef sliding_window(messages: list[dict], max_messages: int = 10) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;保留 system message + 最近 N 条消息\u0026quot;\u0026quot;\u0026quot;\n    system_msgs = [m for m in messages if m[\u0026quot;role\u0026quot;] == \u0026quot;system\u0026quot;]\n    non_system = [m for m in messages if m[\u0026quot;role\u0026quot;] != \u0026quot;system\u0026quot;]\n    return system_msgs + non_system[-max_messages:]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e策略 3：选择性保留（Selective Retention）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e根据消息的\u0026quot;重要性\u0026quot;决定保留还是丢弃。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef selective_retain(messages: list[dict], token_budget: int) -\u0026gt; list[dict]:\n    \u0026quot;\u0026quot;\u0026quot;按重要性保留消息，直到填满 token 预算\u0026quot;\u0026quot;\u0026quot;\n\n    def importance_score(msg: dict) -\u0026gt; int:\n        if msg[\u0026quot;role\u0026quot;] == \u0026quot;system\u0026quot;:\n            return 100  # 永远保留\n        if msg.get(\u0026quot;is_final_result\u0026quot;):\n            return 90   # 最终结果必须保留\n        if msg[\u0026quot;role\u0026quot;] == \u0026quot;user\u0026quot;:\n            return 80   # 用户输入高优先\n        if msg.get(\u0026quot;tool_error\u0026quot;):\n            return 20   # 错误信息低优先（已经被处理过了）\n        if msg.get(\u0026quot;tool_result\u0026quot;):\n            return 40   # 工具结果中等优先\n        return 50\n\n    scored = [(importance_score(m), i, m) for i, m in enumerate(messages)]\n    scored.sort(key=lambda x: (-x[0], x[1]))  # 按重要性降序，原始顺序升序\n\n    retained = []\n    used_tokens = 0\n    for score, idx, msg in scored:\n        msg_tokens = estimate_tokens(msg[\u0026quot;content\u0026quot;])\n        if used_tokens + msg_tokens \u0026lt;= token_budget:\n            retained.append((idx, msg))\n            used_tokens += msg_tokens\n\n    # 恢复原始顺序\n    retained.sort(key=lambda x: x[0])\n    return [msg for _, msg in retained]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.3 Token 预算分配\u003c/h3\u003e\n\u003cp\u003e一个经验性的 Token 预算分配方案（以 8K context window 为例）：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTotal Context Window: 8,192 tokens\n                    │\n    ┌───────────────┼───────────────┐\n    │               │               │\nSystem Prompt    Working Area     Reserved for\n  ~25%            ~60%            Output ~15%\n (2,048)         (4,915)          (1,229)\n    │               │\n    │         ┌─────┴──────┐\n    │         │            │\n    │    Tool Descs    History + State\n    │     ~15%          ~45%\n    │    (1,229)       (3,686)\n    │\n    ├── Identity \u0026amp; Role: 500\n    ├── Behavior Rules: 800\n    ├── Output Format: 500\n    └── Constraints: 248\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键原则：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOutput Reserved 不能省\u003c/strong\u003e：如果留给输出的空间不足，LLM 会输出截断的 JSON，导致解析失败\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSystem Prompt 预算固定\u003c/strong\u003e：行为约束不能因为 context 紧张而被裁剪\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHistory 是最大的压缩空间\u003c/strong\u003e：优先在这里节省 Token\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e工具描述可以按需加载\u003c/strong\u003e：如果 Router 已经选定了工具，后续 Executor 只需要注入被选中工具的描述，而非全部工具\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.4 工具返回值的处理\u003c/h3\u003e\n\u003cp\u003e工具返回值是 context 膨胀的最大单点源头。以下是几种处理策略：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef process_tool_result(result: str, max_tokens: int = 1500) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;处理工具返回值，防止 context 爆炸\u0026quot;\u0026quot;\u0026quot;\n\n    result_tokens = estimate_tokens(result)\n\n    if result_tokens \u0026lt;= max_tokens:\n        return result\n\n    # 策略 1：截断（适用于文本类结果）\n    if is_text(result):\n        return truncate_to_tokens(result, max_tokens) + \u0026quot;\\n[... truncated]\u0026quot;\n\n    # 策略 2：提取摘要（适用于 JSON 类结果）\n    if is_json(result):\n        data = json.loads(result)\n        if isinstance(data, list):\n            # 只保留前 N 条记录 + 总数信息\n            summary = {\n                \u0026quot;total_count\u0026quot;: len(data),\n                \u0026quot;showing_first\u0026quot;: 5,\n                \u0026quot;records\u0026quot;: data[:5],\n                \u0026quot;note\u0026quot;: f\u0026quot;Truncated from {len(data)} records. Request specific filters for more.\u0026quot;\n            }\n            return json.dumps(summary, ensure_ascii=False, indent=2)\n\n    # 策略 3：兜底截断\n    return truncate_to_tokens(result, max_tokens) + \u0026quot;\\n[... truncated]\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 常见陷阱\u003c/h2\u003e\n\u003ch3\u003e8.1 Prompt 太长导致 LLM \u0026quot;忘记\u0026quot;关键指令\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e现象：\u003c/strong\u003e System Prompt 有 3000 token，其中包含 20 条行为规则。LLM 在前几轮严格遵守，但随着 context 变长，开始\u0026quot;遗忘\u0026quot;中间的规则——尤其是第 8-15 条。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e原因：\u003c/strong\u003e LLM 对 prompt 中不同位置内容的\u0026quot;注意力\u0026quot;不均匀。开头和结尾的内容通常被更好地遵循（primacy effect 和 recency effect），中间的内容最容易被忽略。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e应对：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e将最关键的规则放在 System Prompt 的开头和结尾\u003c/li\u003e\n\u003cli\u003e将规则数量控制在 7 条以内（与人类工作记忆容量一致，也利于 LLM）\u003c/li\u003e\n\u003cli\u003e在消息末尾添加 reminder：\u0026quot;Remember: always output valid JSON. Never fabricate tool names.\u0026quot;\u003c/li\u003e\n\u003cli\u003e按当前 Turn 的需要动态注入最相关的规则子集，而非每次都注入全部规则\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e8.2 工具描述和 System Prompt 冲突\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e现象：\u003c/strong\u003e System Prompt 说\u0026quot;不要执行任何数据删除操作\u0026quot;，但某个工具的 description 中包含\u0026quot;Deletes records matching the query\u0026quot;。LLM 收到删除请求时，行为不确定——有时遵循 System Prompt 的禁令，有时遵循工具描述的能力。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e原因：\u003c/strong\u003e LLM 看到的是拼装后的完整 prompt，它不理解\u0026quot;System Prompt 优先级高于工具描述\u0026quot;这个层级关系。两段相互矛盾的文本让 LLM 陷入冲突。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e应对：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e在 Prompt 组装阶段做\u003cstrong\u003e一致性检查\u003c/strong\u003e：扫描工具描述中的关键词，与 System Prompt 的禁止列表做匹配\u003c/li\u003e\n\u003cli\u003e如果某个工具被禁用，\u003cstrong\u003e直接不注入它的描述\u003c/strong\u003e，而不是注入描述然后在 System Prompt 中禁止\u003c/li\u003e\n\u003cli\u003e在 System Prompt 中明确声明优先级：\u0026quot;If any tool description conflicts with these rules, these rules take priority.\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e8.3 过度约束导致 LLM 无法灵活应对\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e现象：\u003c/strong\u003e 为了保证安全，System Prompt 中加了大量限制：\u0026quot;只能调用列表中的工具\u0026quot;、\u0026quot;只能输出 JSON\u0026quot;、\u0026quot;不能包含任何解释\u0026quot;、\u0026quot;不能问用户问题\u0026quot;、\u0026quot;必须在一次调用中完成\u0026quot;......结果 LLM 在遇到无法处理的请求时，输出空 JSON 或无意义的工具调用，而不是合理地拒绝或请求澄清。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e原因：\u003c/strong\u003e 过度约束堵死了 LLM 所有的\u0026quot;逃生通道\u0026quot;。它没有被允许说\u0026quot;我不知道\u0026quot;或\u0026quot;我需要更多信息\u0026quot;，所以只能在约束框架内硬凑一个输出。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e应对：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e永远为 LLM 保留一个\u0026quot;安全出口\u0026quot;：允许它输出 \u003ccode\u003e{\u0026quot;action\u0026quot;: \u0026quot;clarify\u0026quot;, \u0026quot;question\u0026quot;: \u0026quot;...\u0026quot;}\u003c/code\u003e 或 \u003ccode\u003e{\u0026quot;action\u0026quot;: \u0026quot;refuse\u0026quot;, \u0026quot;reason\u0026quot;: \u0026quot;...\u0026quot;}\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e区分\u0026quot;硬约束\u0026quot;和\u0026quot;软约束\u0026quot;：硬约束（安全规则）不可违反，软约束（输出偏好）在特殊情况下可以放松\u003c/li\u003e\n\u003cli\u003e将约束从\u0026quot;禁止列表\u0026quot;改为\u0026quot;优先级列表\u0026quot;：先尝试 X，如果不行可以 Y，最后可以 Z\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e8.4 Prompt Injection 在 Agent 中的放大效应\u003c/h3\u003e\n\u003cp\u003e在 Chatbot 中，Prompt Injection 最多让模型输出不当内容。但在 Agent 中，Prompt Injection 可能触发\u003cstrong\u003e真实的工具调用\u003c/strong\u003e——删除数据、发送邮件、调用 API。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e应对：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e用户输入和系统指令之间必须有明确的分隔标记\u003c/li\u003e\n\u003cli\u003e工具调用前做参数校验（schema validation），而非完全信任 LLM 输出\u003c/li\u003e\n\u003cli\u003e高危操作（删除、支付、发送）增加人工确认步骤\u003c/li\u003e\n\u003cli\u003e将用户输入视为\u0026quot;不可信数据\u0026quot;，在 Prompt 中明确标注：\u003ccode\u003e[USER INPUT - UNTRUSTED]: {user_message}\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 结语：从 Prompt 到 Runtime\u003c/h2\u003e\n\u003cp\u003ePrompt Engineering for Agents 的本质是\u003cstrong\u003e为 LLM 定义一套可编程的行为接口\u003c/strong\u003e。我们在本文中讨论了分层架构、设计模式、推理策略、测试方法和 context 管理——这些都是让 Agent \u0026quot;可控\u0026quot;的基础设施。\u003c/p\u003e\n\u003cp\u003e但 Prompt 本身只是 Agent 系统的一个组件。再好的 Prompt 也需要一个可靠的 Runtime 来驱动——处理 LLM 的响应、管理状态机的转换、执行工具调用、处理错误和重试。\u003c/p\u003e\n\u003cp\u003e下一篇文章《Agent Runtime from Scratch: 不依赖框架构建 Agent》将从零开始实现一个完整的 Agent 运行时。我们会把本文设计的 Prompt 模式，放进一个真实可运行的控制循环中，展示 Prompt、工具、状态管理和错误处理如何在代码层面协同工作。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e进一步思考：\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003ePrompt 的自动优化\u003c/strong\u003e：如果我们有了 Prompt 测试框架和评估指标，是否可以用搜索算法（DSPy 的思路）自动优化 Prompt？这和手工调优的 trade-off 在哪里？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eMulti-Model Prompt 策略\u003c/strong\u003e：Router 用小模型（快、便宜），Planner 用大模型（准、贵），Executor 用中等模型。不同模型对 Prompt 的响应特性不同，如何为不同模型定制 Prompt？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003ePrompt 的可解释性\u003c/strong\u003e：当 Agent 做出错误决策时，我们如何从 Prompt 和输出中定位问题根因？这需要什么样的 observability 基础设施？\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e动态 Prompt 生成\u003c/strong\u003e：是否可以让一个 \u0026quot;Meta-Agent\u0026quot; 根据当前任务特征，动态生成最合适的 Prompt？这会引入什么样的复杂性和风险？\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 06 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/05-Tool%20Calling%20Deep%20Dive\"\u003e05 | Tool Calling Deep Dive\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/07-Agent%20Runtime%20from%20Scratch\"\u003e07 | Agent Runtime from Scratch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-1 text-sm mb-4\",\"children\":[[\"$\",\"$L13\",null,{\"href\":\"/blog/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"博客\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"Engineering\"}],[[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/agentic/page/1\",\"className\":\"text-blue-600 hover:text-blue-700 transition-colors\",\"children\":\"Agentic 系统\"}]]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center mb-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-4 h-4 mr-2 text-gray-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z\"}]}],[\"$\",\"time\",null,{\"dateTime\":\"2025-12-18\",\"children\":\"2025年12月18日\"}]]}]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-6 text-center\",\"children\":\"Tool Calling Deep Dive: 让 LLM 成为可编程接口\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6 justify-center\",\"children\":[[\"$\",\"$L13\",\"Agentic\",{\"href\":\"/blog/tag/Agentic/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Agentic\"}],[\"$\",\"$L13\",\"AI Engineering\",{\"href\":\"/blog/tag/AI%20Engineering/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"AI Engineering\"}],[\"$\",\"$L13\",\"Tool Calling\",{\"href\":\"/blog/tag/Tool%20Calling/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Tool Calling\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto\",\"children\":[\"$\",\"$L14\",null,{\"content\":\"$15\"}]}],[\"$\",\"$10\",null,{\"fallback\":[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":\"加载导航中...\"}],\"children\":[\"$\",\"$L16\",null,{\"globalNav\":{\"prev\":{\"slug\":\"engineering/architecture/高并发系统设计：原理、策略与工程实践\",\"title\":\"高并发系统设计：原理、策略与工程实践\",\"description\":\"系统梳理高并发架构的核心设计策略，从计算层、数据层、流量层到容错层，逐一分析每种策略的适用原理、决策依据与工程实践，构建可落地的高并发设计知识体系。\",\"pubDate\":\"2025-12-15\",\"tags\":[\"高并发\",\"系统架构\",\"性能优化\",\"分布式系统\"],\"heroImage\":\"$undefined\",\"content\":\"$17\"},\"next\":{\"slug\":\"engineering/architecture/架构师的认知升级：从技术深度到系统决策能力\",\"title\":\"架构师的认知升级：从技术深度到系统决策能力\",\"description\":\"系统梳理架构师的核心能力模型、知识体系全景与成长路径，从架构定义到设计方法论，从分布式理论到架构演进，帮助技术人建立完整的架构认知框架。\",\"pubDate\":\"2025-12-20\",\"tags\":[\"架构设计\",\"架构师\",\"技术成长\",\"分布式系统\",\"架构方法论\"],\"heroImage\":\"$undefined\",\"content\":\"$18\"}},\"tagNav\":{\"Agentic\":{\"prev\":{\"slug\":\"engineering/agentic/04-The Agent Control Loop\",\"title\":\"The Agent Control Loop: Agent 运行时的核心抽象\",\"description\":\"Agent 的本质不是一次函数调用，而是一个可中断的控制循环。本文从状态机模型出发，深入剖析 Agent Control Loop 的每个阶段——OBSERVE、THINK、ACT、REFLECT，对比 ReAct 与 Plan-then-Execute 两种主流模式，讨论状态管理、错误处理与性能优化策略，并给出一个不依赖任何框架的完整 Python 实现。\",\"pubDate\":\"2025-12-14\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Runtime\"],\"heroImage\":\"$undefined\",\"content\":\"$19\"},\"next\":{\"slug\":\"engineering/agentic/06-Prompt Engineering for Agents\",\"title\":\"Prompt Engineering for Agents: 面向 Agent 的提示词工程\",\"description\":\"Agent 的 Prompt 不是聊天提示词，而是系统接口规范。本文系统拆解 Agent Prompt 的分层架构、四种关键设计模式（Router / Planner / Executor / Reflector）、Chain-of-Thought 的 Agent 化应用、Few-shot vs Zero-shot 的场景选择、Prompt 工程化实践（模板化 / 版本控制 / 测试 / 组合），以及 Context Window 管理策略。\",\"pubDate\":\"2025-12-23\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Prompt Engineering\"],\"heroImage\":\"$undefined\",\"content\":\"$1a\"}},\"AI Engineering\":{\"prev\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:prev\",\"next\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:next\"},\"Tool Calling\":{\"prev\":null,\"next\":null}}}]}],[\"$\",\"$L1b\",null,{}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"8:null\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"a:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Tool Calling Deep Dive: 让 LLM 成为可编程接口 - Skyfalling Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Tool Calling Deep Dive: 让 LLM 成为可编程接口\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"5\",{\"property\":\"article:published_time\",\"content\":\"2025-12-18\"}],[\"$\",\"meta\",\"6\",{\"property\":\"article:author\",\"content\":\"Skyfalling\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Tool Calling Deep Dive: 让 LLM 成为可编程接口\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Tool Calling 是 LLM 从「对话机器」变成「可编程接口」的关键转折点。本文从底层原理出发，系统拆解 Tool Calling 的工作机制、JSON Schema 契约设计、工具注册与发现策略、错误处理、安全性考量及关键 Trade-off，附带完整可运行代码。\"}],[\"$\",\"link\",\"10\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"13\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n12:{\"metadata\":\"$a:metadata\",\"error\":null,\"di"])</script><script>self.__next_f.push([1,"gest\":\"$undefined\"}\n"])</script></body></html>