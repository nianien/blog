<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/7dd6b3ec14b0b1d8.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42d55485b4428e47.js"/><script src="/_next/static/chunks/4bd1b696-8ec333fca6b38e39.js" async=""></script><script src="/_next/static/chunks/1684-a2aac8a674e5d38c.js" async=""></script><script src="/_next/static/chunks/main-app-2791dc86ed05573e.js" async=""></script><script src="/_next/static/chunks/6874-7791217feaf05c17.js" async=""></script><script src="/_next/static/chunks/app/layout-142e67ac4336647c.js" async=""></script><script src="/_next/static/chunks/968-d7155a2506e36f1d.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js" async=""></script><meta name="next-size-adjust" content=""/><title>From LLM to Agent: Agentic 系统的知识地图 - Skyfalling Blog</title><meta name="description" content="Agentic 系列开篇。从 LLM 的局限出发，定义 Agent 的核心组成，绘制 Agentic 系统全景架构图，并通过代码演示从 ChatCompletion 到完整 Agent 的演进路径。本文是整个系列 14 篇文章的精神锚点与导航地图。"/><meta property="og:title" content="From LLM to Agent: Agentic 系统的知识地图"/><meta property="og:description" content="Agentic 系列开篇。从 LLM 的局限出发，定义 Agent 的核心组成，绘制 Agentic 系统全景架构图，并通过代码演示从 ChatCompletion 到完整 Agent 的演进路径。本文是整个系列 14 篇文章的精神锚点与导航地图。"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-12-01"/><meta property="article:author" content="Skyfalling"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="From LLM to Agent: Agentic 系统的知识地图"/><meta name="twitter:description" content="Agentic 系列开篇。从 LLM 的局限出发，定义 Agent 的核心组成，绘制 Agentic 系统全景架构图，并通过代码演示从 ChatCompletion 到完整 Agent 的演进路径。本文是整个系列 14 篇文章的精神锚点与导航地图。"/><link rel="shortcut icon" href="/favicon.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/favicon.png"/><link rel="apple-touch-icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen flex flex-col"><header class="bg-[var(--background)]"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a class="-m-1.5 p-1.5" href="/"><span class="sr-only">Skyfalling Blog</span><span class="text-2xl font-bold text-gray-900">Skyfalling</span></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">打开主菜单</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/">首页</a><a class="text-base font-semibold leading-6 transition-colors text-blue-600 border-b-2 border-blue-600 pb-1" href="/blog/">博客</a><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/about/">关于</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"></div></nav></header><main class="flex-1"><article class="min-h-screen"><div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8"><div class="rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12"><header class="mb-8"><nav class="flex items-center gap-1 text-sm mb-4"><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/page/1/">博客</a><span class="text-gray-300">/</span><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/category/engineering/page/1/">Engineering</a><span class="text-gray-300">/</span><a class="text-blue-600 hover:text-blue-700 transition-colors" href="/blog/category/engineering/agentic/page/1/">Agentic 系统</a></nav><div class="flex items-center mb-6"><div class="inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal"><svg class="w-4 h-4 mr-2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2025-12-01">2025年12月01日</time></div></div><h1 class="text-4xl font-bold text-gray-900 mb-6 text-center">From LLM to Agent: Agentic 系统的知识地图</h1><div class="flex flex-wrap gap-2 mb-6 justify-center"><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Agentic/page/1/">Agentic</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/AI%20Engineering/page/1/">AI Engineering</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/LLM/page/1/">LLM</a></div></header><div class="max-w-5xl mx-auto"><div class="prose prose-lg prose-gray mx-auto max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:text-blue-700 prose-strong:text-gray-900 prose-strong:font-semibold prose-li:text-gray-700 prose-hr:border-gray-300"><h1>From LLM to Agent: Agentic 系统的知识地图</h1>
<blockquote>
<p>大语言模型是一个令人惊叹的函数：Text In, Text Out。但函数不等于系统，生成不等于行动，回答不等于解决。</p>
<p>本文是 Agentic 系列 14 篇文章的开篇。我们将从&quot;LLM 能做什么&quot;出发，推导出&quot;Agent 必须做什么&quot;，然后为整个系列绘制一张完整的知识地图。</p>
</blockquote>
<hr>
<h2>1. 为什么需要从 LLM 走向 Agent</h2>
<h3>1.1 LLM 是一个了不起的函数</h3>
<p>2022 年底以来，以 GPT-4、Claude、Gemini 为代表的大语言模型展示了令人印象深刻的能力：理解自然语言、生成结构化文本、进行多步推理、甚至通过各类考试。但如果我们冷静地回到工程视角，LLM 本质上是一个<strong>无状态的文本映射函数</strong>：</p>
<pre><code>f(prompt: str, context: str) → response: str
</code></pre>
<p>它接收一段文本，返回一段文本。仅此而已。</p>
<h3>1.2 LLM 的五个结构性局限</h3>
<p>当你试图用 LLM 解决真实世界的任务时，会迅速撞上以下墙壁：</p>
<table>
<thead>
<tr>
<th>局限</th>
<th>本质原因</th>
<th>后果</th>
</tr>
</thead>
<tbody><tr>
<td><strong>知识静态</strong></td>
<td>训练数据有截止日期</td>
<td>无法回答实时问题，产生幻觉</td>
</tr>
<tr>
<td><strong>无法行动</strong></td>
<td>输出是文本，不是可执行指令</td>
<td>不能查数据库、调 API、操作文件</td>
</tr>
<tr>
<td><strong>记忆易失</strong></td>
<td>上下文窗口有限且无持久状态</td>
<td>长对话丢失信息，跨会话失忆</td>
</tr>
<tr>
<td><strong>单步思维</strong></td>
<td>一次 completion 只做一次推理</td>
<td>复杂任务无法分解、无法迭代</td>
</tr>
<tr>
<td><strong>不会反思</strong></td>
<td>不检查自己的输出质量</td>
<td>错误会被自信地传递下去</td>
</tr>
</tbody></table>
<p>这五个局限不是&quot;模型不够大&quot;能解决的问题——它们是<strong>架构层面的缺失</strong>。更大的模型只是让函数 <code>f</code> 更强，但不会让函数变成系统。</p>
<h3>1.3 从函数到系统的必然性</h3>
<p>真实世界的任务天然具有以下特征：</p>
<ul>
<li><strong>需要多步执行</strong>：完成一次数据分析需要查询 → 清洗 → 计算 → 可视化</li>
<li><strong>需要外部交互</strong>：查实时数据、调第三方 API、读写文件</li>
<li><strong>需要持久记忆</strong>：记住用户偏好、历史决策、领域知识</li>
<li><strong>需要自我纠错</strong>：发现错误后能回退、重试、换策略</li>
<li><strong>需要可靠执行</strong>：有超时、有重试、有降级、有审计</li>
</ul>
<p>当这些需求叠加在一起，你需要的不再是一个&quot;更好的 prompt&quot;，而是一个<strong>围绕 LLM 构建的系统</strong>。这个系统，就是 Agent。</p>
<hr>
<h2>2. 定义 Agent</h2>
<h3>2.1 一个精确的定义</h3>
<p><strong>Agent = LLM + Memory + Tools + Planner + Runtime</strong></p>
<p>这不是随意的拼凑，而是对上一节五个局限的逐一回应：</p>
<pre><code>局限：知识静态     → 解法：Memory（外部知识 + RAG）
局限：无法行动     → 解法：Tools（函数调用 + 外部接口）
局限：记忆易失     → 解法：Memory（会话状态 + 持久化记忆）
局限：单步思维     → 解法：Planner（任务分解 + 多步规划）
局限：不会反思     → 解法：Runtime（控制循环 + 反思机制）
</code></pre>
<p>每个组件都有明确的职责：</p>
<ul>
<li><strong>LLM</strong>：核心推理引擎。理解意图、生成计划、选择工具、产出结果。它是&quot;大脑&quot;，但不是全部。</li>
<li><strong>Memory</strong>：分为短期记忆（当前对话上下文、工作区状态）和长期记忆（向量数据库中的文档、用户画像、历史经验）。短期记忆保证连贯性，长期记忆突破知识边界。</li>
<li><strong>Tools</strong>：Agent 与外部世界的接口。一个 Tool 就是一个带有 JSON Schema 描述的可调用函数。搜索引擎、数据库查询、代码执行器、API 网关——都是 Tool。</li>
<li><strong>Planner</strong>：将复杂任务分解为可执行的子步骤。从简单的 ReAct（交替推理和行动）到复杂的分层规划（Hierarchical Planning），Planner 决定了 Agent 的&quot;智商上限&quot;。</li>
<li><strong>Runtime</strong>：Agent 的执行环境。负责控制循环的调度、工具调用的执行、错误处理、超时控制、状态持久化。没有 Runtime，前面四个组件只是散落的零件。</li>
</ul>
<h3>2.2 Agent 与 LLM 的本质差异</h3>
<p>用一个类比来强化理解：</p>
<pre><code>LLM  ≈ CPU             —— 强大的计算单元，但单独无法工作
Agent ≈ Operating System —— 围绕 CPU 构建的完整运行时

LLM  是 Pure Function   —— 相同输入，相同输出，无副作用
Agent 是 Stateful System —— 有状态、有副作用、有执行循环
</code></pre>
<p>这个区分极其重要。很多团队把 LLM 当 Agent 用（期望一次 prompt 解决所有问题），或者把 Agent 当 LLM 用（忽略控制循环和状态管理），都会走进死胡同。</p>
<hr>
<h2>3. Agent 的核心控制循环</h2>
<p>Agent 之所以能完成复杂任务，核心在于它运行一个<strong>持续的控制循环</strong>。这个循环可以抽象为六个阶段：</p>
<pre><code>                    ┌──────────────────────────────────┐
                    │         Agent Control Loop        │
                    └──────────────────────────────────┘

                           ┌─────────────┐
                     ┌────▶│   Observe   │─────┐
                     │     │ (感知输入)   │     │
                     │     └─────────────┘     │
                     │                          ▼
              ┌──────┴──────┐           ┌─────────────┐
              │    Update   │           │    Think    │
              │ (更新状态)   │           │ (理解意图)   │
              └──────┬──────┘           └──────┬──────┘
                     ▲                          │
                     │                          ▼
              ┌──────┴──────┐           ┌─────────────┐
              │   Reflect   │           │    Plan     │
              │ (评估结果)   │◀──────────│ (制定计划)   │
              └─────────────┘           └──────┬──────┘
                                               │
                                               ▼
                                        ┌─────────────┐
                                        │     Act     │
                                        │ (执行动作)   │
                                        └─────────────┘
</code></pre>
<p>各阶段职责：</p>
<ol>
<li><strong>Observe（感知）</strong>：接收用户输入或环境变化。不仅是文本——可能是工具返回的结果、系统事件、定时触发。</li>
<li><strong>Think（思考）</strong>：LLM 理解当前状态和目标。这一步对应 prompt 中的 System Message 和上下文组装。</li>
<li><strong>Plan（规划）</strong>：决定下一步做什么。可能是调用工具、请求更多信息、或直接回答。ReAct 框架在此步生成 Thought + Action。</li>
<li><strong>Act（执行）</strong>：真正执行动作。调用 API、查询数据库、运行代码、生成文件。这一步有<strong>副作用</strong>。</li>
<li><strong>Reflect（反思）</strong>：检查执行结果是否符合预期。结果有错误？重试。结果不完整？补充。任务完成？退出循环。</li>
<li><strong>Update（更新）</strong>：将本轮的观察、决策、结果写入记忆。更新会话上下文，可能也写入长期记忆。</li>
</ol>
<p><strong>关键设计决策：何时退出循环？</strong></p>
<p>这是 Agent 设计中最容易被忽视的问题。常见策略：</p>
<ul>
<li><strong>Max Iterations</strong>：硬性限制最大循环次数（防止无限循环和 token 爆炸）</li>
<li><strong>Goal Completion</strong>：LLM 判断任务已完成（但 LLM 判断可能不准）</li>
<li><strong>Confidence Threshold</strong>：当 Reflect 阶段的置信度低于阈值时，请求人类介入</li>
<li><strong>Token Budget</strong>：累计 token 消耗达到上限时强制退出</li>
</ul>
<p>在生产系统中，通常需要<strong>组合多种策略</strong>，以 Max Iterations 作为保底。</p>
<hr>
<h2>4. Agentic 系统的全景架构</h2>
<p>下面这张图展示了一个完整的 Agentic 系统的分层架构。它是整个系列 14 篇文章的&quot;地图&quot;：</p>
<pre><code>┌─────────────────────────────────────────────────────────────────────┐
│                     Production Layer                                │
│  Observability │ Evaluation │ Security │ Cost Control │ Deployment  │
├─────────────────────────────────────────────────────────────────────┤
│                     Protocol Layer                                  │
│         MCP (Model Context Protocol) │ Tool Registry               │
│         Capability Declaration │ Permission Control                 │
├─────────────────────────────────────────────────────────────────────┤
│                     Multi-Agent Layer                               │
│    Supervisor/Worker │ Peer-to-Peer │ Graph-based Orchestration    │
│    Message Passing │ Shared State │ Agent Registry                  │
├─────────────────────────────────────────────────────────────────────┤
│                     Planner Layer                                   │
│    ReAct │ Chain-of-Thought │ Tree-of-Thought │ Hierarchical Plan  │
│    Task Decomposition │ Self-Evaluation │ Retry Budget              │
├─────────────────────────────────────────────────────────────────────┤
│                     Memory Layer                                    │
│    Short-term: Conversation State │ Working Memory                  │
│    Long-term: Vector DB │ Knowledge Graph │ User Profile            │
│    RAG Pipeline: Chunk → Embed → Index → Retrieve → Rerank         │
├─────────────────────────────────────────────────────────────────────┤
│                     Tool Layer                                      │
│    Function Calling │ JSON Schema │ Structured Output               │
│    Tool Validation │ Sandbox Execution │ Error Handling             │
├─────────────────────────────────────────────────────────────────────┤
│                     Control Loop Layer                              │
│    Observe → Think → Plan → Act → Reflect → Update                 │
│    State Machine │ Execution Engine │ Interrupt &amp; Resume            │
├─────────────────────────────────────────────────────────────────────┤
│                     LLM Runtime Layer                               │
│    ChatCompletion API │ Streaming │ Token Management                │
│    Model Router │ Fallback │ Rate Limiting │ Caching               │
└─────────────────────────────────────────────────────────────────────┘
</code></pre>
<p><strong>架构解读</strong>：</p>
<ul>
<li><strong>自底向上</strong>：每一层为上一层提供能力。LLM Runtime 提供推理能力，Control Loop 提供执行循环，Tool 提供行动能力，Memory 提供持久化，Planner 提供智能规划，Multi-Agent 提供协作，Protocol 提供互操作性，Production 提供生产级保障。</li>
<li><strong>耦合方向</strong>：上层依赖下层，但下层不应感知上层。Tool Layer 不需要知道自己被 Multi-Agent 调用还是 Single-Agent 调用。</li>
<li><strong>灵活组合</strong>：不是每个系统都需要所有层。一个简单的 RAG 聊天机器人可能只需要 LLM Runtime + Memory Layer。一个自动化运维 Agent 可能需要 Control Loop + Tool + Planner。架构图是上界，不是下界。</li>
</ul>
<hr>
<h2>5. 14 篇文章导航地图</h2>
<p>以下是整个系列的文章列表，以及每篇文章对应全景图中的位置：</p>
<h3>Phase 1: What Is an Agent?</h3>
<table>
<thead>
<tr>
<th>#</th>
<th>文章</th>
<th>聚焦层</th>
</tr>
</thead>
<tbody><tr>
<td><strong>01</strong></td>
<td><strong>From LLM to Agent: Agentic 系统的知识地图</strong> ← 本文</td>
<td>全景总览</td>
</tr>
<tr>
<td>02</td>
<td>From Prompt to Agent: 为什么 LLM 本身不是 Agent</td>
<td>LLM Runtime → Control Loop</td>
</tr>
<tr>
<td>03</td>
<td>Agent vs Workflow vs Automation: 选对抽象才是关键</td>
<td>架构决策</td>
</tr>
</tbody></table>
<h3>Phase 2: How to Program an Agent?</h3>
<table>
<thead>
<tr>
<th>#</th>
<th>文章</th>
<th>聚焦层</th>
</tr>
</thead>
<tbody><tr>
<td>04</td>
<td>The Agent Control Loop: Agent 运行时的核心抽象</td>
<td>Control Loop Layer</td>
</tr>
<tr>
<td>05</td>
<td>Tool Calling Deep Dive: 让 LLM 成为可编程接口</td>
<td>Tool Layer</td>
</tr>
<tr>
<td>06</td>
<td>Prompt Engineering for Agents: 面向 Agent 的提示词工程</td>
<td>LLM Runtime + Planner</td>
</tr>
<tr>
<td>07</td>
<td>Agent Runtime from Scratch: 不依赖框架构建 Agent</td>
<td>Control Loop + Tool + Memory</td>
</tr>
</tbody></table>
<h3>Phase 3: How to Scale Agent Intelligence?</h3>
<table>
<thead>
<tr>
<th>#</th>
<th>文章</th>
<th>聚焦层</th>
</tr>
</thead>
<tbody><tr>
<td>08</td>
<td>Memory Architecture: Agent 的状态与记忆体系</td>
<td>Memory Layer</td>
</tr>
<tr>
<td>09</td>
<td>RAG as Cognitive Memory: 检索增强生成的工程实践</td>
<td>Memory Layer (RAG)</td>
</tr>
<tr>
<td>10</td>
<td>Planning and Reflection: 从 ReAct 到分层规划</td>
<td>Planner Layer</td>
</tr>
<tr>
<td>11</td>
<td>Multi-Agent Collaboration: 多 Agent 协作模式</td>
<td>Multi-Agent Layer</td>
</tr>
</tbody></table>
<h3>Phase 4: How to Ship Agents to Production?</h3>
<table>
<thead>
<tr>
<th>#</th>
<th>文章</th>
<th>聚焦层</th>
</tr>
</thead>
<tbody><tr>
<td>12</td>
<td>LangChain vs LangGraph: 框架的价值与边界</td>
<td>Control Loop + Tool (框架视角)</td>
</tr>
<tr>
<td>13</td>
<td>MCP and Tool Protocol: Agent 工具的协议化未来</td>
<td>Protocol Layer</td>
</tr>
<tr>
<td>14</td>
<td>Production-Grade Agent Systems: 评估、成本与安全</td>
<td>Production Layer</td>
</tr>
</tbody></table>
<p>每篇文章都可以独立阅读，但按顺序阅读可以获得最连贯的知识构建过程。</p>
<hr>
<h2>6. 从 ChatCompletion 到 Agent 的演进路径</h2>
<p>下面通过代码展示从最简单的 API 调用到完整 Agent 的逐步演进。每一级都在前一级的基础上增加一个关键能力。理解这个演进过程，就理解了 Agent 的设计逻辑。</p>
<h3>Level 0: 单次 ChatCompletion</h3>
<p>最基础的用法——一问一答，无状态，无工具。</p>
<pre><code class="language-python">import openai

def chat(user_message: str) -&gt; str:
    &quot;&quot;&quot;Level 0: 纯粹的 LLM 调用，Text In → Text Out&quot;&quot;&quot;
    response = openai.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=[
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message},
        ],
    )
    return response.choices[0].message.content

# 能力边界：只能回答训练数据内的问题，无法查实时数据，无法执行动作
</code></pre>
<p><strong>局限</strong>：这就是一个函数调用。它不知道今天是星期几，不能帮你查天气，不记得你上一句说了什么。</p>
<h3>Level 1: + Tool Calling</h3>
<p>让 LLM 能够调用外部函数，从&quot;能说&quot;进化到&quot;能做&quot;。</p>
<pre><code class="language-python">import json

# 定义工具：用 JSON Schema 描述函数签名
tools = [
    {
        &quot;type&quot;: &quot;function&quot;,
        &quot;function&quot;: {
            &quot;name&quot;: &quot;get_weather&quot;,
            &quot;description&quot;: &quot;获取指定城市的当前天气&quot;,
            &quot;parameters&quot;: {
                &quot;type&quot;: &quot;object&quot;,
                &quot;properties&quot;: {
                    &quot;city&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;城市名称&quot;}
                },
                &quot;required&quot;: [&quot;city&quot;],
            },
        },
    }
]

# 工具实现
def get_weather(city: str) -&gt; str:
    # 实际场景中调用天气 API
    return json.dumps({&quot;city&quot;: city, &quot;temp&quot;: &quot;22°C&quot;, &quot;condition&quot;: &quot;晴&quot;})

# 工具注册表：名称 → 函数的映射
tool_registry = {&quot;get_weather&quot;: get_weather}

def chat_with_tools(user_message: str) -&gt; str:
    &quot;&quot;&quot;Level 1: LLM + Tool Calling&quot;&quot;&quot;
    messages = [
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message},
    ]

    response = openai.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=messages,
        tools=tools,
    )

    msg = response.choices[0].message

    # 如果 LLM 决定调用工具
    if msg.tool_calls:
        # 执行工具调用
        for tool_call in msg.tool_calls:
            fn_name = tool_call.function.name
            fn_args = json.loads(tool_call.function.arguments)
            result = tool_registry[fn_name](**fn_args)

            # 将工具结果反馈给 LLM
            messages.append(msg)
            messages.append({
                &quot;role&quot;: &quot;tool&quot;,
                &quot;tool_call_id&quot;: tool_call.id,
                &quot;content&quot;: result,
            })

        # LLM 根据工具结果生成最终回答
        final = openai.chat.completions.create(
            model=&quot;gpt-4o&quot;, messages=messages
        )
        return final.choices[0].message.content

    return msg.content
</code></pre>
<p><strong>进步</strong>：LLM 现在能&quot;做事&quot;了——但只能做一步。如果任务需要先查天气、再查航班、最后订酒店，这个结构无法处理。</p>
<h3>Level 2: + Control Loop</h3>
<p>引入循环，让 Agent 能够多步执行、迭代推进。</p>
<pre><code class="language-python">MAX_ITERATIONS = 10

def agent_loop(user_message: str) -&gt; str:
    &quot;&quot;&quot;Level 2: LLM + Tools + Control Loop&quot;&quot;&quot;
    messages = [
        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant with tools.&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message},
    ]

    for i in range(MAX_ITERATIONS):
        response = openai.chat.completions.create(
            model=&quot;gpt-4o&quot;, messages=messages, tools=tools
        )
        msg = response.choices[0].message
        messages.append(msg)

        # 退出条件：LLM 不再请求工具调用，认为任务完成
        if not msg.tool_calls:
            return msg.content

        # 执行所有工具调用
        for tool_call in msg.tool_calls:
            fn_name = tool_call.function.name
            fn_args = json.loads(tool_call.function.arguments)

            try:
                result = tool_registry[fn_name](**fn_args)
            except Exception as e:
                result = json.dumps({&quot;error&quot;: str(e)})

            messages.append({
                &quot;role&quot;: &quot;tool&quot;,
                &quot;tool_call_id&quot;: tool_call.id,
                &quot;content&quot;: result,
            })

    return &quot;达到最大迭代次数，任务未完成。&quot;
</code></pre>
<p><strong>进步</strong>：Agent 现在能连续执行多步操作。但它没有记忆——每次对话从零开始，也没有规划能力——走一步看一步。</p>
<h3>Level 3: + Memory</h3>
<p>加入记忆系统，让 Agent 能跨步骤、甚至跨会话地积累信息。</p>
<pre><code class="language-python">from dataclasses import dataclass, field
from typing import Any

@dataclass
class AgentMemory:
    &quot;&quot;&quot;Agent 的记忆系统&quot;&quot;&quot;
    # 短期记忆：当前会话的消息历史
    conversation: list[dict] = field(default_factory=list)
    # 工作记忆：当前任务的中间状态
    working: dict[str, Any] = field(default_factory=dict)
    # 长期记忆：跨会话持久化（简化版，生产中用向量数据库）
    long_term: list[dict] = field(default_factory=list)

    def add_message(self, message: dict):
        self.conversation.append(message)

    def store_fact(self, key: str, value: Any):
        &quot;&quot;&quot;存入工作记忆&quot;&quot;&quot;
        self.working[key] = value

    def commit_to_long_term(self, summary: str):
        &quot;&quot;&quot;将重要信息提交到长期记忆&quot;&quot;&quot;
        self.long_term.append({
            &quot;summary&quot;: summary,
            &quot;timestamp&quot;: __import__(&quot;time&quot;).time(),
        })

    def get_context_window(self, max_messages: int = 20) -&gt; list[dict]:
        &quot;&quot;&quot;获取上下文窗口：最近的消息 + 长期记忆摘要&quot;&quot;&quot;
        context = []
        # 注入长期记忆摘要
        if self.long_term:
            memory_text = &quot;\n&quot;.join(m[&quot;summary&quot;] for m in self.long_term[-5:])
            context.append({
                &quot;role&quot;: &quot;system&quot;,
                &quot;content&quot;: f&quot;你的长期记忆：\n{memory_text}&quot;,
            })
        # 最近的对话消息
        context.extend(self.conversation[-max_messages:])
        return context


def agent_with_memory(user_message: str, memory: AgentMemory) -&gt; str:
    &quot;&quot;&quot;Level 3: LLM + Tools + Control Loop + Memory&quot;&quot;&quot;
    memory.add_message({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message})

    system_prompt = {
        &quot;role&quot;: &quot;system&quot;,
        &quot;content&quot;: &quot;You are a helpful assistant. Use your memory and tools.&quot;,
    }
    messages = [system_prompt] + memory.get_context_window()

    for i in range(MAX_ITERATIONS):
        response = openai.chat.completions.create(
            model=&quot;gpt-4o&quot;, messages=messages, tools=tools
        )
        msg = response.choices[0].message
        memory.add_message(msg.model_dump())

        if not msg.tool_calls:
            # 任务完成，考虑是否需要存入长期记忆
            return msg.content

        for tool_call in msg.tool_calls:
            fn_name = tool_call.function.name
            fn_args = json.loads(tool_call.function.arguments)
            try:
                result = tool_registry[fn_name](**fn_args)
                # 将关键结果存入工作记忆
                memory.store_fact(f&quot;{fn_name}_result&quot;, result)
            except Exception as e:
                result = json.dumps({&quot;error&quot;: str(e)})

            tool_msg = {
                &quot;role&quot;: &quot;tool&quot;,
                &quot;tool_call_id&quot;: tool_call.id,
                &quot;content&quot;: result,
            }
            memory.add_message(tool_msg)

        messages = [system_prompt] + memory.get_context_window()

    return &quot;达到最大迭代次数。&quot;
</code></pre>
<p><strong>进步</strong>：Agent 有了&quot;记性&quot;。但它仍然是 reactive 的——一步一步地响应，没有全局计划。</p>
<h3>Level 4: + Planner</h3>
<p>加入规划能力，让 Agent 先思考再行动。这是 ReAct 模式的核心思想。</p>
<pre><code class="language-python">PLANNER_PROMPT = &quot;&quot;&quot;你是一个任务规划器。给定用户的目标，你需要：
1. 将目标分解为具体的子步骤
2. 为每个步骤指定需要的工具
3. 标明步骤间的依赖关系
4. 输出 JSON 格式的计划

输出格式：
{
  &quot;goal&quot;: &quot;用户目标&quot;,
  &quot;steps&quot;: [
    {&quot;id&quot;: 1, &quot;action&quot;: &quot;描述&quot;, &quot;tool&quot;: &quot;工具名或null&quot;, &quot;depends_on&quot;: []},
    ...
  ]
}
&quot;&quot;&quot;

def plan_task(goal: str) -&gt; dict:
    &quot;&quot;&quot;使用 LLM 生成执行计划&quot;&quot;&quot;
    response = openai.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=[
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: PLANNER_PROMPT},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: goal},
        ],
        response_format={&quot;type&quot;: &quot;json_object&quot;},
    )
    return json.loads(response.choices[0].message.content)


REFLECT_PROMPT = &quot;&quot;&quot;你是一个任务审查器。根据以下信息判断：
- 原始目标：{goal}
- 已执行步骤：{executed_steps}
- 当前结果：{current_result}

请回答：
1. 任务是否已完成？(yes/no)
2. 如果未完成，下一步应该做什么？
3. 是否需要修改原计划？
&quot;&quot;&quot;

def agent_with_planner(user_message: str, memory: AgentMemory) -&gt; str:
    &quot;&quot;&quot;Level 4: LLM + Tools + Loop + Memory + Planner&quot;&quot;&quot;
    # Phase 1: Plan
    plan = plan_task(user_message)
    memory.store_fact(&quot;plan&quot;, plan)

    executed = []

    # Phase 2: Execute plan step by step
    for step in plan.get(&quot;steps&quot;, []):
        # 检查依赖是否满足
        deps = step.get(&quot;depends_on&quot;, [])
        if not all(d in [s[&quot;id&quot;] for s in executed] for d in deps):
            continue

        if step.get(&quot;tool&quot;):
            # 通过 agent_loop 执行工具调用
            result = agent_loop(
                f&quot;执行以下步骤：{step[&#39;action&#39;]}。只使用 {step[&#39;tool&#39;]} 工具。&quot;
            )
        else:
            result = agent_loop(step[&quot;action&quot;])

        executed.append({&quot;id&quot;: step[&quot;id&quot;], &quot;result&quot;: result})

    # Phase 3: Reflect
    reflection_prompt = REFLECT_PROMPT.format(
        goal=user_message,
        executed_steps=json.dumps(executed, ensure_ascii=False),
        current_result=executed[-1][&quot;result&quot;] if executed else &quot;无结果&quot;,
    )

    final = openai.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: reflection_prompt}],
    )

    return final.choices[0].message.content
</code></pre>
<p><strong>进步</strong>：Agent 现在会&quot;想了再做&quot;。但这还不是终态。</p>
<h3>Level 5: Full Agent System</h3>
<p>完整的 Agent 系统不只是上述组件的堆叠，还需要生产级的工程保障：</p>
<pre><code class="language-python">@dataclass
class AgentConfig:
    &quot;&quot;&quot;Agent 系统配置&quot;&quot;&quot;
    model: str = &quot;gpt-4o&quot;
    max_iterations: int = 10
    max_tokens_budget: int = 50000       # token 预算上限
    tool_timeout_seconds: int = 30       # 工具调用超时
    enable_reflection: bool = True       # 是否启用反思
    enable_planning: bool = True         # 是否启用规划
    fallback_model: str = &quot;gpt-4o-mini&quot;  # 降级模型


class Agent:
    &quot;&quot;&quot;Level 5: 完整的 Agent 系统骨架&quot;&quot;&quot;

    def __init__(self, config: AgentConfig):
        self.config = config
        self.memory = AgentMemory()
        self.tools = ToolRegistry()       # 工具注册中心
        self.planner = Planner(config)    # 规划器
        self.observer = Observer()        # 可观测性（trace/log/metrics）
        self.token_usage = 0             # token 消耗追踪

    def run(self, user_input: str) -&gt; str:
        &quot;&quot;&quot;Agent 主入口：完整的控制循环&quot;&quot;&quot;
        self.observer.trace_start(user_input)

        try:
            # 1. Observe: 接收输入，组装上下文
            context = self._observe(user_input)

            # 2. Plan: 如果启用规划，先生成执行计划
            plan = None
            if self.config.enable_planning:
                plan = self.planner.create_plan(context)
                self.observer.log_plan(plan)

            # 3. Execute: 控制循环
            result = self._execute_loop(context, plan)

            # 4. Reflect: 如果启用反思，评估结果质量
            if self.config.enable_reflection:
                result = self._reflect_and_refine(context, result)

            # 5. Update: 更新记忆
            self.memory.commit_to_long_term(
                f&quot;用户问: {user_input[:100]}... → 结果: {result[:100]}...&quot;
            )

            self.observer.trace_end(result, self.token_usage)
            return result

        except Exception as e:
            self.observer.trace_error(e)
            return f&quot;Agent 执行出错: {str(e)}&quot;

    def _observe(self, user_input: str) -&gt; dict:
        &quot;&quot;&quot;感知阶段：组装完整上下文&quot;&quot;&quot;
        return {
            &quot;user_input&quot;: user_input,
            &quot;conversation&quot;: self.memory.get_context_window(),
            &quot;working_memory&quot;: self.memory.working,
            &quot;available_tools&quot;: self.tools.list_schemas(),
        }

    def _execute_loop(self, context: dict, plan: dict | None) -&gt; str:
        &quot;&quot;&quot;核心执行循环&quot;&quot;&quot;
        steps = plan[&quot;steps&quot;] if plan else [{&quot;action&quot;: context[&quot;user_input&quot;]}]

        results = []
        for step in steps:
            for i in range(self.config.max_iterations):
                # 预算检查
                if self.token_usage &gt; self.config.max_tokens_budget:
                    return &quot;Token 预算耗尽，任务中断。&quot;

                # LLM 推理（含自动降级）
                response = self._call_llm(context, step)

                if response.tool_calls:
                    self._execute_tools(response.tool_calls)
                else:
                    results.append(response.content)
                    break

        return &quot;\n&quot;.join(results)

    def _call_llm(self, context, step):
        &quot;&quot;&quot;LLM 调用，含降级逻辑&quot;&quot;&quot;
        try:
            return self._invoke(self.config.model, context, step)
        except Exception:
            # 降级到备用模型
            return self._invoke(self.config.fallback_model, context, step)

    # ... 省略 _execute_tools, _reflect_and_refine 等实现细节
</code></pre>
<p><strong>这不是最终代码，而是架构骨架。</strong> 生产系统还需要：并发控制、幂等性保证、结构化日志、指标采集、灰度发布、A/B 测试、成本告警等。这些内容将在系列后续文章中逐一展开。</p>
<h3>演进路径总结</h3>
<pre><code>Level 0   Level 1     Level 2        Level 3         Level 4         Level 5
 LLM ───→ +Tools ───→ +Loop ───→ +Memory ───→ +Planner ───→ +Production
  │          │           │           │             │              │
  │          │           │           │             │              │
单次调用   一步行动    多步执行    有记忆的      有规划的      生产级
无状态     无循环     有迭代       迭代执行      智能执行      完整系统
</code></pre>
<p>每一级都引入一个<strong>新的能力维度</strong>，也同时引入<strong>新的复杂度和 trade-off</strong>。不是所有场景都需要 Level 5。选择哪个级别，取决于你的任务复杂度和工程约束。</p>
<hr>
<h2>7. Agent 不是银弹</h2>
<h3>7.1 适用场景</h3>
<p>Agent 擅长处理以下类型的任务：</p>
<ul>
<li><strong>探索性任务</strong>：不确定最终需要几步、用什么工具才能完成。例：研究某个技术方案的可行性。</li>
<li><strong>多工具协作</strong>：需要组合多个 API/数据源的信息。例：跨平台数据聚合分析。</li>
<li><strong>需要迭代优化</strong>：初版结果不够好，需要反思和改进。例：代码生成 + 自动测试 + 修复。</li>
<li><strong>半结构化流程</strong>：有大致方向但细节灵活。例：客户支持中的问题诊断。</li>
</ul>
<h3>7.2 不适用场景</h3>
<p>Agent 在以下场景中可能是错误的选择：</p>
<ul>
<li><strong>确定性流程</strong>：如果你能用 DAG 或状态机画出完整流程，用 Workflow 引擎比 Agent 更可靠、更可预测、更便宜。Agent 的价值在于处理&quot;不确定性&quot;——如果没有不确定性，你不需要 Agent。</li>
<li><strong>低延迟要求</strong>：Agent 的控制循环意味着多次 LLM 调用，延迟以秒计。对于需要毫秒级响应的场景，Agent 不合适。</li>
<li><strong>高精度要求 + 零容错</strong>：金融交易、医疗诊断等场景。LLM 的概率性本质意味着 Agent 不能保证 100% 正确。它可以辅助决策，但不应成为最终决策者。</li>
<li><strong>简单的问答</strong>：如果用户只是问&quot;1+1等于几&quot;，一次 ChatCompletion 足矣，不需要 Agent 的全部架构。</li>
</ul>
<h3>7.3 关键 Trade-off</h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>更多 Agent 能力</th>
<th>代价</th>
</tr>
</thead>
<tbody><tr>
<td>自主性</td>
<td>Agent 自主决策，减少人工干预</td>
<td>不可预测行为，调试困难</td>
</tr>
<tr>
<td>复杂度</td>
<td>能处理更复杂的任务</td>
<td>系统复杂度指数增长</td>
</tr>
<tr>
<td>成本</td>
<td>每个任务消耗更多 token</td>
<td>月度 API 账单可能惊人</td>
</tr>
<tr>
<td>延迟</td>
<td>多步推理产出更好结果</td>
<td>用户等待时间更长</td>
</tr>
<tr>
<td>可靠性</td>
<td>有反思和重试机制</td>
<td>但每一步都可能出错，错误会累积</td>
</tr>
</tbody></table>
<p><strong>核心决策原则</strong>：</p>
<blockquote>
<p>用最简单的抽象解决问题。如果 prompt engineering 够用，不要上 Agent。如果 Agent 够用，不要上 Multi-Agent。每增加一层抽象，都要问自己：这层抽象带来的能力提升，是否值得它引入的复杂度？</p>
</blockquote>
<hr>
<h2>8. 结语与后续预告</h2>
<p>本文作为系列开篇，建立了三个关键认知：</p>
<ol>
<li><strong>LLM 是函数，Agent 是系统</strong>。从函数到系统，需要补齐 Memory、Tools、Planner、Runtime 四个维度。</li>
<li><strong>Agent 的核心是控制循环</strong>。Observe → Think → Plan → Act → Reflect → Update。循环赋予了 Agent 迭代解决问题的能力。</li>
<li><strong>Agent 不是银弹</strong>。选择 Agent 是一个架构决策，需要在能力与复杂度之间做出权衡。</li>
</ol>
<p>在接下来的文章中，我们将逐层深入：</p>
<ul>
<li><strong>下一篇（02）</strong>：From Prompt to Agent —— 我们将用更严格的方式论证&quot;为什么 LLM 本身不是 Agent&quot;，并深入讨论从 Prompt Engineering 到 Agent Engineering 的思维转换。</li>
<li><strong>第 03 篇</strong>：Agent vs Workflow vs Automation —— 你的场景到底该用 Agent、DAG 还是规则引擎？我们会给出一个清晰的决策框架。</li>
<li><strong>第 04 篇</strong>：The Agent Control Loop —— 深入控制循环的每一个环节，讨论状态管理、中断恢复、错误处理的工程细节。</li>
</ul>
<p>整个系列的目标不是教你使用某个框架的 API，而是帮你建立<strong>从第一性原理理解 Agentic 系统</strong>的能力。框架会变，API 会变，但系统设计的基本原理不会变。</p>
<hr>
<blockquote>
<p><strong>系列导航</strong>：本文是 Agentic 系列的第 01 篇。</p>
<ul>
<li>下一篇：<a href="/blog/engineering/agentic/02-From%20Prompt%20to%20Agent">02 | From Prompt to Agent</a></li>
<li>完整目录见第 5 节</li>
</ul>
</blockquote>
</div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="mt-12 pt-8 border-t border-gray-200">加载导航中...</div><!--/$--><div class="mt-16 border-t border-gray-200 pt-8"><div class="mx-auto max-w-3xl"><h3 class="text-2xl font-bold text-gray-900 mb-8">评论</h3></div></div></div></div></article><!--$--><!--/$--></main><footer class="bg-[var(--background)]"><div class="mx-auto max-w-7xl px-6 py-12 lg:px-8"><p class="text-center text-xs leading-5 text-gray-400">© <!-- -->2026<!-- --> Skyfalling</p></div></footer></div><script src="/_next/static/chunks/webpack-42d55485b4428e47.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[10616,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"7177\",\"static/chunks/app/layout-142e67ac4336647c.js\"],\"default\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n6:I[59665,[],\"OutletBoundary\"]\n9:I[74911,[],\"AsyncMetadataOutlet\"]\nb:I[59665,[],\"ViewportBoundary\"]\nd:I[59665,[],\"MetadataBoundary\"]\nf:I[26614,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/7dd6b3ec14b0b1d8.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"kLuGQpYNrv7rzQ0jpQCVp\",\"p\":\"\",\"c\":[\"\",\"blog\",\"engineering\",\"agentic\",\"01-From%20LLM%20to%20Agent\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"engineering/agentic/01-From%20LLM%20to%20Agent\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7dd6b3ec14b0b1d8.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-[var(--background)]\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-6 py-12 lg:px-8\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs leading-5 text-gray-400\",\"children\":[\"© \",2026,\" Skyfalling\"]}]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"engineering/agentic/01-From%20LLM%20to%20Agent\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",null,[\"$\",\"$L6\",null,{\"children\":[\"$L7\",\"$L8\",[\"$\",\"$L9\",null,{\"promise\":\"$@a\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"I-N9gMUJQ85TtpCt1jVh-v\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:\"$Sreact.suspense\"\n11:I[74911,[],\"AsyncMetadata\"]\n13:I[6874,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"\"]\n14:I[32923,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n16:I[40780,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n1b:I[85300,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\ne:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]}]}]\n15:T9629,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eFrom LLM to Agent: Agentic 系统的知识地图\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e大语言模型是一个令人惊叹的函数：Text In, Text Out。但函数不等于系统，生成不等于行动，回答不等于解决。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列 14 篇文章的开篇。我们将从\u0026quot;LLM 能做什么\u0026quot;出发，推导出\u0026quot;Agent 必须做什么\u0026quot;，然后为整个系列绘制一张完整的知识地图。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么需要从 LLM 走向 Agent\u003c/h2\u003e\n\u003ch3\u003e1.1 LLM 是一个了不起的函数\u003c/h3\u003e\n\u003cp\u003e2022 年底以来，以 GPT-4、Claude、Gemini 为代表的大语言模型展示了令人印象深刻的能力：理解自然语言、生成结构化文本、进行多步推理、甚至通过各类考试。但如果我们冷静地回到工程视角，LLM 本质上是一个\u003cstrong\u003e无状态的文本映射函数\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ef(prompt: str, context: str) → response: str\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e它接收一段文本，返回一段文本。仅此而已。\u003c/p\u003e\n\u003ch3\u003e1.2 LLM 的五个结构性局限\u003c/h3\u003e\n\u003cp\u003e当你试图用 LLM 解决真实世界的任务时，会迅速撞上以下墙壁：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e局限\u003c/th\u003e\n\u003cth\u003e本质原因\u003c/th\u003e\n\u003cth\u003e后果\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e知识静态\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e训练数据有截止日期\u003c/td\u003e\n\u003ctd\u003e无法回答实时问题，产生幻觉\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e无法行动\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e输出是文本，不是可执行指令\u003c/td\u003e\n\u003ctd\u003e不能查数据库、调 API、操作文件\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e记忆易失\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e上下文窗口有限且无持久状态\u003c/td\u003e\n\u003ctd\u003e长对话丢失信息，跨会话失忆\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e单步思维\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e一次 completion 只做一次推理\u003c/td\u003e\n\u003ctd\u003e复杂任务无法分解、无法迭代\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e不会反思\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不检查自己的输出质量\u003c/td\u003e\n\u003ctd\u003e错误会被自信地传递下去\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e这五个局限不是\u0026quot;模型不够大\u0026quot;能解决的问题——它们是\u003cstrong\u003e架构层面的缺失\u003c/strong\u003e。更大的模型只是让函数 \u003ccode\u003ef\u003c/code\u003e 更强，但不会让函数变成系统。\u003c/p\u003e\n\u003ch3\u003e1.3 从函数到系统的必然性\u003c/h3\u003e\n\u003cp\u003e真实世界的任务天然具有以下特征：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e需要多步执行\u003c/strong\u003e：完成一次数据分析需要查询 → 清洗 → 计算 → 可视化\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e需要外部交互\u003c/strong\u003e：查实时数据、调第三方 API、读写文件\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e需要持久记忆\u003c/strong\u003e：记住用户偏好、历史决策、领域知识\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e需要自我纠错\u003c/strong\u003e：发现错误后能回退、重试、换策略\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e需要可靠执行\u003c/strong\u003e：有超时、有重试、有降级、有审计\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当这些需求叠加在一起，你需要的不再是一个\u0026quot;更好的 prompt\u0026quot;，而是一个\u003cstrong\u003e围绕 LLM 构建的系统\u003c/strong\u003e。这个系统，就是 Agent。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 定义 Agent\u003c/h2\u003e\n\u003ch3\u003e2.1 一个精确的定义\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eAgent = LLM + Memory + Tools + Planner + Runtime\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这不是随意的拼凑，而是对上一节五个局限的逐一回应：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e局限：知识静态     → 解法：Memory（外部知识 + RAG）\n局限：无法行动     → 解法：Tools（函数调用 + 外部接口）\n局限：记忆易失     → 解法：Memory（会话状态 + 持久化记忆）\n局限：单步思维     → 解法：Planner（任务分解 + 多步规划）\n局限：不会反思     → 解法：Runtime（控制循环 + 反思机制）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e每个组件都有明确的职责：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLLM\u003c/strong\u003e：核心推理引擎。理解意图、生成计划、选择工具、产出结果。它是\u0026quot;大脑\u0026quot;，但不是全部。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMemory\u003c/strong\u003e：分为短期记忆（当前对话上下文、工作区状态）和长期记忆（向量数据库中的文档、用户画像、历史经验）。短期记忆保证连贯性，长期记忆突破知识边界。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTools\u003c/strong\u003e：Agent 与外部世界的接口。一个 Tool 就是一个带有 JSON Schema 描述的可调用函数。搜索引擎、数据库查询、代码执行器、API 网关——都是 Tool。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlanner\u003c/strong\u003e：将复杂任务分解为可执行的子步骤。从简单的 ReAct（交替推理和行动）到复杂的分层规划（Hierarchical Planning），Planner 决定了 Agent 的\u0026quot;智商上限\u0026quot;。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRuntime\u003c/strong\u003e：Agent 的执行环境。负责控制循环的调度、工具调用的执行、错误处理、超时控制、状态持久化。没有 Runtime，前面四个组件只是散落的零件。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.2 Agent 与 LLM 的本质差异\u003c/h3\u003e\n\u003cp\u003e用一个类比来强化理解：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eLLM  ≈ CPU             —— 强大的计算单元，但单独无法工作\nAgent ≈ Operating System —— 围绕 CPU 构建的完整运行时\n\nLLM  是 Pure Function   —— 相同输入，相同输出，无副作用\nAgent 是 Stateful System —— 有状态、有副作用、有执行循环\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这个区分极其重要。很多团队把 LLM 当 Agent 用（期望一次 prompt 解决所有问题），或者把 Agent 当 LLM 用（忽略控制循环和状态管理），都会走进死胡同。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. Agent 的核心控制循环\u003c/h2\u003e\n\u003cp\u003eAgent 之所以能完成复杂任务，核心在于它运行一个\u003cstrong\u003e持续的控制循环\u003c/strong\u003e。这个循环可以抽象为六个阶段：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌──────────────────────────────────┐\n                    │         Agent Control Loop        │\n                    └──────────────────────────────────┘\n\n                           ┌─────────────┐\n                     ┌────▶│   Observe   │─────┐\n                     │     │ (感知输入)   │     │\n                     │     └─────────────┘     │\n                     │                          ▼\n              ┌──────┴──────┐           ┌─────────────┐\n              │    Update   │           │    Think    │\n              │ (更新状态)   │           │ (理解意图)   │\n              └──────┬──────┘           └──────┬──────┘\n                     ▲                          │\n                     │                          ▼\n              ┌──────┴──────┐           ┌─────────────┐\n              │   Reflect   │           │    Plan     │\n              │ (评估结果)   │◀──────────│ (制定计划)   │\n              └─────────────┘           └──────┬──────┘\n                                               │\n                                               ▼\n                                        ┌─────────────┐\n                                        │     Act     │\n                                        │ (执行动作)   │\n                                        └─────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e各阶段职责：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eObserve（感知）\u003c/strong\u003e：接收用户输入或环境变化。不仅是文本——可能是工具返回的结果、系统事件、定时触发。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eThink（思考）\u003c/strong\u003e：LLM 理解当前状态和目标。这一步对应 prompt 中的 System Message 和上下文组装。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlan（规划）\u003c/strong\u003e：决定下一步做什么。可能是调用工具、请求更多信息、或直接回答。ReAct 框架在此步生成 Thought + Action。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAct（执行）\u003c/strong\u003e：真正执行动作。调用 API、查询数据库、运行代码、生成文件。这一步有\u003cstrong\u003e副作用\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReflect（反思）\u003c/strong\u003e：检查执行结果是否符合预期。结果有错误？重试。结果不完整？补充。任务完成？退出循环。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUpdate（更新）\u003c/strong\u003e：将本轮的观察、决策、结果写入记忆。更新会话上下文，可能也写入长期记忆。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e关键设计决策：何时退出循环？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是 Agent 设计中最容易被忽视的问题。常见策略：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMax Iterations\u003c/strong\u003e：硬性限制最大循环次数（防止无限循环和 token 爆炸）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGoal Completion\u003c/strong\u003e：LLM 判断任务已完成（但 LLM 判断可能不准）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConfidence Threshold\u003c/strong\u003e：当 Reflect 阶段的置信度低于阈值时，请求人类介入\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eToken Budget\u003c/strong\u003e：累计 token 消耗达到上限时强制退出\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在生产系统中，通常需要\u003cstrong\u003e组合多种策略\u003c/strong\u003e，以 Max Iterations 作为保底。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Agentic 系统的全景架构\u003c/h2\u003e\n\u003cp\u003e下面这张图展示了一个完整的 Agentic 系统的分层架构。它是整个系列 14 篇文章的\u0026quot;地图\u0026quot;：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────────────────┐\n│                     Production Layer                                │\n│  Observability │ Evaluation │ Security │ Cost Control │ Deployment  │\n├─────────────────────────────────────────────────────────────────────┤\n│                     Protocol Layer                                  │\n│         MCP (Model Context Protocol) │ Tool Registry               │\n│         Capability Declaration │ Permission Control                 │\n├─────────────────────────────────────────────────────────────────────┤\n│                     Multi-Agent Layer                               │\n│    Supervisor/Worker │ Peer-to-Peer │ Graph-based Orchestration    │\n│    Message Passing │ Shared State │ Agent Registry                  │\n├─────────────────────────────────────────────────────────────────────┤\n│                     Planner Layer                                   │\n│    ReAct │ Chain-of-Thought │ Tree-of-Thought │ Hierarchical Plan  │\n│    Task Decomposition │ Self-Evaluation │ Retry Budget              │\n├─────────────────────────────────────────────────────────────────────┤\n│                     Memory Layer                                    │\n│    Short-term: Conversation State │ Working Memory                  │\n│    Long-term: Vector DB │ Knowledge Graph │ User Profile            │\n│    RAG Pipeline: Chunk → Embed → Index → Retrieve → Rerank         │\n├─────────────────────────────────────────────────────────────────────┤\n│                     Tool Layer                                      │\n│    Function Calling │ JSON Schema │ Structured Output               │\n│    Tool Validation │ Sandbox Execution │ Error Handling             │\n├─────────────────────────────────────────────────────────────────────┤\n│                     Control Loop Layer                              │\n│    Observe → Think → Plan → Act → Reflect → Update                 │\n│    State Machine │ Execution Engine │ Interrupt \u0026amp; Resume            │\n├─────────────────────────────────────────────────────────────────────┤\n│                     LLM Runtime Layer                               │\n│    ChatCompletion API │ Streaming │ Token Management                │\n│    Model Router │ Fallback │ Rate Limiting │ Caching               │\n└─────────────────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e架构解读\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e自底向上\u003c/strong\u003e：每一层为上一层提供能力。LLM Runtime 提供推理能力，Control Loop 提供执行循环，Tool 提供行动能力，Memory 提供持久化，Planner 提供智能规划，Multi-Agent 提供协作，Protocol 提供互操作性，Production 提供生产级保障。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e耦合方向\u003c/strong\u003e：上层依赖下层，但下层不应感知上层。Tool Layer 不需要知道自己被 Multi-Agent 调用还是 Single-Agent 调用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e灵活组合\u003c/strong\u003e：不是每个系统都需要所有层。一个简单的 RAG 聊天机器人可能只需要 LLM Runtime + Memory Layer。一个自动化运维 Agent 可能需要 Control Loop + Tool + Planner。架构图是上界，不是下界。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 14 篇文章导航地图\u003c/h2\u003e\n\u003cp\u003e以下是整个系列的文章列表，以及每篇文章对应全景图中的位置：\u003c/p\u003e\n\u003ch3\u003ePhase 1: What Is an Agent?\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e#\u003c/th\u003e\n\u003cth\u003e文章\u003c/th\u003e\n\u003cth\u003e聚焦层\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e01\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eFrom LLM to Agent: Agentic 系统的知识地图\u003c/strong\u003e ← 本文\u003c/td\u003e\n\u003ctd\u003e全景总览\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e02\u003c/td\u003e\n\u003ctd\u003eFrom Prompt to Agent: 为什么 LLM 本身不是 Agent\u003c/td\u003e\n\u003ctd\u003eLLM Runtime → Control Loop\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e03\u003c/td\u003e\n\u003ctd\u003eAgent vs Workflow vs Automation: 选对抽象才是关键\u003c/td\u003e\n\u003ctd\u003e架构决策\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003ePhase 2: How to Program an Agent?\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e#\u003c/th\u003e\n\u003cth\u003e文章\u003c/th\u003e\n\u003cth\u003e聚焦层\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e04\u003c/td\u003e\n\u003ctd\u003eThe Agent Control Loop: Agent 运行时的核心抽象\u003c/td\u003e\n\u003ctd\u003eControl Loop Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e05\u003c/td\u003e\n\u003ctd\u003eTool Calling Deep Dive: 让 LLM 成为可编程接口\u003c/td\u003e\n\u003ctd\u003eTool Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e06\u003c/td\u003e\n\u003ctd\u003ePrompt Engineering for Agents: 面向 Agent 的提示词工程\u003c/td\u003e\n\u003ctd\u003eLLM Runtime + Planner\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e07\u003c/td\u003e\n\u003ctd\u003eAgent Runtime from Scratch: 不依赖框架构建 Agent\u003c/td\u003e\n\u003ctd\u003eControl Loop + Tool + Memory\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003ePhase 3: How to Scale Agent Intelligence?\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e#\u003c/th\u003e\n\u003cth\u003e文章\u003c/th\u003e\n\u003cth\u003e聚焦层\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e08\u003c/td\u003e\n\u003ctd\u003eMemory Architecture: Agent 的状态与记忆体系\u003c/td\u003e\n\u003ctd\u003eMemory Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e09\u003c/td\u003e\n\u003ctd\u003eRAG as Cognitive Memory: 检索增强生成的工程实践\u003c/td\u003e\n\u003ctd\u003eMemory Layer (RAG)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003ePlanning and Reflection: 从 ReAct 到分层规划\u003c/td\u003e\n\u003ctd\u003ePlanner Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e11\u003c/td\u003e\n\u003ctd\u003eMulti-Agent Collaboration: 多 Agent 协作模式\u003c/td\u003e\n\u003ctd\u003eMulti-Agent Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003ePhase 4: How to Ship Agents to Production?\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e#\u003c/th\u003e\n\u003cth\u003e文章\u003c/th\u003e\n\u003cth\u003e聚焦层\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e12\u003c/td\u003e\n\u003ctd\u003eLangChain vs LangGraph: 框架的价值与边界\u003c/td\u003e\n\u003ctd\u003eControl Loop + Tool (框架视角)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e13\u003c/td\u003e\n\u003ctd\u003eMCP and Tool Protocol: Agent 工具的协议化未来\u003c/td\u003e\n\u003ctd\u003eProtocol Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e14\u003c/td\u003e\n\u003ctd\u003eProduction-Grade Agent Systems: 评估、成本与安全\u003c/td\u003e\n\u003ctd\u003eProduction Layer\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e每篇文章都可以独立阅读，但按顺序阅读可以获得最连贯的知识构建过程。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 从 ChatCompletion 到 Agent 的演进路径\u003c/h2\u003e\n\u003cp\u003e下面通过代码展示从最简单的 API 调用到完整 Agent 的逐步演进。每一级都在前一级的基础上增加一个关键能力。理解这个演进过程，就理解了 Agent 的设计逻辑。\u003c/p\u003e\n\u003ch3\u003eLevel 0: 单次 ChatCompletion\u003c/h3\u003e\n\u003cp\u003e最基础的用法——一问一答，无状态，无工具。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport openai\n\ndef chat(user_message: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;Level 0: 纯粹的 LLM 调用，Text In → Text Out\u0026quot;\u0026quot;\u0026quot;\n    response = openai.chat.completions.create(\n        model=\u0026quot;gpt-4o\u0026quot;,\n        messages=[\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;You are a helpful assistant.\u0026quot;},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_message},\n        ],\n    )\n    return response.choices[0].message.content\n\n# 能力边界：只能回答训练数据内的问题，无法查实时数据，无法执行动作\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e局限\u003c/strong\u003e：这就是一个函数调用。它不知道今天是星期几，不能帮你查天气，不记得你上一句说了什么。\u003c/p\u003e\n\u003ch3\u003eLevel 1: + Tool Calling\u003c/h3\u003e\n\u003cp\u003e让 LLM 能够调用外部函数，从\u0026quot;能说\u0026quot;进化到\u0026quot;能做\u0026quot;。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\n\n# 定义工具：用 JSON Schema 描述函数签名\ntools = [\n    {\n        \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot;,\n        \u0026quot;function\u0026quot;: {\n            \u0026quot;name\u0026quot;: \u0026quot;get_weather\u0026quot;,\n            \u0026quot;description\u0026quot;: \u0026quot;获取指定城市的当前天气\u0026quot;,\n            \u0026quot;parameters\u0026quot;: {\n                \u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\n                \u0026quot;properties\u0026quot;: {\n                    \u0026quot;city\u0026quot;: {\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;description\u0026quot;: \u0026quot;城市名称\u0026quot;}\n                },\n                \u0026quot;required\u0026quot;: [\u0026quot;city\u0026quot;],\n            },\n        },\n    }\n]\n\n# 工具实现\ndef get_weather(city: str) -\u0026gt; str:\n    # 实际场景中调用天气 API\n    return json.dumps({\u0026quot;city\u0026quot;: city, \u0026quot;temp\u0026quot;: \u0026quot;22°C\u0026quot;, \u0026quot;condition\u0026quot;: \u0026quot;晴\u0026quot;})\n\n# 工具注册表：名称 → 函数的映射\ntool_registry = {\u0026quot;get_weather\u0026quot;: get_weather}\n\ndef chat_with_tools(user_message: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;Level 1: LLM + Tool Calling\u0026quot;\u0026quot;\u0026quot;\n    messages = [\n        {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;You are a helpful assistant.\u0026quot;},\n        {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_message},\n    ]\n\n    response = openai.chat.completions.create(\n        model=\u0026quot;gpt-4o\u0026quot;,\n        messages=messages,\n        tools=tools,\n    )\n\n    msg = response.choices[0].message\n\n    # 如果 LLM 决定调用工具\n    if msg.tool_calls:\n        # 执行工具调用\n        for tool_call in msg.tool_calls:\n            fn_name = tool_call.function.name\n            fn_args = json.loads(tool_call.function.arguments)\n            result = tool_registry[fn_name](**fn_args)\n\n            # 将工具结果反馈给 LLM\n            messages.append(msg)\n            messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;tool_call_id\u0026quot;: tool_call.id,\n                \u0026quot;content\u0026quot;: result,\n            })\n\n        # LLM 根据工具结果生成最终回答\n        final = openai.chat.completions.create(\n            model=\u0026quot;gpt-4o\u0026quot;, messages=messages\n        )\n        return final.choices[0].message.content\n\n    return msg.content\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e进步\u003c/strong\u003e：LLM 现在能\u0026quot;做事\u0026quot;了——但只能做一步。如果任务需要先查天气、再查航班、最后订酒店，这个结构无法处理。\u003c/p\u003e\n\u003ch3\u003eLevel 2: + Control Loop\u003c/h3\u003e\n\u003cp\u003e引入循环，让 Agent 能够多步执行、迭代推进。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eMAX_ITERATIONS = 10\n\ndef agent_loop(user_message: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;Level 2: LLM + Tools + Control Loop\u0026quot;\u0026quot;\u0026quot;\n    messages = [\n        {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;You are a helpful assistant with tools.\u0026quot;},\n        {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_message},\n    ]\n\n    for i in range(MAX_ITERATIONS):\n        response = openai.chat.completions.create(\n            model=\u0026quot;gpt-4o\u0026quot;, messages=messages, tools=tools\n        )\n        msg = response.choices[0].message\n        messages.append(msg)\n\n        # 退出条件：LLM 不再请求工具调用，认为任务完成\n        if not msg.tool_calls:\n            return msg.content\n\n        # 执行所有工具调用\n        for tool_call in msg.tool_calls:\n            fn_name = tool_call.function.name\n            fn_args = json.loads(tool_call.function.arguments)\n\n            try:\n                result = tool_registry[fn_name](**fn_args)\n            except Exception as e:\n                result = json.dumps({\u0026quot;error\u0026quot;: str(e)})\n\n            messages.append({\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;tool_call_id\u0026quot;: tool_call.id,\n                \u0026quot;content\u0026quot;: result,\n            })\n\n    return \u0026quot;达到最大迭代次数，任务未完成。\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e进步\u003c/strong\u003e：Agent 现在能连续执行多步操作。但它没有记忆——每次对话从零开始，也没有规划能力——走一步看一步。\u003c/p\u003e\n\u003ch3\u003eLevel 3: + Memory\u003c/h3\u003e\n\u003cp\u003e加入记忆系统，让 Agent 能跨步骤、甚至跨会话地积累信息。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Any\n\n@dataclass\nclass AgentMemory:\n    \u0026quot;\u0026quot;\u0026quot;Agent 的记忆系统\u0026quot;\u0026quot;\u0026quot;\n    # 短期记忆：当前会话的消息历史\n    conversation: list[dict] = field(default_factory=list)\n    # 工作记忆：当前任务的中间状态\n    working: dict[str, Any] = field(default_factory=dict)\n    # 长期记忆：跨会话持久化（简化版，生产中用向量数据库）\n    long_term: list[dict] = field(default_factory=list)\n\n    def add_message(self, message: dict):\n        self.conversation.append(message)\n\n    def store_fact(self, key: str, value: Any):\n        \u0026quot;\u0026quot;\u0026quot;存入工作记忆\u0026quot;\u0026quot;\u0026quot;\n        self.working[key] = value\n\n    def commit_to_long_term(self, summary: str):\n        \u0026quot;\u0026quot;\u0026quot;将重要信息提交到长期记忆\u0026quot;\u0026quot;\u0026quot;\n        self.long_term.append({\n            \u0026quot;summary\u0026quot;: summary,\n            \u0026quot;timestamp\u0026quot;: __import__(\u0026quot;time\u0026quot;).time(),\n        })\n\n    def get_context_window(self, max_messages: int = 20) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;获取上下文窗口：最近的消息 + 长期记忆摘要\u0026quot;\u0026quot;\u0026quot;\n        context = []\n        # 注入长期记忆摘要\n        if self.long_term:\n            memory_text = \u0026quot;\\n\u0026quot;.join(m[\u0026quot;summary\u0026quot;] for m in self.long_term[-5:])\n            context.append({\n                \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                \u0026quot;content\u0026quot;: f\u0026quot;你的长期记忆：\\n{memory_text}\u0026quot;,\n            })\n        # 最近的对话消息\n        context.extend(self.conversation[-max_messages:])\n        return context\n\n\ndef agent_with_memory(user_message: str, memory: AgentMemory) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;Level 3: LLM + Tools + Control Loop + Memory\u0026quot;\u0026quot;\u0026quot;\n    memory.add_message({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_message})\n\n    system_prompt = {\n        \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n        \u0026quot;content\u0026quot;: \u0026quot;You are a helpful assistant. Use your memory and tools.\u0026quot;,\n    }\n    messages = [system_prompt] + memory.get_context_window()\n\n    for i in range(MAX_ITERATIONS):\n        response = openai.chat.completions.create(\n            model=\u0026quot;gpt-4o\u0026quot;, messages=messages, tools=tools\n        )\n        msg = response.choices[0].message\n        memory.add_message(msg.model_dump())\n\n        if not msg.tool_calls:\n            # 任务完成，考虑是否需要存入长期记忆\n            return msg.content\n\n        for tool_call in msg.tool_calls:\n            fn_name = tool_call.function.name\n            fn_args = json.loads(tool_call.function.arguments)\n            try:\n                result = tool_registry[fn_name](**fn_args)\n                # 将关键结果存入工作记忆\n                memory.store_fact(f\u0026quot;{fn_name}_result\u0026quot;, result)\n            except Exception as e:\n                result = json.dumps({\u0026quot;error\u0026quot;: str(e)})\n\n            tool_msg = {\n                \u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;,\n                \u0026quot;tool_call_id\u0026quot;: tool_call.id,\n                \u0026quot;content\u0026quot;: result,\n            }\n            memory.add_message(tool_msg)\n\n        messages = [system_prompt] + memory.get_context_window()\n\n    return \u0026quot;达到最大迭代次数。\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e进步\u003c/strong\u003e：Agent 有了\u0026quot;记性\u0026quot;。但它仍然是 reactive 的——一步一步地响应，没有全局计划。\u003c/p\u003e\n\u003ch3\u003eLevel 4: + Planner\u003c/h3\u003e\n\u003cp\u003e加入规划能力，让 Agent 先思考再行动。这是 ReAct 模式的核心思想。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ePLANNER_PROMPT = \u0026quot;\u0026quot;\u0026quot;你是一个任务规划器。给定用户的目标，你需要：\n1. 将目标分解为具体的子步骤\n2. 为每个步骤指定需要的工具\n3. 标明步骤间的依赖关系\n4. 输出 JSON 格式的计划\n\n输出格式：\n{\n  \u0026quot;goal\u0026quot;: \u0026quot;用户目标\u0026quot;,\n  \u0026quot;steps\u0026quot;: [\n    {\u0026quot;id\u0026quot;: 1, \u0026quot;action\u0026quot;: \u0026quot;描述\u0026quot;, \u0026quot;tool\u0026quot;: \u0026quot;工具名或null\u0026quot;, \u0026quot;depends_on\u0026quot;: []},\n    ...\n  ]\n}\n\u0026quot;\u0026quot;\u0026quot;\n\ndef plan_task(goal: str) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;使用 LLM 生成执行计划\u0026quot;\u0026quot;\u0026quot;\n    response = openai.chat.completions.create(\n        model=\u0026quot;gpt-4o\u0026quot;,\n        messages=[\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: PLANNER_PROMPT},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: goal},\n        ],\n        response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n    )\n    return json.loads(response.choices[0].message.content)\n\n\nREFLECT_PROMPT = \u0026quot;\u0026quot;\u0026quot;你是一个任务审查器。根据以下信息判断：\n- 原始目标：{goal}\n- 已执行步骤：{executed_steps}\n- 当前结果：{current_result}\n\n请回答：\n1. 任务是否已完成？(yes/no)\n2. 如果未完成，下一步应该做什么？\n3. 是否需要修改原计划？\n\u0026quot;\u0026quot;\u0026quot;\n\ndef agent_with_planner(user_message: str, memory: AgentMemory) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;Level 4: LLM + Tools + Loop + Memory + Planner\u0026quot;\u0026quot;\u0026quot;\n    # Phase 1: Plan\n    plan = plan_task(user_message)\n    memory.store_fact(\u0026quot;plan\u0026quot;, plan)\n\n    executed = []\n\n    # Phase 2: Execute plan step by step\n    for step in plan.get(\u0026quot;steps\u0026quot;, []):\n        # 检查依赖是否满足\n        deps = step.get(\u0026quot;depends_on\u0026quot;, [])\n        if not all(d in [s[\u0026quot;id\u0026quot;] for s in executed] for d in deps):\n            continue\n\n        if step.get(\u0026quot;tool\u0026quot;):\n            # 通过 agent_loop 执行工具调用\n            result = agent_loop(\n                f\u0026quot;执行以下步骤：{step[\u0026#39;action\u0026#39;]}。只使用 {step[\u0026#39;tool\u0026#39;]} 工具。\u0026quot;\n            )\n        else:\n            result = agent_loop(step[\u0026quot;action\u0026quot;])\n\n        executed.append({\u0026quot;id\u0026quot;: step[\u0026quot;id\u0026quot;], \u0026quot;result\u0026quot;: result})\n\n    # Phase 3: Reflect\n    reflection_prompt = REFLECT_PROMPT.format(\n        goal=user_message,\n        executed_steps=json.dumps(executed, ensure_ascii=False),\n        current_result=executed[-1][\u0026quot;result\u0026quot;] if executed else \u0026quot;无结果\u0026quot;,\n    )\n\n    final = openai.chat.completions.create(\n        model=\u0026quot;gpt-4o\u0026quot;,\n        messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: reflection_prompt}],\n    )\n\n    return final.choices[0].message.content\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e进步\u003c/strong\u003e：Agent 现在会\u0026quot;想了再做\u0026quot;。但这还不是终态。\u003c/p\u003e\n\u003ch3\u003eLevel 5: Full Agent System\u003c/h3\u003e\n\u003cp\u003e完整的 Agent 系统不只是上述组件的堆叠，还需要生产级的工程保障：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass AgentConfig:\n    \u0026quot;\u0026quot;\u0026quot;Agent 系统配置\u0026quot;\u0026quot;\u0026quot;\n    model: str = \u0026quot;gpt-4o\u0026quot;\n    max_iterations: int = 10\n    max_tokens_budget: int = 50000       # token 预算上限\n    tool_timeout_seconds: int = 30       # 工具调用超时\n    enable_reflection: bool = True       # 是否启用反思\n    enable_planning: bool = True         # 是否启用规划\n    fallback_model: str = \u0026quot;gpt-4o-mini\u0026quot;  # 降级模型\n\n\nclass Agent:\n    \u0026quot;\u0026quot;\u0026quot;Level 5: 完整的 Agent 系统骨架\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, config: AgentConfig):\n        self.config = config\n        self.memory = AgentMemory()\n        self.tools = ToolRegistry()       # 工具注册中心\n        self.planner = Planner(config)    # 规划器\n        self.observer = Observer()        # 可观测性（trace/log/metrics）\n        self.token_usage = 0             # token 消耗追踪\n\n    def run(self, user_input: str) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;Agent 主入口：完整的控制循环\u0026quot;\u0026quot;\u0026quot;\n        self.observer.trace_start(user_input)\n\n        try:\n            # 1. Observe: 接收输入，组装上下文\n            context = self._observe(user_input)\n\n            # 2. Plan: 如果启用规划，先生成执行计划\n            plan = None\n            if self.config.enable_planning:\n                plan = self.planner.create_plan(context)\n                self.observer.log_plan(plan)\n\n            # 3. Execute: 控制循环\n            result = self._execute_loop(context, plan)\n\n            # 4. Reflect: 如果启用反思，评估结果质量\n            if self.config.enable_reflection:\n                result = self._reflect_and_refine(context, result)\n\n            # 5. Update: 更新记忆\n            self.memory.commit_to_long_term(\n                f\u0026quot;用户问: {user_input[:100]}... → 结果: {result[:100]}...\u0026quot;\n            )\n\n            self.observer.trace_end(result, self.token_usage)\n            return result\n\n        except Exception as e:\n            self.observer.trace_error(e)\n            return f\u0026quot;Agent 执行出错: {str(e)}\u0026quot;\n\n    def _observe(self, user_input: str) -\u0026gt; dict:\n        \u0026quot;\u0026quot;\u0026quot;感知阶段：组装完整上下文\u0026quot;\u0026quot;\u0026quot;\n        return {\n            \u0026quot;user_input\u0026quot;: user_input,\n            \u0026quot;conversation\u0026quot;: self.memory.get_context_window(),\n            \u0026quot;working_memory\u0026quot;: self.memory.working,\n            \u0026quot;available_tools\u0026quot;: self.tools.list_schemas(),\n        }\n\n    def _execute_loop(self, context: dict, plan: dict | None) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;核心执行循环\u0026quot;\u0026quot;\u0026quot;\n        steps = plan[\u0026quot;steps\u0026quot;] if plan else [{\u0026quot;action\u0026quot;: context[\u0026quot;user_input\u0026quot;]}]\n\n        results = []\n        for step in steps:\n            for i in range(self.config.max_iterations):\n                # 预算检查\n                if self.token_usage \u0026gt; self.config.max_tokens_budget:\n                    return \u0026quot;Token 预算耗尽，任务中断。\u0026quot;\n\n                # LLM 推理（含自动降级）\n                response = self._call_llm(context, step)\n\n                if response.tool_calls:\n                    self._execute_tools(response.tool_calls)\n                else:\n                    results.append(response.content)\n                    break\n\n        return \u0026quot;\\n\u0026quot;.join(results)\n\n    def _call_llm(self, context, step):\n        \u0026quot;\u0026quot;\u0026quot;LLM 调用，含降级逻辑\u0026quot;\u0026quot;\u0026quot;\n        try:\n            return self._invoke(self.config.model, context, step)\n        except Exception:\n            # 降级到备用模型\n            return self._invoke(self.config.fallback_model, context, step)\n\n    # ... 省略 _execute_tools, _reflect_and_refine 等实现细节\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e这不是最终代码，而是架构骨架。\u003c/strong\u003e 生产系统还需要：并发控制、幂等性保证、结构化日志、指标采集、灰度发布、A/B 测试、成本告警等。这些内容将在系列后续文章中逐一展开。\u003c/p\u003e\n\u003ch3\u003e演进路径总结\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eLevel 0   Level 1     Level 2        Level 3         Level 4         Level 5\n LLM ───→ +Tools ───→ +Loop ───→ +Memory ───→ +Planner ───→ +Production\n  │          │           │           │             │              │\n  │          │           │           │             │              │\n单次调用   一步行动    多步执行    有记忆的      有规划的      生产级\n无状态     无循环     有迭代       迭代执行      智能执行      完整系统\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e每一级都引入一个\u003cstrong\u003e新的能力维度\u003c/strong\u003e，也同时引入\u003cstrong\u003e新的复杂度和 trade-off\u003c/strong\u003e。不是所有场景都需要 Level 5。选择哪个级别，取决于你的任务复杂度和工程约束。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Agent 不是银弹\u003c/h2\u003e\n\u003ch3\u003e7.1 适用场景\u003c/h3\u003e\n\u003cp\u003eAgent 擅长处理以下类型的任务：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e探索性任务\u003c/strong\u003e：不确定最终需要几步、用什么工具才能完成。例：研究某个技术方案的可行性。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多工具协作\u003c/strong\u003e：需要组合多个 API/数据源的信息。例：跨平台数据聚合分析。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e需要迭代优化\u003c/strong\u003e：初版结果不够好，需要反思和改进。例：代码生成 + 自动测试 + 修复。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e半结构化流程\u003c/strong\u003e：有大致方向但细节灵活。例：客户支持中的问题诊断。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.2 不适用场景\u003c/h3\u003e\n\u003cp\u003eAgent 在以下场景中可能是错误的选择：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e确定性流程\u003c/strong\u003e：如果你能用 DAG 或状态机画出完整流程，用 Workflow 引擎比 Agent 更可靠、更可预测、更便宜。Agent 的价值在于处理\u0026quot;不确定性\u0026quot;——如果没有不确定性，你不需要 Agent。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e低延迟要求\u003c/strong\u003e：Agent 的控制循环意味着多次 LLM 调用，延迟以秒计。对于需要毫秒级响应的场景，Agent 不合适。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e高精度要求 + 零容错\u003c/strong\u003e：金融交易、医疗诊断等场景。LLM 的概率性本质意味着 Agent 不能保证 100% 正确。它可以辅助决策，但不应成为最终决策者。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e简单的问答\u003c/strong\u003e：如果用户只是问\u0026quot;1+1等于几\u0026quot;，一次 ChatCompletion 足矣，不需要 Agent 的全部架构。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.3 关键 Trade-off\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e更多 Agent 能力\u003c/th\u003e\n\u003cth\u003e代价\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e自主性\u003c/td\u003e\n\u003ctd\u003eAgent 自主决策，减少人工干预\u003c/td\u003e\n\u003ctd\u003e不可预测行为，调试困难\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e复杂度\u003c/td\u003e\n\u003ctd\u003e能处理更复杂的任务\u003c/td\u003e\n\u003ctd\u003e系统复杂度指数增长\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e成本\u003c/td\u003e\n\u003ctd\u003e每个任务消耗更多 token\u003c/td\u003e\n\u003ctd\u003e月度 API 账单可能惊人\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e延迟\u003c/td\u003e\n\u003ctd\u003e多步推理产出更好结果\u003c/td\u003e\n\u003ctd\u003e用户等待时间更长\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可靠性\u003c/td\u003e\n\u003ctd\u003e有反思和重试机制\u003c/td\u003e\n\u003ctd\u003e但每一步都可能出错，错误会累积\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e核心决策原则\u003c/strong\u003e：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e用最简单的抽象解决问题。如果 prompt engineering 够用，不要上 Agent。如果 Agent 够用，不要上 Multi-Agent。每增加一层抽象，都要问自己：这层抽象带来的能力提升，是否值得它引入的复杂度？\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 结语与后续预告\u003c/h2\u003e\n\u003cp\u003e本文作为系列开篇，建立了三个关键认知：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLLM 是函数，Agent 是系统\u003c/strong\u003e。从函数到系统，需要补齐 Memory、Tools、Planner、Runtime 四个维度。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAgent 的核心是控制循环\u003c/strong\u003e。Observe → Think → Plan → Act → Reflect → Update。循环赋予了 Agent 迭代解决问题的能力。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAgent 不是银弹\u003c/strong\u003e。选择 Agent 是一个架构决策，需要在能力与复杂度之间做出权衡。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e在接下来的文章中，我们将逐层深入：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e下一篇（02）\u003c/strong\u003e：From Prompt to Agent —— 我们将用更严格的方式论证\u0026quot;为什么 LLM 本身不是 Agent\u0026quot;，并深入讨论从 Prompt Engineering 到 Agent Engineering 的思维转换。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 03 篇\u003c/strong\u003e：Agent vs Workflow vs Automation —— 你的场景到底该用 Agent、DAG 还是规则引擎？我们会给出一个清晰的决策框架。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 04 篇\u003c/strong\u003e：The Agent Control Loop —— 深入控制循环的每一个环节，讨论状态管理、中断恢复、错误处理的工程细节。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e整个系列的目标不是教你使用某个框架的 API，而是帮你建立\u003cstrong\u003e从第一性原理理解 Agentic 系统\u003c/strong\u003e的能力。框架会变，API 会变，但系统设计的基本原理不会变。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 01 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/02-From%20Prompt%20to%20Agent\"\u003e02 | From Prompt to Agent\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录见第 5 节\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"17:Tbf8e,"])</script><script>self.__next_f.push([1,"\u003ch2\u003e一、为什么你的系统需要限流\u003c/h2\u003e\n\u003cp\u003e每个系统都有容量边界。缓存解决读的问题，降级解决非核心链路的问题，但当写操作高并发、稀缺资源被争抢、昂贵查询集中涌入时——\u003cstrong\u003e只有限流能保护你。\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e手段\u003c/th\u003e\n\u003cth\u003e解决的问题\u003c/th\u003e\n\u003cth\u003e核心机制\u003c/th\u003e\n\u003cth\u003e局限性\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e缓存\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e提速\u003c/td\u003e\n\u003ctd\u003e将高频数据放入更快的存储层\u003c/td\u003e\n\u003ctd\u003e对写操作无能为力\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e降级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e止损\u003c/td\u003e\n\u003ctd\u003e放弃非核心功能保核心链路\u003c/td\u003e\n\u003ctd\u003e前提是有东西可降，秒杀场景无法降级\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e限流\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e控流\u003c/td\u003e\n\u003ctd\u003e主动丢弃/延迟超量请求\u003c/td\u003e\n\u003ctd\u003e需要准确的容量评估，否则误杀或漏放\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e但\u0026quot;限流\u0026quot;这两个字过于笼统。请求涌入太快是限流问题，同时处理的请求太多也是限流问题，同样叫限流，控制的东西完全不同。\u003cstrong\u003e限流不是一个算法，而是一套控制体系。\u003c/strong\u003e 要选对方案，首先要搞清楚：你到底在控制什么？\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e二、你到底在控制什么——四种限流模型\u003c/h2\u003e\n\u003cp\u003e大多数人一提\u0026quot;限流\u0026quot;就想到令牌桶、漏桶。但算法只是手段，在选算法之前要先回答一个更根本的问题：\u003cstrong\u003e你要控制的是什么物理量？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e现实中的限流需求可以归纳为四种控制模型，每种控制着不同的\u0026quot;物理量\u0026quot;，适用不同的场景，也对应不同的算法家族：\u003c/p\u003e\n\u003ch3\u003e到达速率控制——控制\u0026quot;多快进来\u0026quot;\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本质：单位时间内允许通过的请求数量。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e典型场景：API 接口限制每秒 1000 次调用、用户登录接口限制每分钟 5 次尝试、短信验证码 60 秒内只能发一次。\u003c/p\u003e\n\u003cp\u003e这是最常见的限流需求。它的核心关注点是\u0026quot;单位时间的请求数\u0026quot;——不管每个请求要跑多久、占多少资源，只要单位时间内的数量不超标就放行。\u003c/p\u003e\n\u003ch3\u003e并发占用控制——控制\u0026quot;同时多少个\u0026quot;\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本质：任意时刻正在处理的请求数量。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e典型场景：数据库连接池最多 50 个连接、报表导出接口最多同时执行 3 个、文件上传同时只允许 10 个。\u003c/p\u003e\n\u003cp\u003e与速率控制的区别：速率控制不关心每个请求\u0026quot;待多久\u0026quot;，并发控制则相反——一个跑 10 分钟的报表任务，速率限制器根本管不住它。如果你有 10 个这样的任务同时运行，速率限制器显示\u0026quot;每秒只进来 1 个\u0026quot;一切正常，但系统已经被压垮了。\u003c/p\u003e\n\u003ch3\u003e长期配额控制——控制\u0026quot;总共多少次\u0026quot;\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本质：一个较长周期内允许消耗的总量。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e典型场景：免费用户每天 100 次 API 调用、每月 10GB 流量配额、每个租户每月 100 万次查询。\u003c/p\u003e\n\u003cp\u003e配额控制关注的是\u0026quot;累计消耗\u0026quot;，时间尺度从小时到月不等。它与速率控制看似相似（都是\u0026quot;一段时间内的请求数\u0026quot;），但有本质区别：速率控制关注的是\u0026quot;瞬时压力\u0026quot;——保护系统不被打垮；配额控制关注的是\u0026quot;商业资源\u0026quot;——控制成本或实现产品差异化。一个配额为每天 1000 次的用户，完全可以在第一秒就用完所有配额，速率限制器不会拦他。\u003c/p\u003e\n\u003ch3\u003e执行节奏控制——控制\u0026quot;多快出去\u0026quot;\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本质：请求被处理和释放的速率，确保输出均匀平稳。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e典型场景：消息队列消费速率控制、音视频流恒定码率传输、对接物理设备接口（打印机、传感器）。\u003c/p\u003e\n\u003cp\u003e前面三种都是在\u0026quot;入口\u0026quot;做控制：请求来了，判断能不能进。节奏控制不同，它控制的是\u0026quot;出口\u0026quot;——请求已经被接受，但要排队按固定节奏释放。即使系统空闲、令牌充裕，也不会加速处理。\u003c/p\u003e\n\u003ch3\u003e为什么不能互相替代\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e控制模型\u003c/th\u003e\n\u003cth\u003e控制的物理量\u003c/th\u003e\n\u003cth\u003e如果只用速率限制…\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e到达速率\u003c/td\u003e\n\u003ctd\u003e单位时间请求数\u003c/td\u003e\n\u003ctd\u003e✅ 这正是它干的事\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并发占用\u003c/td\u003e\n\u003ctd\u003e同时在处理的请求数\u003c/td\u003e\n\u003ctd\u003e❌ 10 个慢请求各跑 10 分钟，速率上看只有\u0026quot;1 个/分钟\u0026quot;，但并发已爆\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e长期配额\u003c/td\u003e\n\u003ctd\u003e累计消耗总量\u003c/td\u003e\n\u003ctd\u003e❌ 速率 100/s 的限制管不住\u0026quot;每天只许用 1000 次\u0026quot;的商业规则\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e执行节奏\u003c/td\u003e\n\u003ctd\u003e输出的均匀程度\u003c/td\u003e\n\u003ctd\u003e❌ 令牌桶允许突发消费，下游设备收到脉冲流量就炸了\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e需求 → 算法决策总表\u003c/h3\u003e\n\u003cp\u003e在进入具体算法之前，先给出一张导航图。后续章节会逐一展开每种算法的原理和实现：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e你的需求\u003c/th\u003e\n\u003cth\u003e控制模型\u003c/th\u003e\n\u003cth\u003e推荐算法\u003c/th\u003e\n\u003cth\u003e章节\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eAPI 限制每秒 N 次调用\u003c/td\u003e\n\u003ctd\u003e到达速率\u003c/td\u003e\n\u003ctd\u003e固定窗口 / 滑动窗口计数器\u003c/td\u003e\n\u003ctd\u003e3.1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e精确统计每个请求的时间分布\u003c/td\u003e\n\u003ctd\u003e到达速率\u003c/td\u003e\n\u003ctd\u003e滑动窗口日志\u003c/td\u003e\n\u003ctd\u003e3.1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e允许突发但限制平均速率\u003c/td\u003e\n\u003ctd\u003e突发 + 速率\u003c/td\u003e\n\u003ctd\u003e令牌桶 / GCRA\u003c/td\u003e\n\u003ctd\u003e3.2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e下游绝对不能承受波动\u003c/td\u003e\n\u003ctd\u003e执行节奏\u003c/td\u003e\n\u003ctd\u003e漏桶\u003c/td\u003e\n\u003ctd\u003e3.3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e限制同时处理的请求数\u003c/td\u003e\n\u003ctd\u003e并发占用\u003c/td\u003e\n\u003ctd\u003e信号量 / Bulkhead\u003c/td\u003e\n\u003ctd\u003e3.4\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e每天/每月 N 次调用额度\u003c/td\u003e\n\u003ctd\u003e长期配额\u003c/td\u003e\n\u003ctd\u003e固定窗口长周期 / 滚动配额\u003c/td\u003e\n\u003ctd\u003e3.5\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e三、限流算法详解与工程实现\u003c/h2\u003e\n\u003ch3\u003e3.1 速率控制家族——控制\u0026quot;多快进来\u0026quot;\u003c/h3\u003e\n\u003cp\u003e这一族算法的共同目标：在一个时间窗口内，限制请求的通过数量。区别在于如何定义和计算\u0026quot;窗口\u0026quot;。\u003c/p\u003e\n\u003ch4\u003e固定窗口计数器（Fixed Window Counter）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e在一个固定时间窗口内维护计数器，超过阈值就拒绝，窗口结束时归零。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e|← 窗口1 (0-1s) →|← 窗口2 (1-2s) →|\n    count=0→100        count=0→...\n    阈值=100           阈值=100\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e伪代码\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef fixed_window_allow(key, threshold, window_size):\n    window_id = current_time() // window_size  # 当前窗口编号\n    counter_key = f\u0026quot;{key}:{window_id}\u0026quot;\n\n    count = store.increment(counter_key)\n    if count == 1:\n        store.set_expiry(counter_key, window_size)  # 首次请求设置过期\n\n    return count \u0026lt;= threshold\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e经典问题：窗口边界的 2 倍峰值\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e|← 窗口1 →|← 窗口2 →|\n      ↑\n   最后100ms涌入100个  最前100ms涌入100个\n\n   → 200ms 内实际通过了 200 个请求（2 倍于阈值）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e精度要求不高的简单限流（大部分业务场景）\u003c/li\u003e\n\u003cli\u003e需要快速实现的场景\u003c/li\u003e\n\u003cli\u003e阈值本身留有足够余量（2 倍偶发峰值可承受）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e工程判断\u003c/strong\u003e：在很多场景中，固定窗口的精度已经足够。边界处偶尔的 2 倍峰值，对于留有余量的系统来说不是问题。不要为理论上的完美过度工程化。\u003c/p\u003e\n\u003chr\u003e\n\u003ch4\u003e滑动窗口计数器（Sliding Window Counter）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e将时间窗口划分为更细的子窗口（slot），统计时基于当前时间点向前滑动统计。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e子窗口:  |s1|s2|s3|s4|s5|s6|s7|s8|s9|s10|\n当前统计范围:          |←————————————→|\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e与固定窗口的对比\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e固定窗口\u003c/th\u003e\n\u003cth\u003e滑动窗口\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e精度\u003c/td\u003e\n\u003ctd\u003e存在边界 2 倍峰值\u003c/td\u003e\n\u003ctd\u003e消除边界效应\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e实现复杂度\u003c/td\u003e\n\u003ctd\u003e一个计数器\u003c/td\u003e\n\u003ctd\u003eN 个子窗口计数器\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e存储开销\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003eO(N)，N 为子窗口数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用场景\u003c/td\u003e\n\u003ctd\u003e精度要求低、快速实现\u003c/td\u003e\n\u003ctd\u003e精度要求高、阈值接近系统极限\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e伪代码\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef sliding_window_allow(key, threshold, window_size, num_slots):\n    slot_size = window_size / num_slots\n    now = current_time()\n    current_slot = now // slot_size\n\n    # 统计当前窗口内所有子窗口的计数\n    total = 0\n    for i in range(num_slots):\n        slot_key = f\u0026quot;{key}:{current_slot - i}\u0026quot;\n        total += store.get(slot_key, default=0)\n\n    if total \u0026gt;= threshold:\n        return False\n\n    # 当前子窗口计数 +1\n    store.increment(f\u0026quot;{key}:{current_slot}\u0026quot;)\n    store.set_expiry(f\u0026quot;{key}:{current_slot}\u0026quot;, window_size + slot_size)\n    return True\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工程实践：Sentinel 的滑动窗口实现\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e阿里巴巴的 Sentinel 框架使用 \u003ccode\u003eLeapArray\u003c/code\u003e 数据结构实现滑动窗口：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e将 1 秒划分为若干个 \u003ccode\u003eWindowWrap\u003c/code\u003e（默认 2 个，即 500ms 一个子窗口）\u003c/li\u003e\n\u003cli\u003e每个子窗口维护独立的 pass/block/exception 等计数器\u003c/li\u003e\n\u003cli\u003e通过环形数组 + 时间戳判断实现窗口滑动，避免频繁创建销毁对象\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch4\u003e滑动窗口日志（Sliding Window Log）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e记录每一个请求的精确时间戳，判断时移除窗口外的过期记录，然后统计剩余记录数。这是精度最高的速率控制算法——没有子窗口的近似，每个请求的时间位置都被精确记录。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e窗口大小 = 1s，阈值 = 5\n\n请求日志: [0.1, 0.3, 0.5, 0.8, 0.9]\n                                    ↑ 当前时间 = 1.2s\n\n移除 \u0026lt; 0.2 的记录 → [0.3, 0.5, 0.8, 0.9]\n当前窗口内 4 个请求 \u0026lt; 阈值 5 → 放行，记录 1.2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e伪代码\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef sliding_log_allow(key, threshold, window_size):\n    now = current_time()\n\n    # 移除窗口外的过期记录\n    store.remove_before(key, now - window_size)\n\n    # 统计当前窗口内的请求数\n    count = store.count(key)\n\n    if count \u0026lt; threshold:\n        store.add(key, now)  # 记录本次请求时间戳\n        return True\n    return False\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优势与代价\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e精度\u003c/td\u003e\n\u003ctd\u003e完美——没有任何窗口边界问题\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e存储开销\u003c/td\u003e\n\u003ctd\u003eO(N)，N 为窗口内的请求数。QPS 1000 + 1s 窗口 = 1000 条记录\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用场景\u003c/td\u003e\n\u003ctd\u003e低 QPS + 高精度要求（如 API 计费、安全审计）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e不适用\u003c/td\u003e\n\u003ctd\u003e高 QPS 场景——存储和清理开销过大\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e工程判断\u003c/strong\u003e：滑动窗口日志的精度是三种窗口算法中最高的，但存储成本也最高。在 Redis 中通常用 Sorted Set 实现（第四章会详细展示）。对于大多数业务场景，滑动窗口计数器是更好的平衡点。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003e3.2 突发与平均速率——控制\u0026quot;允许多大的脉冲\u0026quot;\u003c/h3\u003e\n\u003cp\u003e窗口类算法有一个共同的局限：它们只看\u0026quot;窗口内的总量\u0026quot;，不区分\u0026quot;均匀到达\u0026quot;和\u0026quot;一瞬间全来\u0026quot;。令牌桶和 GCRA 解决的正是这个问题——允许一定程度的突发，但限制长期平均速率。\u003c/p\u003e\n\u003ch4\u003e令牌桶算法（Token Bucket）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e令牌桶的理念：\u003cstrong\u003e在空闲时积蓄能力，在繁忙时释放能力。\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e令牌生成器 ──恒定速率──→ [  令牌桶（有容量上限）  ]\n                                    ↓\n                         请求到达 → 取令牌 → 有令牌则通过\n                                           → 无令牌则拒绝/等待\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e系统以恒定速率向桶中放入令牌\u003c/li\u003e\n\u003cli\u003e每个请求消耗一个（或多个）令牌\u003c/li\u003e\n\u003cli\u003e令牌充足时请求立即通过\u003c/li\u003e\n\u003cli\u003e令牌耗尽时请求被拒绝或阻塞等待\u003c/li\u003e\n\u003cli\u003e桶有容量上限，多余令牌溢出\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心参数\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e参数\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e设计考量\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e令牌生成速率\u003c/td\u003e\n\u003ctd\u003e系统的持续处理能力\u003c/td\u003e\n\u003ctd\u003e对应系统稳态吞吐上限\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e桶容量\u003c/td\u003e\n\u003ctd\u003e允许的最大突发量\u003c/td\u003e\n\u003ctd\u003e编码了对突发流量的容忍度\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e伪代码\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass TokenBucket:\n    def __init__(self, rate, capacity):\n        self.rate = rate          # 令牌生成速率（个/秒）\n        self.capacity = capacity  # 桶容量\n        self.tokens = capacity    # 当前令牌数\n        self.last_refill = current_time()\n\n    def allow(self, cost=1):\n        now = current_time()\n        # 懒填充：按经过的时间计算应补充的令牌\n        elapsed = now - self.last_refill\n        self.tokens = min(self.capacity, self.tokens + elapsed * self.rate)\n        self.last_refill = now\n\n        if self.tokens \u0026gt;= cost:\n            self.tokens -= cost\n            return True\n        return False\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键实现细节：\u0026quot;懒填充\u0026quot;（lazy refill）。不需要一个后台线程不断往桶里放令牌，只需在每次请求到来时，根据距上次填充的时间差计算应补充的令牌数。这让实现变得无锁且高效。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e互联网 API 限流（绝大多数场景的首选）\u003c/li\u003e\n\u003cli\u003e允许合理突发的业务场景（秒杀、热点事件引发的流量脉冲）\u003c/li\u003e\n\u003cli\u003e需要区分长期速率和瞬时峰值的场景\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e工程实践：Guava RateLimiter 的两种模式\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eGuava 提供了两种令牌桶实现，对应两种不同的业务需求：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// 模式一：SmoothBursty —— 允许突发\n// 以每秒 100 个令牌的速率生成，桶容量等于 1 秒的产量（100）\nRateLimiter limiter = RateLimiter.create(100.0);\n\n// 场景：API 网关限流\n// 特点：空闲期积累的令牌可以一次性消费，应对突发\nif (limiter.tryAcquire()) {\n    processRequest();\n} else {\n    return Response.status(429).build();\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// 模式二：SmoothWarmingUp —— 冷启动预热\n// 速率 100/s，预热期 3 秒\nRateLimiter limiter = RateLimiter.create(100.0, 3, TimeUnit.SECONDS);\n\n// 场景：数据库连接池、缓存冷启动\n// 特点：系统刚启动时不会全速放量，给下游一个\u0026quot;热身\u0026quot;时间\n// 预热期内速率从低到高线性增长，避免冷系统被瞬时流量打垮\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSmoothBursty vs SmoothWarmingUp 的选择\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eSmoothBursty\u003c/th\u003e\n\u003cth\u003eSmoothWarmingUp\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e突发处理\u003c/td\u003e\n\u003ctd\u003e允许消费积累的令牌，支持突发\u003c/td\u003e\n\u003ctd\u003e冷启动期间限制突发\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e典型场景\u003c/td\u003e\n\u003ctd\u003eAPI 限流、消息推送\u003c/td\u003e\n\u003ctd\u003e数据库预热、缓存预热\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e核心关注\u003c/td\u003e\n\u003ctd\u003e流量的峰谷平衡\u003c/td\u003e\n\u003ctd\u003e系统的冷热状态转换\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e关键注意\u003c/strong\u003e：Guava RateLimiter 是\u003cstrong\u003e单机限流\u003c/strong\u003e。它只能控制当前 JVM 进程的流量，在分布式环境下需要配合 Redis 方案使用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch4\u003eGCRA（Generic Cell Rate Algorithm）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eGCRA 是令牌桶的数学等价形式，但实现更精简。它不维护\u0026quot;当前令牌数\u0026quot;，而是维护一个\u0026quot;理论到达时间\u0026quot;（TAT，Theoretical Arrival Time）——下一个请求最早应该在什么时候到达。\u003c/p\u003e\n\u003cp\u003e核心思想：如果请求到达得比预期频率更快，TAT 会不断后推；如果请求到达得比预期慢，TAT 会被拉回到当前时间附近（但不会超前太多，受突发容量限制）。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e参数：\n  emission_interval = 1/rate     -- 每个请求的理论间隔\n  burst_tolerance   = burst * emission_interval  -- 允许的最大提前量\n\n判断逻辑：\n  TAT = max(TAT, now) + emission_interval\n  如果 TAT - now \u0026gt; burst_tolerance → 拒绝（超前太多，突发已耗尽）\n  否则 → 放行，更新 TAT\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e伪代码\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass GCRA:\n    def __init__(self, rate, burst):\n        self.emission_interval = 1.0 / rate       # 每个请求的理论间隔\n        self.burst_tolerance = burst * self.emission_interval  # 最大提前量\n        self.tat = 0  # 理论到达时间（Theoretical Arrival Time）\n\n    def allow(self):\n        now = current_time()\n        # 新的 TAT = max(上次TAT, 当前时间) + 一个间隔\n        new_tat = max(self.tat, now) + self.emission_interval\n\n        # 如果 TAT 超前当前时间太多，说明突发额度已用完\n        if new_tat - now \u0026gt; self.burst_tolerance:\n            return False\n\n        self.tat = new_tat\n        return True\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e为什么 GCRA 值得关注\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e优势\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e状态极简\u003c/td\u003e\n\u003ctd\u003e只需存储一个值（TAT），对比令牌桶需要存 tokens + last_refill\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e天然适合分布式\u003c/td\u003e\n\u003ctd\u003e一个 Redis key 存一个时间戳，原子 CAS 即可更新\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数学精确\u003c/td\u003e\n\u003ctd\u003e与令牌桶行为完全等价，但无浮点累积误差\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e工程实践\u003c/strong\u003e：GCRA 广泛用于网络设备的 ATM 流量控制（这也是它名字中\u0026quot;Cell Rate\u0026quot;的来源），在互联网领域被 Cloudflare、Stripe 等公司采用作为 API 限流的核心算法。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003e3.3 流量整形——控制\u0026quot;多快出去\u0026quot;\u003c/h3\u003e\n\u003ch4\u003e漏桶算法（Leaky Bucket）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e漏桶的逻辑可以用一句话概括：\u003cstrong\u003e无论流入多快，流出永远恒定。\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e请求流入 → [  桶（有容量上限）  ] → 恒定速率流出 → 下游处理\n                    ↓\n              桶满则丢弃\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e请求以任意速率流入桶中\u003c/li\u003e\n\u003cli\u003e桶底以固定速率流出（处理请求）\u003c/li\u003e\n\u003cli\u003e桶有容量上限，溢出的请求被直接丢弃\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心参数\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e参数\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e设计考量\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e流出速率\u003c/td\u003e\n\u003ctd\u003e下游能承受的恒定处理能力\u003c/td\u003e\n\u003ctd\u003e取决于下游系统的稳态吞吐上限\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e桶容量\u003c/td\u003e\n\u003ctd\u003e允许暂存的最大请求数\u003c/td\u003e\n\u003ctd\u003e过大导致延迟积累，过小导致突发流量全被丢弃\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e与令牌桶的本质区别\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e令牌桶控制的是\u0026quot;允许进入的速率\u0026quot;（入口），漏桶控制的是\u0026quot;实际处理的速率\u0026quot;（出口）。令牌桶在空闲后可以突发放行一批请求，漏桶永远不会——即使桶里积攒了很多请求，也只能按固定速率一个个出去。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e对接物理设备或硬件接口（严格不允许任何突发）\u003c/li\u003e\n\u003cli\u003e需要绝对平滑的输出流量（如音视频流的恒定码率传输）\u003c/li\u003e\n\u003cli\u003e流量整形（traffic shaping）场景\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e不适用场景\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e互联网业务的 API 限流（真实流量天然是突发的，漏桶的死板会浪费系统空闲容量）\u003c/li\u003e\n\u003cli\u003e需要快速响应突发请求的场景\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e工程实践：Nginx 的 \u003ccode\u003elimit_req\u003c/code\u003e 就是漏桶实现\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-nginx\"\u003e# 定义限流区域：10MB 共享内存，每个 IP 每秒 10 个请求\nlimit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n\nserver {\n    location /api/ {\n        # burst=20：桶容量为 20，超出的排队\n        # nodelay：排队请求不延迟，立即处理（占用 burst 配额）\n        limit_req zone=api burst=20 nodelay;\n\n        # 超限返回 429 而非默认的 503\n        limit_req_status 429;\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这里有个常见误区：\u003ccode\u003eburst=20 nodelay\u003c/code\u003e 不是\u0026quot;允许突发 20 个请求\u0026quot;那么简单。\u003ccode\u003enodelay\u003c/code\u003e 的含义是突发请求立即转发（不排队等待），但每个突发请求会\u0026quot;占用\u0026quot;一个 burst 槽位，槽位按 \u003ccode\u003erate\u003c/code\u003e 的速率恢复。实际效果是：瞬间可以通过 30 个请求（rate + burst），但之后必须等槽位恢复。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003e3.4 并发控制——控制\u0026quot;同时多少个\u0026quot;\u003c/h3\u003e\n\u003cp\u003e前面所有算法都在控制\u0026quot;速率\u0026quot;——单位时间通过多少个请求。但有些场景下，速率不是瓶颈，并发才是。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题场景\u003c/strong\u003e：一个报表导出接口，每次调用需要 30 秒完成，消耗大量 CPU 和内存。即使限制为每秒 1 个请求，如果 30 秒内每秒都来一个，就有 30 个同时在执行——足以打垮服务。\u003c/p\u003e\n\u003ch4\u003e信号量 / Bulkhead\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e维护一个并发计数器。请求进入时 +1，请求完成时 -1。计数器达到上限时，新请求被拒绝或排队。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e请求进入 → 计数器 +1 → [正在处理：当前 3/5] → 完成 → 计数器 -1\n                ↓\n          计数器 = 5 → 拒绝/排队\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e伪代码\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ConcurrencyLimiter:\n    def __init__(self, max_concurrent):\n        self.max_concurrent = max_concurrent\n        self.current = 0         # 当前并发数\n        self.lock = Lock()\n\n    def acquire(self):\n        with self.lock:\n            if self.current \u0026gt;= self.max_concurrent:\n                return False\n            self.current += 1\n            return True\n\n    def release(self):\n        with self.lock:\n            self.current -= 1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e关键区别：为什么速率限制替代不了并发控制？\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景\u003c/th\u003e\n\u003cth\u003e速率限制（10 req/s）\u003c/th\u003e\n\u003cth\u003e并发控制（max=5）\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e快请求（10ms）\u003c/td\u003e\n\u003ctd\u003e正常工作\u003c/td\u003e\n\u003ctd\u003e不会触发（并发始终很低）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e慢请求（30s）\u003c/td\u003e\n\u003ctd\u003e30s 内放入 300 个请求，全部同时在跑\u003c/td\u003e\n\u003ctd\u003e只允许 5 个同时执行，第 6 个等待\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e资源保护效果\u003c/td\u003e\n\u003ctd\u003e慢请求场景下完全失效\u003c/td\u003e\n\u003ctd\u003e精确保护下游并发能力\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e工程实践\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eJava：\u003ccode\u003eSemaphore\u003c/code\u003e、Resilience4j 的 \u003ccode\u003eBulkhead\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e数据库：连接池本质就是并发控制\u003c/li\u003e\n\u003cli\u003eNginx：\u003ccode\u003elimit_conn\u003c/code\u003e 限制并发连接数\u003c/li\u003e\n\u003cli\u003eHystrix/Sentinel：线程池隔离（每个下游依赖独立的并发上限）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBulkhead（舱壁隔离）模式\u003c/strong\u003e：把不同依赖的并发限制隔离开，A 服务的慢查询把自己的并发额度用完，不会影响 B 服务的调用。\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003e3.5 配额控制——控制\u0026quot;总共多少次\u0026quot;\u003c/h3\u003e\n\u003ch4\u003e固定窗口长周期 / 滚动配额\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e核心原理\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e配额控制在技术实现上往往就是一个大窗口的固定窗口计数器——窗口大小从分钟级变成天/月级。但它的设计意图完全不同：速率控制保护系统不被打垮，配额控制实现商业规则。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型实现\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef check_quota(user_id, tier):\n    quotas = {\n        \u0026quot;free\u0026quot;: {\u0026quot;daily\u0026quot;: 100, \u0026quot;monthly\u0026quot;: 1000},\n        \u0026quot;pro\u0026quot;:  {\u0026quot;daily\u0026quot;: 10000, \u0026quot;monthly\u0026quot;: 100000},\n    }\n\n    daily_key = f\u0026quot;quota:daily:{user_id}:{today()}\u0026quot;\n    monthly_key = f\u0026quot;quota:monthly:{user_id}:{this_month()}\u0026quot;\n\n    daily_count = store.get(daily_key, 0)\n    monthly_count = store.get(monthly_key, 0)\n\n    limits = quotas[tier]\n    if daily_count \u0026gt;= limits[\u0026quot;daily\u0026quot;] or monthly_count \u0026gt;= limits[\u0026quot;monthly\u0026quot;]:\n        return False, remaining(limits, daily_count, monthly_count)\n\n    store.increment(daily_key)\n    store.increment(monthly_key)\n    return True, remaining(limits, daily_count + 1, monthly_count + 1)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工程要点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e配额通常需要返回剩余量（\u003ccode\u003eX-RateLimit-Remaining\u003c/code\u003e header），方便调用方规划使用\u003c/li\u003e\n\u003cli\u003e长周期配额的窗口边界（如月初重置）是产品决策，不是技术决策\u003c/li\u003e\n\u003cli\u003e配额超限的拒绝策略通常比速率限制更\u0026quot;温和\u0026quot;——返回明确的额度信息和升级引导，而非简单的 429\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch3\u003e算法对比总表\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e算法\u003c/th\u003e\n\u003cth\u003e控制模型\u003c/th\u003e\n\u003cth\u003e核心特征\u003c/th\u003e\n\u003cth\u003e突发处理\u003c/th\u003e\n\u003cth\u003e存储开销\u003c/th\u003e\n\u003cth\u003e推荐场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e固定窗口\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e到达速率\u003c/td\u003e\n\u003ctd\u003e简单计数\u003c/td\u003e\n\u003ctd\u003e边界 2 倍峰值\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003e快速实现、精度要求低\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e滑动窗口计数器\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e到达速率\u003c/td\u003e\n\u003ctd\u003e子窗口聚合\u003c/td\u003e\n\u003ctd\u003e平滑\u003c/td\u003e\n\u003ctd\u003eO(N) 子窗口数\u003c/td\u003e\n\u003ctd\u003e精度要求高、阈值紧\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e滑动窗口日志\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e到达速率\u003c/td\u003e\n\u003ctd\u003e精确时间戳\u003c/td\u003e\n\u003ctd\u003e完美\u003c/td\u003e\n\u003ctd\u003eO(N) 请求数\u003c/td\u003e\n\u003ctd\u003e低 QPS + 高精度\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e令牌桶\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e突发 + 速率\u003c/td\u003e\n\u003ctd\u003e积蓄+释放\u003c/td\u003e\n\u003ctd\u003e允许有限突发\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003eAPI 限流（首选）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eGCRA\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e突发 + 速率\u003c/td\u003e\n\u003ctd\u003e单时间戳\u003c/td\u003e\n\u003ctd\u003e允许有限突发\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003e分布式 API 限流\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e漏桶\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e执行节奏\u003c/td\u003e\n\u003ctd\u003e恒定输出\u003c/td\u003e\n\u003ctd\u003e不允许突发\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003e流量整形、硬件接口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e信号量\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e并发占用\u003c/td\u003e\n\u003ctd\u003e进出计数\u003c/td\u003e\n\u003ctd\u003e不涉及\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003e慢请求、连接池\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e固定窗口长周期\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e长期配额\u003c/td\u003e\n\u003ctd\u003e累计统计\u003c/td\u003e\n\u003ctd\u003e不涉及\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003e商业配额、计费\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e选择策略\u003c/strong\u003e：先确定你的控制模型（速率/并发/配额/节奏），再在对应的算法家族中选择。如果没有特殊需求，令牌桶是互联网业务的默认选择。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e四、从单机到分布式：最关键的认知跃迁\u003c/h2\u003e\n\u003ch3\u003e单机限流为什么在集群中失效\u003c/h3\u003e\n\u003cp\u003e一个团队用 Guava RateLimiter 限制短信 API 调用为 400 QPS，本地测试完美。代码部署到 4 个节点后，4 个节点各自以 400 QPS 发送，服务商实际承受 1600 QPS，接口再次崩溃。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e根因：单机限流只能控制单个进程的流量，对其他节点一无所知。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e直觉的修复是均分配额：4 个节点各分 100 QPS。但这引入新问题：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e理想中：\n  节点A: 100 QPS → 25%\n  节点B: 100 QPS → 25%\n  节点C: 100 QPS → 25%\n  节点D: 100 QPS → 25%\n\n现实中（负载不均）：\n  节点A: 240 QPS → 只放行 100，拒绝 140 ✗\n  节点B: 120 QPS → 只放行 100，拒绝  20 ✗\n  节点C:  30 QPS → 只用了 30，浪费  70\n  节点D:  10 QPS → 只用了 10，浪费  90\n\n  总放行：240 QPS（理论可放 400，实际只放了 240）\n  → 系统实际吞吐远低于理论上限\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e动态调整配额（根据节点负载实时重新分配）？复杂度爆炸——你需要协调机制感知节点上下线、收集实时负载、计算下发配额，这本身就是一个分布式系统问题。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e标准答案：将限流状态提升到共享的集中存储中。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003e分布式限流的核心原则\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e限流的粒度决定了它的准确性。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e保护对象\u003c/th\u003e\n\u003cth\u003e限流粒度\u003c/th\u003e\n\u003cth\u003e方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e本机 CPU/内存\u003c/td\u003e\n\u003ctd\u003e进程级\u003c/td\u003e\n\u003ctd\u003eGuava RateLimiter、Sentinel\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e外部 API 配额\u003c/td\u003e\n\u003ctd\u003e系统级（全集群）\u003c/td\u003e\n\u003ctd\u003eRedis 分布式计数器\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e业务规则（如用户发送频率）\u003c/td\u003e\n\u003ctd\u003e用户级\u003c/td\u003e\n\u003ctd\u003eRedis + 用户维度 key\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003eRedis 分布式限流：为什么是标准答案\u003c/h3\u003e\n\u003cp\u003eRedis 之所以成为分布式限流的事实标准，是因为它的特性精确匹配了限流的每一个核心需求：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e限流需求\u003c/th\u003e\n\u003cth\u003eRedis 特性\u003c/th\u003e\n\u003cth\u003e为什么匹配\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e原子性：\u0026quot;读取-判断-递增\u0026quot;必须原子\u003c/td\u003e\n\u003ctd\u003eINCR 原子命令 + Lua 脚本\u003c/td\u003e\n\u003ctd\u003e单线程模型，天然无并发冲突\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e极致性能：每个请求都要过限流\u003c/td\u003e\n\u003ctd\u003e内存操作，亚毫秒级延迟\u003c/td\u003e\n\u003ctd\u003e不成为业务瓶颈\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e共享状态：所有节点看到同一个计数器\u003c/td\u003e\n\u003ctd\u003e独立服务，集群可访问\u003c/td\u003e\n\u003ctd\u003e分布式协调问题消失\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e自动过期：时间窗口结束后计数器清零\u003c/td\u003e\n\u003ctd\u003eKey 级别 TTL\u003c/td\u003e\n\u003ctd\u003e无需额外清理逻辑\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e工程实践：基于 Redis + Lua 的固定窗口限流\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e为什么必须用 Lua 脚本？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e不用 Lua 的伪代码：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecount = redis.GET(key)          -- 步骤1：读取\nif count \u0026lt; threshold:           -- 步骤2：判断\n    redis.INCR(key)             -- 步骤3：递增\n    return ALLOW\nelse:\n    return REJECT\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e并发问题：两个节点同时读到 count=399（阈值 400），都判断\u0026quot;未超限\u0026quot;，都执行 INCR。最终 count=401，但两个请求都通过了。高并发下，这种竞态条件被急剧放大，限流形同虚设。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLua 脚本实现（原子操作）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-lua\"\u003e-- KEYS[1]: 限流 key，如 \u0026quot;rate_limit:sms_api:1609459200\u0026quot;\n-- ARGV[1]: 阈值\n-- ARGV[2]: 窗口过期时间（秒）\n\nlocal key = KEYS[1]\nlocal threshold = tonumber(ARGV[1])\nlocal expire_time = tonumber(ARGV[2])\n\nlocal current = tonumber(redis.call(\u0026#39;GET\u0026#39;, key) or \u0026quot;0\u0026quot;)\n\nif current + 1 \u0026gt; threshold then\n    return 0  -- 拒绝\nelse\n    redis.call(\u0026#39;INCR\u0026#39;, key)\n    if current == 0 then\n        redis.call(\u0026#39;EXPIRE\u0026#39;, key, expire_time)\n    end\n    return 1  -- 放行\nend\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eKey 设计规范\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e格式：rate_limit:{业务标识}:{维度}:{时间窗口}\n示例：\n  rate_limit:sms_api:global:1609459200       -- 全局短信 API 限流\n  rate_limit:login:user:12345:1609459200     -- 用户维度登录限流\n  rate_limit:order:tenant:abc:1609459200     -- 租户维度下单限流\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e工程实践：基于 Redis 的滑动窗口限流\u003c/h3\u003e\n\u003cp\u003e当固定窗口的边界问题不可接受时，可以用 Redis Sorted Set 实现滑动窗口：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-lua\"\u003e-- KEYS[1]: 限流 key\n-- ARGV[1]: 阈值\n-- ARGV[2]: 窗口大小（毫秒）\n-- ARGV[3]: 当前时间戳（毫秒）\n-- ARGV[4]: 唯一请求ID\n\nlocal key = KEYS[1]\nlocal threshold = tonumber(ARGV[1])\nlocal window = tonumber(ARGV[2])\nlocal now = tonumber(ARGV[3])\nlocal request_id = ARGV[4]\n\n-- 移除窗口外的过期记录\nredis.call(\u0026#39;ZREMRANGEBYSCORE\u0026#39;, key, 0, now - window)\n\n-- 统计当前窗口内的请求数\nlocal count = redis.call(\u0026#39;ZCARD\u0026#39;, key)\n\nif count \u0026lt; threshold then\n    -- 添加当前请求，score 为时间戳\n    redis.call(\u0026#39;ZADD\u0026#39;, key, now, request_id)\n    redis.call(\u0026#39;PEXPIRE\u0026#39;, key, window)\n    return 1  -- 放行\nelse\n    return 0  -- 拒绝\nend\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e两种 Redis 方案的对比\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e固定窗口（String + INCR）\u003c/th\u003e\n\u003cth\u003e滑动窗口（Sorted Set）\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e存储开销\u003c/td\u003e\n\u003ctd\u003eO(1)，一个 key 一个计数器\u003c/td\u003e\n\u003ctd\u003eO(N)，N 为窗口内请求数\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e时间复杂度\u003c/td\u003e\n\u003ctd\u003eO(1)\u003c/td\u003e\n\u003ctd\u003eO(log N)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e精度\u003c/td\u003e\n\u003ctd\u003e边界可能 2 倍峰值\u003c/td\u003e\n\u003ctd\u003e精确\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用\u003c/td\u003e\n\u003ctd\u003e大部分场景\u003c/td\u003e\n\u003ctd\u003e阈值紧、精度要求高\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e工程建议\u003c/strong\u003e：优先用固定窗口方案。只有当阈值非常接近系统极限（余量 \u0026lt; 20%）时，才需要滑动窗口的精度。\u003c/p\u003e\n\u003ch3\u003e关于时钟同步\u003c/h3\u003e\n\u003cp\u003e分布式系统中，各节点用本地时间计算 Redis key 中的时间窗口标识，时钟偏移可能导致不同节点在不同窗口中计数。严格做法是用 Redis 服务端时间 \u003ccode\u003eredis.call(\u0026#39;TIME\u0026#39;)\u003c/code\u003e。但现代服务器通过 NTP 同步后的时钟偏差通常在毫秒级，对秒级窗口几乎无影响。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e工程判断\u003c/strong\u003e：对于秒级窗口，使用本地时间戳即可。对于百毫秒级窗口或对精度有极端要求的场景，使用 Redis 服务端时间。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e五、多层限流：纵深防御架构\u003c/h2\u003e\n\u003cp\u003e一个常见误区是试图在某一层解决所有限流问题。良好的限流架构应该是分层的——每一层保护不同的东西，承担不同的职责。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                     请求流入\n                        ↓\n┌──────────────────────────────────────────┐\n│  第一层：接入层（Nginx / CDN）            │  ← 挡住恶意流量和 DDoS\n│  基于 IP 的连接数和请求速率限制            │\n└──────────────────────────────────────────┘\n                        ↓\n┌──────────────────────────────────────────┐\n│  第二层：API 网关（Gateway）              │  ← 业务感知型限流\n│  基于用户/租户/API 维度的差异化限流        │\n└──────────────────────────────────────────┘\n                        ↓\n┌──────────────────────────────────────────┐\n│  第三层：业务层                           │  ← 业务规则型限流\n│  业务语义的频率控制（发帖/下单/发短信）     │\n└──────────────────────────────────────────┘\n                        ↓\n┌──────────────────────────────────────────┐\n│  第四层：数据层                           │  ← 最后一道防线\n│  连接池 / 线程池隔离 / 熔断器             │\n└──────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e各层详细对比\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e层级\u003c/th\u003e\n\u003cth\u003e保护对象\u003c/th\u003e\n\u003cth\u003e限流维度\u003c/th\u003e\n\u003cth\u003e典型工具\u003c/th\u003e\n\u003cth\u003e算法\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e接入层\u003c/td\u003e\n\u003ctd\u003e基础设施\u003c/td\u003e\n\u003ctd\u003eIP、连接数\u003c/td\u003e\n\u003ctd\u003eNginx \u003ccode\u003elimit_req\u003c/code\u003e/\u003ccode\u003elimit_conn\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e漏桶\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAPI 网关\u003c/td\u003e\n\u003ctd\u003e服务处理能力\u003c/td\u003e\n\u003ctd\u003e用户 ID、API Key、租户\u003c/td\u003e\n\u003ctd\u003eRedis + Lua、Sentinel\u003c/td\u003e\n\u003ctd\u003e令牌桶/滑动窗口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e业务层\u003c/td\u003e\n\u003ctd\u003e业务规则\u003c/td\u003e\n\u003ctd\u003e业务实体（用户行为频率）\u003c/td\u003e\n\u003ctd\u003eRedis + 业务代码\u003c/td\u003e\n\u003ctd\u003e固定窗口\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据层\u003c/td\u003e\n\u003ctd\u003e存储和依赖\u003c/td\u003e\n\u003ctd\u003e并发连接数\u003c/td\u003e\n\u003ctd\u003e连接池、Hystrix、Resilience4j\u003c/td\u003e\n\u003ctd\u003e信号量/熔断\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e各层工程实践\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e接入层：Nginx 配置示例\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-nginx\"\u003ehttp {\n    # IP 维度的请求速率限制\n    limit_req_zone $binary_remote_addr zone=ip_rate:10m rate=100r/s;\n\n    # IP 维度的并发连接数限制\n    limit_conn_zone $binary_remote_addr zone=ip_conn:10m;\n\n    server {\n        # API 接口：每 IP 100r/s，突发 50\n        location /api/ {\n            limit_req zone=ip_rate burst=50 nodelay;\n            limit_conn ip_conn 50;\n            limit_req_status 429;\n        }\n\n        # 登录接口：更严格的限制\n        location /api/login {\n            limit_req zone=ip_rate burst=5;\n            limit_req_status 429;\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eAPI 网关层：差异化限流\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// 不同级别用户的限流配置\npublic class RateLimitConfig {\n    // 免费用户：60 次/分钟\n    // 付费用户：600 次/分钟\n    // 企业用户：6000 次/分钟\n\n    public int getThreshold(User user) {\n        return switch (user.getTier()) {\n            case FREE       -\u0026gt; 60;\n            case PREMIUM    -\u0026gt; 600;\n            case ENTERPRISE -\u0026gt; 6000;\n        };\n    }\n\n    // 不同 API 端点的限流配置\n    // 重查询接口：50 QPS\n    // 轻量读接口：5000 QPS\n    // 写操作接口：200 QPS\n\n    public int getThreshold(String endpoint) {\n        return switch (endpoint) {\n            case \u0026quot;/api/report/generate\u0026quot; -\u0026gt; 50;    // 计算密集\n            case \u0026quot;/api/user/info\u0026quot;       -\u0026gt; 5000;  // 轻量读\n            case \u0026quot;/api/order/create\u0026quot;    -\u0026gt; 200;   // 写操作\n            default                     -\u0026gt; 1000;\n        };\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e业务层：业务规则型限流\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// 业务限流的阈值来自产品需求，不是压测\npublic class BusinessRateLimiter {\n\n    // 防骚扰：每用户每分钟最多 5 条短信\n    public boolean allowSendSms(long userId) {\n        String key = \u0026quot;biz:sms:\u0026quot; + userId + \u0026quot;:\u0026quot; + currentMinute();\n        return redisRateLimiter.tryAcquire(key, 5, 60);\n    }\n\n    // 反垃圾：新账号 24 小时内最多发 10 条帖子\n    public boolean allowPost(long userId, boolean isNewAccount) {\n        if (!isNewAccount) return true;\n        String key = \u0026quot;biz:post:new:\u0026quot; + userId + \u0026quot;:\u0026quot; + today();\n        return redisRateLimiter.tryAcquire(key, 10, 86400);\n    }\n\n    // 运营策略：商家每天最多创建 100 个促销活动\n    public boolean allowCreatePromotion(long merchantId) {\n        String key = \u0026quot;biz:promo:\u0026quot; + merchantId + \u0026quot;:\u0026quot; + today();\n        return redisRateLimiter.tryAcquire(key, 100, 86400);\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e数据层：隐式限流\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e数据层的\u0026quot;限流\u0026quot;通常不以限流的名义出现，但本质上发挥着同样的作用：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e连接池\u003c/strong\u003e：连接池满时新请求排队等待 → 并发度上限\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e线程池隔离\u003c/strong\u003e：为每个下游依赖分配独立线程池 → 故障隔离\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e熔断器\u003c/strong\u003e：错误率超阈值时直接停止调用 → 自适应限流\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e每一层保护不同的东西。\u003c/strong\u003e 接入层保护基础设施不被滥用流量冲垮；API 网关保护服务处理能力不被超载；业务层保护业务规则不被绕过；数据层保护最脆弱的存储和依赖。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e六、限流的工程闭环\u003c/h2\u003e\n\u003cp\u003e限流架构设计完了，还差两个关键环节：阈值从哪来？被拒绝的请求去哪了？这两个问题不解决，限流就是半成品。\u003c/p\u003e\n\u003ch3\u003e6.1 阈值从哪来\u003c/h3\u003e\n\u003cp\u003e所有限流工程中最难的问题不是技术实现，而是：\u003cstrong\u003e阈值应该设多少？\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e四步确定阈值\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e步骤\u003c/th\u003e\n\u003cth\u003e方法\u003c/th\u003e\n\u003cth\u003e产出\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e1. 压测基线\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e逐步加压，观察 P99 延迟和错误率的拐点\u003c/td\u003e\n\u003ctd\u003e系统实际容量边界\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e2. 安全系数\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e阈值 = 容量边界 × 70%~80%\u003c/td\u003e\n\u003ctd\u003e留出余量应对突发波动\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e3. 持续监控\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e监控 P99、错误率、CPU、内存\u003c/td\u003e\n\u003ctd\u003e发现容量变化及时调整\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e4. 渐进调整\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e从保守值开始，观察线上表现后逐步放宽\u003c/td\u003e\n\u003ctd\u003e避免上线即翻车\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e自适应限流\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e更高级的形态是基于实时指标的自动限流。以 Sentinel 为例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-java\"\u003e// 基于系统负载的自适应限流\nSystemRule rule = new SystemRule();\nrule.setHighestCpuUsage(0.8);    // CPU \u0026gt; 80% 时触发限流\nrule.setHighestSystemLoad(2.5);   // System Load \u0026gt; 2.5 时触发限流\nrule.setAvgRt(200);               // 平均 RT \u0026gt; 200ms 时触发限流\n\n// 优点：省去人为猜测阈值\n// 风险：正常流量波动可能触发误限，需仔细调试灵敏度\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e阈值是业务决策\u003c/strong\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e限流阈值不是纯技术参数，而是一个业务决策。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e它编码的是\u0026quot;我们愿意承受多大负载，以及拒绝超额流量的业务成本是什么\u0026quot;。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e面向消费者的核心交易链路：拒绝一个请求 = 损失一笔订单 → 阈值宜宽\u003c/li\u003e\n\u003cli\u003e内部数据分析任务：晚执行几分钟无损失 → 阈值可严\u003c/li\u003e\n\u003cli\u003e计算密集的报表接口：单个请求消耗大量资源 → 阈值必须严\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e阈值设定必须综合技术容量和业务容忍度，需要工程团队和产品团队协同决策。\u003c/p\u003e\n\u003ch3\u003e6.2 被拒绝的请求去哪了\u003c/h3\u003e\n\u003cp\u003e大多数限流讨论都集中在\u0026quot;如何拒绝\u0026quot;，很少有人思考\u0026quot;拒绝之后怎么办\u0026quot;。而在真实业务中，后者往往更重要。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e做法\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003cth\u003e风险\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e直接拒绝\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e返回 429 + Retry-After\u003c/td\u003e\n\u003ctd\u003e开放 API、程序化调用方\u003c/td\u003e\n\u003ctd\u003e用户体验差\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e排队等待\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e写入 MQ，消费者限速消费\u003c/td\u003e\n\u003ctd\u003e异步操作（短信、邮件、报表）\u003c/td\u003e\n\u003ctd\u003e队列积压导致延迟不可控\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e降级响应\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e返回缓存/兜底数据\u003c/td\u003e\n\u003ctd\u003e推荐、搜索、详情页非核心模块\u003c/td\u003e\n\u003ctd\u003e数据时效性降低\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e引流分担\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e导向备用路径（CDN/只读副本）\u003c/td\u003e\n\u003ctd\u003e读多写少的场景\u003c/td\u003e\n\u003ctd\u003e需要备用链路的维护成本\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e关键原则：限流策略和拒绝策略必须配套设计。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e回到短信发送事故：被限流的短信不能直接丢弃，必须进入重试队列。秒杀请求被限流？直接告知\u0026quot;已售罄\u0026quot;比让用户苦等体验更好。商品详情页被限流？返回缓存数据即可，用户感知的是\u0026quot;数据没那么新\u0026quot;而不是\u0026quot;服务挂了\u0026quot;。\u003c/p\u003e\n\u003cp\u003e只设计了限流而没考虑拒绝后的处理，就像只安装了闸门却没修泄洪渠——水是拦住了，但迟早会溃坝。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e七、金融场景：限流 ≠ 正确性\u003c/h2\u003e\n\u003cp\u003e在金融、支付等对正确性有极高要求的领域，限流只是防御体系的一环。很多团队犯的错误是：觉得\u0026quot;加了限流就安全了\u0026quot;。现实是，限流解决的是\u003cstrong\u003e流量问题\u003c/strong\u003e，不是\u003cstrong\u003e正确性问题\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e三层防护：限流 + 并发控制 + 幂等\u003c/h3\u003e\n\u003cp\u003e考虑一个支付场景：用户点了两次\u0026quot;付款\u0026quot;按钮。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e防护层\u003c/th\u003e\n\u003cth\u003e解决的问题\u003c/th\u003e\n\u003cth\u003e如果只有这一层\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e限流\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e防止支付接口被高频调用打垮\u003c/td\u003e\n\u003ctd\u003e两次点击间隔 100ms，速率限制 10/s → 都放行，扣两次款\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e并发控制\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e同一笔订单同一时刻只允许一个支付请求在处理\u003c/td\u003e\n\u003ctd\u003e第二次被排队/拒绝，但如果第一次失败后重试呢？\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e幂等\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e同一笔支付操作无论执行几次，结果只生效一次\u003c/td\u003e\n\u003ctd\u003e无论重试多少次、并发多少个，最终只扣一次款\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e三层必须配合使用：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e限流是\u003cstrong\u003e外围护栏\u003c/strong\u003e——挡住异常流量，保护系统不被打垮\u003c/li\u003e\n\u003cli\u003e并发控制是\u003cstrong\u003e执行调度\u003c/strong\u003e——同一资源同一时刻只有一个操作在执行\u003c/li\u003e\n\u003cli\u003e幂等是\u003cstrong\u003e正确性保障\u003c/strong\u003e——即使前两层被突破，最终结果仍然正确\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e伪代码：PaymentProtection 组合示例\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass PaymentProtection:\n    def __init__(self):\n        self.rate_limiter = TokenBucket(rate=100, capacity=200)    # 限流\n        self.locks = DistributedLockManager()                       # 并发控制\n        self.idempotency = IdempotencyStore()                       # 幂等\n\n    def process_payment(self, order_id, idempotency_key, amount):\n        # 第一层：限流 —— 保护系统不被打垮\n        if not self.rate_limiter.allow():\n            return Error(\u0026quot;RATE_LIMITED\u0026quot;, \u0026quot;系统繁忙，请稍后重试\u0026quot;)\n\n        # 第二层：幂等检查 —— 如果这个操作已经成功过，直接返回之前的结果\n        existing = self.idempotency.get(idempotency_key)\n        if existing:\n            return existing  # 重复请求，返回之前的结果\n\n        # 第三层：并发控制 —— 同一订单同一时刻只处理一个支付请求\n        lock = self.locks.acquire(f\u0026quot;payment:{order_id}\u0026quot;, timeout=10)\n        if not lock:\n            return Error(\u0026quot;CONCURRENT\u0026quot;, \u0026quot;订单正在处理中\u0026quot;)\n\n        try:\n            # 再次检查幂等（拿到锁之后的 double-check）\n            existing = self.idempotency.get(idempotency_key)\n            if existing:\n                return existing\n\n            # 执行实际支付\n            result = do_payment(order_id, amount)\n\n            # 记录幂等结果\n            self.idempotency.store(idempotency_key, result)\n            return result\n        finally:\n            lock.release()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e核心认知\u003c/strong\u003e：限流是流量层面的保护，幂等才是业务正确性的最后防线。在金融场景中，这三层缺一不可。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e八、总结：限流是一种系统思维\u003c/h2\u003e\n\u003cp\u003e限流从表面看是算法选择题，但真正落地到生产环境时，它是一个系统设计问题：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e核心问题\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e控制对象\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e你在控制什么？速率、并发、配额还是节奏？控制模型选错，算法再精妙也解决不了问题\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e容量\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e系统到底能承受多少？需要压测和监控，不是拍脑袋\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e优先级\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e必须拒绝时，拒绝谁？VIP vs 普通、核心 vs 边缘、写 vs 读\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e失败模式\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e限流触发后怎么办？报错、排队、降级还是引流\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e权衡\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e平滑性 vs 响应性、精确性 vs 性能、简单性 vs 灵活性\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e最好的限流系统是你感觉不到它存在的系统。流量平稳时安静旁观，突增时默默吸收合理突发，真正超限时优雅拒绝——确保已接受的请求仍能正常处理。它不是一堵墙，而是一个阀门：精确控制流量进出，让系统在极端压力下保持可控、可预测、可依赖。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e限流的本质，是对系统能力边界的敬畏，以及在边界之内追求最大价值的工程智慧。\u003c/strong\u003e\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"18:T72c6,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eSET化架构：从单元化原理到大规模落地实践\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e当系统规模突破单机房、单集群的承载极限，当一次机房故障就可能导致全站不可用时，SET 化架构就成为了必然选择。它不是一种特定的技术方案，而是一种\u003cstrong\u003e将系统划分为独立自治单元，实现水平扩展和故障隔离\u003c/strong\u003e的架构思想。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e互联网业务的高速增长给架构带来了两个根本性挑战：\u003cstrong\u003e容量的天花板\u003c/strong\u003e和\u003cstrong\u003e可用性的脆弱性\u003c/strong\u003e。传统的垂直扩展（Scale-up）终有极限，而简单的水平扩展（Scale-out）在数据一致性、服务依赖、运维复杂度等方面又面临诸多困难。\u003c/p\u003e\n\u003cp\u003eSET 化架构（也称为单元化架构、Cell-based Architecture）正是为了系统性地解决这些问题而诞生的。本文将从原理到实践，全面解析 SET 化架构的设计与落地。\u003c/p\u003e\n\u003ch2\u003e什么是 SET 化架构？\u003c/h2\u003e\n\u003ch3\u003e概念定义\u003c/h3\u003e\n\u003cp\u003eSET（Scalable Elastic Topology，可扩展弹性拓扑）化架构是一种\u003cstrong\u003e将系统按照某个维度（通常是用户 ID）划分为多个独立、自包含的部署单元\u003c/strong\u003e的架构模式。每个 SET 都是一个\u0026quot;小型完整系统\u0026quot;，拥有独立的应用服务、缓存、数据库等全套基础设施，能够独立处理分配给它的流量。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSET 化的核心思想：\n\n传统架构：         所有用户 → 一套系统\n                    （纵向扩展，存在单点瓶颈）\n\nSET 化架构：       用户按规则分组 → 每组对应一个 SET\n                    SET-1: 用户 0~999W    → 独立的一套完整系统\n                    SET-2: 用户 1000W~1999W → 独立的一套完整系统\n                    SET-3: 用户 2000W~2999W → 独立的一套完整系统\n                    （水平扩展，理论上无上限）\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eSET 的核心特征\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e特征\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e自包含\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个 SET 拥有完整的服务栈（应用、缓存、DB），能独立处理请求\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e对等部署\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e所有 SET 的架构相同，只是处理的数据分片不同\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e故障隔离\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单个 SET 的故障不会影响其他 SET\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e水平扩展\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e通过增加 SET 数量实现容量扩展\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e流量可调度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e通过路由规则灵活调度流量在 SET 间的分配\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003eSET 化与传统分布式的区别\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e传统分布式架构\u003c/th\u003e\n\u003cth\u003eSET 化架构\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e扩展方式\u003c/td\u003e\n\u003ctd\u003e各层独立扩展（加应用节点、加 DB 从库）\u003c/td\u003e\n\u003ctd\u003e整体作为一个单元扩展\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e故障影响\u003c/td\u003e\n\u003ctd\u003e某一层故障影响全局\u003c/td\u003e\n\u003ctd\u003e故障隔离在单个 SET 内\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据分片\u003c/td\u003e\n\u003ctd\u003e数据库层分片，应用层无感知\u003c/td\u003e\n\u003ctd\u003e从入口到数据库全链路分片\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e部署单元\u003c/td\u003e\n\u003ctd\u003e按服务部署\u003c/td\u003e\n\u003ctd\u003e按 SET（单元）部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e容量规划\u003c/td\u003e\n\u003ctd\u003e各组件独立评估\u003c/td\u003e\n\u003ctd\u003e按 SET 整体评估\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003eSET 化架构演进历程\u003c/h2\u003e\n\u003cp\u003eSET 化不是一步到位的设计，而是随着业务规模增长逐步演化的结果。\u003c/p\u003e\n\u003ch3\u003e阶段一：单体架构\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户 → 应用服务器 → 数据库\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e所有功能在一个应用中，单库单表。适用于初创期，简单高效。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e瓶颈\u003c/strong\u003e：单机容量有限，数据库成为瓶颈。\u003c/p\u003e\n\u003ch3\u003e阶段二：读写分离 + 缓存\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户 → 应用集群 → 缓存 → 主库（写）/ 从库（读）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e通过读写分离缓解数据库压力，引入缓存降低 DB 负载。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e瓶颈\u003c/strong\u003e：写入瓶颈无法解决，主库仍是单点。\u003c/p\u003e\n\u003ch3\u003e阶段三：分库分表\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户 → 应用集群 → 数据库中间件 → DB 分片 1 / DB 分片 2 / DB 分片 N\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e数据库水平拆分，解决写入瓶颈。但分片逻辑散落在各处，跨分片查询复杂。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e瓶颈\u003c/strong\u003e：应用层无分片感知，缓存与 DB 分片不对齐，运维复杂。\u003c/p\u003e\n\u003ch3\u003e阶段四：服务化（微服务）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户 → API 网关 → 微服务 A / 微服务 B / ... → 各自的 DB\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e按业务域拆分为独立服务，各服务独立部署和扩展。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e瓶颈\u003c/strong\u003e：服务间调用复杂，全链路缺乏统一的分片和隔离机制。\u003c/p\u003e\n\u003ch3\u003e阶段五：SET 化（单元化）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户 → 统一路由层 → SET-1（完整服务栈）/ SET-2 / SET-N\n                       ↕ 数据同步\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e全链路按统一维度分片，每个 SET 自包含完整服务栈，实现真正的水平扩展和故障隔离。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e这就是 SET 化架构的终态。\u003c/strong\u003e 下面详细介绍每个核心组件的设计。\u003c/p\u003e\n\u003ch2\u003e核心设计一：流量路由\u003c/h2\u003e\n\u003cp\u003e流量路由是 SET 化架构的\u0026quot;大脑\u0026quot;，它决定了每个请求应该被路由到哪个 SET。\u003c/p\u003e\n\u003ch3\u003e路由键的选择\u003c/h3\u003e\n\u003cp\u003e路由键（Sharding Key）是 SET 化的核心决策之一，选择不当会导致严重的跨 SET 调用问题。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e路由键\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003cth\u003e适用业务\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e用户 ID\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e用户维度天然隔离，覆盖面广\u003c/td\u003e\n\u003ctd\u003e用户间交互需跨 SET\u003c/td\u003e\n\u003ctd\u003e电商、社交、O2O\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e商户 ID\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e商户维度隔离\u003c/td\u003e\n\u003ctd\u003e用户下单需跨 SET\u003c/td\u003e\n\u003ctd\u003eB 端平台\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e地理区域\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e天然的流量隔离\u003c/td\u003e\n\u003ctd\u003e跨区域业务需特殊处理\u003c/td\u003e\n\u003ctd\u003e本地生活、物流\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e订单 ID\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e订单维度隔离\u003c/td\u003e\n\u003ctd\u003e需要提前生成带路由信息的 ID\u003c/td\u003e\n\u003ctd\u003e交易系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e实践经验\u003c/strong\u003e：绝大多数 C 端业务选择\u003cstrong\u003e用户 ID\u003c/strong\u003e 作为路由键，因为用户是最核心的业务实体，以用户为维度分片可以最大程度地减少跨 SET 调用。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003e路由架构设计\u003c/h3\u003e\n\u003cp\u003eSET 化的路由通常分为三层：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e第一层：接入路由（DNS / LB 层）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e在最外层通过 DNS 或负载均衡器将流量分配到对应的 SET。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e用户请求 → DNS 解析 → 全局负载均衡（GSLB）\n                            ↓\n                    根据用户 ID 哈希路由\n                    ↓           ↓           ↓\n                 SET-1 LB    SET-2 LB    SET-3 LB\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e第二层：网关路由（API Gateway 层）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAPI 网关根据请求中的路由键（如 Header、Cookie、Token 中的用户 ID）将请求路由到正确的 SET。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e请求 → API Gateway → 提取路由键 → 查询路由表 → 转发到目标 SET\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e第三层：服务路由（RPC 层）\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e服务间调用时，RPC 框架自动根据上下文中的路由键将请求路由到同 SET 的服务实例。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eService A (SET-1) → RPC Framework → 自动路由到 → Service B (SET-1)\n                    （通过上下文传递 SET 标识）\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e路由表设计\u003c/h3\u003e\n\u003cp\u003e路由表是映射用户到 SET 的核心数据结构：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e路由表结构：\n┌──────────────┬──────────┬──────────┐\n│  分片范围      │  SET ID  │  状态     │\n├──────────────┼──────────┼──────────┤\n│  0 ~ 999      │  SET-1   │  Active  │\n│  1000 ~ 1999  │  SET-2   │  Active  │\n│  2000 ~ 2999  │  SET-3   │  Active  │\n│  3000 ~ 3999  │  SET-1   │  Active  │  ← 同一个 SET 可承载多个分片\n└──────────────┴──────────┴──────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e路由策略的关键设计要点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e虚拟分片\u003c/strong\u003e：不直接将用户映射到物理 SET，而是先映射到虚拟分片（如 1024 个），再将虚拟分片映射到物理 SET。这样扩容时只需调整虚拟分片的映射关系\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e路由缓存\u003c/strong\u003e：路由表在网关和服务端本地缓存，避免每次请求都查询路由服务\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e路由一致性\u003c/strong\u003e：路由表变更时需要保证全链路一致性，避免请求被路由到错误的 SET\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e核心设计二：数据分片与同步\u003c/h2\u003e\n\u003cp\u003e数据层是 SET 化最复杂的部分，需要解决数据分片、跨 SET 数据访问、数据同步等问题。\u003c/p\u003e\n\u003ch3\u003e数据分类\u003c/h3\u003e\n\u003cp\u003eSET 化架构中的数据按照与路由键的关系分为三类：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e数据类型\u003c/th\u003e\n\u003cth\u003e定义\u003c/th\u003e\n\u003cth\u003e存储方式\u003c/th\u003e\n\u003cth\u003e举例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSET 内数据\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e与路由键强绑定的数据\u003c/td\u003e\n\u003ctd\u003e仅存储在对应 SET\u003c/td\u003e\n\u003ctd\u003e用户订单、用户资产、购物车\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e全局数据\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e所有 SET 共享的数据\u003c/td\u003e\n\u003ctd\u003e全局存储 + 各 SET 只读副本\u003c/td\u003e\n\u003ctd\u003e商品信息、配置数据、类目\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e跨 SET 数据\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e涉及多个路由键的数据\u003c/td\u003e\n\u003ctd\u003e全局存储或冗余存储\u003c/td\u003e\n\u003ctd\u003e商户维度的聚合数据、排行榜\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003eSET 内数据\u003c/h3\u003e\n\u003cp\u003eSET 内数据遵循\u0026quot;谁的数据谁存储\u0026quot;原则，每个 SET 只处理和存储自己分片内的数据：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSET-1 数据库：只存储 UserID 0~999 的数据\nSET-2 数据库：只存储 UserID 1000~1999 的数据\n\n用户 A (ID=500) 下单 → 请求路由到 SET-1 → 订单写入 SET-1 DB\n用户 B (ID=1500) 下单 → 请求路由到 SET-2 → 订单写入 SET-2 DB\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e全局数据\u003c/h3\u003e\n\u003cp\u003e全局数据（如商品信息）需要所有 SET 都能访问，通常采用以下方案：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e方案\u003c/th\u003e\n\u003cth\u003e原理\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e全局服务\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e独立部署的全局服务 + 数据库\u003c/td\u003e\n\u003ctd\u003e数据一致性好\u003c/td\u003e\n\u003ctd\u003e全局服务成为依赖瓶颈\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e数据广播\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e写入全局库后异步同步到各 SET\u003c/td\u003e\n\u003ctd\u003e本地读取性能好\u003c/td\u003e\n\u003ctd\u003e数据有延迟，存储冗余\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e缓存分发\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e全局数据写入后推送到各 SET 缓存\u003c/td\u003e\n\u003ctd\u003e读取极快\u003c/td\u003e\n\u003ctd\u003e缓存一致性需要保障\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e实践建议\u003c/strong\u003e：高频读取的全局数据（如商品详情）采用\u0026quot;数据广播 + 本地缓存\u0026quot;方案；低频但要求强一致的全局数据（如配置变更）采用\u0026quot;全局服务\u0026quot;方案。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003e数据同步机制\u003c/h3\u003e\n\u003cp\u003eSET 间的数据同步是保证业务连续性的关键，特别是在故障切换场景下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                     主 SET                          备 SET\n                 ┌──────────┐                    ┌──────────┐\n                 │  应用层    │                    │  应用层    │\n                 │  缓存层    │                    │  缓存层    │\n                 │  数据库    │ ── Binlog 同步 ──→ │  数据库    │\n                 └──────────┘                    └──────────┘\n\n        同步方式：MySQL Binlog → Canal/DTS → 目标 SET 数据库\n        同步延迟：通常 \u0026lt; 1s，需要监控告警\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e数据同步的关键指标：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e指标\u003c/th\u003e\n\u003cth\u003e目标值\u003c/th\u003e\n\u003cth\u003e监控方式\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e同步延迟\u003c/td\u003e\n\u003ctd\u003e\u0026lt; 1 秒\u003c/td\u003e\n\u003ctd\u003eBinlog 位点差监控\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据一致性\u003c/td\u003e\n\u003ctd\u003e99.99%\u003c/td\u003e\n\u003ctd\u003e定期全量对账\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e同步可用性\u003c/td\u003e\n\u003ctd\u003e99.99%\u003c/td\u003e\n\u003ctd\u003e同步链路健康检查\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e核心设计三：全局服务\u003c/h2\u003e\n\u003cp\u003e有些服务天然不能被 SET 化，它们需要作为全局服务为所有 SET 提供能力。\u003c/p\u003e\n\u003ch3\u003e全局 ID 生成\u003c/h3\u003e\n\u003cp\u003e在 SET 化架构中，ID 生成必须保证全局唯一且带有路由信息：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eID 结构设计：\n┌────────────┬──────────┬───────────┬──────────┐\n│  时间戳      │  SET ID  │  机器 ID   │  序列号   │\n│  41 bits    │  5 bits  │  5 bits   │  12 bits │\n└────────────┴──────────┴───────────┴──────────┘\n\n总长度：63 bits（Long 类型）\n\u003c/code\u003e\u003c/pre\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e生成方案\u003c/th\u003e\n\u003cth\u003e优点\u003c/th\u003e\n\u003cth\u003e缺点\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e全局 ID 服务\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e全局唯一性保证最强\u003c/td\u003e\n\u003ctd\u003e依赖外部服务，存在可用性风险\u003c/td\u003e\n\u003ctd\u003e核心业务（订单、支付）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e本地 Snowflake\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e无外部依赖，性能最高\u003c/td\u003e\n\u003ctd\u003e需要解决时钟回拨问题\u003c/td\u003e\n\u003ctd\u003e非核心业务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e号段模式\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e批量获取减少调用\u003c/td\u003e\n\u003ctd\u003e号段用尽时有短暂延迟\u003c/td\u003e\n\u003ctd\u003e通用场景\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e兜底策略\u003c/strong\u003e：本地 ID 生成作为兜底方案，当全局 ID 服务不可用时自动降级为本地生成，确保业务不中断。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003e全局配置中心\u003c/h3\u003e\n\u003cp\u003e配置中心负责管理所有 SET 的路由规则、业务配置和开关：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e配置中心架构：\n                  ┌─────────────────┐\n                  │   配置中心集群     │\n                  │  (ZK/Nacos/etcd) │\n                  └────────┬────────┘\n                     ↙     ↓     ↘\n            SET-1 Agent  SET-2 Agent  SET-3 Agent\n               ↓            ↓            ↓\n            本地缓存      本地缓存      本地缓存\n\n推送机制：配置变更 → 配置中心 → 推送给各 SET Agent → 更新本地缓存\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e全局调度中心\u003c/h3\u003e\n\u003cp\u003e负责 SET 的健康监控、故障检测和流量调度：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e功能\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e健康检查\u003c/td\u003e\n\u003ctd\u003e定期探测各 SET 的健康状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e故障检测\u003c/td\u003e\n\u003ctd\u003e发现 SET 异常时触发告警\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e流量切换\u003c/td\u003e\n\u003ctd\u003e故障 SET 的流量自动切换到备用 SET\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e容量管理\u003c/td\u003e\n\u003ctd\u003e监控各 SET 的容量使用率\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e扩缩容编排\u003c/td\u003e\n\u003ctd\u003e新增或下线 SET 时的流量编排\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e核心设计四：故障隔离与切换\u003c/h2\u003e\n\u003cp\u003e故障隔离是 SET 化架构最核心的价值之一。\u003c/p\u003e\n\u003ch3\u003e故障域划分\u003c/h3\u003e\n\u003cp\u003eSET 化架构将故障影响范围从\u0026quot;全站\u0026quot;缩小到\u0026quot;单个 SET\u0026quot;：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e传统架构故障：\n  DB 主库宕机 → 全站不可用 → 影响 100% 用户\n\nSET 化架构故障：\n  SET-2 DB 宕机 → 仅 SET-2 不可用 → 影响约 33% 用户（假设 3 个 SET）\n                    ↓ 自动切换\n                 SET-2 流量切换到备用 → 影响时间 \u0026lt; 分钟级\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e故障切换策略\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e切换速度\u003c/th\u003e\n\u003cth\u003e数据风险\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e主备切换\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e秒级~分钟级\u003c/td\u003e\n\u003ctd\u003e可能丢失未同步数据\u003c/td\u003e\n\u003ctd\u003eSET 内部 DB 主备切换\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSET 间切换\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e分钟级\u003c/td\u003e\n\u003ctd\u003e依赖数据同步延迟\u003c/td\u003e\n\u003ctd\u003e整个 SET 故障\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e跨机房切换\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e分钟级~小时级\u003c/td\u003e\n\u003ctd\u003e需要全量数据同步\u003c/td\u003e\n\u003ctd\u003e机房级故障\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e故障切换流程\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e正常状态：\n  用户流量 → 路由层 → SET-2（主）\n\n故障检测：\n  健康检查失败 → 确认 SET-2 不可用 → 触发切换流程\n\n切换执行：\n  1. 停止 SET-2 的流量接入（路由层摘除）\n  2. 等待 SET-2 → SET-2-备 的数据同步完成（或接受部分数据丢失）\n  3. 更新路由表：SET-2 的分片 → SET-2-备\n  4. 开放 SET-2-备 的流量接入\n  5. 验证切换后的业务正确性\n\n恢复状态：\n  用户流量 → 路由层 → SET-2-备（新主）\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e容灾等级\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e等级\u003c/th\u003e\n\u003cth\u003e容灾范围\u003c/th\u003e\n\u003cth\u003e实现方式\u003c/th\u003e\n\u003cth\u003eRTO\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eL1\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e单机故障\u003c/td\u003e\n\u003ctd\u003e应用集群 + DB 主备\u003c/td\u003e\n\u003ctd\u003e秒级\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eL2\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e机架故障\u003c/td\u003e\n\u003ctd\u003e跨机架部署\u003c/td\u003e\n\u003ctd\u003e秒级\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eL3\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e机房故障\u003c/td\u003e\n\u003ctd\u003e同城双机房 SET 互备\u003c/td\u003e\n\u003ctd\u003e分钟级\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eL4\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e城市故障\u003c/td\u003e\n\u003ctd\u003e异地 SET 互备\u003c/td\u003e\n\u003ctd\u003e分钟级~小时级\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch2\u003e核心设计五：SET 扩缩容\u003c/h2\u003e\n\u003cp\u003eSET 化架构的一个重要优势是可以通过增减 SET 数量来调整系统容量。\u003c/p\u003e\n\u003ch3\u003e扩容流程\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e扩容场景：当前 3 个 SET 容量不足，需要扩容到 4 个 SET\n\nStep 1: 部署新 SET（SET-4）\n  - 部署完整的应用服务、缓存、数据库\n  - 从现有 SET 同步全局数据\n\nStep 2: 数据迁移\n  - 将 SET-1 的部分虚拟分片的数据迁移到 SET-4\n  - 采用双写方案保证迁移过程不中断服务\n\nStep 3: 路由切换\n  - 更新路由表：迁移的虚拟分片指向 SET-4\n  - 灰度切换流量，逐步验证\n\nStep 4: 清理\n  - 验证完成后，清理 SET-1 中已迁移的数据\n  - 回收空闲资源\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e虚拟分片的价值\u003c/h3\u003e\n\u003cp\u003e虚拟分片是实现平滑扩缩容的关键：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e初始状态（3 个 SET，1024 个虚拟分片）：\n  SET-1: 虚拟分片 0~341\n  SET-2: 虚拟分片 342~682\n  SET-3: 虚拟分片 683~1023\n\n扩容到 4 个 SET（只需调整虚拟分片映射）：\n  SET-1: 虚拟分片 0~255\n  SET-2: 虚拟分片 256~511\n  SET-3: 虚拟分片 512~767\n  SET-4: 虚拟分片 768~1023\n\n优势：用户 → 虚拟分片的映射不变，只调整虚拟分片 → 物理 SET 的映射\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e实践案例：电商交易系统 SET 化\u003c/h2\u003e\n\u003cp\u003e以一个典型的电商交易系统为例，展示 SET 化的具体落地方案。\u003c/p\u003e\n\u003ch3\u003e业务分析\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e服务\u003c/th\u003e\n\u003cth\u003e路由键关系\u003c/th\u003e\n\u003cth\u003eSET 化策略\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e用户服务\u003c/td\u003e\n\u003ctd\u003e用户 ID（强绑定）\u003c/td\u003e\n\u003ctd\u003eSET 内部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e订单服务\u003c/td\u003e\n\u003ctd\u003e用户 ID（强绑定）\u003c/td\u003e\n\u003ctd\u003eSET 内部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e支付服务\u003c/td\u003e\n\u003ctd\u003e用户 ID（强绑定）\u003c/td\u003e\n\u003ctd\u003eSET 内部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e商品服务\u003c/td\u003e\n\u003ctd\u003e无关（全局数据）\u003c/td\u003e\n\u003ctd\u003e全局部署 + 数据广播\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e库存服务\u003c/td\u003e\n\u003ctd\u003e商品维度（跨 SET）\u003c/td\u003e\n\u003ctd\u003e全局部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e搜索服务\u003c/td\u003e\n\u003ctd\u003e无关（全局数据）\u003c/td\u003e\n\u003ctd\u003e全局部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e营销服务\u003c/td\u003e\n\u003ctd\u003e活动维度（跨 SET）\u003c/td\u003e\n\u003ctd\u003e全局部署\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e整体架构\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                        ┌──────────────────────────────────┐\n                        │          统一接入层（GSLB）         │\n                        └───────────────┬──────────────────┘\n                                        ↓\n                        ┌──────────────────────────────────┐\n                        │         API Gateway（路由层）       │\n                        │    提取 UserID → 查询路由表 → 转发   │\n                        └──┬──────────────┬────────────┬───┘\n                           ↓              ↓            ↓\n                    ┌─────────────┐ ┌─────────────┐ ┌─────────────┐\n                    │   SET-1     │ │   SET-2     │ │   SET-3     │\n                    │ ┌─────────┐ │ │ ┌─────────┐ │ │ ┌─────────┐ │\n                    │ │用户服务  │ │ │ │用户服务  │ │ │ │用户服务  │ │\n                    │ │订单服务  │ │ │ │订单服务  │ │ │ │订单服务  │ │\n                    │ │支付服务  │ │ │ │支付服务  │ │ │ │支付服务  │ │\n                    │ │Redis    │ │ │ │Redis    │ │ │ │Redis    │ │\n                    │ │MySQL    │ │ │ │MySQL    │ │ │ │MySQL    │ │\n                    │ └─────────┘ │ │ └─────────┘ │ │ └─────────┘ │\n                    └─────────────┘ └─────────────┘ └─────────────┘\n                           ↕              ↕            ↕\n                    ┌──────────────────────────────────────────┐\n                    │              全局服务层                     │\n                    │  商品服务 │ 库存服务 │ 搜索服务 │ 营销服务    │\n                    │         全局 ID 服务 │ 配置中心              │\n                    └──────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e下单流程的 SET 化处理\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e用户 A（ID=500）下单购买商品 X：\n\n1. 请求到达 API Gateway\n2. Gateway 提取 UserID=500，查路由表 → SET-1\n3. 请求转发到 SET-1 的订单服务\n4. 订单服务调用全局商品服务查询商品信息\n5. 订单服务调用全局库存服务扣减库存\n6. 订单服务在 SET-1 本地 DB 创建订单\n7. 订单服务调用 SET-1 本地的支付服务发起支付\n8. 支付完成后，SET-1 的订单服务更新本地订单状态\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键点：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e用户维度的数据操作（创建订单、支付）在 SET 内完成，无跨 SET 调用\u003c/li\u003e\n\u003cli\u003e商品、库存等全局数据通过全局服务访问\u003c/li\u003e\n\u003cli\u003eRPC 框架自动将 SET 标识通过上下文传递，保证 SET 内调用的正确性\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eSET 化实施路线\u003c/h2\u003e\n\u003cp\u003eSET 化是一个渐进式的过程，不应该一步到位。\u003c/p\u003e\n\u003ch3\u003e阶段规划\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e阶段\u003c/th\u003e\n\u003cth\u003e目标\u003c/th\u003e\n\u003cth\u003e关键动作\u003c/th\u003e\n\u003cth\u003e周期\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eP0：基础设施准备\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e具备 SET 化的基础能力\u003c/td\u003e\n\u003ctd\u003e统一 RPC 框架、引入路由组件、改造 ID 生成\u003c/td\u003e\n\u003ctd\u003e1~2 月\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eP1：核心链路 SET 化\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e交易核心链路实现 SET 化\u003c/td\u003e\n\u003ctd\u003e订单、支付、用户服务 SET 化部署\u003c/td\u003e\n\u003ctd\u003e2~3 月\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eP2：全链路 SET 化\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e所有服务完成 SET 化改造\u003c/td\u003e\n\u003ctd\u003e非核心服务 SET 化、全局服务治理\u003c/td\u003e\n\u003ctd\u003e3~6 月\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eP3：异地 SET\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e实现异地多活能力\u003c/td\u003e\n\u003ctd\u003e跨机房 SET 部署、数据同步、故障切换\u003c/td\u003e\n\u003ctd\u003e3~6 月\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e改造清单\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e应用层改造\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e所有服务支持从请求上下文中提取和传递路由键\u003c/li\u003e\n\u003cli\u003eRPC 框架支持基于路由键的服务路由\u003c/li\u003e\n\u003cli\u003e消息队列的生产和消费支持 SET 路由\u003c/li\u003e\n\u003cli\u003e定时任务支持按 SET 分片执行\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e数据层改造\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e数据库按 SET 进行物理隔离\u003c/li\u003e\n\u003cli\u003e缓存按 SET 进行 namespace 隔离\u003c/li\u003e\n\u003cli\u003e全局数据的同步机制建设\u003c/li\u003e\n\u003cli\u003e数据对账和修复工具\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e基础设施改造\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e统一路由服务建设\u003c/li\u003e\n\u003cli\u003e全局 ID 生成服务建设\u003c/li\u003e\n\u003cli\u003e监控体系支持 SET 维度\u003c/li\u003e\n\u003cli\u003e发布系统支持按 SET 灰度\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eSET 化与异地多活的关系\u003c/h2\u003e\n\u003cp\u003eSET 化架构是异地多活的基础。两者的关系可以这样理解：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSET 化 = 单元化部署 + 流量路由 + 数据分片\n异地多活 = SET 化 + 跨地域部署 + 数据同步 + 故障切换\n\u003c/code\u003e\u003c/pre\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e同城 SET 化\u003c/th\u003e\n\u003cth\u003e异地多活 SET 化\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e部署范围\u003c/td\u003e\n\u003ctd\u003e同城多机房\u003c/td\u003e\n\u003ctd\u003e跨城市多机房\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e网络延迟\u003c/td\u003e\n\u003ctd\u003e\u0026lt; 1ms\u003c/td\u003e\n\u003ctd\u003e10~50ms\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据同步\u003c/td\u003e\n\u003ctd\u003e同步/半同步复制\u003c/td\u003e\n\u003ctd\u003e异步复制（最终一致性）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e故障切换\u003c/td\u003e\n\u003ctd\u003e自动秒级切换\u003c/td\u003e\n\u003ctd\u003e手动/半自动分钟级切换\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e核心挑战\u003c/td\u003e\n\u003ctd\u003e路由准确性\u003c/td\u003e\n\u003ctd\u003e数据一致性 + 切换决策\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSET 化架构天然具备\u0026quot;每个 SET 独立自治\u0026quot;的特性，这为异地多活提供了完美的基础。只需将不同的 SET 部署到不同的地域，配合数据同步和流量调度，就能实现异地多活。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e常见问题与解决方案\u003c/h2\u003e\n\u003ch3\u003e跨 SET 调用问题\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e问题\u003c/strong\u003e：部分业务场景不可避免需要跨 SET 访问数据。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解决方案\u003c/strong\u003e：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景\u003c/th\u003e\n\u003cth\u003e解决方案\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e用户查看商户信息\u003c/td\u003e\n\u003ctd\u003e商户数据作为全局数据广播\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e商户查看所有订单\u003c/td\u003e\n\u003ctd\u003e聚合服务从各 SET 并行查询后合并\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e全站排行榜\u003c/td\u003e\n\u003ctd\u003e各 SET 本地计算后汇总到全局服务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e跨用户转账\u003c/td\u003e\n\u003ctd\u003e通过消息队列异步通知目标 SET\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e数据迁移问题\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e问题\u003c/strong\u003e：扩容时需要在 SET 间迁移数据。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解决方案\u003c/strong\u003e：双写方案\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePhase 1: 新 SET 开始从旧 SET 同步增量数据（Binlog 订阅）\nPhase 2: 同步追上后，开启双写模式（新请求同时写入新旧 SET）\nPhase 3: 路由切换，新请求全部路由到新 SET\nPhase 4: 验证无误后，停止双写，清理旧数据\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e全局服务瓶颈\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e问题\u003c/strong\u003e：全局服务成为所有 SET 的共同依赖，可能成为瓶颈。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e解决方案\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e数据本地化\u003c/strong\u003e：全局数据尽可能广播到各 SET 本地，减少全局服务调用\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缓存优先\u003c/strong\u003e：全局数据走多级缓存，降低对全局 DB 的访问\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e异步化\u003c/strong\u003e：非实时性要求的全局操作通过消息队列异步处理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e弹性扩展\u003c/strong\u003e：全局服务本身也需要集群化部署和弹性扩展\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e总结\u003c/h2\u003e\n\u003cp\u003eSET 化架构是应对互联网业务规模化增长的系统性解决方案。它的核心思想并不复杂——\u003cstrong\u003e把一个大系统拆分成多个独立自治的小系统\u003c/strong\u003e——但真正的挑战在于落地过程中的每一个细节。\u003c/p\u003e\n\u003cp\u003e回顾 SET 化的关键设计决策：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e路由键选择决定了架构的天花板\u003c/strong\u003e。选错路由键会导致大量跨 SET 调用，抵消 SET 化的优势\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e数据分类是 SET 化的基础\u003c/strong\u003e。明确哪些是 SET 内数据、哪些是全局数据，才能设计合理的数据架构\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e虚拟分片是弹性扩展的关键\u003c/strong\u003e。不要将用户直接映射到物理 SET，虚拟分片层带来的灵活性至关重要\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e全局服务的治理不能忽视\u003c/strong\u003e。全局服务是所有 SET 的共同依赖，必须做到高可用和高性能\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e渐进式实施是务实的选择\u003c/strong\u003e。从核心链路开始，逐步扩展，而不是试图一步到位\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eSET 化不是目的，而是手段。\u003c/strong\u003e 它服务于两个根本目标：让系统能够水平扩展以承载业务增长，让故障影响可控以保障用户体验。在实施 SET 化之前，先问自己：当前的业务规模真的需要 SET 化吗？\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"19:T8130,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eFrom Prompt to Agent: 为什么 LLM 本身不是 Agent\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e当我们说\u0026quot;让 AI 帮我完成这件事\u0026quot;时，我们期望的不是一次文本生成，而是一次\u003cstrong\u003e有目标、有规划、有执行、有反馈\u003c/strong\u003e的任务完成过程。这正是 LLM 和 Agent 的根本区别。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 02 篇。上一篇我们绘制了全景地图，这一篇我们回到原点：为什么一个再强大的 LLM，本身也不是 Agent？从\u0026quot;不是什么\u0026quot;出发，才能精确定义\u0026quot;是什么\u0026quot;。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. LLM 的本质：一个文本到文本的函数\u003c/h2\u003e\n\u003cp\u003e把所有复杂性剥离，LLM 的数学本质极其简洁：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ef(prompt) → response\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e给定一段输入文本（prompt），经过前向推理，输出一段文本（response）。就这样。\u003c/p\u003e\n\u003cp\u003e更严格地说，LLM 做的是\u003cstrong\u003e条件概率采样\u003c/strong\u003e：给定已有 token 序列 \u003ccode\u003e[t₁, t₂, ..., tₙ]\u003c/code\u003e，逐个预测下一个 token 的概率分布 \u003ccode\u003eP(tₙ₊₁ | t₁, ..., tₙ)\u003c/code\u003e，然后按某种策略（greedy、top-k、top-p）从分布中采样。\u003c/p\u003e\n\u003cp\u003e这意味着三个关键性质：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e无状态（Stateless）\u003c/strong\u003e：模型权重在推理时不变，两次相同输入产生的概率分布相同（忽略采样随机性）。模型本身不存储任何关于\u0026quot;之前发生了什么\u0026quot;的信息。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e无副作用（Side-effect Free）\u003c/strong\u003e：模型不会改变外部世界的任何状态——不会写文件、不会调 API、不会修改数据库。它只输出文本。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e无记忆（Memoryless）\u003c/strong\u003e：每次调用都是独立的函数调用。上一次对话的内容，除非你手动拼接进 prompt，否则模型完全不知道。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e用一个 Python 类比，LLM 就是一个纯函数：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef llm(prompt: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;\n    纯函数：相同输入 → 相同输出分布\n    无副作用：不修改任何外部状态\n    无记忆：不保留任何调用历史\n    \u0026quot;\u0026quot;\u0026quot;\n    tokens = tokenize(prompt)\n    output_tokens = []\n    for _ in range(max_tokens):\n        next_token_probs = model.forward(tokens + output_tokens)\n        next_token = sample(next_token_probs, temperature=0.7)\n        output_tokens.append(next_token)\n        if next_token == EOS:\n            break\n    return detokenize(output_tokens)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这是一个非常优雅的抽象。但正是这个抽象的简洁性，决定了它的局限性。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. LLM 的五大局限\u003c/h2\u003e\n\u003ch3\u003e2.1 无记忆：每次对话都是独立宇宙\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：你让 LLM 帮你写一个项目方案。第一轮你说了需求，第二轮你补充了约束，第三轮你修改了目标。LLM 怎么\u0026quot;记住\u0026quot;前两轮？\u003c/p\u003e\n\u003cp\u003e答案是：它不记。所谓的\u0026quot;多轮对话\u0026quot;，本质上是\u003cstrong\u003e客户端把历史消息全部拼接进 prompt\u003c/strong\u003e 重新发送。每一轮调用，LLM 都在从零开始阅读整个对话历史。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 所谓\u0026quot;多轮对话\u0026quot;的真相\nmessages = [\n    {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;帮我写个项目方案\u0026quot;},          # 第一轮\n    {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;好的，请问项目目标是什么？\u0026quot;},\n    {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;做一个推荐系统\u0026quot;},            # 第二轮\n    {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;了解，技术栈偏好？\u0026quot;},\n    {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;用 Python，预算 50 万\u0026quot;},     # 第三轮\n]\n# 每次都是把 *全部* messages 发给 LLM，它并不\u0026quot;记得\u0026quot;前两轮\nresponse = llm.chat(messages)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这带来两个工程问题：一是 \u003cstrong\u003econtext window 有限\u003c/strong\u003e，对话太长会被截断，早期关键信息丢失；二是 \u003cstrong\u003etoken 成本线性增长\u003c/strong\u003e，每一轮都在为重复传输历史对话付费。\u003c/p\u003e\n\u003ch3\u003e2.2 无工具：只能生成文本，不能执行操作\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：你问 LLM\u0026quot;现在北京气温多少度？\u0026quot;它会给你一个看起来很自信的答案——但这个答案是从训练数据中\u0026quot;编\u0026quot;出来的，不是实时查询的结果。\u003c/p\u003e\n\u003cp\u003eLLM 不能发 HTTP 请求，不能查数据库，不能读文件系统，不能调用任何外部服务。它唯一的\u0026quot;输出通道\u0026quot;就是文本。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e用户：帮我创建一个 GitHub 仓库叫 my-project\nLLM：好的，已经为您创建了 GitHub 仓库 my-project！  ← 这是幻觉，什么都没发生\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLLM 的\u0026quot;执行\u0026quot;是一种语言层面的模拟——它可以生成看起来像执行结果的文本，但实际上没有任何副作用发生。这是 hallucination 问题在工具层面的体现。\u003c/p\u003e\n\u003ch3\u003e2.3 无规划：只有 next-token prediction，没有 multi-step reasoning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：你让 LLM\u0026quot;规划一次三天的日本旅行\u0026quot;。它会一口气输出一个看起来完整的方案。但这不是\u0026quot;规划\u0026quot;——这是\u0026quot;自回归生成\u0026quot;。它不会先列出约束（预算、时间、兴趣），再枚举可能的方案，再比较 trade-off，再做决策。它只是在逐 token 地预测\u0026quot;下一个最可能的词\u0026quot;。\u003c/p\u003e\n\u003cp\u003e真正的规划需要：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e目标分解\u003c/strong\u003e：把大目标拆成子目标\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e约束满足\u003c/strong\u003e：在多个维度上满足约束条件\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e方案评估\u003c/strong\u003e：对多个候选方案进行比较\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e回溯修正\u003c/strong\u003e：发现某条路不通时能回退\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLLM 的自回归生成是单向的、线性的，没有回溯机制。它无法在生成第 50 个 token 时\u0026quot;回头修改\u0026quot;第 10 个 token。所有看起来像\u0026quot;规划\u0026quot;的输出，都是语言模式匹配的结果，不是搜索与优化的结果。\u003c/p\u003e\n\u003ch3\u003e2.4 无状态：不知道自己之前做了什么\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：你让 LLM 执行一个多步骤任务——先查数据，再分析，再写报告。即使它能生成每一步的文本描述，它也不知道\u0026quot;第一步的结果是什么\u0026quot;，因为它没有一个持久化的状态空间来记录执行进度。\u003c/p\u003e\n\u003cp\u003e无状态和无记忆不同：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e无记忆\u003c/strong\u003e强调的是跨调用的信息丢失\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e无状态\u003c/strong\u003e强调的是在一次任务中，没有结构化的执行状态追踪\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e一个 Agent 需要知道：\u0026quot;我已经完成了步骤 1 和 2，步骤 3 失败了，我需要重试步骤 3\u0026quot;。LLM 没有这个能力。\u003c/p\u003e\n\u003ch3\u003e2.5 无反思：无法评估自己的输出质量\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景\u003c/strong\u003e：你让 LLM 写一段代码。它写完了。这段代码是否正确？LLM 不知道。它不会自动运行代码验证，不会检查边界条件，不会评估时间复杂度是否满足要求。\u003c/p\u003e\n\u003cp\u003e更深层的问题是：LLM 无法区分\u0026quot;我确信这是对的\u0026quot;和\u0026quot;我在瞎猜\u0026quot;。它的 confidence 不等于 correctness。一个 softmax 输出 0.95 的概率，并不意味着答案有 95% 的概率是正确的。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                    LLM 的五大局限\n\n    +----------+----------+----------+----------+----------+\n    |          |          |          |          |          |\n    | 无记忆    | 无工具    | 无规划    | 无状态    | 无反思    |\n    | Memoryless| Toolless | Planless | Stateless| Reflectless|\n    |          |          |          |          |          |\n    | 跨调用    | 只输出    | 单向生成  | 无执行    | 无法自我  |\n    | 信息丢失  | 文本     | 无回溯    | 进度追踪  | 评估质量  |\n    |          |          |          |          |          |\n    +----------+----------+----------+----------+----------+\n                          |\n                          v\n              LLM 需要一个\u0026quot;外壳\u0026quot;来弥补这些局限\n              这个外壳，就是 Agent Runtime\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e3. Agent 的精确定义\u003c/h2\u003e\n\u003ch3\u003e3.1 定义\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eAgent = LLM + Memory + Tools + Planner + Runtime\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这不是一个松散的隐喻，而是一个精确的组件模型。每个组件有明确的职责边界：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e组件\u003c/th\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003cth\u003e类比\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eLLM\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e语义理解、推理、生成\u003c/td\u003e\n\u003ctd\u003e大脑的语言区\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eMemory\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e存储对话历史、任务状态、长期知识\u003c/td\u003e\n\u003ctd\u003e海马体 + 笔记本\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eTools\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e与外部世界交互的能力集合\u003c/td\u003e\n\u003ctd\u003e双手 + 工具箱\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ePlanner\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e目标分解、行动排序、策略选择\u003c/td\u003e\n\u003ctd\u003e前额叶皮层\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRuntime\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e控制循环、状态管理、错误处理、生命周期\u003c/td\u003e\n\u003ctd\u003e自主神经系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e3.2 组件交互模型\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e    +---------------------------------------------------------+\n    |                     Agent Runtime                        |\n    |                                                         |\n    |   +----------+     +----------+     +----------+        |\n    |   |          |     |          |     |          |        |\n    |   |  Memory  |\u0026lt;---\u0026gt;|   LLM    |\u0026lt;---\u0026gt;| Planner  |        |\n    |   |          |     |          |     |          |        |\n    |   +----+-----+     +----+-----+     +----+-----+        |\n    |        |                |                 |              |\n    |        |           +----v-----+           |              |\n    |        +----------\u0026gt;|          |\u0026lt;----------+              |\n    |                    |  Tools   |                          |\n    |                    |          |                          |\n    |                    +----+-----+                          |\n    |                         |                                |\n    +---------------------------------------------------------+\n                              |\n                              v\n                     External World\n                  (APIs, DBs, Files, Users)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e交互流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eRuntime\u003c/strong\u003e 接收外部输入（用户消息、系统事件）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRuntime\u003c/strong\u003e 从 \u003cstrong\u003eMemory\u003c/strong\u003e 加载相关上下文\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLLM\u003c/strong\u003e 基于输入 + 上下文进行推理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlanner\u003c/strong\u003e（通常由 LLM 驱动）决定下一步行动\u003c/li\u003e\n\u003cli\u003e如果需要执行操作，\u003cstrong\u003eRuntime\u003c/strong\u003e 调度 \u003cstrong\u003eTools\u003c/strong\u003e 执行\u003c/li\u003e\n\u003cli\u003e工具执行结果写回 \u003cstrong\u003eMemory\u003c/strong\u003e，进入下一轮循环\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e关键设计决策：\u003cstrong\u003ePlanner 是一个独立组件，还是 LLM 的一部分？\u003c/strong\u003e 这取决于你对确定性的需求。如果 Planner 由 LLM 驱动（如 ReAct 模式），灵活但不可控；如果 Planner 是硬编码的状态机，可控但不灵活。这个 trade-off 贯穿整个 Agent 架构设计，我们会在第 03 篇深入讨论。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Agent 的核心循环详解\u003c/h2\u003e\n\u003cp\u003eAgent 的运行可以抽象为六个阶段的循环：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e    +-------+     +-------+     +------+\n    |       |     |       |     |      |\n    |Observe+----\u0026gt;| Think +----\u0026gt;| Plan |\n    |       |     |       |     |      |\n    +---^---+     +-------+     +--+---+\n        |                          |\n        |                          v\n    +---+----+                 +---+---+\n    |        |                 |       |\n    | Update |\u0026lt;----+ Reflect  \u0026lt;+ Act   |\n    |        |     |          ||       |\n    +--------+     +----------++-------+\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.1 各阶段详解\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eObserve（感知）\u003c/strong\u003e：收集当前环境信息。这包括用户的最新输入、上一步工具的返回结果、系统级事件（如超时、异常）、从 Memory 中检索的相关上下文。感知阶段的核心问题是\u003cstrong\u003e信息筛选\u003c/strong\u003e——不是所有信息都应该进入 LLM 的上下文，context window 是稀缺资源。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThink（推理）\u003c/strong\u003e：基于感知到的信息，理解当前处境。这是 LLM 最擅长的部分——语义理解、意图识别、情境分析。Think 阶段的输出是对当前状态的结构化理解，而不是最终答案。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePlan（规划）\u003c/strong\u003e：基于对当前状态的理解，决定下一步做什么。Plan 可以是单步的（\u0026quot;调用天气 API\u0026quot;），也可以是多步的（\u0026quot;先查天气，再根据天气决定穿什么，再创建提醒\u0026quot;）。规划的粒度直接影响系统的可控性和灵活性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAct（执行）\u003c/strong\u003e：执行规划中的动作。可能是调用工具（Tool Calling）、生成文本回复、更新内部状态，或者向用户提问以获取更多信息。执行是唯一产生副作用的阶段。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReflect（反思）\u003c/strong\u003e：评估执行结果。工具调用成功了吗？返回的数据符合预期吗？是否需要重试或换一个方案？反思是 Agent 与简单 Chain 的关键区别——它引入了\u003cstrong\u003e自我纠错\u003c/strong\u003e的能力。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eUpdate（更新）\u003c/strong\u003e：将本轮循环中产生的信息写入 Memory。包括更新对话历史、记录执行结果、修改任务状态。Update 确保下一轮循环有最新的上下文可用。\u003c/p\u003e\n\u003ch3\u003e4.2 最简实现\u003c/h3\u003e\n\u003cp\u003e下面是这个控制循环的 Python 伪代码实现。注意，这不是生产代码，而是用于精确表达架构意图的最简抽象：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Any\n\n@dataclass\nclass AgentState:\n    \u0026quot;\u0026quot;\u0026quot;Agent 的可序列化状态\u0026quot;\u0026quot;\u0026quot;\n    messages: list[dict] = field(default_factory=list)       # 对话历史\n    task_status: str = \u0026quot;pending\u0026quot;                              # 任务状态\n    plan: list[str] = field(default_factory=list)             # 当前计划\n    step_index: int = 0                                       # 执行进度\n    observations: list[Any] = field(default_factory=list)     # 感知缓冲\n\nclass Agent:\n    def __init__(self, llm, tools: dict, max_iterations: int = 10):\n        self.llm = llm\n        self.tools = tools           # {\u0026quot;tool_name\u0026quot;: callable}\n        self.max_iterations = max_iterations\n        self.state = AgentState()\n\n    def run(self, user_input: str) -\u0026gt; str:\n        self.state.messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: user_input})\n\n        for i in range(self.max_iterations):\n            # --- Observe ---\n            context = self._observe()\n\n            # --- Think ---\n            thought = self.llm.generate(\n                system_prompt=THINK_PROMPT,\n                messages=context,\n            )\n\n            # --- Plan ---\n            plan = self.llm.generate(\n                system_prompt=PLAN_PROMPT,\n                messages=context + [{\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: thought}],\n                response_format={\u0026quot;type\u0026quot;: \u0026quot;json\u0026quot;, \u0026quot;schema\u0026quot;: PlanSchema},\n            )\n\n            if plan.action == \u0026quot;finish\u0026quot;:\n                return plan.final_answer\n\n            # --- Act ---\n            tool_name = plan.tool_name\n            tool_args = plan.tool_args\n            try:\n                result = self.tools[tool_name](**tool_args)\n            except Exception as e:\n                result = f\u0026quot;Error: {e}\u0026quot;\n\n            # --- Reflect ---\n            reflection = self.llm.generate(\n                system_prompt=REFLECT_PROMPT,\n                messages=context + [\n                    {\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;Action: {tool_name}({tool_args})\u0026quot;},\n                    {\u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;, \u0026quot;content\u0026quot;: str(result)},\n                ],\n            )\n\n            # --- Update ---\n            self.state.messages.append({\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: thought})\n            self.state.messages.append({\u0026quot;role\u0026quot;: \u0026quot;tool\u0026quot;, \u0026quot;content\u0026quot;: str(result)})\n            self.state.observations.append({\n                \u0026quot;step\u0026quot;: i,\n                \u0026quot;action\u0026quot;: tool_name,\n                \u0026quot;result\u0026quot;: result,\n                \u0026quot;reflection\u0026quot;: reflection,\n            })\n\n            if reflection.should_retry:\n                continue  # 重试当前步骤\n            self.state.step_index += 1\n\n        return \u0026quot;达到最大迭代次数，任务未完成。\u0026quot;\n\n    def _observe(self) -\u0026gt; list[dict]:\n        \u0026quot;\u0026quot;\u0026quot;从 Memory 中组装当前上下文\u0026quot;\u0026quot;\u0026quot;\n        # 实际系统中这里会有复杂的上下文压缩、检索等逻辑\n        return self.state.messages[-20:]  # 简化：取最近 20 条消息\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码中有几个值得关注的设计决策：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eThink 和 Plan 分两次 LLM 调用\u003c/strong\u003e：可以使用不同的 system prompt 引导不同的思维模式，也便于独立观测和调试。代价是额外的 latency 和 token 成本。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlan 使用 Structured Output\u003c/strong\u003e：规划结果以 JSON Schema 约束，确保输出可解析、可校验。这是将 LLM 的非确定性输出转化为确定性执行的关键桥梁。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReflect 独立成阶段\u003c/strong\u003e：而不是合并到下一轮的 Think 中。这使得反思的 prompt 可以专注于\u0026quot;评估\u0026quot;而不是\u0026quot;理解+评估\u0026quot;，通常能得到更准确的自我评价。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003emax_iterations 作为安全阀\u003c/strong\u003e：防止 Agent 陷入无限循环。这是生产系统中必须有的机制，没有它，一个错误的 Reflect 判断就可能导致无限重试。\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 从 Chatbot 到 Agent 的光谱\u003c/h2\u003e\n\u003cp\u003eAgent 不是一个二元概念——\u0026quot;是 Agent\u0026quot;或\u0026quot;不是 Agent\u0026quot;。从最简单的 LLM 调用到完整的 Agent 系统，中间存在一个连续的光谱，每向右移动一步，都在引入新的复杂性来换取新的能力。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e确定性 ←─────────────────────────────────────────────────→ 自主性\n\nPure LLM    System     RAG       Tool       ReAct       Full\n            Prompt               Calling    Agent       Agent\n\n  f(x)→y   定制化     知识增强   函数调用   推理+执行    完整系统\n            对话                            循环\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e下表从六个维度对比这个光谱的各个阶段：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e阶段\u003c/th\u003e\n\u003cth\u003e记忆\u003c/th\u003e\n\u003cth\u003e工具\u003c/th\u003e\n\u003cth\u003e规划\u003c/th\u003e\n\u003cth\u003e状态\u003c/th\u003e\n\u003cth\u003e反思\u003c/th\u003e\n\u003cth\u003e典型产品/模式\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003ePure LLM\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e单次 API 调用\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e+ System Prompt\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e定制化 Chatbot\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e+ RAG\u003c/td\u003e\n\u003ctd\u003e外部知识\u003c/td\u003e\n\u003ctd\u003e检索\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e知识问答系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e+ Tool Calling\u003c/td\u003e\n\u003ctd\u003e会话级\u003c/td\u003e\n\u003ctd\u003e有\u003c/td\u003e\n\u003ctd\u003e单步\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003e无\u003c/td\u003e\n\u003ctd\u003eFunction Calling\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e+ Loop（ReAct）\u003c/td\u003e\n\u003ctd\u003e会话级\u003c/td\u003e\n\u003ctd\u003e有\u003c/td\u003e\n\u003ctd\u003e多步\u003c/td\u003e\n\u003ctd\u003e运行时\u003c/td\u003e\n\u003ctd\u003e隐式\u003c/td\u003e\n\u003ctd\u003eReAct Agent\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eFull Agent\u003c/td\u003e\n\u003ctd\u003e长期\u003c/td\u003e\n\u003ctd\u003e有\u003c/td\u003e\n\u003ctd\u003e多步\u003c/td\u003e\n\u003ctd\u003e持久化\u003c/td\u003e\n\u003ctd\u003e显式\u003c/td\u003e\n\u003ctd\u003e自主 Agent 系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e每个阶段的跃迁都有明确的 trade-off：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePure LLM → + System Prompt\u003c/strong\u003e：几乎零成本，但能显著改变模型的行为风格和专业度。Trade-off：prompt 越长，留给用户输入的 context window 越少。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e+ System Prompt → + RAG\u003c/strong\u003e：引入外部知识源，解决知识时效性和专业性问题。Trade-off：检索质量直接决定回答质量（garbage in, garbage out），且增加了 latency 和基础设施成本。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e+ RAG → + Tool Calling\u003c/strong\u003e：从\u0026quot;只读\u0026quot;变成\u0026quot;可写\u0026quot;，LLM 可以触发外部操作。Trade-off：引入了安全风险（LLM 可能调用不该调用的工具）和确定性问题（工具调用可能失败）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e+ Tool Calling → + Loop\u003c/strong\u003e：从单次推理变成多步推理-执行循环。这是质变。Trade-off：循环次数不可预测，token 成本不可预测，调试复杂度指数级上升。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e+ Loop → Full Agent\u003c/strong\u003e：引入持久化记忆和显式反思。Trade-off：系统复杂度大幅提升，需要处理记忆一致性、状态持久化、长时间运行等问题。\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 一个完整的例子\u003c/h2\u003e\n\u003cp\u003e用同一个任务——\u0026quot;帮我查看明天北京的天气并创建日程提醒\u0026quot;——展示不同阶段的实现差异。\u003c/p\u003e\n\u003ch3\u003e6.1 Pure LLM\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eresponse = llm.generate(\u0026quot;帮我查看明天北京的天气并创建日程提醒\u0026quot;)\n# 输出：好的，明天北京的天气大约是 25°C，晴转多云...（纯幻觉，没有真实数据）\n# 日程提醒也不会真的被创建\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e问题：没有真实数据，没有真实执行，一切都是生成的\u0026quot;假\u0026quot;内容。\u003c/p\u003e\n\u003ch3\u003e6.2 LLM + RAG\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 预先检索天气相关知识\nweather_docs = retriever.search(\u0026quot;北京天气预报\u0026quot;)\ncontext = format_docs(weather_docs)\n\nresponse = llm.generate(\n    f\u0026quot;根据以下信息回答用户问题：\\n{context}\\n\\n用户：帮我查看明天北京的天气并创建日程提醒\u0026quot;\n)\n# 输出基于检索到的文档，但如果文档不包含明天的天气（高概率），仍然无法回答\n# 日程提醒依然无法创建\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e问题：RAG 提供了知识，但无法获取实时数据，更无法执行\u0026quot;创建日程\u0026quot;这个写操作。\u003c/p\u003e\n\u003ch3\u003e6.3 LLM + Tool Calling（单步）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003etools = [\n    {\n        \u0026quot;name\u0026quot;: \u0026quot;get_weather\u0026quot;,\n        \u0026quot;description\u0026quot;: \u0026quot;获取指定城市的天气预报\u0026quot;,\n        \u0026quot;parameters\u0026quot;: {\u0026quot;city\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;date\u0026quot;: \u0026quot;string\u0026quot;}\n    },\n    {\n        \u0026quot;name\u0026quot;: \u0026quot;create_reminder\u0026quot;,\n        \u0026quot;description\u0026quot;: \u0026quot;创建日程提醒\u0026quot;,\n        \u0026quot;parameters\u0026quot;: {\u0026quot;title\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;time\u0026quot;: \u0026quot;string\u0026quot;, \u0026quot;note\u0026quot;: \u0026quot;string\u0026quot;}\n    }\n]\n\nresponse = llm.generate(\n    \u0026quot;帮我查看明天北京的天气并创建日程提醒\u0026quot;,\n    tools=tools,\n)\n# LLM 返回一个 tool_call：get_weather(city=\u0026quot;北京\u0026quot;, date=\u0026quot;2025-08-04\u0026quot;)\n# 但只能调用一个工具——它选了查天气，日程提醒怎么办？\n# 需要第二轮调用，但谁来发起？没有循环机制。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e问题：单步 Tool Calling 只能执行一个动作。多步任务需要外部编排。\u003c/p\u003e\n\u003ch3\u003e6.4 LLM + Tools + Loop（ReAct Agent）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eagent = Agent(llm=llm, tools={\u0026quot;get_weather\u0026quot;: get_weather, \u0026quot;create_reminder\u0026quot;: create_reminder})\nresult = agent.run(\u0026quot;帮我查看明天北京的天气并创建日程提醒\u0026quot;)\n\n# Agent 内部执行过程：\n#\n# [Iteration 1]\n# Think:  用户想查天气并创建提醒，我需要先查天气，再用天气信息创建提醒。\n# Plan:   调用 get_weather(city=\u0026quot;北京\u0026quot;, date=\u0026quot;2025-08-04\u0026quot;)\n# Act:    → {\u0026quot;temp\u0026quot;: 31, \u0026quot;condition\u0026quot;: \u0026quot;多云转雷阵雨\u0026quot;, \u0026quot;humidity\u0026quot;: 78}\n# Reflect: 成功获取天气数据，接下来需要创建日程提醒。\n# Update:  记录天气数据到 state。\n#\n# [Iteration 2]\n# Think:  已获取天气信息（31°C，多云转雷阵雨），需要创建提醒。\n# Plan:   调用 create_reminder(\n#             title=\u0026quot;明天北京天气提醒\u0026quot;,\n#             time=\u0026quot;2025-08-04T07:00:00\u0026quot;,\n#             note=\u0026quot;31°C，多云转雷阵雨，湿度 78%，建议带伞\u0026quot;\n#         )\n# Act:    → {\u0026quot;status\u0026quot;: \u0026quot;created\u0026quot;, \u0026quot;id\u0026quot;: \u0026quot;rem_abc123\u0026quot;}\n# Reflect: 提醒创建成功。两个子任务都已完成，可以返回最终结果。\n# Plan:   finish\n#\n# 最终输出：\n# \u0026quot;明天北京天气：31°C，多云转雷阵雨，湿度 78%。\n#  已为您创建早上 7:00 的天气提醒，建议带伞。\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这才是我们期望的行为：\u003cstrong\u003e理解意图 → 分解任务 → 逐步执行 → 组合结果\u003c/strong\u003e。注意 Agent 做了几件 Pure LLM 做不到的事：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e任务分解\u003c/strong\u003e：识别出\u0026quot;查天气\u0026quot;和\u0026quot;创建提醒\u0026quot;是两个子任务，且有依赖关系\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e信息传递\u003c/strong\u003e：把第一步的天气数据作为第二步的输入（note 字段）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e智能补全\u003c/strong\u003e：用户没说提醒时间，Agent 推断了一个合理的时间（早上 7 点）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e结果整合\u003c/strong\u003e：把多步执行的结果组合成一个连贯的自然语言回复\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e6.5 Full Agent（增加长期记忆与反思）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Full Agent 在 ReAct 基础上增加：\n\n# 1. 长期记忆：记住用户偏好\nuser_profile = memory.recall(user_id=\u0026quot;u_001\u0026quot;)\n# → {\u0026quot;preferred_reminder_time\u0026quot;: \u0026quot;06:30\u0026quot;, \u0026quot;weather_sensitivity\u0026quot;: \u0026quot;rain\u0026quot;}\n\n# 2. 个性化决策：基于用户历史偏好\n# Agent 不再推断 7:00，而是使用用户偏好的 6:30\n# Agent 知道用户对雨天敏感，会强调带伞建议\n\n# 3. 显式反思：执行后回顾\nreflection = agent.reflect(\n    task=\u0026quot;查天气并创建提醒\u0026quot;,\n    result=result,\n    criteria=[\u0026quot;信息完整性\u0026quot;, \u0026quot;时间合理性\u0026quot;, \u0026quot;个性化程度\u0026quot;]\n)\n# → \u0026quot;时间使用了用户偏好，天气包含了降雨提醒。但缺少穿衣建议，下次可以补充。\u0026quot;\n\n# 4. 记忆更新：学习本次交互\nmemory.store(\n    user_id=\u0026quot;u_001\u0026quot;,\n    fact=\u0026quot;用户关注北京天气，可能是北京居民或近期有出行计划\u0026quot;,\n    source=\u0026quot;interaction_20250803\u0026quot;\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFull Agent 的核心区别在于：\u003cstrong\u003e它在跨会话的时间尺度上持续学习和个性化\u003c/strong\u003e。这需要一个完整的 Memory 架构来支撑——短期会话记忆、长期用户画像、事实知识库——我们将在第 08 篇详细展开。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Agent 的设计哲学\u003c/h2\u003e\n\u003ch3\u003e7.1 LLM as the Reasoning Engine, Not the Entire System\u003c/h3\u003e\n\u003cp\u003e这是 Agent 架构最核心的设计原则。LLM 是推理引擎，不是整个系统。就像汽车的发动机不是汽车本身——你还需要变速箱（Planner）、方向盘（Tools）、仪表盘（Memory）和底盘（Runtime）。\u003c/p\u003e\n\u003cp\u003e这个原则的工程含义是：\u003cstrong\u003e不要让 LLM 做所有事情。\u003c/strong\u003e 让它做它擅长的——语义理解、推理、决策——然后用确定性代码处理其余部分。\u003c/p\u003e\n\u003ch3\u003e7.2 确定性 vs 非确定性的边界\u003c/h3\u003e\n\u003cp\u003eAgent 系统的核心设计问题之一是：\u003cstrong\u003e哪些部分让 LLM 做（非确定性），哪些部分用代码做（确定性）？\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e    确定性 (代码)                        非确定性 (LLM)\n    +-----------------------+          +-----------------------+\n    | 输入校验              |          | 意图理解              |\n    | 工具调度              |          | 工具选择              |\n    | 参数类型检查          |          | 参数填充              |\n    | 权限控制              |          | 上下文摘要            |\n    | 错误重试逻辑          |          | 结果解释              |\n    | 速率限制              |          | 对话策略              |\n    | 日志记录              |          | 异常情况判断          |\n    | 状态持久化            |          | 任务分解              |\n    +-----------------------+          +-----------------------+\n            |                                    |\n            v                                    v\n    可预测、可审计、可测试            灵活、自适应、但不可控\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e决策原则：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e如果逻辑可以穷举，用代码\u003c/strong\u003e。比如\u0026quot;用户必须先登录才能创建日程\u0026quot;——这是业务规则，不需要 LLM 判断。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e如果需要理解自然语言语义，用 LLM\u003c/strong\u003e。比如\u0026quot;用户说\u0026#39;帮我约个会\u0026#39;是什么意思\u0026quot;——这需要语义理解。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e如果错误的代价很高，用代码兜底\u003c/strong\u003e。比如转账操作的金额校验，无论 LLM 怎么说，都必须用代码做最终确认。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e如果需要处理开放域输入，用 LLM\u003c/strong\u003e。比如用户可能用任何方式描述他们的需求，只有 LLM 能处理这种多样性。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e7.3 何时不需要 Agent\u003c/h3\u003e\n\u003cp\u003e并非所有问题都需要 Agent。以下场景用更简单的方案更好：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e固定流程的自动化\u003c/strong\u003e：发票处理、数据同步——用 Workflow（DAG）更可靠\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e单轮问答\u003c/strong\u003e：FAQ、知识检索——LLM + RAG 就够了\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e确定性决策\u003c/strong\u003e：基于规则的审批——规则引擎更合适\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e高吞吐低延迟\u003c/strong\u003e：实时推荐——Agent 的多轮调用延迟太高\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAgent 的最佳应用场景是：\u003cstrong\u003e任务需要多步推理、工具组合使用、且执行路径在运行时才能确定\u003c/strong\u003e。如果执行路径在编译时就能确定，你需要的是 Workflow，不是 Agent。这正是我们下一篇要深入讨论的主题。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e8. 总结与思考\u003c/h2\u003e\n\u003cp\u003e本文从 LLM 的本质出发，论证了为什么 \u003ccode\u003ef(prompt) → response\u003c/code\u003e 不等于 Agent。核心论点可以压缩为一句话：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eLLM 是推理能力的来源，Agent 是将推理能力转化为行动能力的系统。\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e我们建立了三个关键的心智模型：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e组件模型\u003c/strong\u003e：Agent = LLM + Memory + Tools + Planner + Runtime，五个组件各有职责，协作运行。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e循环模型\u003c/strong\u003e：Observe → Think → Plan → Act → Reflect → Update，Agent 通过控制循环将单次推理扩展为多步执行。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e光谱模型\u003c/strong\u003e：从 Pure LLM 到 Full Agent 是一个连续光谱，每一步都有明确的能力增益和复杂性代价。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e进一步思考\u003c/h3\u003e\n\u003cp\u003e在进入下一篇之前，留几个值得深入思考的问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于 Agent 的边界\u003c/strong\u003e：如果 Planner 是硬编码的（比如一个固定的 DAG），这还算 Agent 吗？如果所有工具都是预定义的、参数是模板化的，LLM 只负责填参数，这算 Agent 还是 Workflow？这个边界在哪里，决定了你在工程实践中应该选择什么样的架构。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于 LLM 的演进\u003c/strong\u003e：随着模型能力的增强（更长的 context window、更强的 reasoning、内置的 tool use），LLM 和 Agent 之间的边界是否会逐渐模糊？OpenAI 的 o1/o3 系列通过 chain-of-thought 在模型内部实现了某种程度的\u0026quot;规划\u0026quot;，这是否意味着 Agent Runtime 的部分功能会被吸收进模型本身？\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于成本和延迟\u003c/strong\u003e：Agent 的每一轮循环都包含至少一次 LLM 调用。如果一个任务需要 5 轮循环，每轮 3 次 LLM 调用（Think + Plan + Reflect），就是 15 次调用。这个成本和延迟在生产环境中是否可接受？如何在 Agent 的灵活性和系统的性能之间找到平衡点？\u003c/p\u003e\n\u003cp\u003e这些问题没有标准答案，但它们定义了 Agentic 系统设计的核心张力。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 02 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/03-Agent%20vs%20Workflow%20vs%20Automation\"\u003e03 | Agent vs Workflow vs Automation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"1a:T498b,"])</script><script>self.__next_f.push([1,"\u003ch2\u003e一、引言\u003c/h2\u003e\n\u003cp\u003e人工智能正处于一次范式迁移的节点：从“能说”的大语言模型（LLM）走向“能做”的智能体（Agent）。LLM 带来了通用的语言理解和生成能力，但它仍然是一个\u003cbr\u003e\u003cstrong\u003e封闭、被动、短期记忆\u003c/strong\u003e的系统：知识停留在训练时刻，无法直接访问实时世界；只能在用户输入后响应；上下文窗口限制使得记忆易失；输出不含可执行语义，更谈不上与外界系统协作。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAgent\u003c/strong\u003e 的提出，正是为 LLM 补齐“行动力”：通过\u003cstrong\u003e工具调用\u003c/strong\u003e连入 API/数据库/计算环境，通过\u003cstrong\u003e记忆\u003c/strong\u003e维持跨会话状态，通过\u003cstrong\u003e编排\u003cbr\u003e\u003cstrong\u003e将复杂任务拆解为可控的工作流，必要时引入\u003c/strong\u003e多 Agent 协作\u003c/strong\u003e。当这四个维度协同起来，语言就不再是终点，而是驱动系统执行任务的接口。\u003c/p\u003e\n\u003ch2\u003e二、Agent 是什么\u003c/h2\u003e\n\u003cp\u003e我们将 Agent 抽象为：\u003cstrong\u003e大脑（LLM） + 工具（Tools/Functions） + 记忆（Memory） + 编排（Orchestration）\u003c/strong\u003e。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e大脑\u003c/strong\u003e：理解意图、推理计划、生成结构化中间表示（思考链/计划/工具参数）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e工具\u003c/strong\u003e：把自然语言转化为\u003cstrong\u003e外部动作\u003c/strong\u003e：HTTP API、数据库查询、代码执行、文件读写，甚至机器人控制。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e记忆\u003c/strong\u003e：短期记忆承载对话上下文与临时事实；长期记忆借助向量数据库/关系库沉淀用户偏好、文档知识与任务状态。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e编排\u003c/strong\u003e：以\u003cstrong\u003e状态机/DAG\u003c/strong\u003e表达任务流程，处理条件分支、并行、重试回退、超时与配额，提供可观测性与审计。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e换句话说：Agent 是“会说话的操作系统进程”。它既遵循自然语言接口，又遵守工程系统的边界与约束。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e三、Agent 能做什么\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e检索增强生成（RAG）\u003c/strong\u003e：在回答前检索企业知识库或互联网，降低幻觉，确保时效与可追溯引用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e工具化操作\u003c/strong\u003e：把“帮我预定会议室/查 Jira/跑报表”翻译为真实 API 调用与数据落库。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e任务分解与计划执行\u003c/strong\u003e：从“调研—起草—审稿—发布”的完整管道，到“数据提取—转换—加载（ETL）”的数据工程链路。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e多 Agent 协作\u003c/strong\u003e：研究员、撰稿员、质检员、执行官等角色并行或串行协同。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e持续记忆与个性化\u003c/strong\u003e：长期学习用户偏好与业务上下文，形成“专属助理”。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e这些能力已在\u003cstrong\u003e客服、法务审查、财务报表、运维巡检、投研分析、政企知识库\u003c/strong\u003e等场景落地。\u003c/p\u003e\n\u003ch2\u003e四、为什么需要编排\u003c/h2\u003e\n\u003cp\u003e单一 LLM + 工具调用可以跑出 demo，但难以支撑生产。\u003cstrong\u003e编排\u003c/strong\u003e让 Agent 系统具备：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e任务有序性\u003c/strong\u003e：复杂流程的前后置依赖、并行合并、条件分支。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可靠性\u003c/strong\u003e：失败重试、幂等、回退策略、超时与熔断、降级链路。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e安全性\u003c/strong\u003e：提示注入防护、工具白名单、参数校验、沙箱执行、RBAC 与审计。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可观测性\u003c/strong\u003e：结构化日志、链路追踪（OTEL）、成本与延迟指标、交互回放。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e没有编排，就没有“可运营”的 Agent。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e五、主流框架详解\u003c/h2\u003e\n\u003cp\u003e当前最具代表性的范式与框架：\u003cbr\u003e\u003cstrong\u003eReAct、Plan-and-Execute、LLMCompiler、LangChain、LangGraph、LlamaIndex、CrewAI/AutoGen\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e5.1 ReAct（Reason + Act）\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003e2022 年提出，动机是让 LLM 的行为\u003cem\u003e可解释\u003c/em\u003e：将“思考过程”与“实际动作”分离，便于调试与审计。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e让模型在调用工具前给出\u003cstrong\u003e思考链（Thought）\u003c/strong\u003e，避免“黑箱行动”。\u003c/li\u003e\n\u003cli\u003e在“思考—行动—观察”循环中逐步逼近目标。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心机制\u003c/strong\u003e\u003cbr\u003e\u003ccode\u003eThought → Action(tool, params) → Observation → Thought → ...\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThought\u003c/strong\u003e：输出中间推理（可省略给用户，但用于系统决策）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAction\u003c/strong\u003e：按 JSON/函数签名触发工具调用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eObservation\u003c/strong\u003e：工具/环境返回，再进入下一轮推理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003cbr\u003eReAct 已成为各框架默认参考范式，LangChain/AutoGen 等均内置。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRAG 问答（先思考应检索哪些关键字→检索→解读→回答）。\u003c/li\u003e\n\u003cli\u003e金融/运维查询（先枚举数据源→调用行情/监控 API→计算→结论）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：透明、易调试、适合逐步探索。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：每步都要调 LLM，延迟与成本上升；需要控制泄露 Thought。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（LangChain 简化）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom langchain.agents import initialize_agent, load_tools\nfrom langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(model=\u0026quot;gpt-4o-mini\u0026quot;)\ntools = load_tools([\u0026quot;serpapi\u0026quot;, \u0026quot;llm-math\u0026quot;], llm=llm)\n\nagent = initialize_agent(tools, llm, agent=\u0026quot;zero-shot-react-description\u0026quot;, verbose=True)\nagent.run(\u0026quot;美元兑日元的即期汇率是多少？100 美元大约换多少日元？\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e先学 ReAct，再看其他模式；理解“中间思考—外部行动”的边界与安全性。\u003c/p\u003e\n\u003ch3\u003e5.2 Plan-and-Execute\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003e为缓解 ReAct 调用频繁、成本高的问题，提出“先规划再执行”，把 LLM 调用集中到\u003cstrong\u003e规划阶段\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e降低长任务的 LLM 调用次数与延迟。\u003c/li\u003e\n\u003cli\u003e提高执行阶段的确定性与可回放性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心机制\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePlanning\u003c/strong\u003e：LLM 产出任务分解（步骤、依赖、所需工具）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExecution\u003c/strong\u003e：流程引擎按计划逐步执行，必要时少量“再规划”。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003cbr\u003eLangChain 等框架提供内置链路；在复杂长任务中广泛使用。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e报告/白皮书生成（规划章节→检索资料→写作→审稿）。\u003c/li\u003e\n\u003cli\u003e数据工程（ETL）与指标计算。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：成本可控；对工程侧友好。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：对“初始计划质量”依赖高；需要良好的失败恢复策略。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（伪代码）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eplan = llm(\u0026quot;把‘新能源车行业研究’分解为可执行步骤\u0026quot;)\nfor step in plan.steps:\n    execute(step)  # 工具/代码/SQL\nfinal = llm(f\u0026quot;根据执行产物撰写摘要：{collect_outputs()}\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e结合任务编排引擎（如 LangGraph）使用；关注“计划修正”的闭环设计。\u003c/p\u003e\n\u003ch3\u003e5.3 LLMCompiler\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003e源自微软研究，借鉴编译器思想：把自然语言任务\u003cstrong\u003e编译\u003c/strong\u003e为可并行执行的\u003cstrong\u003eDAG\u003c/strong\u003e，以获得高吞吐。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e将多工具/多数据源任务并行化，避免串行瓶颈。\u003c/li\u003e\n\u003cli\u003e把“任务—执行图”的关系结构化，便于优化。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心机制\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e编译\u003c/strong\u003e：LLM 将任务语义转成节点与依赖（DAG）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e执行\u003c/strong\u003e：节点并行运行，统一汇总。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003cbr\u003e学术与实验为主，工程落地探索中。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e多网站并行爬取与聚合分析。\u003c/li\u003e\n\u003cli\u003e多 API 并行获取数据后统一建模。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：吞吐高、结构清晰。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：实现复杂；缺少成熟的标准化工具链。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（伪代码）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edag = compile_to_dag(\u0026quot;对‘政策/销量/技术’三方面做新能源车行业分析\u0026quot;)\ndag.execute_parallel()\nsummary = llm(\u0026quot;汇总 DAG 结果并给出结论\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e理解 DAG/并行执行与幂等性；适合系统工程背景的团队。\u003c/p\u003e\n\u003ch3\u003e5.4 LangChain\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003e2022 年开源，首个“把 LLM 嵌入应用”的\u003cstrong\u003e通用开发框架\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e统一抽象 Prompt/LLM/Memory/Tools/Chains/Agents。\u003c/li\u003e\n\u003cli\u003e快速搭建原型与 PoC，降低入门门槛。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征/架构\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLLM Wrappers\u003c/strong\u003e：适配主流云模型与本地模型。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePromptTemplates\u003c/strong\u003e：可参数化提示词。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMemory\u003c/strong\u003e：会话/长期记忆，支持自定义后端。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTools\u003c/strong\u003e：声明式工具定义与参数校验。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eChains/Agents\u003c/strong\u003e：组装工作流或启用工具化智能体。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e社区最大、教程与示例最全；大量第三方集成。\u003c/li\u003e\n\u003cli\u003e复杂生产系统往往与\u003cstrong\u003eLangGraph\u003c/strong\u003e/自研编排结合使用。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e文档问答（RAG Agent）。\u003c/li\u003e\n\u003cli\u003e智能客服/助手。\u003c/li\u003e\n\u003cli\u003e代码/数据处理助手。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：生态全、迭代快、原型成本低。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：组件众多、耦合度易升高；需谨慎裁剪。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（RAG QA 极简）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom langchain.chains import RetrievalQA\nfrom langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(model=\u0026quot;gpt-4o-mini\u0026quot;)\nqa = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever())\nprint(qa.run(\u0026quot;总结这份合同的关键风险\u0026quot;))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e用它“站起来”，但不要把它当全部；与观测/编排/缓存协同设计。\u003c/p\u003e\n\u003ch3\u003e5.5 LangGraph（含 LangGraph Platform）\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003eLangChain 的链式范式难以表达\u003cstrong\u003e循环、回退、并行\u003c/strong\u003e与\u003cstrong\u003e长时状态\u003c/strong\u003e。LangGraph 将 Agent 视为\u003cstrong\u003e显式状态机\u003c/strong\u003e/DAG，并与观测平台集成。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e复杂工作流的\u003cstrong\u003e可控性\u003c/strong\u003e与\u003cstrong\u003e可观测性\u003c/strong\u003e。\u003c/li\u003e\n\u003cli\u003e长运行任务的\u003cstrong\u003e状态持久化\u003c/strong\u003e与\u003cstrong\u003e弹性伸缩\u003c/strong\u003e。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征/架构\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e状态图（StateGraph）\u003c/strong\u003e：定义节点（函数/Agent）与边（条件/并行/回路）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e人机协作\u003c/strong\u003e：在关键节点注入“人工审核/纠偏”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e与 LangSmith/OTEL\u003c/strong\u003e 联动：日志、追踪、成本面板。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlatform\u003c/strong\u003e：受管端点、持久队列、版本化与回放。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003cbr\u003e企业采用度上升；Platform 侧提供“从开发到部署”的一体化体验。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e合规审查流水线：抽取 → 规则/LLM 检查 → 复核 → 报告。\u003c/li\u003e\n\u003cli\u003e企业知识库问答：检索 → 生成 → 评估不合格回退。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：工程化最佳平衡点；对复杂任务友好。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：学习成本较高；图的演进需要治理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（检索→生成→评估→回退）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom langgraph.graph import StateGraph\n\n\ndef retrieve(state): ...\n\n\ndef generate(state): ...\n\n\ndef evaluate(state): ...  # 返回 pass/fail\n\n\ng = StateGraph()\ng.add_node(\u0026quot;retrieve\u0026quot;, retrieve)\ng.add_node(\u0026quot;generate\u0026quot;, generate)\ng.add_node(\u0026quot;evaluate\u0026quot;, evaluate)\n\ng.set_entry_point(\u0026quot;retrieve\u0026quot;)\ng.add_edge(\u0026quot;retrieve\u0026quot;, \u0026quot;generate\u0026quot;)\ng.add_edge(\u0026quot;generate\u0026quot;, \u0026quot;evaluate\u0026quot;)\ng.add_conditional_edges(\u0026quot;evaluate\u0026quot;, {\u0026quot;pass\u0026quot;: \u0026quot;END\u0026quot;, \u0026quot;fail\u0026quot;: \u0026quot;generate\u0026quot;})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e把“业务流程图”翻译成“状态图”，自下而上替换节点：先用伪实现跑通，再替换为真实工具/服务。\u003c/p\u003e\n\u003ch3\u003e5.6 LlamaIndex\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003e（原 GPT Index）从“让 LLM 使用外部数据”出发，沉淀为\u003cstrong\u003e数据接入与检索增强平台\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e把文档/表格/数据库接入到 LLM。\u003c/li\u003e\n\u003cli\u003e提供\u003cstrong\u003e多索引\u003c/strong\u003e与\u003cstrong\u003e混合检索\u003c/strong\u003e以提高召回与可控性。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征/架构\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e数据连接器\u003c/strong\u003e：FS、S3、GDrive、Notion、数据库等。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e索引\u003c/strong\u003e：向量索引、关键词索引、图索引等。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e检索\u003c/strong\u003e：BM25 + 向量 + 重排（可插拔）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e与 LangChain/LangGraph 兼容\u003c/strong\u003e，可作为检索层。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003cbr\u003e在知识库/文档问答领域最常用；正扩展到多模态。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e合同与政策问答；内部 Wiki 助手；会议纪要问答。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：数据侧强、接入快、检索策略丰富。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：编排弱；需要配合工作流框架。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（向量索引）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n\ndocs = SimpleDirectoryReader(\u0026quot;docs\u0026quot;).load_data()\nindex = GPTVectorStoreIndex.from_documents(docs)\nquery_engine = index.as_query_engine()\nprint(query_engine.query(\u0026quot;列出这份合同的终止条款\u0026quot;))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e作为“数据/RAG 层”的强力搭档，与 LangGraph 共同组成“检索 + 编排”的主干。\u003c/p\u003e\n\u003ch3\u003e5.7 CrewAI / AutoGen（多 Agent 协作）\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e背景\u003c/strong\u003e\u003cbr\u003e开源社区探索“虚拟团队”形态：通过多个角色化 Agent 的协作完成复杂任务。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e要解决的问题\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e单 Agent 能力边界：需要专家分工与相互制衡。\u003c/li\u003e\n\u003cli\u003e让“研究—写作—审稿—发布”自然映射到多 Agent。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征/架构\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e角色与职责\u003c/strong\u003e：researcher、writer、reviewer 等。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e消息编排\u003c/strong\u003e：对话驱动的协同；可插人类审核。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e任务路由\u003c/strong\u003e：不同子任务交由不同角色处理。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e现状与生态\u003c/strong\u003e\u003cbr\u003e科研/实验社区活跃；企业落地需要补齐观测、安全与治理。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e典型应用\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e行业研报与竞品分析；内容生产流水线。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优缺点\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e优点\u003c/strong\u003e：贴近人的协作心智模型，易扩展角色库。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：生产治理薄弱；复杂度随角色数上升。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e示例（AutoGen 极简）\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom autogen import AssistantAgent, UserProxyAgent\n\nassistant = AssistantAgent(\u0026quot;researcher\u0026quot;, llm_config={\u0026quot;model\u0026quot;: \u0026quot;gpt-4o-mini\u0026quot;})\nuser_proxy = UserProxyAgent(\u0026quot;writer\u0026quot;, human_input_mode=\u0026quot;NEVER\u0026quot;)\nuser_proxy.initiate_chat(assistant, message=\u0026quot;写一份新能源车行业调研大纲\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e学习建议\u003c/strong\u003e\u003cbr\u003e以“小团队”起步（2–3 角色），收敛职责边界；引入编排框架承接生产治理。\u003c/p\u003e\n\u003ch2\u003e六、学习路径（技术依赖关系）\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e只给“依赖链”，便于立刻开工：\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e语言与接口\u003c/strong\u003e → Python/JS 基础；HTTP/JSON；异步与并发。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLLM 能力\u003c/strong\u003e → Prompt Engineering；\u003cstrong\u003eFunction Calling/Tool Use\u003c/strong\u003e；结构化输出（JSON Schema）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRAG 能力\u003c/strong\u003e → 文档分块与清洗；嵌入模型；\u003cstrong\u003e向量数据库（pgvector/Milvus/Weaviate）\u003c/strong\u003e；混合检索与重排。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e编排能力\u003c/strong\u003e → \u003cstrong\u003e状态机/DAG（LangGraph）\u003c/strong\u003e；重试回退；超时熔断；人机协作。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e运维能力\u003c/strong\u003e → 日志/追踪（OpenTelemetry）；指标（Prometheus/Grafana）；安全（提示注入防护、RBAC、审计）；部署（Docker/K8s/Cloud\u003cbr\u003eRun）。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e沿这条路径递进，你可以从“能调模型与工具”，稳步走到“能搭生产可运维的 Agent 系统”。\u003c/p\u003e\n\u003ch2\u003e七、未来展望\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e多模态 Agent\u003c/strong\u003e 将同时处理文本、图像、语音与视频，统一在一个任务图里协同；\u003cstrong\u003e模型路由与降级\u003c/strong\u003e会让系统自动在质量、成本、延迟之间折中；\u003cbr\u003e\u003cstrong\u003eAgent OS/编排平台\u003c/strong\u003e将成为企业的“智能内核”，承载权限、任务、审计与经济计量；而 \u003cstrong\u003eLLMOps 标准化\u003c/strong\u003e\u003cbr\u003e则会把“可观测、安全治理、回放评测”固化为工程必修课。\u003c/p\u003e\n\u003ch2\u003e八、结语\u003c/h2\u003e\n\u003cp\u003e从 LLM 到 Agent，不只是“接口变了”，而是\u003cstrong\u003e软件工程边界\u003c/strong\u003e的扩大：语言成了新的“应用协议”，编排成了“智能内核”，数据与工具成了“外设”。掌握本文的框架图谱与依赖链，意味着你可以按需组装：以\u003cbr\u003eLlamaIndex 做数据底座，以 LangGraph 管编排，以 LangChain/AutoGen/CrewAI 做场景拼装，再用监控与安全把它变成真正\u003cstrong\u003e可运营\u003c/strong\u003e\u003cbr\u003e的系统。愿你从 demo 出发，驶向生产。\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-1 text-sm mb-4\",\"children\":[[\"$\",\"$L13\",null,{\"href\":\"/blog/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"博客\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"Engineering\"}],[[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/agentic/page/1\",\"className\":\"text-blue-600 hover:text-blue-700 transition-colors\",\"children\":\"Agentic 系统\"}]]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center mb-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-4 h-4 mr-2 text-gray-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z\"}]}],[\"$\",\"time\",null,{\"dateTime\":\"2025-12-01\",\"children\":\"2025年12月01日\"}]]}]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-6 text-center\",\"children\":\"From LLM to Agent: Agentic 系统的知识地图\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6 justify-center\",\"children\":[[\"$\",\"$L13\",\"Agentic\",{\"href\":\"/blog/tag/Agentic/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Agentic\"}],[\"$\",\"$L13\",\"AI Engineering\",{\"href\":\"/blog/tag/AI%20Engineering/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"AI Engineering\"}],[\"$\",\"$L13\",\"LLM\",{\"href\":\"/blog/tag/LLM/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"LLM\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto\",\"children\":[\"$\",\"$L14\",null,{\"content\":\"$15\"}]}],[\"$\",\"$10\",null,{\"fallback\":[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":\"加载导航中...\"}],\"children\":[\"$\",\"$L16\",null,{\"globalNav\":{\"prev\":{\"slug\":\"engineering/architecture/限流的本质：从限流算法到分布式流控的架构思考\",\"title\":\"限流的本质：从限流算法到分布式流控的架构思考\",\"description\":\"限流不是一个算法问题，而是一个系统设计问题。从速率控制到并发保护，从单机令牌桶到分布式 Redis 计数器，从 Nginx 接入层到业务层精细化流控——每一层的限流策略背后，都是对系统容量、业务优先级和降级策略的深度思考。\",\"pubDate\":\"2025-11-25\",\"tags\":[\"限流\",\"分布式系统\",\"系统架构\",\"高可用\"],\"heroImage\":\"$undefined\",\"content\":\"$17\"},\"next\":{\"slug\":\"engineering/architecture/SET化架构：从单元化原理到大规模落地实践\",\"title\":\"SET化架构：从单元化原理到大规模落地实践\",\"description\":\"深入剖析SET化（单元化）架构的核心原理与设计实践，涵盖流量路由、数据分片、全局服务、故障隔离等关键环节，结合美团、阿里等大厂实践经验，构建可水平扩展的弹性架构体系。\",\"pubDate\":\"2025-12-05\",\"tags\":[\"架构设计\",\"SET化架构\",\"单元化\",\"异地多活\",\"高可用\"],\"heroImage\":\"$undefined\",\"content\":\"$18\"}},\"tagNav\":{\"Agentic\":{\"prev\":null,\"next\":{\"slug\":\"engineering/agentic/02-From Prompt to Agent\",\"title\":\"From Prompt to Agent: 为什么 LLM 本身不是 Agent\",\"description\":\"LLM 是一个无状态的文本函数，Agent 是一个有状态的推理系统。本文从 LLM 的五大局限出发，精确定义 Agent 的组件模型与控制循环，并沿 Chatbot → Agent 的光谱逐级拆解，帮助你建立从 Prompt 到 Agent 的完整认知框架。\",\"pubDate\":\"2025-12-05\",\"tags\":[\"Agentic\",\"AI Engineering\",\"LLM\"],\"heroImage\":\"$undefined\",\"content\":\"$19\"}},\"AI Engineering\":{\"prev\":null,\"next\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:next\"},\"LLM\":{\"prev\":{\"slug\":\"insights/technology/AI-Agent技术科普\",\"title\":\"Agent 技术科普：开启智能体的新时代\",\"description\":\"本文面向工程与产品落地，采用“概述长文 + 框架细化 + 技术依赖链”的结构：前半部分回答*为什么与是什么*，中段把*主流框架逐一讲透*（背景、要解决的问题、核心机制、现状与生态、典型应用、优缺点、示例、学习建议），最后给出*最小依赖链*以便快速动手。\",\"pubDate\":\"2025-09-25\",\"tags\":[\"AI Agent\",\"LLM\",\"智能体\"],\"heroImage\":\"$undefined\",\"content\":\"$1a\"},\"next\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:next\"}}}]}],[\"$\",\"$L1b\",null,{}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"8:null\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"a:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"From LLM to Agent: Agentic 系统的知识地图 - Skyfalling Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Agentic 系列开篇。从 LLM 的局限出发，定义 Agent 的核心组成，绘制 Agentic 系统全景架构图，并通过代码演示从 ChatCompletion 到完整 Agent 的演进路径。本文是整个系列 14 篇文章的精神锚点与导航地图。\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"From LLM to Agent: Agentic 系统的知识地图\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"Agentic 系列开篇。从 LLM 的局限出发，定义 Agent 的核心组成，绘制 Agentic 系统全景架构图，并通过代码演示从 ChatCompletion 到完整 Agent 的演进路径。本文是整个系列 14 篇文章的精神锚点与导航地图。\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"5\",{\"property\":\"article:published_time\",\"content\":\"2025-12-01\"}],[\"$\",\"meta\",\"6\",{\"property\":\"article:author\",\"content\":\"Skyfalling\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"From LLM to Agent: Agentic 系统的知识地图\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Agentic 系列开篇。从 LLM 的局限出发，定义 Agent 的核心组成，绘制 Agentic 系统全景架构图，并通过代码演示从 ChatCompletion 到完整 Agent 的演进路径。本文是整个系列 14 篇文章的精神锚点与导航地图。\"}],[\"$\",\"link\",\"10\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"13\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n12:{\"metadata\":\"$a:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>