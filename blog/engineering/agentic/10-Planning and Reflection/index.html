<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/ab9f9bc568942ddd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42d55485b4428e47.js"/><script src="/_next/static/chunks/4bd1b696-8ec333fca6b38e39.js" async=""></script><script src="/_next/static/chunks/1684-a2aac8a674e5d38c.js" async=""></script><script src="/_next/static/chunks/main-app-2791dc86ed05573e.js" async=""></script><script src="/_next/static/chunks/6874-7791217feaf05c17.js" async=""></script><script src="/_next/static/chunks/app/layout-142e67ac4336647c.js" async=""></script><script src="/_next/static/chunks/968-d7155a2506e36f1d.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js" async=""></script><meta name="next-size-adjust" content=""/><title>Planning and Reflection: 从 ReAct 到分层规划与自我纠错 - Skyfalling Blog</title><meta name="description" content="Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。"/><meta property="og:title" content="Planning and Reflection: 从 ReAct 到分层规划与自我纠错"/><meta property="og:description" content="Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-01-12"/><meta property="article:author" content="Skyfalling"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Planning and Reflection: 从 ReAct 到分层规划与自我纠错"/><meta name="twitter:description" content="Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。"/><link rel="shortcut icon" href="/favicon.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/favicon.png"/><link rel="apple-touch-icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen flex flex-col"><header class="bg-[var(--background)]"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a class="-m-1.5 p-1.5" href="/"><span class="sr-only">Skyfalling Blog</span><span class="text-2xl font-bold text-gray-900">Skyfalling</span></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">打开主菜单</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/">首页</a><a class="text-base font-semibold leading-6 transition-colors text-blue-600 border-b-2 border-blue-600 pb-1" href="/blog/">博客</a><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/about/">关于</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"></div></nav></header><main class="flex-1"><article class="min-h-screen"><div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8"><div class="rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12"><header class="mb-8"><nav class="flex items-center gap-1 text-sm mb-4"><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/page/1/">博客</a><span class="text-gray-300">/</span><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/category/engineering/page/1/">Engineering</a><span class="text-gray-300">/</span><a class="text-blue-600 hover:text-blue-700 transition-colors" href="/blog/category/engineering/agentic/page/1/">Agentic 系统</a></nav><div class="flex items-center mb-6"><div class="inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal"><svg class="w-4 h-4 mr-2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2026-01-12">2026年01月12日</time></div></div><h1 class="text-4xl font-bold text-gray-900 mb-6 text-center">Planning and Reflection: 从 ReAct 到分层规划与自我纠错</h1><div class="flex flex-wrap gap-2 mb-6 justify-center"><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Agentic/page/1/">Agentic</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/AI%20Engineering/page/1/">AI Engineering</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Planning/page/1/">Planning</a></div></header><div class="max-w-5xl mx-auto"><div class="prose prose-lg prose-gray mx-auto max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:text-blue-700 prose-strong:text-gray-900 prose-strong:font-semibold prose-li:text-gray-700 prose-hr:border-gray-300"><h1>Planning and Reflection: 从 ReAct 到分层规划与自我纠错</h1>
<blockquote>
<p>LLM 的 next-token prediction 天生是&quot;短视&quot;的——它只看到当前 token 的概率分布，不会思考十步之后的结局。规划（Planning）让 Agent 具备&quot;远视&quot;能力，反思（Reflection）让 Agent 具备&quot;纠错&quot;能力。二者结合，是 Agent 从&quot;工具调用器&quot;进化为&quot;问题解决者&quot;的关键。</p>
<p>本文是 Agentic 系列的第 10 篇。我们将从规划范式的演进出发，深入分析 ReAct、Plan-and-Execute、Tree-of-Thought、Hierarchical Planning 四种规划模式，再系统探讨 Reflection 机制的设计与陷阱。</p>
</blockquote>
<hr>
<h2>1. 为什么 Agent 需要规划和反思</h2>
<p>LLM 的核心训练目标是 next-token prediction：给定前文，预测最可能的下一个 token。这种机制天然缺乏两种能力：</p>
<ul>
<li><strong>前瞻（Lookahead）</strong>：生成第一步时不会考虑&quot;这个决定在第五步会导致什么后果&quot;——每一步都选局部最优，但局部最优的叠加不等于全局最优。</li>
<li><strong>回溯（Backtrack）</strong>：一旦生成了一段文本就不会主动回头修正，即使中间步骤出了错，后续 token 也会基于错误的前提继续生成。</li>
</ul>
<p><strong>规划（Planning）</strong> 弥补前瞻缺陷——在执行前把大目标拆成子目标，考虑步骤间的依赖和顺序。<strong>反思（Reflection）</strong> 弥补回溯缺陷——在执行后检查结果、分析错误、决定重试或调整。</p>
<pre><code>没有规划的 Agent：走一步看一步（Greedy, Reactive）
有规划的 Agent：先想好路线再出发（Deliberate, Proactive）
有反思的 Agent：走错了能发现、能纠正（Self-correcting）
</code></pre>
<p>二者结合，Agent 才能从&quot;工具调用器&quot;进化为&quot;问题解决者&quot;。</p>
<hr>
<h2>2. 规划范式的演进</h2>
<pre><code>   2022              2023 early         2023 mid            2023+ now
    │                    │                  │                    │
    ▼                    ▼                  ▼                    ▼
┌────────┐      ┌──────────────┐    ┌──────────────┐   ┌────────────────┐
│No Plan │─────▶│    ReAct     │───▶│Plan-and-Exec │──▶│ Hierarchical   │
│直接回答 │      │Thought-Act-  │    │先规划再执行   │   │  Planning      │
└────────┘      │Observation   │    └──────────────┘   │ 多层级分解     │
                └──────┬───────┘                       └────────────────┘
                       │           ┌──────────────┐           ▲
                       └──────────▶│Tree-of-Thought│──────────┘
                                   │多路径搜索     │
                                   └──────────────┘

能力维度：单步回答 ──▶ 逐步推理 ──▶ 全局规划 ──▶ 多路径探索 ──▶ 递归分解
</code></pre>
<table>
<thead>
<tr>
<th>范式</th>
<th>核心思想</th>
<th>解决了什么</th>
<th>新的问题</th>
</tr>
</thead>
<tbody><tr>
<td>No Planning</td>
<td>LLM 直接回答</td>
<td>—</td>
<td>无法处理多步任务</td>
</tr>
<tr>
<td>ReAct</td>
<td>交替 Thought-Action-Observation</td>
<td>多步推理+行动</td>
<td>Greedy，缺乏全局视野</td>
</tr>
<tr>
<td>Plan-and-Execute</td>
<td>先规划再逐步执行</td>
<td>全局视野，可追踪</td>
<td>计划可能过时，修正成本高</td>
</tr>
<tr>
<td>Tree-of-Thought</td>
<td>多条路径搜索选优</td>
<td>探索多种可能性</td>
<td>成本倍增</td>
</tr>
<tr>
<td>Hierarchical</td>
<td>多层级递归分解</td>
<td>处理真正复杂的任务</td>
<td>架构复杂，调试困难</td>
</tr>
</tbody></table>
<hr>
<h2>3. ReAct 深入分析</h2>
<h3>3.1 原理：Reason + Act 交替进行</h3>
<p>ReAct（Yao et al., 2022）让 LLM 在推理（Thought）和行动（Action）之间交替，每次行动后观察结果（Observation），再基于观察继续推理。</p>
<pre><code>User Question
     │
     ▼
┌──────────┐     ┌──────────┐     ┌──────────────┐
│ Thought  │────▶│  Action  │────▶│ Observation  │
│ (推理)   │     │ (行动)   │     │ (观察结果)    │
└──────────┘     └──────────┘     └──────┬───────┘
     ▲                                    │
     └────────────────────────────────────┘
</code></pre>
<h3>3.2 ReAct Prompt 模板</h3>
<pre><code class="language-python">REACT_SYSTEM_PROMPT = &quot;&quot;&quot;You operate in a loop of Thought, Action, Observation.

- Thought: Analyze the situation and decide the next step.
- Action: Call a tool. Format: Action: tool_name({&quot;param&quot;: &quot;value&quot;})
- Observation: Review the tool&#39;s result.

When ready, respond: Final Answer: &lt;your answer&gt;

Available tools:
{tool_descriptions}

Rules:
1. Always think before acting.
2. If a tool fails, analyze why and try differently.
3. Do not fabricate information — use only tool results.
&quot;&quot;&quot;
</code></pre>
<h3>3.3 优点与缺点</h3>
<p><strong>优点</strong>：灵活自适应（每步可根据 Observation 调整）、实现简单（while 循环 + prompt）、可解释性强（Thought 暴露推理过程）、容错好（失败后下一步可换策略）。</p>
<p><strong>缺点</strong>：Greedy / 短视（不考虑长期后果）、效率低（每步完整 LLM 调用）、上下文膨胀（步骤越多 token 越多）、容易循环（重复同一失败策略）。</p>
<h3>3.4 Python 实现</h3>
<pre><code class="language-python">import json
from dataclasses import dataclass
from typing import Callable
import openai

@dataclass
class Tool:
    name: str
    description: str
    parameters: dict
    function: Callable

class ReActAgent:
    def __init__(self, model: str = &quot;gpt-4o&quot;, tools: list[Tool] | None = None,
                 max_iterations: int = 10):
        self.model = model
        self.tools = {t.name: t for t in (tools or [])}
        self.max_iterations = max_iterations
        self.client = openai.OpenAI()

    def _build_system_prompt(self) -&gt; str:
        tool_desc = &quot;\n&quot;.join(
            f&quot;- {t.name}: {t.description}&quot; for t in self.tools.values()
        )
        return REACT_SYSTEM_PROMPT.format(tool_descriptions=tool_desc)

    def _parse_action(self, text: str) -&gt; tuple[str, dict] | None:
        for line in text.split(&quot;\n&quot;):
            if line.strip().startswith(&quot;Action:&quot;):
                action_str = line.strip()[len(&quot;Action:&quot;):].strip()
                paren = action_str.find(&quot;(&quot;)
                if paren == -1:
                    return None
                name = action_str[:paren].strip()
                params_str = action_str[paren + 1:].rstrip(&quot;)&quot;)
                params = json.loads(params_str) if params_str else {}
                return name, params
        return None

    def _execute_tool(self, name: str, params: dict) -&gt; str:
        if name not in self.tools:
            return f&quot;Error: Unknown tool &#39;{name}&#39;&quot;
        try:
            return str(self.tools[name].function(**params))
        except Exception as e:
            return f&quot;Error: {e}&quot;

    def run(self, query: str) -&gt; str:
        messages = [
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: self._build_system_prompt()},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: query},
        ]
        for _ in range(self.max_iterations):
            resp = self.client.chat.completions.create(
                model=self.model, messages=messages, temperature=0.0,
            )
            text = resp.choices[0].message.content
            messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: text})

            if &quot;Final Answer:&quot; in text:
                return text.split(&quot;Final Answer:&quot;)[-1].strip()

            action = self._parse_action(text)
            if action is None:
                messages.append({&quot;role&quot;: &quot;user&quot;,
                                 &quot;content&quot;: &quot;Provide a valid Action or Final Answer.&quot;})
                continue

            observation = self._execute_tool(*action)
            messages.append({&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: f&quot;Observation: {observation}&quot;})

        return &quot;Reached max iterations without final answer.&quot;
</code></pre>
<p>注意：随着迭代增加 <code>messages</code> 不断膨胀，token 消耗呈线性增长。超过 5-6 步的任务需要考虑上下文压缩（如摘要历史步骤）。</p>
<hr>
<h2>4. Plan-and-Execute 模式</h2>
<h3>4.1 原理：先规划再执行</h3>
<p>Plan-and-Execute 将规划与执行分离：先用一次 LLM 调用生成完整计划，再逐个执行子任务，必要时触发 Replanning。</p>
<pre><code>┌────────────┐       Plan: [S1, S2, S3]      ┌────────────┐
│  Planner   │──────────────────────────────▶│  Executor  │
│ (全局规划)  │                                │ (逐步执行)  │
└────────────┘                                └─────┬──────┘
      ▲                                             │ 执行失败
      │            ┌─────────────┐                  │
      └────────────│  Replanner  │◀─────────────────┘
                   │ (动态修正)   │
                   └─────────────┘
</code></pre>
<h3>4.2 Planner / Executor 分离的优势</h3>
<ol>
<li><strong>关注点分离</strong>：Planner 负责&quot;做什么&quot;，Executor 负责&quot;怎么做&quot;，可以分别用不同模型优化</li>
<li><strong>可并行</strong>：无依赖的步骤可以并行执行</li>
<li><strong>可追踪</strong>：计划本身是结构化数据，便于监控和审计</li>
<li><strong>可中断恢复</strong>：执行到一半中断后可从某一步重启</li>
</ol>
<h3>4.3 计划的动态修正</h3>
<p>三种 Replan 策略：<strong>完全重新规划</strong>（全局优化但可能丢弃已有成果）、<strong>局部修正</strong>（成本低但可能保留错误前提）、<strong>条件触发</strong>（仅在步骤失败或偏差超阈值时 Replan）。生产中通常用条件触发 + 局部修正的组合。</p>
<h3>4.4 Python 实现</h3>
<pre><code class="language-python">from dataclasses import dataclass, field

@dataclass
class PlanStep:
    id: int
    description: str
    tool: str | None = None
    depends_on: list[int] = field(default_factory=list)
    status: str = &quot;pending&quot;   # pending / completed / failed
    result: str | None = None

PLANNER_PROMPT = &quot;&quot;&quot;Decompose the goal into concrete steps (max 7).
Available tools: {tool_names}
Output JSON: {{&quot;goal&quot;: &quot;...&quot;, &quot;steps&quot;: [{{&quot;id&quot;: 1, &quot;description&quot;: &quot;...&quot;,
&quot;tool&quot;: &quot;tool_name or null&quot;, &quot;depends_on&quot;: []}}]}}&quot;&quot;&quot;

class PlanAndExecuteAgent:
    def __init__(self, tools: dict[str, Tool],
                 planner_model: str = &quot;gpt-4o&quot;,
                 executor_model: str = &quot;gpt-4o-mini&quot;,
                 max_replans: int = 3):
        self.tools = tools
        self.planner_model = planner_model
        self.executor_model = executor_model
        self.max_replans = max_replans
        self.client = openai.OpenAI()

    def _create_plan(self, goal: str) -&gt; list[PlanStep]:
        resp = self.client.chat.completions.create(
            model=self.planner_model,
            messages=[
                {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: PLANNER_PROMPT.format(
                    tool_names=&quot;, &quot;.join(self.tools.keys()))},
                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: goal},
            ],
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        data = json.loads(resp.choices[0].message.content)
        return [PlanStep(**s) for s in data[&quot;steps&quot;]]

    def _execute_step(self, step: PlanStep, context: dict) -&gt; str:
        if step.tool and step.tool in self.tools:
            param_resp = self.client.chat.completions.create(
                model=self.executor_model,
                messages=[{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;:
                    f&quot;Call tool &#39;{step.tool}&#39; for: {step.description}\n&quot;
                    f&quot;Context: {json.dumps(context)}\nReturn JSON params only.&quot;}],
                response_format={&quot;type&quot;: &quot;json_object&quot;},
            )
            params = json.loads(param_resp.choices[0].message.content)
            return str(self.tools[step.tool].function(**params))
        resp = self.client.chat.completions.create(
            model=self.executor_model,
            messages=[{&quot;role&quot;: &quot;user&quot;,
                       &quot;content&quot;: f&quot;Task: {step.description}\nContext: {json.dumps(context)}&quot;}],
        )
        return resp.choices[0].message.content

    def run(self, goal: str) -&gt; str:
        steps = self._create_plan(goal)
        context = {}
        for replan in range(self.max_replans + 1):
            for step in steps:
                if step.status == &quot;completed&quot;:
                    continue
                deps_met = all(
                    any(s.id == d and s.status == &quot;completed&quot; for s in steps)
                    for d in step.depends_on
                )
                if not deps_met:
                    continue
                try:
                    step.result = self._execute_step(step, context)
                    step.status = &quot;completed&quot;
                    context[f&quot;step_{step.id}&quot;] = step.result
                except Exception as e:
                    step.status = &quot;failed&quot;
                    step.result = str(e)
                    steps = self._replan(goal, steps, step)
                    break
            if all(s.status == &quot;completed&quot; for s in steps):
                return self._synthesize(goal, context)
        return &quot;Exceeded max replans.&quot;

    def _replan(self, goal, steps, failed) -&gt; list[PlanStep]:
        # 将已完成步骤 + 失败信息交给 Planner 重新规划
        completed = [{&quot;id&quot;: s.id, &quot;result&quot;: s.result}
                     for s in steps if s.status == &quot;completed&quot;]
        resp = self.client.chat.completions.create(
            model=self.planner_model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;:
                f&quot;Replan. Goal: {goal}\nCompleted: {json.dumps(completed)}\n&quot;
                f&quot;Failed step: {failed.description} -&gt; {failed.result}&quot;}],
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        data = json.loads(resp.choices[0].message.content)
        return [PlanStep(**s) for s in data[&quot;steps&quot;]]

    def _synthesize(self, goal, context):
        resp = self.client.chat.completions.create(
            model=self.planner_model,
            messages=[{&quot;role&quot;: &quot;user&quot;,
                       &quot;content&quot;: f&quot;Goal: {goal}\nResults: {json.dumps(context)}\n&quot;
                       &quot;Synthesize a final answer.&quot;}],
        )
        return resp.choices[0].message.content
</code></pre>
<p>Planner 用 <code>gpt-4o</code>（强规划），Executor 用 <code>gpt-4o-mini</code>（快执行）——这是生产中常见的成本优化手段。</p>
<hr>
<h2>5. Tree-of-Thought</h2>
<h3>5.1 原理</h3>
<p>Tree-of-Thought（ToT，Yao et al. 2023）模拟人类&quot;深思熟虑&quot;：同时考虑多条推理路径，评估每条的前景，选择最优的继续深入。</p>
<pre><code>                       Root (问题)
                      /     |     \
                   Th1     Th2    Th3      ← 生成多个候选 Thought
                  /   \     |    /   \
               T1a   T1b  T2a  T3a  T3b   ← 继续展开
                ✗      ✓    ✗    ✓    ✗    ← 评估函数打分，剪枝
</code></pre>
<p>三个核心组件：<strong>Thought Generator</strong>（每步生成 k 个候选）、<strong>State Evaluator</strong>（对候选打分）、<strong>Search Algorithm</strong>（BFS 或 DFS）。</p>
<h3>5.2 BFS vs DFS</h3>
<ul>
<li><strong>BFS</strong>：每层展开 k 个，评估后保留 top-k 进入下一层。适合步骤少、每步选择多的问题。总调用 ≈ k x depth x 2（生成+评估）。</li>
<li><strong>DFS</strong>：选当前最优一路深入，死胡同时回溯。适合步骤多、每步选择少的问题。最好 O(depth)，最坏 O(k^depth)。</li>
</ul>
<h3>5.3 评估函数设计</h3>
<ol>
<li><strong>LLM 自评</strong>：让 LLM 对每个 Thought 打分。简单但可能有系统性偏见。</li>
<li><strong>投票法</strong>：多次评估取多数。更稳健但成本更高。</li>
<li><strong>外部验证</strong>：可验证的问题（数学/代码）用外部工具检查。最可靠但适用范围有限。</li>
</ol>
<h3>5.4 Trade-off：质量 vs 成本</h3>
<pre><code>方法           LLM 调用次数      质量    适用场景
─────────────  ──────────────   ─────   ──────────
ReAct(单路径)   O(steps)         基准    大多数任务
ToT-BFS        O(k * d * 2)     高      创意/数学/方案选型
ToT-DFS        O(k^d) 最坏      中-高   深度推理
</code></pre>
<p>k=3, d=3 时 ToT 可能需要 40+ 次 LLM 调用，ReAct 只需 5-6 次——<strong>8-10 倍成本差距</strong>。只有当正确性要求高且存在多条有意义的推理路径时，ToT 的投入才有回报。</p>
<h3>5.5 Python 实现</h3>
<pre><code class="language-python">import json
from dataclasses import dataclass, field
import openai

@dataclass
class ThoughtNode:
    &quot;&quot;&quot;搜索树中的节点，每个节点代表一条推理路径的当前状态&quot;&quot;&quot;
    state: str                           # 当前推理状态（累积的 thought 文本）
    score: float = 0.0                   # 评估函数打分
    depth: int = 0
    children: list[&quot;ThoughtNode&quot;] = field(default_factory=list)

class TreeOfThought:
    def __init__(self, model: str = &quot;gpt-4o&quot;, k: int = 3, max_depth: int = 3):
        &quot;&quot;&quot;
        k: 每层生成的候选 thought 数量（BFS 宽度）
        max_depth: 搜索树最大深度
        &quot;&quot;&quot;
        self.model = model
        self.k = k
        self.max_depth = max_depth
        self.client = openai.OpenAI()

    def generate_thoughts(self, problem: str, current_state: str) -&gt; list[str]:
        &quot;&quot;&quot;生成 k 个候选 thought&quot;&quot;&quot;
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;:
                f&quot;Given the problem and current reasoning state, &quot;
                f&quot;generate exactly {self.k} distinct next-step thoughts.\n&quot;
                f&#39;Return JSON: {{&quot;thoughts&quot;: [&quot;thought1&quot;, &quot;thought2&quot;, ...]}}&#39;},
                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;:
                f&quot;Problem: {problem}\nCurrent state: {current_state or &#39;(start)&#39;}&quot;}],
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        data = json.loads(resp.choices[0].message.content)
        return data[&quot;thoughts&quot;][:self.k]

    def evaluate_thought(self, problem: str, state: str) -&gt; float:
        &quot;&quot;&quot;评估当前推理状态的前景，返回 0-1 分数&quot;&quot;&quot;
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;:
                &quot;Evaluate how promising this reasoning state is for solving the problem.\n&quot;
                &#39;Return JSON: {&quot;score&quot;: 0.0-1.0, &quot;reason&quot;: &quot;...&quot;}&#39;},
                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;:
                f&quot;Problem: {problem}\nReasoning so far: {state}&quot;}],
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        data = json.loads(resp.choices[0].message.content)
        return float(data[&quot;score&quot;])

    def solve(self, problem: str) -&gt; str:
        &quot;&quot;&quot;BFS 搜索：每层生成 k 个候选，评估后保留 top-k 进入下一层&quot;&quot;&quot;
        # 初始化：根节点
        current_level = [ThoughtNode(state=&quot;&quot;, depth=0)]

        for depth in range(self.max_depth):
            candidates: list[ThoughtNode] = []

            for node in current_level:
                # 为每个节点生成 k 个候选 thought
                thoughts = self.generate_thoughts(problem, node.state)
                for thought in thoughts:
                    new_state = f&quot;{node.state}\nStep {depth+1}: {thought}&quot;.strip()
                    score = self.evaluate_thought(problem, new_state)
                    child = ThoughtNode(state=new_state, score=score, depth=depth+1)
                    node.children.append(child)
                    candidates.append(child)

            # 保留 top-k 进入下一层（BFS 剪枝）
            candidates.sort(key=lambda n: n.score, reverse=True)
            current_level = candidates[:self.k]

        # 返回最终得分最高的推理路径
        best = max(current_level, key=lambda n: n.score)
        return best.state
</code></pre>
<p>核心观察：BFS 宽度 <code>k</code> 和搜索深度 <code>max_depth</code> 共同控制质量-成本的 trade-off。<code>k</code> 越大，每层探索的候选越多，找到好路径的概率越高，但 LLM 调用次数以 O(k² × d) 增长（每层 k 个节点各生成 k 个候选 + k 次评估）。实践中 k=2<del>3、depth=2</del>3 是较好的起点，可根据任务复杂度动态调整。</p>
<hr>
<h2>6. 分层规划（Hierarchical Planning）</h2>
<p>当任务复杂到&quot;设计并实现用户权限系统&quot;这种级别时，一层计划无法覆盖从架构到实现的所有粒度。分层规划通过<strong>递归分解</strong>解决：高层拆子目标，低层拆具体动作。</p>
<pre><code>高层规划器 (Strategic)
├─ 子目标1: 设计数据模型
│   └─ 低层规划器 (Tactical)
│       ├─ Action: 分析需求
│       ├─ Action: 设计 ER 图
│       └─ Action: 定义 API Schema
├─ 子目标2: 实现认证模块
│   └─ 低层规划器
│       ├─ Action: 实现 JWT 签发
│       └─ Action: 编写测试
└─ 子目标3: 实现授权模块
    └─ 低层规划器
        ├─ Action: 实现 RBAC
        └─ Action: 集成测试
</code></pre>
<h3>6.1 递归分解的终止条件</h3>
<ol>
<li><strong>原子性</strong>：任务可用单次工具调用完成 → 停止分解</li>
<li><strong>深度限制</strong>：最大 2-3 层，防止过度分解</li>
<li><strong>预算约束</strong>：剩余 token 预算不足以继续分解 → 当前粒度直接执行</li>
</ol>
<pre><code class="language-python">class HierarchicalPlanner:
    def __init__(self, client: openai.OpenAI, model=&quot;gpt-4o&quot;, max_depth=3):
        self.client, self.model, self.max_depth = client, model, max_depth

    def decompose(self, goal: str, depth: int = 0) -&gt; dict:
        if depth &gt;= self.max_depth:
            return {&quot;type&quot;: &quot;action&quot;, &quot;description&quot;: goal}

        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;:
                &quot;Decide if this goal is atomic or compound.\n&quot;
                &#39;Atomic: {&quot;type&quot;:&quot;action&quot;,&quot;description&quot;:&quot;...&quot;}\n&#39;
                &#39;Compound: {&quot;type&quot;:&quot;goal&quot;,&quot;description&quot;:&quot;...&quot;,&quot;subgoals&quot;:[&quot;...&quot;,]}&#39;},
                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: goal}],
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        node = json.loads(resp.choices[0].message.content)
        if node[&quot;type&quot;] == &quot;action&quot;:
            return node
        node[&quot;children&quot;] = [self.decompose(sg, depth+1) for sg in node.get(&quot;subgoals&quot;,[])]
        return node
</code></pre>
<p>实践中 2 层（Strategic + Tactical）通常够用。3 层以上的调试成本会快速失控。</p>
<h3>6.2 执行层：递归执行分解后的计划</h3>
<p><code>HierarchicalPlanner</code> 只负责分解，执行需要单独的 Executor。核心逻辑：叶节点（type=&quot;action&quot;）直接调用 LLM 或工具执行，分支节点（type=&quot;goal&quot;）递归执行所有子节点并聚合结果。</p>
<pre><code class="language-python">@dataclass
class ExecutionResult:
    description: str
    output: str
    success: bool
    children: list[&quot;ExecutionResult&quot;] = field(default_factory=list)

class HierarchicalExecutor:
    def __init__(self, client: openai.OpenAI, model: str = &quot;gpt-4o-mini&quot;,
                 tools: dict[str, Callable] | None = None):
        self.client = client
        self.model = model
        self.tools = tools or {}

    def execute(self, node: dict) -&gt; ExecutionResult:
        &quot;&quot;&quot;递归执行分解后的计划树&quot;&quot;&quot;
        desc = node.get(&quot;description&quot;, &quot;&quot;)

        # 叶节点：直接执行
        if node[&quot;type&quot;] == &quot;action&quot;:
            output = self._execute_action(desc)
            return ExecutionResult(description=desc, output=output, success=True)

        # 分支节点：递归执行所有子节点
        child_results = [self.execute(child) for child in node.get(&quot;children&quot;, [])]
        all_success = all(r.success for r in child_results)

        # 聚合子节点结果
        summary = self._aggregate(desc, child_results)
        return ExecutionResult(
            description=desc, output=summary,
            success=all_success, children=child_results,
        )

    def _execute_action(self, action: str) -&gt; str:
        &quot;&quot;&quot;执行单个原子动作——优先使用工具，否则 fallback 到 LLM&quot;&quot;&quot;
        for tool_name, tool_fn in self.tools.items():
            if tool_name.lower() in action.lower():
                return str(tool_fn(action))
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: f&quot;Execute this task: {action}&quot;}],
        )
        return resp.choices[0].message.content

    def _aggregate(self, goal: str, results: list[ExecutionResult]) -&gt; str:
        &quot;&quot;&quot;将子节点执行结果聚合为父目标的总结&quot;&quot;&quot;
        parts = &quot;\n&quot;.join(f&quot;- {r.description}: {r.output[:200]}&quot; for r in results)
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;:
                f&quot;Goal: {goal}\nSub-results:\n{parts}\nSummarize the overall outcome.&quot;}],
        )
        return resp.choices[0].message.content
</code></pre>
<p>分解与执行分离的好处：<code>HierarchicalPlanner</code> 可以用强模型（gpt-4o）做规划，<code>HierarchicalExecutor</code> 用快模型（gpt-4o-mini）做执行，兼顾规划质量和执行成本。同时，执行层可以独立替换——例如将 <code>_execute_action</code> 改为调用真实 API 或 Code Interpreter，而不影响规划逻辑。</p>
<hr>
<h2>7. Reflection（反思）机制</h2>
<h3>7.1 为什么需要反思</h3>
<p>Agent 有三类常见失败：LLM 输出错误（幻觉/逻辑错误）、工具执行失败（超时/参数错误）、计划不可行（前提假设不成立）。没有反思，错误会<strong>无意识地传播</strong>——第 2 步的错成为第 3 步的输入，错误不断累积。</p>
<h3>7.2 Self-Critique</h3>
<p>用同一个 LLM 评估自己的输出。理论支持：LLM 在<strong>验证</strong>上通常比<strong>生成</strong>更强（就像检查别人的代码比自己写更容易）。但盲区在于：LLM 的系统性偏见在生成和评估中是一致的。</p>
<h3>7.3 结构化反思</h3>
<pre><code class="language-python">@dataclass
class ReflectionResult:
    what_went_well: list[str]
    what_went_wrong: list[str]
    root_cause: str
    what_to_do_next: str
    should_retry: bool
    confidence: float  # 0-1

REFLECTION_PROMPT = &quot;&quot;&quot;Analyze this execution result.
Goal: {goal} | Steps: {steps} | Result: {result}
Return JSON: {{&quot;what_went_well&quot;:[], &quot;what_went_wrong&quot;:[], &quot;root_cause&quot;:&quot;&quot;,
&quot;what_to_do_next&quot;:&quot;&quot;, &quot;should_retry&quot;: bool, &quot;confidence&quot;: 0.0-1.0}}&quot;&quot;&quot;
</code></pre>
<h3>7.4 Retry Budget 与 Stop Condition</h3>
<p>反思不能无限循环。必须有 Stop Condition：</p>
<pre><code>                  反思完成
                     │
          ┌──────────▼──────────┐   是
          │ 质量 &gt;= 阈值？       │─────▶ 返回结果
          └──────────┬──────────┘
                     │ 否
          ┌──────────▼──────────┐   是
          │ 达到最大重试？       │─────▶ 返回最好的结果
          └──────────┬──────────┘
                     │ 否
          ┌──────────▼──────────┐   是
          │ 改进幅度 &lt; 阈值？    │─────▶ 停止（再试也没用）
          └──────────┬──────────┘
                     │ 否
          ┌──────────▼──────────┐   是
          │ 成本超出预算？       │─────▶ 返回当前结果
          └──────────┬──────────┘
                     │ 否
                  继续重试
</code></pre>
<p>四个条件形成<strong>多层安全网</strong>：质量达标是正常退出，最大重试和成本预算是硬性保底，改进幅度检测是&quot;聪明的&quot;提前退出。</p>
<h3>7.5 代码实现</h3>
<pre><code class="language-python">@dataclass
class ReflectionPolicy:
    max_retries: int = 3
    quality_threshold: float = 0.7
    improvement_threshold: float = 0.1
    cost_limit_tokens: int = 10000

class ReflectiveAgent:
    def __init__(self, base_agent: ReActAgent, policy: ReflectionPolicy,
                 model: str = &quot;gpt-4o-mini&quot;):
        self.base_agent = base_agent
        self.policy = policy
        self.model = model
        self.client = openai.OpenAI()

    def _reflect(self, goal, steps, result) -&gt; ReflectionResult:
        resp = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: REFLECTION_PROMPT.format(
                goal=goal, steps=json.dumps(steps), result=result)}],
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        return ReflectionResult(**json.loads(resp.choices[0].message.content))

    def run(self, goal: str) -&gt; str:
        best_result, best_score = None, 0.0
        history = []

        for attempt in range(self.policy.max_retries + 1):
            # 执行（重试时注入反思结论）
            if attempt == 0:
                result = self.base_agent.run(goal)
            else:
                enhanced = (f&quot;{goal}\n\nPrevious issues: {reflection.what_went_wrong}&quot;
                           f&quot;\nRoot cause: {reflection.root_cause}&quot;
                           f&quot;\nSuggestion: {reflection.what_to_do_next}&quot;)
                result = self.base_agent.run(enhanced)

            reflection = self._reflect(goal, history, result)

            # Stop conditions
            if reflection.confidence &gt;= self.policy.quality_threshold:
                best_result, best_score = result, reflection.confidence
                break
            if not reflection.should_retry:
                break
            if attempt &gt; 0 and (reflection.confidence - best_score) &lt; self.policy.improvement_threshold:
                break  # 改进幅度不足，再试也没用

            # 更新最优结果（放在 stop condition 之后，避免 improvement 检查失效）
            if reflection.confidence &gt; best_score:
                best_result, best_score = result, reflection.confidence

            history.append({&quot;attempt&quot;: attempt, &quot;issues&quot;: reflection.what_went_wrong})

        return best_result or result
</code></pre>
<hr>
<h2>8. Reflection 的陷阱</h2>
<h3>8.1 无限循环</h3>
<p>Agent 不断反思但不改进——反思发现了问题却没有提供有效的改进方向。解法：<code>improvement_threshold</code> 检测，连续两轮质量差距 &lt; 0.1 直接停止。</p>
<h3>8.2 过度反思</h3>
<p>简单任务（&quot;今天天气怎么样&quot;）也要三轮反思，浪费 3-4 倍 token。解法：引入复杂度判断，简单任务跳过反思。</p>
<pre><code class="language-python">def needs_reflection(task: str, result: str) -&gt; bool:
    &quot;&quot;&quot;简单任务不值得反思&quot;&quot;&quot;
    if len(result) &lt; 100:  # 结果很短 → 可能是简单查询
        return False
    simple_patterns = [&quot;什么是&quot;, &quot;查一下&quot;, &quot;告诉我&quot;]
    return not any(p in task for p in simple_patterns)
</code></pre>
<h3>8.3 成本爆炸</h3>
<p>每次反思是完整 LLM 调用，包含完整上下文。对策：(1) 反思用小模型（GPT-4o-mini）；(2) 压缩上下文传摘要版本；(3) 采样反思（30% 的执行触发反思而非 100%）。</p>
<h3>8.4 合理的 Reflection 策略</h3>
<pre><code>Q1: 任务的错误成本高吗？
  高 → 启用反思    低 → 跳过

Q2: 错误可自动检测吗？
  是（代码可测试） → 外部验证（更可靠更便宜）
  否（文案质量）   → LLM Self-Critique

Q3: 预算够吗？
  够   → 结构化反思 + 多轮重试
  不够 → 单轮 Self-Critique

Q4: 延迟敏感吗？
  是 → 最多一轮，超时直接返回
  否 → 多轮直到质量达标
</code></pre>
<hr>
<h2>9. 规划模式选型指南</h2>
<table>
<thead>
<tr>
<th>场景</th>
<th>推荐模式</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>简单工具调用（查天气、算术）</td>
<td><strong>ReAct</strong></td>
<td>1-2 步完成，规划是过度设计</td>
</tr>
<tr>
<td>多步研究（竞品分析、技术调研）</td>
<td><strong>Plan-and-Execute</strong></td>
<td>需要全局视野和步骤追踪</td>
</tr>
<tr>
<td>创意/数学/代码</td>
<td><strong>Tree-of-Thought</strong></td>
<td>需探索多条路径并选最优</td>
</tr>
<tr>
<td>复杂项目（系统设计）</td>
<td><strong>Hierarchical</strong></td>
<td>粒度跨度大，需递归分解</td>
</tr>
<tr>
<td>高可靠（金融/法律）</td>
<td><strong>Plan-and-Execute + Reflection</strong></td>
<td>全局规划 + 结果验证</td>
</tr>
<tr>
<td>实时交互（客服/对话）</td>
<td><strong>ReAct</strong></td>
<td>延迟敏感，逐步响应</td>
</tr>
<tr>
<td>长时任务（数据管道）</td>
<td><strong>Hierarchical + Plan-Exec</strong></td>
<td>可中断、可恢复、可并行</td>
</tr>
</tbody></table>
<p><strong>二维决策矩阵：</strong></p>
<pre><code>                  任务步骤少            任务步骤多
             ┌──────────────────┬──────────────────┐
 确定性高    │  ReAct            │  Plan-and-Exec   │
 (路径清晰)  │ (甚至不需要Agent)  │                  │
             ├──────────────────┼──────────────────┤
 确定性低    │  Tree-of-Thought  │  Hierarchical    │
 (需要探索)  │                   │  + Reflection    │
             └──────────────────┴──────────────────┘
</code></pre>
<p><strong>模式组合</strong>在生产中很常见：Hierarchical + Plan-and-Execute（高层分解子目标，内部用 Plan-Exec 执行）；ReAct + Reflection（逐步执行，每 N 步检查方向）。关键原则：<strong>从 ReAct 开始，只有当它的局限性确实成为瓶颈时再升级。</strong></p>
<hr>
<h2>10. 结语：规划的边界与 Multi-Agent 的必要性</h2>
<p>规划和反思让单个 Agent 从&quot;走一步看一步&quot;进化到&quot;先想后做再检查&quot;。但单 Agent 的规划能力终有上限：</p>
<ul>
<li><strong>上下文窗口限制</strong>：任务涉及的知识和状态超出 context window 时，单 Agent 力不从心</li>
<li><strong>专业性限制</strong>：一个 Agent 很难同时擅长编码、写作和数据分析——就像一个人很难同时是程序员、设计师和产品经理</li>
<li><strong>执行效率限制</strong>：单 Agent 串行执行，即使计划中的步骤可以并行</li>
</ul>
<p>当这些限制成为瓶颈，你需要的不是更好的规划算法，而是<strong>多个 Agent 的协作</strong>——每个 Agent 专注于擅长领域，由 Orchestrator 协调。这正是下一篇的主题：<strong>Multi-Agent Collaboration: 多 Agent 协作模式与架构。</strong></p>
<hr>
<blockquote>
<p><strong>进一步思考：</strong></p>
<ol>
<li>规划质量高度依赖 LLM 对任务域的理解。如果 LLM 从未见过某类任务，能否通过 few-shot examples 注入领域知识来提升规划质量？</li>
<li>&quot;LLM 评估 LLM&quot; 的反思机制在多大程度上可靠？是否能引入外部验证信号（代码测试、人类反馈）来补强？</li>
<li>Tree-of-Thought 的搜索空间是指数级的。能否借鉴 AlphaGo 的 MCTS 来更高效搜索？Reasoning model（如 o1、o3）是否已在内部做了类似的事情？</li>
<li>规划和反思的 token 成本显著。能否缓存和复用已有的计划，为相似任务跳过规划阶段？</li>
</ol>
</blockquote>
<hr>
<blockquote>
<p><strong>系列导航</strong>：本文是 Agentic 系列的第 10 篇。</p>
<ul>
<li>上一篇：<a href="/blog/engineering/agentic/09-RAG%20as%20Cognitive%20Memory">09 | RAG as Cognitive Memory</a></li>
<li>下一篇：<a href="/blog/engineering/agentic/11-Multi-Agent%20Collaboration">11 | Multi-Agent Collaboration</a></li>
<li>完整目录：<a href="/blog/engineering/agentic/01-From%20LLM%20to%20Agent">01 | From LLM to Agent</a></li>
</ul>
</blockquote>
</div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="mt-12 pt-8 border-t border-gray-200">加载导航中...</div><!--/$--><div class="mt-16 border-t border-gray-200 pt-8"><div class="mx-auto max-w-3xl"><h3 class="text-2xl font-bold text-gray-900 mb-8">评论</h3></div></div></div></div></article><!--$--><!--/$--></main><footer class="bg-[var(--background)]"><div class="mx-auto max-w-7xl px-6 py-12 lg:px-8"><p class="text-center text-xs leading-5 text-gray-400">© <!-- -->2026<!-- --> Skyfalling</p></div></footer></div><script src="/_next/static/chunks/webpack-42d55485b4428e47.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[10616,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"7177\",\"static/chunks/app/layout-142e67ac4336647c.js\"],\"default\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n6:I[59665,[],\"OutletBoundary\"]\n9:I[74911,[],\"AsyncMetadataOutlet\"]\nb:I[59665,[],\"ViewportBoundary\"]\nd:I[59665,[],\"MetadataBoundary\"]\nf:I[26614,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/ab9f9bc568942ddd.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"CEV2RmJ4qYe381pMG-_gT\",\"p\":\"\",\"c\":[\"\",\"blog\",\"engineering\",\"agentic\",\"10-Planning%20and%20Reflection\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"engineering/agentic/10-Planning%20and%20Reflection\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/ab9f9bc568942ddd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-[var(--background)]\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-6 py-12 lg:px-8\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs leading-5 text-gray-400\",\"children\":[\"© \",2026,\" Skyfalling\"]}]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"engineering/agentic/10-Planning%20and%20Reflection\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",null,[\"$\",\"$L6\",null,{\"children\":[\"$L7\",\"$L8\",[\"$\",\"$L9\",null,{\"promise\":\"$@a\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"rRzbGeCYZapQl31gsxQX_v\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:\"$Sreact.suspense\"\n11:I[74911,[],\"AsyncMetadata\"]\n13:I[6874,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"\"]\n14:I[32923,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n16:I[40780,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n1a:I[85300,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\ne:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]}]}]\n15:T9ed3,"])</script><script>self.__next_f.push([1,"\u003ch1\u003ePlanning and Reflection: 从 ReAct 到分层规划与自我纠错\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLLM 的 next-token prediction 天生是\u0026quot;短视\u0026quot;的——它只看到当前 token 的概率分布，不会思考十步之后的结局。规划（Planning）让 Agent 具备\u0026quot;远视\u0026quot;能力，反思（Reflection）让 Agent 具备\u0026quot;纠错\u0026quot;能力。二者结合，是 Agent 从\u0026quot;工具调用器\u0026quot;进化为\u0026quot;问题解决者\u0026quot;的关键。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列的第 10 篇。我们将从规划范式的演进出发，深入分析 ReAct、Plan-and-Execute、Tree-of-Thought、Hierarchical Planning 四种规划模式，再系统探讨 Reflection 机制的设计与陷阱。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么 Agent 需要规划和反思\u003c/h2\u003e\n\u003cp\u003eLLM 的核心训练目标是 next-token prediction：给定前文，预测最可能的下一个 token。这种机制天然缺乏两种能力：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e前瞻（Lookahead）\u003c/strong\u003e：生成第一步时不会考虑\u0026quot;这个决定在第五步会导致什么后果\u0026quot;——每一步都选局部最优，但局部最优的叠加不等于全局最优。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e回溯（Backtrack）\u003c/strong\u003e：一旦生成了一段文本就不会主动回头修正，即使中间步骤出了错，后续 token 也会基于错误的前提继续生成。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e规划（Planning）\u003c/strong\u003e 弥补前瞻缺陷——在执行前把大目标拆成子目标，考虑步骤间的依赖和顺序。\u003cstrong\u003e反思（Reflection）\u003c/strong\u003e 弥补回溯缺陷——在执行后检查结果、分析错误、决定重试或调整。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e没有规划的 Agent：走一步看一步（Greedy, Reactive）\n有规划的 Agent：先想好路线再出发（Deliberate, Proactive）\n有反思的 Agent：走错了能发现、能纠正（Self-correcting）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e二者结合，Agent 才能从\u0026quot;工具调用器\u0026quot;进化为\u0026quot;问题解决者\u0026quot;。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 规划范式的演进\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e   2022              2023 early         2023 mid            2023+ now\n    │                    │                  │                    │\n    ▼                    ▼                  ▼                    ▼\n┌────────┐      ┌──────────────┐    ┌──────────────┐   ┌────────────────┐\n│No Plan │─────▶│    ReAct     │───▶│Plan-and-Exec │──▶│ Hierarchical   │\n│直接回答 │      │Thought-Act-  │    │先规划再执行   │   │  Planning      │\n└────────┘      │Observation   │    └──────────────┘   │ 多层级分解     │\n                └──────┬───────┘                       └────────────────┘\n                       │           ┌──────────────┐           ▲\n                       └──────────▶│Tree-of-Thought│──────────┘\n                                   │多路径搜索     │\n                                   └──────────────┘\n\n能力维度：单步回答 ──▶ 逐步推理 ──▶ 全局规划 ──▶ 多路径探索 ──▶ 递归分解\n\u003c/code\u003e\u003c/pre\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e范式\u003c/th\u003e\n\u003cth\u003e核心思想\u003c/th\u003e\n\u003cth\u003e解决了什么\u003c/th\u003e\n\u003cth\u003e新的问题\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eNo Planning\u003c/td\u003e\n\u003ctd\u003eLLM 直接回答\u003c/td\u003e\n\u003ctd\u003e—\u003c/td\u003e\n\u003ctd\u003e无法处理多步任务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eReAct\u003c/td\u003e\n\u003ctd\u003e交替 Thought-Action-Observation\u003c/td\u003e\n\u003ctd\u003e多步推理+行动\u003c/td\u003e\n\u003ctd\u003eGreedy，缺乏全局视野\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePlan-and-Execute\u003c/td\u003e\n\u003ctd\u003e先规划再逐步执行\u003c/td\u003e\n\u003ctd\u003e全局视野，可追踪\u003c/td\u003e\n\u003ctd\u003e计划可能过时，修正成本高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTree-of-Thought\u003c/td\u003e\n\u003ctd\u003e多条路径搜索选优\u003c/td\u003e\n\u003ctd\u003e探索多种可能性\u003c/td\u003e\n\u003ctd\u003e成本倍增\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHierarchical\u003c/td\u003e\n\u003ctd\u003e多层级递归分解\u003c/td\u003e\n\u003ctd\u003e处理真正复杂的任务\u003c/td\u003e\n\u003ctd\u003e架构复杂，调试困难\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e3. ReAct 深入分析\u003c/h2\u003e\n\u003ch3\u003e3.1 原理：Reason + Act 交替进行\u003c/h3\u003e\n\u003cp\u003eReAct（Yao et al., 2022）让 LLM 在推理（Thought）和行动（Action）之间交替，每次行动后观察结果（Observation），再基于观察继续推理。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eUser Question\n     │\n     ▼\n┌──────────┐     ┌──────────┐     ┌──────────────┐\n│ Thought  │────▶│  Action  │────▶│ Observation  │\n│ (推理)   │     │ (行动)   │     │ (观察结果)    │\n└──────────┘     └──────────┘     └──────┬───────┘\n     ▲                                    │\n     └────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.2 ReAct Prompt 模板\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eREACT_SYSTEM_PROMPT = \u0026quot;\u0026quot;\u0026quot;You operate in a loop of Thought, Action, Observation.\n\n- Thought: Analyze the situation and decide the next step.\n- Action: Call a tool. Format: Action: tool_name({\u0026quot;param\u0026quot;: \u0026quot;value\u0026quot;})\n- Observation: Review the tool\u0026#39;s result.\n\nWhen ready, respond: Final Answer: \u0026lt;your answer\u0026gt;\n\nAvailable tools:\n{tool_descriptions}\n\nRules:\n1. Always think before acting.\n2. If a tool fails, analyze why and try differently.\n3. Do not fabricate information — use only tool results.\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.3 优点与缺点\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：灵活自适应（每步可根据 Observation 调整）、实现简单（while 循环 + prompt）、可解释性强（Thought 暴露推理过程）、容错好（失败后下一步可换策略）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：Greedy / 短视（不考虑长期后果）、效率低（每步完整 LLM 调用）、上下文膨胀（步骤越多 token 越多）、容易循环（重复同一失败策略）。\u003c/p\u003e\n\u003ch3\u003e3.4 Python 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nfrom dataclasses import dataclass\nfrom typing import Callable\nimport openai\n\n@dataclass\nclass Tool:\n    name: str\n    description: str\n    parameters: dict\n    function: Callable\n\nclass ReActAgent:\n    def __init__(self, model: str = \u0026quot;gpt-4o\u0026quot;, tools: list[Tool] | None = None,\n                 max_iterations: int = 10):\n        self.model = model\n        self.tools = {t.name: t for t in (tools or [])}\n        self.max_iterations = max_iterations\n        self.client = openai.OpenAI()\n\n    def _build_system_prompt(self) -\u0026gt; str:\n        tool_desc = \u0026quot;\\n\u0026quot;.join(\n            f\u0026quot;- {t.name}: {t.description}\u0026quot; for t in self.tools.values()\n        )\n        return REACT_SYSTEM_PROMPT.format(tool_descriptions=tool_desc)\n\n    def _parse_action(self, text: str) -\u0026gt; tuple[str, dict] | None:\n        for line in text.split(\u0026quot;\\n\u0026quot;):\n            if line.strip().startswith(\u0026quot;Action:\u0026quot;):\n                action_str = line.strip()[len(\u0026quot;Action:\u0026quot;):].strip()\n                paren = action_str.find(\u0026quot;(\u0026quot;)\n                if paren == -1:\n                    return None\n                name = action_str[:paren].strip()\n                params_str = action_str[paren + 1:].rstrip(\u0026quot;)\u0026quot;)\n                params = json.loads(params_str) if params_str else {}\n                return name, params\n        return None\n\n    def _execute_tool(self, name: str, params: dict) -\u0026gt; str:\n        if name not in self.tools:\n            return f\u0026quot;Error: Unknown tool \u0026#39;{name}\u0026#39;\u0026quot;\n        try:\n            return str(self.tools[name].function(**params))\n        except Exception as e:\n            return f\u0026quot;Error: {e}\u0026quot;\n\n    def run(self, query: str) -\u0026gt; str:\n        messages = [\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self._build_system_prompt()},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: query},\n        ]\n        for _ in range(self.max_iterations):\n            resp = self.client.chat.completions.create(\n                model=self.model, messages=messages, temperature=0.0,\n            )\n            text = resp.choices[0].message.content\n            messages.append({\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: text})\n\n            if \u0026quot;Final Answer:\u0026quot; in text:\n                return text.split(\u0026quot;Final Answer:\u0026quot;)[-1].strip()\n\n            action = self._parse_action(text)\n            if action is None:\n                messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\n                                 \u0026quot;content\u0026quot;: \u0026quot;Provide a valid Action or Final Answer.\u0026quot;})\n                continue\n\n            observation = self._execute_tool(*action)\n            messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;Observation: {observation}\u0026quot;})\n\n        return \u0026quot;Reached max iterations without final answer.\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意：随着迭代增加 \u003ccode\u003emessages\u003c/code\u003e 不断膨胀，token 消耗呈线性增长。超过 5-6 步的任务需要考虑上下文压缩（如摘要历史步骤）。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Plan-and-Execute 模式\u003c/h2\u003e\n\u003ch3\u003e4.1 原理：先规划再执行\u003c/h3\u003e\n\u003cp\u003ePlan-and-Execute 将规划与执行分离：先用一次 LLM 调用生成完整计划，再逐个执行子任务，必要时触发 Replanning。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌────────────┐       Plan: [S1, S2, S3]      ┌────────────┐\n│  Planner   │──────────────────────────────▶│  Executor  │\n│ (全局规划)  │                                │ (逐步执行)  │\n└────────────┘                                └─────┬──────┘\n      ▲                                             │ 执行失败\n      │            ┌─────────────┐                  │\n      └────────────│  Replanner  │◀─────────────────┘\n                   │ (动态修正)   │\n                   └─────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.2 Planner / Executor 分离的优势\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e关注点分离\u003c/strong\u003e：Planner 负责\u0026quot;做什么\u0026quot;，Executor 负责\u0026quot;怎么做\u0026quot;，可以分别用不同模型优化\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可并行\u003c/strong\u003e：无依赖的步骤可以并行执行\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可追踪\u003c/strong\u003e：计划本身是结构化数据，便于监控和审计\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可中断恢复\u003c/strong\u003e：执行到一半中断后可从某一步重启\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e4.3 计划的动态修正\u003c/h3\u003e\n\u003cp\u003e三种 Replan 策略：\u003cstrong\u003e完全重新规划\u003c/strong\u003e（全局优化但可能丢弃已有成果）、\u003cstrong\u003e局部修正\u003c/strong\u003e（成本低但可能保留错误前提）、\u003cstrong\u003e条件触发\u003c/strong\u003e（仅在步骤失败或偏差超阈值时 Replan）。生产中通常用条件触发 + 局部修正的组合。\u003c/p\u003e\n\u003ch3\u003e4.4 Python 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\n\n@dataclass\nclass PlanStep:\n    id: int\n    description: str\n    tool: str | None = None\n    depends_on: list[int] = field(default_factory=list)\n    status: str = \u0026quot;pending\u0026quot;   # pending / completed / failed\n    result: str | None = None\n\nPLANNER_PROMPT = \u0026quot;\u0026quot;\u0026quot;Decompose the goal into concrete steps (max 7).\nAvailable tools: {tool_names}\nOutput JSON: {{\u0026quot;goal\u0026quot;: \u0026quot;...\u0026quot;, \u0026quot;steps\u0026quot;: [{{\u0026quot;id\u0026quot;: 1, \u0026quot;description\u0026quot;: \u0026quot;...\u0026quot;,\n\u0026quot;tool\u0026quot;: \u0026quot;tool_name or null\u0026quot;, \u0026quot;depends_on\u0026quot;: []}}]}}\u0026quot;\u0026quot;\u0026quot;\n\nclass PlanAndExecuteAgent:\n    def __init__(self, tools: dict[str, Tool],\n                 planner_model: str = \u0026quot;gpt-4o\u0026quot;,\n                 executor_model: str = \u0026quot;gpt-4o-mini\u0026quot;,\n                 max_replans: int = 3):\n        self.tools = tools\n        self.planner_model = planner_model\n        self.executor_model = executor_model\n        self.max_replans = max_replans\n        self.client = openai.OpenAI()\n\n    def _create_plan(self, goal: str) -\u0026gt; list[PlanStep]:\n        resp = self.client.chat.completions.create(\n            model=self.planner_model,\n            messages=[\n                {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: PLANNER_PROMPT.format(\n                    tool_names=\u0026quot;, \u0026quot;.join(self.tools.keys()))},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: goal},\n            ],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return [PlanStep(**s) for s in data[\u0026quot;steps\u0026quot;]]\n\n    def _execute_step(self, step: PlanStep, context: dict) -\u0026gt; str:\n        if step.tool and step.tool in self.tools:\n            param_resp = self.client.chat.completions.create(\n                model=self.executor_model,\n                messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                    f\u0026quot;Call tool \u0026#39;{step.tool}\u0026#39; for: {step.description}\\n\u0026quot;\n                    f\u0026quot;Context: {json.dumps(context)}\\nReturn JSON params only.\u0026quot;}],\n                response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n            )\n            params = json.loads(param_resp.choices[0].message.content)\n            return str(self.tools[step.tool].function(**params))\n        resp = self.client.chat.completions.create(\n            model=self.executor_model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\n                       \u0026quot;content\u0026quot;: f\u0026quot;Task: {step.description}\\nContext: {json.dumps(context)}\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\n    def run(self, goal: str) -\u0026gt; str:\n        steps = self._create_plan(goal)\n        context = {}\n        for replan in range(self.max_replans + 1):\n            for step in steps:\n                if step.status == \u0026quot;completed\u0026quot;:\n                    continue\n                deps_met = all(\n                    any(s.id == d and s.status == \u0026quot;completed\u0026quot; for s in steps)\n                    for d in step.depends_on\n                )\n                if not deps_met:\n                    continue\n                try:\n                    step.result = self._execute_step(step, context)\n                    step.status = \u0026quot;completed\u0026quot;\n                    context[f\u0026quot;step_{step.id}\u0026quot;] = step.result\n                except Exception as e:\n                    step.status = \u0026quot;failed\u0026quot;\n                    step.result = str(e)\n                    steps = self._replan(goal, steps, step)\n                    break\n            if all(s.status == \u0026quot;completed\u0026quot; for s in steps):\n                return self._synthesize(goal, context)\n        return \u0026quot;Exceeded max replans.\u0026quot;\n\n    def _replan(self, goal, steps, failed) -\u0026gt; list[PlanStep]:\n        # 将已完成步骤 + 失败信息交给 Planner 重新规划\n        completed = [{\u0026quot;id\u0026quot;: s.id, \u0026quot;result\u0026quot;: s.result}\n                     for s in steps if s.status == \u0026quot;completed\u0026quot;]\n        resp = self.client.chat.completions.create(\n            model=self.planner_model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Replan. Goal: {goal}\\nCompleted: {json.dumps(completed)}\\n\u0026quot;\n                f\u0026quot;Failed step: {failed.description} -\u0026gt; {failed.result}\u0026quot;}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return [PlanStep(**s) for s in data[\u0026quot;steps\u0026quot;]]\n\n    def _synthesize(self, goal, context):\n        resp = self.client.chat.completions.create(\n            model=self.planner_model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\n                       \u0026quot;content\u0026quot;: f\u0026quot;Goal: {goal}\\nResults: {json.dumps(context)}\\n\u0026quot;\n                       \u0026quot;Synthesize a final answer.\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePlanner 用 \u003ccode\u003egpt-4o\u003c/code\u003e（强规划），Executor 用 \u003ccode\u003egpt-4o-mini\u003c/code\u003e（快执行）——这是生产中常见的成本优化手段。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. Tree-of-Thought\u003c/h2\u003e\n\u003ch3\u003e5.1 原理\u003c/h3\u003e\n\u003cp\u003eTree-of-Thought（ToT，Yao et al. 2023）模拟人类\u0026quot;深思熟虑\u0026quot;：同时考虑多条推理路径，评估每条的前景，选择最优的继续深入。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                       Root (问题)\n                      /     |     \\\n                   Th1     Th2    Th3      ← 生成多个候选 Thought\n                  /   \\     |    /   \\\n               T1a   T1b  T2a  T3a  T3b   ← 继续展开\n                ✗      ✓    ✗    ✓    ✗    ← 评估函数打分，剪枝\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e三个核心组件：\u003cstrong\u003eThought Generator\u003c/strong\u003e（每步生成 k 个候选）、\u003cstrong\u003eState Evaluator\u003c/strong\u003e（对候选打分）、\u003cstrong\u003eSearch Algorithm\u003c/strong\u003e（BFS 或 DFS）。\u003c/p\u003e\n\u003ch3\u003e5.2 BFS vs DFS\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBFS\u003c/strong\u003e：每层展开 k 个，评估后保留 top-k 进入下一层。适合步骤少、每步选择多的问题。总调用 ≈ k x depth x 2（生成+评估）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDFS\u003c/strong\u003e：选当前最优一路深入，死胡同时回溯。适合步骤多、每步选择少的问题。最好 O(depth)，最坏 O(k^depth)。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e5.3 评估函数设计\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLLM 自评\u003c/strong\u003e：让 LLM 对每个 Thought 打分。简单但可能有系统性偏见。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e投票法\u003c/strong\u003e：多次评估取多数。更稳健但成本更高。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e外部验证\u003c/strong\u003e：可验证的问题（数学/代码）用外部工具检查。最可靠但适用范围有限。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e5.4 Trade-off：质量 vs 成本\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e方法           LLM 调用次数      质量    适用场景\n─────────────  ──────────────   ─────   ──────────\nReAct(单路径)   O(steps)         基准    大多数任务\nToT-BFS        O(k * d * 2)     高      创意/数学/方案选型\nToT-DFS        O(k^d) 最坏      中-高   深度推理\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ek=3, d=3 时 ToT 可能需要 40+ 次 LLM 调用，ReAct 只需 5-6 次——\u003cstrong\u003e8-10 倍成本差距\u003c/strong\u003e。只有当正确性要求高且存在多条有意义的推理路径时，ToT 的投入才有回报。\u003c/p\u003e\n\u003ch3\u003e5.5 Python 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nfrom dataclasses import dataclass, field\nimport openai\n\n@dataclass\nclass ThoughtNode:\n    \u0026quot;\u0026quot;\u0026quot;搜索树中的节点，每个节点代表一条推理路径的当前状态\u0026quot;\u0026quot;\u0026quot;\n    state: str                           # 当前推理状态（累积的 thought 文本）\n    score: float = 0.0                   # 评估函数打分\n    depth: int = 0\n    children: list[\u0026quot;ThoughtNode\u0026quot;] = field(default_factory=list)\n\nclass TreeOfThought:\n    def __init__(self, model: str = \u0026quot;gpt-4o\u0026quot;, k: int = 3, max_depth: int = 3):\n        \u0026quot;\u0026quot;\u0026quot;\n        k: 每层生成的候选 thought 数量（BFS 宽度）\n        max_depth: 搜索树最大深度\n        \u0026quot;\u0026quot;\u0026quot;\n        self.model = model\n        self.k = k\n        self.max_depth = max_depth\n        self.client = openai.OpenAI()\n\n    def generate_thoughts(self, problem: str, current_state: str) -\u0026gt; list[str]:\n        \u0026quot;\u0026quot;\u0026quot;生成 k 个候选 thought\u0026quot;\u0026quot;\u0026quot;\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Given the problem and current reasoning state, \u0026quot;\n                f\u0026quot;generate exactly {self.k} distinct next-step thoughts.\\n\u0026quot;\n                f\u0026#39;Return JSON: {{\u0026quot;thoughts\u0026quot;: [\u0026quot;thought1\u0026quot;, \u0026quot;thought2\u0026quot;, ...]}}\u0026#39;},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Problem: {problem}\\nCurrent state: {current_state or \u0026#39;(start)\u0026#39;}\u0026quot;}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return data[\u0026quot;thoughts\u0026quot;][:self.k]\n\n    def evaluate_thought(self, problem: str, state: str) -\u0026gt; float:\n        \u0026quot;\u0026quot;\u0026quot;评估当前推理状态的前景，返回 0-1 分数\u0026quot;\u0026quot;\u0026quot;\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                \u0026quot;Evaluate how promising this reasoning state is for solving the problem.\\n\u0026quot;\n                \u0026#39;Return JSON: {\u0026quot;score\u0026quot;: 0.0-1.0, \u0026quot;reason\u0026quot;: \u0026quot;...\u0026quot;}\u0026#39;},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Problem: {problem}\\nReasoning so far: {state}\u0026quot;}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return float(data[\u0026quot;score\u0026quot;])\n\n    def solve(self, problem: str) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;BFS 搜索：每层生成 k 个候选，评估后保留 top-k 进入下一层\u0026quot;\u0026quot;\u0026quot;\n        # 初始化：根节点\n        current_level = [ThoughtNode(state=\u0026quot;\u0026quot;, depth=0)]\n\n        for depth in range(self.max_depth):\n            candidates: list[ThoughtNode] = []\n\n            for node in current_level:\n                # 为每个节点生成 k 个候选 thought\n                thoughts = self.generate_thoughts(problem, node.state)\n                for thought in thoughts:\n                    new_state = f\u0026quot;{node.state}\\nStep {depth+1}: {thought}\u0026quot;.strip()\n                    score = self.evaluate_thought(problem, new_state)\n                    child = ThoughtNode(state=new_state, score=score, depth=depth+1)\n                    node.children.append(child)\n                    candidates.append(child)\n\n            # 保留 top-k 进入下一层（BFS 剪枝）\n            candidates.sort(key=lambda n: n.score, reverse=True)\n            current_level = candidates[:self.k]\n\n        # 返回最终得分最高的推理路径\n        best = max(current_level, key=lambda n: n.score)\n        return best.state\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e核心观察：BFS 宽度 \u003ccode\u003ek\u003c/code\u003e 和搜索深度 \u003ccode\u003emax_depth\u003c/code\u003e 共同控制质量-成本的 trade-off。\u003ccode\u003ek\u003c/code\u003e 越大，每层探索的候选越多，找到好路径的概率越高，但 LLM 调用次数以 O(k² × d) 增长（每层 k 个节点各生成 k 个候选 + k 次评估）。实践中 k=2\u003cdel\u003e3、depth=2\u003c/del\u003e3 是较好的起点，可根据任务复杂度动态调整。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 分层规划（Hierarchical Planning）\u003c/h2\u003e\n\u003cp\u003e当任务复杂到\u0026quot;设计并实现用户权限系统\u0026quot;这种级别时，一层计划无法覆盖从架构到实现的所有粒度。分层规划通过\u003cstrong\u003e递归分解\u003c/strong\u003e解决：高层拆子目标，低层拆具体动作。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e高层规划器 (Strategic)\n├─ 子目标1: 设计数据模型\n│   └─ 低层规划器 (Tactical)\n│       ├─ Action: 分析需求\n│       ├─ Action: 设计 ER 图\n│       └─ Action: 定义 API Schema\n├─ 子目标2: 实现认证模块\n│   └─ 低层规划器\n│       ├─ Action: 实现 JWT 签发\n│       └─ Action: 编写测试\n└─ 子目标3: 实现授权模块\n    └─ 低层规划器\n        ├─ Action: 实现 RBAC\n        └─ Action: 集成测试\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.1 递归分解的终止条件\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e原子性\u003c/strong\u003e：任务可用单次工具调用完成 → 停止分解\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e深度限制\u003c/strong\u003e：最大 2-3 层，防止过度分解\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e预算约束\u003c/strong\u003e：剩余 token 预算不足以继续分解 → 当前粒度直接执行\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass HierarchicalPlanner:\n    def __init__(self, client: openai.OpenAI, model=\u0026quot;gpt-4o\u0026quot;, max_depth=3):\n        self.client, self.model, self.max_depth = client, model, max_depth\n\n    def decompose(self, goal: str, depth: int = 0) -\u0026gt; dict:\n        if depth \u0026gt;= self.max_depth:\n            return {\u0026quot;type\u0026quot;: \u0026quot;action\u0026quot;, \u0026quot;description\u0026quot;: goal}\n\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                \u0026quot;Decide if this goal is atomic or compound.\\n\u0026quot;\n                \u0026#39;Atomic: {\u0026quot;type\u0026quot;:\u0026quot;action\u0026quot;,\u0026quot;description\u0026quot;:\u0026quot;...\u0026quot;}\\n\u0026#39;\n                \u0026#39;Compound: {\u0026quot;type\u0026quot;:\u0026quot;goal\u0026quot;,\u0026quot;description\u0026quot;:\u0026quot;...\u0026quot;,\u0026quot;subgoals\u0026quot;:[\u0026quot;...\u0026quot;,]}\u0026#39;},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: goal}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        node = json.loads(resp.choices[0].message.content)\n        if node[\u0026quot;type\u0026quot;] == \u0026quot;action\u0026quot;:\n            return node\n        node[\u0026quot;children\u0026quot;] = [self.decompose(sg, depth+1) for sg in node.get(\u0026quot;subgoals\u0026quot;,[])]\n        return node\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实践中 2 层（Strategic + Tactical）通常够用。3 层以上的调试成本会快速失控。\u003c/p\u003e\n\u003ch3\u003e6.2 执行层：递归执行分解后的计划\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eHierarchicalPlanner\u003c/code\u003e 只负责分解，执行需要单独的 Executor。核心逻辑：叶节点（type=\u0026quot;action\u0026quot;）直接调用 LLM 或工具执行，分支节点（type=\u0026quot;goal\u0026quot;）递归执行所有子节点并聚合结果。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ExecutionResult:\n    description: str\n    output: str\n    success: bool\n    children: list[\u0026quot;ExecutionResult\u0026quot;] = field(default_factory=list)\n\nclass HierarchicalExecutor:\n    def __init__(self, client: openai.OpenAI, model: str = \u0026quot;gpt-4o-mini\u0026quot;,\n                 tools: dict[str, Callable] | None = None):\n        self.client = client\n        self.model = model\n        self.tools = tools or {}\n\n    def execute(self, node: dict) -\u0026gt; ExecutionResult:\n        \u0026quot;\u0026quot;\u0026quot;递归执行分解后的计划树\u0026quot;\u0026quot;\u0026quot;\n        desc = node.get(\u0026quot;description\u0026quot;, \u0026quot;\u0026quot;)\n\n        # 叶节点：直接执行\n        if node[\u0026quot;type\u0026quot;] == \u0026quot;action\u0026quot;:\n            output = self._execute_action(desc)\n            return ExecutionResult(description=desc, output=output, success=True)\n\n        # 分支节点：递归执行所有子节点\n        child_results = [self.execute(child) for child in node.get(\u0026quot;children\u0026quot;, [])]\n        all_success = all(r.success for r in child_results)\n\n        # 聚合子节点结果\n        summary = self._aggregate(desc, child_results)\n        return ExecutionResult(\n            description=desc, output=summary,\n            success=all_success, children=child_results,\n        )\n\n    def _execute_action(self, action: str) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;执行单个原子动作——优先使用工具，否则 fallback 到 LLM\u0026quot;\u0026quot;\u0026quot;\n        for tool_name, tool_fn in self.tools.items():\n            if tool_name.lower() in action.lower():\n                return str(tool_fn(action))\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;Execute this task: {action}\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\n    def _aggregate(self, goal: str, results: list[ExecutionResult]) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;将子节点执行结果聚合为父目标的总结\u0026quot;\u0026quot;\u0026quot;\n        parts = \u0026quot;\\n\u0026quot;.join(f\u0026quot;- {r.description}: {r.output[:200]}\u0026quot; for r in results)\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Goal: {goal}\\nSub-results:\\n{parts}\\nSummarize the overall outcome.\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e分解与执行分离的好处：\u003ccode\u003eHierarchicalPlanner\u003c/code\u003e 可以用强模型（gpt-4o）做规划，\u003ccode\u003eHierarchicalExecutor\u003c/code\u003e 用快模型（gpt-4o-mini）做执行，兼顾规划质量和执行成本。同时，执行层可以独立替换——例如将 \u003ccode\u003e_execute_action\u003c/code\u003e 改为调用真实 API 或 Code Interpreter，而不影响规划逻辑。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Reflection（反思）机制\u003c/h2\u003e\n\u003ch3\u003e7.1 为什么需要反思\u003c/h3\u003e\n\u003cp\u003eAgent 有三类常见失败：LLM 输出错误（幻觉/逻辑错误）、工具执行失败（超时/参数错误）、计划不可行（前提假设不成立）。没有反思，错误会\u003cstrong\u003e无意识地传播\u003c/strong\u003e——第 2 步的错成为第 3 步的输入，错误不断累积。\u003c/p\u003e\n\u003ch3\u003e7.2 Self-Critique\u003c/h3\u003e\n\u003cp\u003e用同一个 LLM 评估自己的输出。理论支持：LLM 在\u003cstrong\u003e验证\u003c/strong\u003e上通常比\u003cstrong\u003e生成\u003c/strong\u003e更强（就像检查别人的代码比自己写更容易）。但盲区在于：LLM 的系统性偏见在生成和评估中是一致的。\u003c/p\u003e\n\u003ch3\u003e7.3 结构化反思\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ReflectionResult:\n    what_went_well: list[str]\n    what_went_wrong: list[str]\n    root_cause: str\n    what_to_do_next: str\n    should_retry: bool\n    confidence: float  # 0-1\n\nREFLECTION_PROMPT = \u0026quot;\u0026quot;\u0026quot;Analyze this execution result.\nGoal: {goal} | Steps: {steps} | Result: {result}\nReturn JSON: {{\u0026quot;what_went_well\u0026quot;:[], \u0026quot;what_went_wrong\u0026quot;:[], \u0026quot;root_cause\u0026quot;:\u0026quot;\u0026quot;,\n\u0026quot;what_to_do_next\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;should_retry\u0026quot;: bool, \u0026quot;confidence\u0026quot;: 0.0-1.0}}\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.4 Retry Budget 与 Stop Condition\u003c/h3\u003e\n\u003cp\u003e反思不能无限循环。必须有 Stop Condition：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                  反思完成\n                     │\n          ┌──────────▼──────────┐   是\n          │ 质量 \u0026gt;= 阈值？       │─────▶ 返回结果\n          └──────────┬──────────┘\n                     │ 否\n          ┌──────────▼──────────┐   是\n          │ 达到最大重试？       │─────▶ 返回最好的结果\n          └──────────┬──────────┘\n                     │ 否\n          ┌──────────▼──────────┐   是\n          │ 改进幅度 \u0026lt; 阈值？    │─────▶ 停止（再试也没用）\n          └──────────┬──────────┘\n                     │ 否\n          ┌──────────▼──────────┐   是\n          │ 成本超出预算？       │─────▶ 返回当前结果\n          └──────────┬──────────┘\n                     │ 否\n                  继续重试\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e四个条件形成\u003cstrong\u003e多层安全网\u003c/strong\u003e：质量达标是正常退出，最大重试和成本预算是硬性保底，改进幅度检测是\u0026quot;聪明的\u0026quot;提前退出。\u003c/p\u003e\n\u003ch3\u003e7.5 代码实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ReflectionPolicy:\n    max_retries: int = 3\n    quality_threshold: float = 0.7\n    improvement_threshold: float = 0.1\n    cost_limit_tokens: int = 10000\n\nclass ReflectiveAgent:\n    def __init__(self, base_agent: ReActAgent, policy: ReflectionPolicy,\n                 model: str = \u0026quot;gpt-4o-mini\u0026quot;):\n        self.base_agent = base_agent\n        self.policy = policy\n        self.model = model\n        self.client = openai.OpenAI()\n\n    def _reflect(self, goal, steps, result) -\u0026gt; ReflectionResult:\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: REFLECTION_PROMPT.format(\n                goal=goal, steps=json.dumps(steps), result=result)}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        return ReflectionResult(**json.loads(resp.choices[0].message.content))\n\n    def run(self, goal: str) -\u0026gt; str:\n        best_result, best_score = None, 0.0\n        history = []\n\n        for attempt in range(self.policy.max_retries + 1):\n            # 执行（重试时注入反思结论）\n            if attempt == 0:\n                result = self.base_agent.run(goal)\n            else:\n                enhanced = (f\u0026quot;{goal}\\n\\nPrevious issues: {reflection.what_went_wrong}\u0026quot;\n                           f\u0026quot;\\nRoot cause: {reflection.root_cause}\u0026quot;\n                           f\u0026quot;\\nSuggestion: {reflection.what_to_do_next}\u0026quot;)\n                result = self.base_agent.run(enhanced)\n\n            reflection = self._reflect(goal, history, result)\n\n            # Stop conditions\n            if reflection.confidence \u0026gt;= self.policy.quality_threshold:\n                best_result, best_score = result, reflection.confidence\n                break\n            if not reflection.should_retry:\n                break\n            if attempt \u0026gt; 0 and (reflection.confidence - best_score) \u0026lt; self.policy.improvement_threshold:\n                break  # 改进幅度不足，再试也没用\n\n            # 更新最优结果（放在 stop condition 之后，避免 improvement 检查失效）\n            if reflection.confidence \u0026gt; best_score:\n                best_result, best_score = result, reflection.confidence\n\n            history.append({\u0026quot;attempt\u0026quot;: attempt, \u0026quot;issues\u0026quot;: reflection.what_went_wrong})\n\n        return best_result or result\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. Reflection 的陷阱\u003c/h2\u003e\n\u003ch3\u003e8.1 无限循环\u003c/h3\u003e\n\u003cp\u003eAgent 不断反思但不改进——反思发现了问题却没有提供有效的改进方向。解法：\u003ccode\u003eimprovement_threshold\u003c/code\u003e 检测，连续两轮质量差距 \u0026lt; 0.1 直接停止。\u003c/p\u003e\n\u003ch3\u003e8.2 过度反思\u003c/h3\u003e\n\u003cp\u003e简单任务（\u0026quot;今天天气怎么样\u0026quot;）也要三轮反思，浪费 3-4 倍 token。解法：引入复杂度判断，简单任务跳过反思。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef needs_reflection(task: str, result: str) -\u0026gt; bool:\n    \u0026quot;\u0026quot;\u0026quot;简单任务不值得反思\u0026quot;\u0026quot;\u0026quot;\n    if len(result) \u0026lt; 100:  # 结果很短 → 可能是简单查询\n        return False\n    simple_patterns = [\u0026quot;什么是\u0026quot;, \u0026quot;查一下\u0026quot;, \u0026quot;告诉我\u0026quot;]\n    return not any(p in task for p in simple_patterns)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.3 成本爆炸\u003c/h3\u003e\n\u003cp\u003e每次反思是完整 LLM 调用，包含完整上下文。对策：(1) 反思用小模型（GPT-4o-mini）；(2) 压缩上下文传摘要版本；(3) 采样反思（30% 的执行触发反思而非 100%）。\u003c/p\u003e\n\u003ch3\u003e8.4 合理的 Reflection 策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eQ1: 任务的错误成本高吗？\n  高 → 启用反思    低 → 跳过\n\nQ2: 错误可自动检测吗？\n  是（代码可测试） → 外部验证（更可靠更便宜）\n  否（文案质量）   → LLM Self-Critique\n\nQ3: 预算够吗？\n  够   → 结构化反思 + 多轮重试\n  不够 → 单轮 Self-Critique\n\nQ4: 延迟敏感吗？\n  是 → 最多一轮，超时直接返回\n  否 → 多轮直到质量达标\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 规划模式选型指南\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景\u003c/th\u003e\n\u003cth\u003e推荐模式\u003c/th\u003e\n\u003cth\u003e原因\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e简单工具调用（查天气、算术）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eReAct\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e1-2 步完成，规划是过度设计\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e多步研究（竞品分析、技术调研）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePlan-and-Execute\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e需要全局视野和步骤追踪\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e创意/数学/代码\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eTree-of-Thought\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e需探索多条路径并选最优\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e复杂项目（系统设计）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eHierarchical\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e粒度跨度大，需递归分解\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e高可靠（金融/法律）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePlan-and-Execute + Reflection\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e全局规划 + 结果验证\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e实时交互（客服/对话）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eReAct\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e延迟敏感，逐步响应\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e长时任务（数据管道）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eHierarchical + Plan-Exec\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e可中断、可恢复、可并行\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e二维决策矩阵：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                  任务步骤少            任务步骤多\n             ┌──────────────────┬──────────────────┐\n 确定性高    │  ReAct            │  Plan-and-Exec   │\n (路径清晰)  │ (甚至不需要Agent)  │                  │\n             ├──────────────────┼──────────────────┤\n 确定性低    │  Tree-of-Thought  │  Hierarchical    │\n (需要探索)  │                   │  + Reflection    │\n             └──────────────────┴──────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e模式组合\u003c/strong\u003e在生产中很常见：Hierarchical + Plan-and-Execute（高层分解子目标，内部用 Plan-Exec 执行）；ReAct + Reflection（逐步执行，每 N 步检查方向）。关键原则：\u003cstrong\u003e从 ReAct 开始，只有当它的局限性确实成为瓶颈时再升级。\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 结语：规划的边界与 Multi-Agent 的必要性\u003c/h2\u003e\n\u003cp\u003e规划和反思让单个 Agent 从\u0026quot;走一步看一步\u0026quot;进化到\u0026quot;先想后做再检查\u0026quot;。但单 Agent 的规划能力终有上限：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e上下文窗口限制\u003c/strong\u003e：任务涉及的知识和状态超出 context window 时，单 Agent 力不从心\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e专业性限制\u003c/strong\u003e：一个 Agent 很难同时擅长编码、写作和数据分析——就像一个人很难同时是程序员、设计师和产品经理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e执行效率限制\u003c/strong\u003e：单 Agent 串行执行，即使计划中的步骤可以并行\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当这些限制成为瓶颈，你需要的不是更好的规划算法，而是\u003cstrong\u003e多个 Agent 的协作\u003c/strong\u003e——每个 Agent 专注于擅长领域，由 Orchestrator 协调。这正是下一篇的主题：\u003cstrong\u003eMulti-Agent Collaboration: 多 Agent 协作模式与架构。\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e进一步思考：\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e规划质量高度依赖 LLM 对任务域的理解。如果 LLM 从未见过某类任务，能否通过 few-shot examples 注入领域知识来提升规划质量？\u003c/li\u003e\n\u003cli\u003e\u0026quot;LLM 评估 LLM\u0026quot; 的反思机制在多大程度上可靠？是否能引入外部验证信号（代码测试、人类反馈）来补强？\u003c/li\u003e\n\u003cli\u003eTree-of-Thought 的搜索空间是指数级的。能否借鉴 AlphaGo 的 MCTS 来更高效搜索？Reasoning model（如 o1、o3）是否已在内部做了类似的事情？\u003c/li\u003e\n\u003cli\u003e规划和反思的 token 成本显著。能否缓存和复用已有的计划，为相似任务跳过规划阶段？\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 10 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/09-RAG%20as%20Cognitive%20Memory\"\u003e09 | RAG as Cognitive Memory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/11-Multi-Agent%20Collaboration\"\u003e11 | Multi-Agent Collaboration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"17:Td4c4,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eRAG as Cognitive Memory: 检索增强生成的工程实践\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e系列第 9 篇。上一篇我们讨论了 Agent 的记忆架构——会话状态、短期记忆与长期记忆。本篇聚焦长期记忆中最核心的工程问题：如何让 Agent 在海量知识中精准找到它需要的信息。\u003c/p\u003e\n\u003cp\u003e核心命题：\u003cstrong\u003e检索质量 \u0026gt; 模型大小。\u003c/strong\u003e 一个用 GPT-3.5 + 优秀 RAG 的系统，往往比 GPT-4 + 粗糙检索的系统表现更好。RAG 是工程问题，不是模型问题。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. RAG 不是\u0026quot;搜索+拼接\u0026quot;\u003c/h2\u003e\n\u003cp\u003e很多团队对 RAG 的理解停留在\u0026quot;把搜索结果塞进 prompt\u0026quot;这一层。这种理解会导致系统质量的天花板极低。\u003c/p\u003e\n\u003cp\u003eRAG 的本质是 \u003cstrong\u003eAgent 的认知记忆系统\u003c/strong\u003e。人类回答问题时，不是把大脑里所有信息倒出来再筛选——而是根据问题的语义，精准地从记忆中提取相关片段，重新组织后输出回答。RAG 做的事情完全一样：理解 Query 的意图，从知识库中检索最相关的上下文，以最优的方式组织给 LLM，让它生成有据可依的回答。\u003c/p\u003e\n\u003cp\u003e这个过程中，每一个环节都会影响最终质量：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eChunking 策略\u003c/strong\u003e决定了知识的粒度——切得不好，语义被割裂，检索再准也没用\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmbedding 质量\u003c/strong\u003e决定了语义理解的上限——模型选错了，同义词都搜不到\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e检索策略\u003c/strong\u003e决定了召回的完整性——只用向量搜索，专有名词和 ID 就会丢失\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReranking\u003c/strong\u003e决定了精排的准确性——Top 100 召回可能很好，但 Top 5 的排序决定了 LLM 看到什么\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContext Packing\u003c/strong\u003e决定了 LLM 的信息利用率——塞太多噪声，LLM 反而会被干扰\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e一个工程事实：在大多数 RAG 系统中，\u003cstrong\u003e80% 的质量问题出在检索侧，而非生成侧。\u003c/strong\u003e 换一个更贵的模型不如把检索做好。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. RAG Pipeline 全景图\u003c/h2\u003e\n\u003cp\u003e一个生产级 RAG 系统的完整数据流如下：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────────────────┐\n│                        OFFLINE (Indexing)                           │\n│                                                                     │\n│  ┌──────────┐   ┌───────────┐   ┌──────────┐   ┌────────────────┐  │\n│  │ Document │──→│ Ingestion │──→│ Chunking │──→│   Embedding    │  │\n│  │  Sources │   │ \u0026amp; Cleaning│   │ Strategy │   │ (Text → Vec)   │  │\n│  └──────────┘   └───────────┘   └──────────┘   └───────┬────────┘  │\n│   PDF/HTML/MD    格式归一化       语义切分              │           │\n│   Code/DB        元数据提取       重叠策略         ┌────┴─────┐    │\n│                                                   │ Indexing  │    │\n│                                                   │ (Vector + │    │\n│                                                   │  BM25 DB) │    │\n│                                                   └────┬─────┘    │\n└────────────────────────────────────────────────────────┼──────────┘\n                                                         │\n─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┼ ─ ─ ─ ─ ─\n                                                         │\n┌────────────────────────────────────────────────────────┼──────────┐\n│                        ONLINE (Retrieval)              │           │\n│                                                        ▼           │\n│  ┌───────┐   ┌──────────┐   ┌───────────┐   ┌────────────────┐   │\n│  │ User  │──→│  Query   │──→│  Hybrid   │──→│   Reranking    │   │\n│  │ Query │   │ Expansion│   │  Search   │   │ (Cross-Encoder)│   │\n│  └───────┘   └──────────┘   │ BM25+Vec  │   └───────┬────────┘   │\n│               HyDE/扩写      └───────────┘           │            │\n│                              RRF 融合                 ▼            │\n│                                              ┌────────────────┐   │\n│                                              │Context Packing │   │\n│                                              │ (排序/截断/组织) │   │\n│                                              └───────┬────────┘   │\n│                                                      ▼            │\n│                                              ┌────────────────┐   │\n│                                              │   LLM Generate │   │\n│                                              │  (+ Citation)  │   │\n│                                              └───────┬────────┘   │\n│                                                      ▼            │\n│                                              ┌────────────────┐   │\n│                                              │   Response     │   │\n│                                              └────────────────┘   │\n└───────────────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e整个 Pipeline 分为两个阶段：\u003cstrong\u003e离线索引（Offline Indexing）\u003c/strong\u003e 和 \u003cstrong\u003e在线检索（Online Retrieval）\u003c/strong\u003e。离线阶段处理和索引文档，在线阶段处理用户查询并生成回答。接下来逐一拆解每个环节。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. Ingestion：数据进入系统的第一关\u003c/h2\u003e\n\u003ch3\u003e3.1 数据源多样性\u003c/h3\u003e\n\u003cp\u003e真实世界的知识不会以整洁的纯文本出现。一个企业级 RAG 系统通常需要处理：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e数据源\u003c/th\u003e\n\u003cth\u003e挑战\u003c/th\u003e\n\u003cth\u003e处理策略\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003ePDF\u003c/td\u003e\n\u003ctd\u003e布局复杂、表格、图片、双栏\u003c/td\u003e\n\u003ctd\u003e使用专用解析器（如 PyMuPDF、Unstructured）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHTML\u003c/td\u003e\n\u003ctd\u003e导航栏、广告、模板噪声\u003c/td\u003e\n\u003ctd\u003e内容提取 + boilerplate 去除\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMarkdown\u003c/td\u003e\n\u003ctd\u003e相对规范，但嵌套结构多\u003c/td\u003e\n\u003ctd\u003e按标题层级保留结构信息\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e代码文件\u003c/td\u003e\n\u003ctd\u003e函数、类、注释的语义边界\u003c/td\u003e\n\u003ctd\u003eAST 解析或按函数/类切分\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据库\u003c/td\u003e\n\u003ctd\u003e结构化数据需转换为文本\u003c/td\u003e\n\u003ctd\u003eSchema 描述 + 行级文本化\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e3.2 文档预处理\u003c/h3\u003e\n\u003cp\u003e原始文档进入系统前，必须经过清洗和归一化：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Optional\nimport hashlib\nimport re\n\n@dataclass\nclass Document:\n    \u0026quot;\u0026quot;\u0026quot;归一化后的文档表示\u0026quot;\u0026quot;\u0026quot;\n    content: str\n    source: str                           # 来源标识（URL、文件路径等）\n    doc_type: str                         # pdf, html, markdown, code\n    metadata: dict = field(default_factory=dict)  # 标题、作者、日期等\n    content_hash: str = \u0026quot;\u0026quot;                # 用于增量更新的去重\n\n    def __post_init__(self):\n        if not self.content_hash:\n            self.content_hash = hashlib.sha256(\n                self.content.encode()\n            ).hexdigest()\n\n\ndef preprocess(raw_text: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;文档预处理：清洗 + 归一化\u0026quot;\u0026quot;\u0026quot;\n    # 1. 去除多余空白\n    text = re.sub(r\u0026#39;\\n{3,}\u0026#39;, \u0026#39;\\n\\n\u0026#39;, raw_text)\n    text = re.sub(r\u0026#39; {2,}\u0026#39;, \u0026#39; \u0026#39;, text)\n\n    # 2. 去除特殊控制字符\n    text = re.sub(r\u0026#39;[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\u0026#39;, \u0026#39;\u0026#39;, text)\n\n    # 3. 归一化 Unicode（统一全角/半角等）\n    import unicodedata\n    text = unicodedata.normalize(\u0026#39;NFKC\u0026#39;, text)\n\n    return text.strip()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.3 增量 vs 全量更新\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003cth\u003e实现复杂度\u003c/th\u003e\n\u003cth\u003e一致性保证\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e全量重建\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e文档量小、更新不频繁\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e强（每次全量保证一致）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e增量更新\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e文档量大、频繁变更\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e需额外机制保证\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e增量更新的关键是 \u003cstrong\u003econtent hash 去重\u003c/strong\u003e：对每个文档计算内容哈希，只有哈希变化时才重新处理。还需要处理文档删除——被删除的文档对应的 chunk 和向量必须从索引中清除，否则会产生\u0026quot;幽灵知识\u0026quot;。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Chunking：RAG 质量的胜负手\u003c/h2\u003e\n\u003cp\u003eChunking 是 RAG 中最容易被低估、但对质量影响最大的环节。切分策略直接决定了：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e检索时能否命中相关内容\u003c/li\u003e\n\u003cli\u003e命中的内容是否包含足够上下文\u003c/li\u003e\n\u003cli\u003eLLM 拿到的信息是否有噪声\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.1 固定长度切分\u003c/h3\u003e\n\u003cp\u003e最简单的策略：按字符数或 token 数等间隔切分。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef fixed_size_chunk(text: str, chunk_size: int = 512, overlap: int = 64) -\u0026gt; list[str]:\n    \u0026quot;\u0026quot;\u0026quot;固定长度切分，带重叠\u0026quot;\u0026quot;\u0026quot;\n    chunks = []\n    start = 0\n    while start \u0026lt; len(text):\n        end = start + chunk_size\n        chunks.append(text[start:end])\n        start = end - overlap  # 重叠区域\n    return chunks\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：实现简单，chunk 大小均匀，token 预算可控。\u003cbr\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：完全不考虑语义边界。一个段落可能被从中间切开，一个完整的论述被分到两个 chunk 中，检索时只能命中半句话。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：对内容结构不了解、无法解析的纯文本；快速原型验证。\u003c/p\u003e\n\u003ch3\u003e4.2 语义切分\u003c/h3\u003e\n\u003cp\u003e按文档的天然结构（段落、标题、代码块）切分：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport re\n\ndef semantic_chunk(text: str, max_chunk_size: int = 1024) -\u0026gt; list[str]:\n    \u0026quot;\u0026quot;\u0026quot;基于语义边界的切分\u0026quot;\u0026quot;\u0026quot;\n    # 按标题分割（Markdown）\n    sections = re.split(r\u0026#39;\\n(?=#{1,3}\\s)\u0026#39;, text)\n\n    chunks = []\n    for section in sections:\n        if len(section) \u0026lt;= max_chunk_size:\n            chunks.append(section.strip())\n        else:\n            # 如果单个 section 太大，按段落再分\n            paragraphs = section.split(\u0026#39;\\n\\n\u0026#39;)\n            current_chunk = \u0026quot;\u0026quot;\n            for para in paragraphs:\n                if len(current_chunk) + len(para) \u0026gt; max_chunk_size:\n                    if current_chunk:\n                        chunks.append(current_chunk.strip())\n                    current_chunk = para\n                else:\n                    current_chunk += \u0026quot;\\n\\n\u0026quot; + para\n            if current_chunk:\n                chunks.append(current_chunk.strip())\n\n    return [c for c in chunks if c]  # 过滤空 chunk\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：保留语义完整性，每个 chunk 是一个有意义的信息单元。\u003cbr\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：chunk 大小不均匀；依赖文档格式的规范性。\u003c/p\u003e\n\u003ch3\u003e4.3 递归切分\u003c/h3\u003e\n\u003cp\u003e分层递归：先按最大的结构边界切，切不动再用更小的边界：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef recursive_chunk(\n    text: str,\n    chunk_size: int = 512,\n    separators: list[str] = None\n) -\u0026gt; list[str]:\n    \u0026quot;\u0026quot;\u0026quot;递归切分：先按大结构，再按小结构\u0026quot;\u0026quot;\u0026quot;\n    if separators is None:\n        separators = [\n            \u0026quot;\\n\\n\\n\u0026quot;,   # 章节间空行\n            \u0026quot;\\n\\n\u0026quot;,      # 段落\n            \u0026quot;\\n\u0026quot;,        # 行\n            \u0026quot;. \u0026quot;,        # 句子\n            \u0026quot; \u0026quot;,         # 单词\n        ]\n\n    if len(text) \u0026lt;= chunk_size:\n        return [text]\n\n    # 找到当前层级能用的分隔符\n    for i, sep in enumerate(separators):\n        if sep in text:\n            parts = text.split(sep)\n            chunks = []\n            current = \u0026quot;\u0026quot;\n            for part in parts:\n                candidate = current + sep + part if current else part\n                if len(candidate) \u0026lt;= chunk_size:\n                    current = candidate\n                else:\n                    if current:\n                        chunks.append(current)\n                    # 如果单个 part 仍然超限，用更细的分隔符递归\n                    if len(part) \u0026gt; chunk_size:\n                        chunks.extend(\n                            recursive_chunk(part, chunk_size, separators[i+1:])\n                        )\n                    else:\n                        current = part\n            if current:\n                chunks.append(current)\n            return chunks\n\n    # 最后兜底：硬切\n    return fixed_size_chunk(text, chunk_size)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这是 LangChain 的 \u003ccode\u003eRecursiveCharacterTextSplitter\u003c/code\u003e 采用的核心思路——先试大分隔符，不行再试小的，层层递归。\u003c/p\u003e\n\u003ch3\u003e4.4 Overlap 策略\u003c/h3\u003e\n\u003cp\u003e为什么需要重叠？考虑这段文本被切成两个 chunk：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eChunk 1: \u0026quot;...Transformer 模型的核心是 Self-Attention 机制，它允许模型在\u0026quot;\nChunk 2: \u0026quot;处理每个 token 时参考序列中所有其他 token 的信息...\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e如果用户问\u0026quot;Self-Attention 机制有什么作用\u0026quot;，Chunk 1 命中了关键词但答案不完整，Chunk 2 有答案但没有关键词匹配不上。加入重叠区域后：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eChunk 1: \u0026quot;...Transformer 模型的核心是 Self-Attention 机制，它允许模型在处理每个 token 时\u0026quot;\nChunk 2: \u0026quot;Self-Attention 机制，它允许模型在处理每个 token 时参考序列中所有其他 token 的信息...\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e两个 chunk 都包含了完整的语义。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e重叠多少合适？\u003c/strong\u003e 经验值是 chunk 大小的 10%-20%。太少起不到作用，太多则增加存储和检索冗余。对于 512 token 的 chunk，50-100 token 的 overlap 是合理的起点。\u003c/p\u003e\n\u003ch3\u003e4.5 Chunking 策略选择 Trade-off\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    Chunk 大小 Trade-off\n\n      太小 (\u0026lt; 256 tokens)              太大 (\u0026gt; 2048 tokens)\n      ┌─────────────────┐              ┌─────────────────┐\n      │ + 检索精确        │              │ + 上下文完整     │\n      │ + 噪声少          │              │ + 语义连贯       │\n      │ - 上下文不足       │              │ - 引入噪声       │\n      │ - 需要检索更多 chunk│              │ - 检索不精确     │\n      │ - 容易丢失关联信息  │              │ - token 预算浪费 │\n      └─────────────────┘              └─────────────────┘\n                        │              │\n                        ▼              ▼\n                   ┌─────────────────────┐\n                   │  Sweet Spot         │\n                   │  512 - 1024 tokens  │\n                   │  根据文档类型调整     │\n                   └─────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实际选择建议：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e文档类型\u003c/th\u003e\n\u003cth\u003e推荐 Chunk 大小\u003c/th\u003e\n\u003cth\u003e推荐策略\u003c/th\u003e\n\u003cth\u003e原因\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e技术文档\u003c/td\u003e\n\u003ctd\u003e512-768 tokens\u003c/td\u003e\n\u003ctd\u003e递归（按标题+段落）\u003c/td\u003e\n\u003ctd\u003e结构清晰，段落边界明确\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e法律/合同\u003c/td\u003e\n\u003ctd\u003e768-1024 tokens\u003c/td\u003e\n\u003ctd\u003e语义（按条款）\u003c/td\u003e\n\u003ctd\u003e条款不可割裂\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e代码\u003c/td\u003e\n\u003ctd\u003e按函数/类\u003c/td\u003e\n\u003ctd\u003e语义（AST 辅助）\u003c/td\u003e\n\u003ctd\u003e函数是最小可理解单元\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eFAQ\u003c/td\u003e\n\u003ctd\u003e每个 QA 一个 chunk\u003c/td\u003e\n\u003ctd\u003e自然边界\u003c/td\u003e\n\u003ctd\u003e问答对不可拆分\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e聊天记录\u003c/td\u003e\n\u003ctd\u003e256-512 tokens\u003c/td\u003e\n\u003ctd\u003e按对话轮次\u003c/td\u003e\n\u003ctd\u003e保持对话上下文\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e5. Embedding：将语义映射到向量空间\u003c/h2\u003e\n\u003ch3\u003e5.1 Embedding 模型选择\u003c/h3\u003e\n\u003cp\u003eEmbedding 模型将文本转换为高维向量，使语义相似的文本在向量空间中距离更近。选择合适的模型是基础。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e考量\u003c/th\u003e\n\u003cth\u003e建议\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e通用 vs 领域\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e通用模型覆盖面广但特定领域可能不够精确\u003c/td\u003e\n\u003ctd\u003e先用通用模型验证，数据足够后考虑微调\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e向量维度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e768 / 1024 / 1536 / 3072\u003c/td\u003e\n\u003ctd\u003e768-1024 是性价比最高的区间\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e多语言\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e中英混合场景极其常见\u003c/td\u003e\n\u003ctd\u003e必须选支持多语言的模型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e推理成本\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e高维模型索引和检索更慢\u003c/td\u003e\n\u003ctd\u003e生产环境需要 benchmark 延迟\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e关于维度选择的 Trade-off：维度越高，理论上能表示的语义越丰富——但实际收益递减明显。从 768 到 1536 的提升远小于从 384 到 768。同时，维度翻倍意味着存储翻倍、检索延迟增加。对大多数场景，\u003cstrong\u003e1024 维是一个好的默认选择\u003c/strong\u003e。\u003c/p\u003e\n\u003ch3\u003e5.2 MTEB Benchmark\u003c/h3\u003e\n\u003cp\u003e选择 Embedding 模型时，\u003ca href=\"https://huggingface.co/spaces/mteb/leaderboard\"\u003eMTEB（Massive Text Embedding Benchmark）\u003c/a\u003e 是最权威的参考。它从 Retrieval、Classification、Clustering 等多个维度评估模型能力。\u003c/p\u003e\n\u003cp\u003e但请注意：\u003cstrong\u003eMTEB 排名第一的模型不一定适合你。\u003c/strong\u003e 你需要关注：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e你的数据语言在 benchmark 中是否有代表性\u003c/li\u003e\n\u003cli\u003e模型大小是否符合你的延迟和成本要求\u003c/li\u003e\n\u003cli\u003eRetrieval 子任务的分数（而非总分）才是 RAG 场景最相关的\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e5.3 Embedding 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom typing import Protocol\n\nclass EmbeddingModel(Protocol):\n    \u0026quot;\u0026quot;\u0026quot;Embedding 模型接口抽象\u0026quot;\u0026quot;\u0026quot;\n    def embed(self, texts: list[str]) -\u0026gt; list[list[float]]:\n        ...\n\n    @property\n    def dimension(self) -\u0026gt; int:\n        ...\n\n\nclass OpenAIEmbedding:\n    \u0026quot;\u0026quot;\u0026quot;OpenAI Embedding 实现示例\u0026quot;\u0026quot;\u0026quot;\n    def __init__(self, model: str = \u0026quot;text-embedding-3-small\u0026quot;):\n        from openai import OpenAI\n        self.client = OpenAI()\n        self.model = model\n        self._dimension = 1536  # text-embedding-3-small 默认维度\n\n    def embed(self, texts: list[str]) -\u0026gt; list[list[float]]:\n        # 批量请求，减少 API 调用次数\n        response = self.client.embeddings.create(\n            model=self.model,\n            input=texts\n        )\n        return [item.embedding for item in response.data]\n\n    @property\n    def dimension(self) -\u0026gt; int:\n        return self._dimension\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键工程实践：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e批量 Embedding\u003c/strong\u003e：不要逐条调用 API，而是批量发送（通常 API 限制 2048 条/次）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e缓存\u003c/strong\u003e：相同内容不要重复 Embed，用 content hash 做缓存 key\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e归一化\u003c/strong\u003e：部分模型输出未归一化的向量，需要显式 L2 归一化后再入库，否则 cosine similarity 计算不准\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 检索策略：Hybrid Search\u003c/h2\u003e\n\u003cp\u003e检索是 RAG 的核心。单一检索策略各有盲区，生产系统几乎都采用混合检索。\u003c/p\u003e\n\u003ch3\u003e6.1 稀疏检索（BM25）\u003c/h3\u003e\n\u003cp\u003eBM25 是经典的基于词频的检索算法。它的核心思想：一个词在某篇文档中出现频率高（TF），同时在所有文档中出现频率低（IDF），则该词对该文档的重要性高。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport math\nfrom collections import Counter\n\nclass BM25:\n    \u0026quot;\u0026quot;\u0026quot;简化版 BM25 实现，展示核心原理\u0026quot;\u0026quot;\u0026quot;\n    def __init__(self, documents: list[str], k1: float = 1.5, b: float = 0.75):\n        self.k1 = k1\n        self.b = b\n        self.docs = documents\n        self.doc_count = len(documents)\n\n        # 预处理：分词 + 词频统计\n        self.doc_tokens = [doc.lower().split() for doc in documents]\n        self.doc_lengths = [len(tokens) for tokens in self.doc_tokens]\n        self.avg_dl = sum(self.doc_lengths) / self.doc_count\n\n        # IDF 预计算\n        self.idf = {}\n        df = Counter()  # 包含某词的文档数\n        for tokens in self.doc_tokens:\n            for token in set(tokens):\n                df[token] += 1\n        for token, freq in df.items():\n            self.idf[token] = math.log(\n                (self.doc_count - freq + 0.5) / (freq + 0.5) + 1\n            )\n\n    def score(self, query: str, doc_idx: int) -\u0026gt; float:\n        \u0026quot;\u0026quot;\u0026quot;计算 query 与某文档的 BM25 分数\u0026quot;\u0026quot;\u0026quot;\n        query_tokens = query.lower().split()\n        doc_tokens = self.doc_tokens[doc_idx]\n        doc_len = self.doc_lengths[doc_idx]\n        tf = Counter(doc_tokens)\n\n        score = 0.0\n        for qt in query_tokens:\n            if qt not in self.idf:\n                continue\n            term_freq = tf.get(qt, 0)\n            numerator = term_freq * (self.k1 + 1)\n            denominator = term_freq + self.k1 * (\n                1 - self.b + self.b * doc_len / self.avg_dl\n            )\n            score += self.idf[qt] * numerator / denominator\n        return score\n\n    def search(self, query: str, top_k: int = 10) -\u0026gt; list[tuple[int, float]]:\n        \u0026quot;\u0026quot;\u0026quot;返回 Top-K 结果：(文档索引, 分数)\u0026quot;\u0026quot;\u0026quot;\n        scores = [(i, self.score(query, i)) for i in range(self.doc_count)]\n        scores.sort(key=lambda x: x[1], reverse=True)\n        return scores[:top_k]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eBM25 的优势\u003c/strong\u003e：精确的关键词匹配。用户搜\u0026quot;error code 4012\u0026quot;，BM25 能精确命中包含\u0026quot;4012\u0026quot;的文档，而 Embedding 模型可能完全无法区分\u0026quot;4012\u0026quot;和\u0026quot;4013\u0026quot;。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBM25 的劣势\u003c/strong\u003e：不理解语义。用户问\u0026quot;如何提升系统吞吐量\u0026quot;，包含\u0026quot;提高 QPS\u0026quot;的文档不会被召回，因为没有词汇重叠。\u003c/p\u003e\n\u003ch3\u003e6.2 稠密检索（Vector Search）\u003c/h3\u003e\n\u003cp\u003e基于 Embedding 的向量检索，通过语义相似度匹配：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport numpy as np\n\nclass VectorSearch:\n    \u0026quot;\u0026quot;\u0026quot;基于向量的语义检索\u0026quot;\u0026quot;\u0026quot;\n    def __init__(self, embedder: EmbeddingModel):\n        self.embedder = embedder\n        self.vectors: np.ndarray | None = None\n        self.documents: list[str] = []\n\n    def index(self, documents: list[str]):\n        \u0026quot;\u0026quot;\u0026quot;构建索引\u0026quot;\u0026quot;\u0026quot;\n        self.documents = documents\n        embeddings = self.embedder.embed(documents)\n        self.vectors = np.array(embeddings)\n        # L2 归一化，使 dot product = cosine similarity\n        norms = np.linalg.norm(self.vectors, axis=1, keepdims=True)\n        self.vectors = self.vectors / norms\n\n    def search(self, query: str, top_k: int = 10) -\u0026gt; list[tuple[int, float]]:\n        \u0026quot;\u0026quot;\u0026quot;语义检索\u0026quot;\u0026quot;\u0026quot;\n        query_vec = np.array(self.embedder.embed([query])[0])\n        query_vec = query_vec / np.linalg.norm(query_vec)\n\n        # Cosine Similarity（归一化后等价于点积）\n        similarities = self.vectors @ query_vec\n        top_indices = np.argsort(similarities)[::-1][:top_k]\n        return [(int(i), float(similarities[i])) for i in top_indices]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eVector Search 的优势\u003c/strong\u003e：语义理解。\u0026quot;提升吞吐量\u0026quot;和\u0026quot;提高 QPS\u0026quot;会被映射到相近的向量空间位置。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eVector Search 的劣势\u003c/strong\u003e：对精确匹配不敏感（ID、错误码、专有名词）；向量索引的存储和计算成本较高。\u003c/p\u003e\n\u003ch3\u003e6.3 混合检索与 RRF\u003c/h3\u003e\n\u003cp\u003e混合检索结合 BM25 和 Vector Search 的结果。关键问题是：两路检索返回的分数不在同一尺度上，如何融合？\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eReciprocal Rank Fusion（RRF）\u003c/strong\u003e 是最常用的融合算法。它不关心分数的绝对值，只关心排名：\u003c/p\u003e\n\u003cp\u003e$$RRF(d) = \\sum_{r \\in R} \\frac{1}{k + rank_r(d)}$$\u003c/p\u003e\n\u003cp\u003e其中 $k$ 是常数（通常取 60），$rank_r(d)$ 是文档 $d$ 在检索源 $r$ 中的排名。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef reciprocal_rank_fusion(\n    *result_lists: list[tuple[int, float]],\n    k: int = 60\n) -\u0026gt; list[tuple[int, float]]:\n    \u0026quot;\u0026quot;\u0026quot;\n    RRF 融合多路检索结果\n\n    参数:\n        result_lists: 多路检索结果，每路是 (doc_id, score) 列表（已按 score 降序）\n        k: 平滑常数，默认 60\n\n    返回:\n        融合后的 (doc_id, rrf_score) 列表，按 rrf_score 降序\n    \u0026quot;\u0026quot;\u0026quot;\n    rrf_scores: dict[int, float] = {}\n\n    for results in result_lists:\n        for rank, (doc_id, _score) in enumerate(results):\n            # RRF 公式：只关心排名，不关心原始分数\n            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0.0) + 1.0 / (k + rank + 1)\n\n    # 按 RRF 分数降序排列\n    fused = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n    return fused\n\n\nclass HybridSearch:\n    \u0026quot;\u0026quot;\u0026quot;混合检索：BM25 + Vector + RRF\u0026quot;\u0026quot;\u0026quot;\n    def __init__(self, bm25: BM25, vector_search: VectorSearch):\n        self.bm25 = bm25\n        self.vector_search = vector_search\n\n    def search(self, query: str, top_k: int = 10, retrieve_k: int = 50) -\u0026gt; list[tuple[int, float]]:\n        \u0026quot;\u0026quot;\u0026quot;\n        混合检索\n\n        retrieve_k: 每路检索的召回数量（远大于最终 top_k，保证融合质量）\n        \u0026quot;\u0026quot;\u0026quot;\n        bm25_results = self.bm25.search(query, top_k=retrieve_k)\n        vector_results = self.vector_search.search(query, top_k=retrieve_k)\n\n        fused = reciprocal_rank_fusion(bm25_results, vector_results)\n        return fused[:top_k]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.4 检索策略对比\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e精确匹配\u003c/th\u003e\n\u003cth\u003e语义理解\u003c/th\u003e\n\u003cth\u003e专有名词/ID\u003c/th\u003e\n\u003cth\u003e同义词/意图\u003c/th\u003e\n\u003cth\u003e延迟\u003c/th\u003e\n\u003cth\u003e存储成本\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eBM25\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e弱\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e弱\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eVector\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e弱\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e弱\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eHybrid (RRF)\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e强\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e工程建议\u003c/strong\u003e：除非你非常确定场景只需要语义搜索（比如纯自然语言文档、没有 ID 和代码），否则\u003cstrong\u003e默认使用 Hybrid Search\u003c/strong\u003e。BM25 的实现成本极低，加上它获得的互补收益是巨大的。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Reranking：从召回到精排\u003c/h2\u003e\n\u003ch3\u003e7.1 为什么需要 Reranking\u003c/h3\u003e\n\u003cp\u003e初步检索（BM25 + Vector）的目标是 \u003cstrong\u003e高召回率（Recall）\u003c/strong\u003e——尽量把相关文档都捞出来。但排在前面的不一定最相关。\u003c/p\u003e\n\u003cp\u003e这就像搜索引擎的两阶段架构：第一阶段用轻量算法从亿级文档中召回 1000 条，第二阶段用重模型对 1000 条做精排，选出最终展示的 10 条。\u003c/p\u003e\n\u003cp\u003eRAG 中同样如此：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e阶段一（Retrieval）\u003c/strong\u003e：从整个知识库中召回 Top-50 或 Top-100\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e阶段二（Reranking）\u003c/strong\u003e：对这 50-100 条用更强的模型精排，选出 Top-5 送给 LLM\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.2 Bi-encoder vs Cross-encoder\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eBi-encoder（初步检索阶段）:\n┌───────────┐     ┌───────────┐\n│  Query    │     │ Document  │\n└─────┬─────┘     └─────┬─────┘\n      │                 │\n      ▼                 ▼\n┌───────────┐     ┌───────────┐\n│ Encoder   │     │ Encoder   │     独立编码\n└─────┬─────┘     └─────┬─────┘     ↓ 可以预计算\n      │                 │           ↓ 速度快\n      ▼                 ▼           ↓ 精度有限\n   vec_q            vec_d\n      │                 │\n      └───────┬─────────┘\n              ▼\n        cosine(q, d)  →  score\n\n\nCross-encoder（Reranking 阶段）:\n┌───────────────────────────────┐\n│     [CLS] Query [SEP] Doc    │    拼接在一起\n└───────────────┬───────────────┘\n                │\n                ▼\n┌───────────────────────────────┐\n│       Transformer Encoder      │    联合编码\n│      (交叉注意力)               │    ↓ 不可预计算\n└───────────────┬───────────────┘    ↓ 速度慢\n                │                    ↓ 精度高\n                ▼\n             score\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e核心区别：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBi-encoder\u003c/strong\u003e：Query 和 Document 独立编码，Document 可以离线预计算向量。速度快，适合海量候选。但无法捕捉 Query 和 Document 之间的深层交互。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCross-encoder\u003c/strong\u003e：Query 和 Document 拼接后一起送入 Transformer，模型能看到两者的每个 token 之间的注意力。精度高，但每对 (Query, Document) 都需要实时计算，速度慢。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e因此，Cross-encoder 只适合对少量候选做精排——这正是 Reranking 的定位。\u003c/p\u003e\n\u003ch3\u003e7.3 Reranking 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass\n\n@dataclass\nclass RerankResult:\n    doc_id: int\n    content: str\n    score: float\n\nclass Reranker:\n    \u0026quot;\u0026quot;\u0026quot;基于 Cross-encoder 的重排序\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, model_name: str = \u0026quot;BAAI/bge-reranker-v2-m3\u0026quot;):\n        # 实际使用时可以接入任意 Rerank 服务\n        # 这里展示 API 调用模式\n        self.model_name = model_name\n\n    def rerank(\n        self,\n        query: str,\n        documents: list[str],\n        doc_ids: list[int],\n        top_k: int = 5\n    ) -\u0026gt; list[RerankResult]:\n        \u0026quot;\u0026quot;\u0026quot;\n        对候选文档重排序\n\n        生产环境中通常调用 Rerank API（如 Cohere Rerank、Jina Rerank）\n        或本地部署 Cross-encoder 模型\n        \u0026quot;\u0026quot;\u0026quot;\n        scores = self._compute_relevance(query, documents)\n\n        # 按相关性得分降序排列\n        ranked = sorted(\n            zip(doc_ids, documents, scores),\n            key=lambda x: x[2],\n            reverse=True\n        )\n\n        return [\n            RerankResult(doc_id=did, content=doc, score=s)\n            for did, doc, s in ranked[:top_k]\n        ]\n\n    def _compute_relevance(self, query: str, documents: list[str]) -\u0026gt; list[float]:\n        \u0026quot;\u0026quot;\u0026quot;\n        计算 query 与每个 document 的相关性分数\n        实际实现会调用 Cross-encoder 模型\n        \u0026quot;\u0026quot;\u0026quot;\n        # 伪代码：真实场景替换为模型推理\n        # from sentence_transformers import CrossEncoder\n        # model = CrossEncoder(self.model_name)\n        # pairs = [(query, doc) for doc in documents]\n        # scores = model.predict(pairs)\n        # return scores.tolist()\n        raise NotImplementedError(\u0026quot;替换为实际模型调用\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eReranker 选择建议\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e精度优先\u003c/strong\u003e：Cohere Rerank、BGE Reranker v2 等专用模型\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成本优先\u003c/strong\u003e：可以用小参数量的 Cross-encoder（如 MiniLM 系列）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e延迟敏感\u003c/strong\u003e：控制候选数量（50 条以内），或使用量化版模型\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e8. Context Packing：信息如何送达 LLM\u003c/h2\u003e\n\u003cp\u003e检索和重排序完成后，拿到了 Top-K 个最相关的 chunk。接下来的问题是：如何把这些 chunk 组织到 prompt 中，让 LLM 最大化利用？\u003c/p\u003e\n\u003ch3\u003e8.1 \u0026quot;Lost in the Middle\u0026quot; 问题\u003c/h3\u003e\n\u003cp\u003eStanford 的研究（\u003ca href=\"https://arxiv.org/abs/2307.03172\"\u003eLiu et al., 2023\u003c/a\u003e）发现了一个关键现象：LLM 对 prompt 中间位置的信息利用率显著低于开头和结尾。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eLLM 对不同位置信息的利用率（示意）:\n\n利用率\n  ▲\n  │ █                                              █ █\n  │ █ █                                          █ █ █\n  │ █ █ █                                      █ █ █ █\n  │ █ █ █ █                                  █ █ █ █ █\n  │ █ █ █ █ █                              █ █ █ █ █ █\n  │ █ █ █ █ █ █ ▄ ▄ ▄ ▄ ▄ ▄ ▄ ▄ ▄ ▄ ▄ ▄ █ █ █ █ █ █\n  │ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █\n  └───────────────────────────────────────────────────→ 位置\n    开头                  中间                  结尾\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这意味着：\u003cstrong\u003e最相关的文档应该放在 prompt 的开头或结尾，而非中间。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003e8.2 Context Packing 策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef pack_context(\n    ranked_results: list[RerankResult],\n    max_tokens: int = 3000,\n    strategy: str = \u0026quot;relevance_first\u0026quot;\n) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;\n    将检索结果组织为 LLM 的上下文\n\n    策略:\n        relevance_first: 最相关的放在最前面（默认）\n        edges_first: 最相关的放开头和结尾，次相关的放中间\n    \u0026quot;\u0026quot;\u0026quot;\n    # 1. Token 预算下的截断\n    selected = []\n    current_tokens = 0\n    for result in ranked_results:\n        # 粗略估算 token 数（实际应用 tiktoken）\n        estimated_tokens = len(result.content) // 3\n        if current_tokens + estimated_tokens \u0026gt; max_tokens:\n            break\n        selected.append(result)\n        current_tokens += estimated_tokens\n\n    if not selected:\n        return \u0026quot;\u0026quot;\n\n    # 2. 根据策略决定顺序\n    if strategy == \u0026quot;edges_first\u0026quot; and len(selected) \u0026gt;= 3:\n        # 交替放置：最相关 → 最不相关 → 次相关 → 次不相关 ...\n        reordered = []\n        left, right = 0, len(selected) - 1\n        toggle = True\n        while left \u0026lt;= right:\n            if toggle:\n                reordered.append(selected[left])\n                left += 1\n            else:\n                reordered.append(selected[right])\n                right -= 1\n            toggle = not toggle\n        selected = reordered\n\n    # 3. 格式化\n    context_parts = []\n    for i, result in enumerate(selected):\n        context_parts.append(\n            f\u0026quot;[Document {i+1}] (relevance: {result.score:.3f})\\n{result.content}\u0026quot;\n        )\n\n    return \u0026quot;\\n\\n---\\n\\n\u0026quot;.join(context_parts)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.3 Token 预算管理\u003c/h3\u003e\n\u003cp\u003eLLM 的 context window 是有限的。一个典型的 prompt 结构：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────┐\n│  System Prompt        ~500 tokens       │\n├─────────────────────────────────────────┤\n│  Retrieved Context    ~3000 tokens      │  ← 这里是 Context Packing 的空间\n├─────────────────────────────────────────┤\n│  Conversation History ~1000 tokens      │\n├─────────────────────────────────────────┤\n│  User Query           ~200 tokens       │\n├─────────────────────────────────────────┤\n│  Output Reserve       ~2000 tokens      │  ← 留给模型生成\n└─────────────────────────────────────────┘\n  Total Budget:         ~6700 tokens\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eContext 部分的 token 预算 = 总 context window - system prompt - conversation history - user query - output reserve。在这个预算内，优先放入 Reranking 得分最高的 chunk，直到预算用完。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e决策要点\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e宁可少放几个 chunk、每个 chunk 完整，也不要截断 chunk 送进去——被截断的信息比没有信息更糟糕\u003c/li\u003e\n\u003cli\u003e为每个 chunk 附加来源标识（文档名、URL），方便 LLM 生成 citation\u003c/li\u003e\n\u003cli\u003e如果多个 chunk 来自同一文档的相邻位置，考虑合并后再送入，减少碎片化\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e9. RAG 评估体系\u003c/h2\u003e\n\u003cp\u003e\u0026quot;不可度量则不可改进。\u0026quot; RAG 系统的评估需要覆盖检索和生成两个维度。\u003c/p\u003e\n\u003ch3\u003e9.1 Retrieval 评估\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e指标\u003c/th\u003e\n\u003cth\u003e公式/含义\u003c/th\u003e\n\u003cth\u003e衡量什么\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRecall@K\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e在 Top-K 结果中，相关文档被召回的比例\u003c/td\u003e\n\u003ctd\u003e检索的完整性\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eMRR\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e第一个相关文档的排名的倒数，取平均\u003c/td\u003e\n\u003ctd\u003e用户需要翻多远才能看到答案\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eNDCG@K\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e考虑位置权重的相关性评分（越靠前权重越高）\u003c/td\u003e\n\u003ctd\u003e排序质量\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef recall_at_k(relevant_ids: set[int], retrieved_ids: list[int], k: int) -\u0026gt; float:\n    \u0026quot;\u0026quot;\u0026quot;Recall@K: Top-K 中召回了多少相关文档\u0026quot;\u0026quot;\u0026quot;\n    retrieved_set = set(retrieved_ids[:k])\n    if not relevant_ids:\n        return 0.0\n    return len(relevant_ids \u0026amp; retrieved_set) / len(relevant_ids)\n\n\ndef mrr(relevant_ids: set[int], retrieved_ids: list[int]) -\u0026gt; float:\n    \u0026quot;\u0026quot;\u0026quot;MRR: 第一个相关结果的排名倒数\u0026quot;\u0026quot;\u0026quot;\n    for rank, doc_id in enumerate(retrieved_ids, start=1):\n        if doc_id in relevant_ids:\n            return 1.0 / rank\n    return 0.0\n\n\ndef ndcg_at_k(relevance_scores: list[int], k: int) -\u0026gt; float:\n    \u0026quot;\u0026quot;\u0026quot;\n    NDCG@K: 归一化折损累积增益\n\n    relevance_scores: 按检索排序的相关性评分列表（如 0/1/2/3）\n    \u0026quot;\u0026quot;\u0026quot;\n    import math\n\n    def dcg(scores: list[int], k: int) -\u0026gt; float:\n        return sum(\n            score / math.log2(rank + 2)  # rank 从 0 开始，log2(1) = 0 所以 +2\n            for rank, score in enumerate(scores[:k])\n        )\n\n    actual_dcg = dcg(relevance_scores, k)\n    ideal_dcg = dcg(sorted(relevance_scores, reverse=True), k)\n\n    return actual_dcg / ideal_dcg if ideal_dcg \u0026gt; 0 else 0.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e9.2 Generation 评估\u003c/h3\u003e\n\u003cp\u003e检索质量好不意味着生成质量好。Generation 阶段需要评估：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e指标\u003c/th\u003e\n\u003cth\u003e衡量什么\u003c/th\u003e\n\u003cth\u003e检测方式\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFaithfulness\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e回答是否忠于检索到的上下文（不编造）\u003c/td\u003e\n\u003ctd\u003e检查回答中的每个声明是否有 context 支撑\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAnswer Relevancy\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e回答是否与用户问题相关\u003c/td\u003e\n\u003ctd\u003e生成反向问题，比较与原问题的相似度\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eContext Relevancy\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e检索到的上下文是否与问题相关\u003c/td\u003e\n\u003ctd\u003e评估 context 中有多少内容是回答问题所需的\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e这三个指标构成了 RAG 质量的 \u0026quot;Triad\u0026quot;：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌─────────────┐\n                    │   Query     │\n                    └──────┬──────┘\n                           │\n              ┌────────────┼────────────┐\n              │                         │\n              ▼                         ▼\n     ┌────────────────┐       ┌────────────────┐\n     │   Context      │       │   Answer       │\n     │  (Retrieved)   │       │  (Generated)   │\n     └────────┬───────┘       └────────┬───────┘\n              │                        │\n              │    ┌──────────────┐    │\n              └───→│ Faithfulness │←───┘\n                   └──────────────┘\n\n     Query ↔ Context  = Context Relevancy\n     Query ↔ Answer   = Answer Relevancy\n     Context ↔ Answer = Faithfulness\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e9.3 RAGAS 框架\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://docs.ragas.io/\"\u003eRAGAS（Retrieval Augmented Generation Assessment）\u003c/a\u003e 是目前最流行的端到端 RAG 评估框架，它自动化评估上述指标：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# RAGAS 评估示意（伪代码）\ndef evaluate_rag_pipeline(test_cases: list[dict]) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;\n    每个 test_case 包含:\n        - question: 用户问题\n        - ground_truth: 标准答案（人工标注）\n        - retrieved_contexts: 检索到的上下文\n        - generated_answer: RAG 系统生成的答案\n    \u0026quot;\u0026quot;\u0026quot;\n    metrics = {\n        \u0026quot;faithfulness\u0026quot;: [],       # 回答是否忠于 context\n        \u0026quot;answer_relevancy\u0026quot;: [],   # 回答是否切题\n        \u0026quot;context_relevancy\u0026quot;: [],  # context 是否相关\n        \u0026quot;context_recall\u0026quot;: [],     # context 是否覆盖了 ground truth 的信息\n    }\n\n    for case in test_cases:\n        # Faithfulness: 把 answer 拆成多个 statement，\n        # 逐一检查每个 statement 是否能从 context 中推导出来\n        metrics[\u0026quot;faithfulness\u0026quot;].append(\n            check_faithfulness(case[\u0026quot;generated_answer\u0026quot;], case[\u0026quot;retrieved_contexts\u0026quot;])\n        )\n\n        # Answer Relevancy: 从 answer 反向生成问题，\n        # 计算生成的问题与原始 question 的语义相似度\n        metrics[\u0026quot;answer_relevancy\u0026quot;].append(\n            check_answer_relevancy(case[\u0026quot;question\u0026quot;], case[\u0026quot;generated_answer\u0026quot;])\n        )\n\n        # Context Relevancy: 评估 context 中有多少句子是回答问题所需的\n        metrics[\u0026quot;context_relevancy\u0026quot;].append(\n            check_context_relevancy(case[\u0026quot;question\u0026quot;], case[\u0026quot;retrieved_contexts\u0026quot;])\n        )\n\n        # Context Recall: 对照 ground truth，检查 context 是否包含了必要的信息\n        metrics[\u0026quot;context_recall\u0026quot;].append(\n            check_context_recall(case[\u0026quot;ground_truth\u0026quot;], case[\u0026quot;retrieved_contexts\u0026quot;])\n        )\n\n    return {k: sum(v) / len(v) for k, v in metrics.items()}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e实际操作建议\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e构建 50-100 条高质量的评估数据集（question + ground_truth），这是最值得投入的工作\u003c/li\u003e\n\u003cli\u003e每次修改 Pipeline（换 Embedding、调 Chunking、加 Reranker）后跑一轮评估\u003c/li\u003e\n\u003cli\u003e关注指标的变化方向，而非绝对数值——不同数据集上的绝对分数不可比\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 常见问题与优化\u003c/h2\u003e\n\u003ch3\u003e10.1 检索不到相关内容\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e症状\u003c/strong\u003e：知识库中明明有答案，但检索结果中找不到。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e原因分析\u003c/strong\u003e：用户的 Query 和知识库中的表述方式差异太大。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e优化手段\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eQuery Expansion（查询扩展）\u003c/strong\u003e：将用户的短 Query 扩展为多个变体，增加召回率：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef expand_query(query: str, llm_call) -\u0026gt; list[str]:\n    \u0026quot;\u0026quot;\u0026quot;用 LLM 扩展查询，生成多个语义等价的变体\u0026quot;\u0026quot;\u0026quot;\n    prompt = f\u0026quot;\u0026quot;\u0026quot;Given the search query: \u0026quot;{query}\u0026quot;\n\nGenerate 3 alternative phrasings that express the same intent but use different words.\nReturn each variant on a new line, without numbering.\u0026quot;\u0026quot;\u0026quot;\n\n    variants = llm_call(prompt).strip().split(\u0026quot;\\n\u0026quot;)\n    return [query] + [v.strip() for v in variants if v.strip()]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eHyDE（Hypothetical Document Embeddings）\u003c/strong\u003e：先让 LLM 生成一个\u0026quot;假想答案\u0026quot;，用这个答案的 Embedding 去检索，而不是用 Query 的 Embedding。直觉上，答案和知识库中的文档更\u0026quot;长得像\u0026quot;：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef hyde_search(query: str, llm_call, vector_search: VectorSearch, top_k: int = 10):\n    \u0026quot;\u0026quot;\u0026quot;HyDE: 用假想答案的 Embedding 检索\u0026quot;\u0026quot;\u0026quot;\n    # 1. 让 LLM 生成假想答案（不需要准确，只需要\u0026quot;像\u0026quot;真正的文档）\n    hypothetical_doc = llm_call(\n        f\u0026quot;Please write a short passage that answers the following question: {query}\u0026quot;\n    )\n\n    # 2. 用假想答案的 Embedding 检索（而非 Query 的 Embedding）\n    results = vector_search.search(hypothetical_doc, top_k=top_k)\n    return results\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHyDE 的 trade-off：增加了一次 LLM 调用的延迟和成本，但对检索质量的提升在某些场景下非常显著（尤其是短 Query 场景）。\u003c/p\u003e\n\u003ch3\u003e10.2 检索到了但 LLM 没用上\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e症状\u003c/strong\u003e：检索结果中包含正确答案，但 LLM 的回答忽略了它或回答错误。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e原因分析\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eContext 太长，答案被\u0026quot;淹没\u0026quot;在噪声中（Lost in the Middle）\u003c/li\u003e\n\u003cli\u003e多个 chunk 包含矛盾信息，LLM 困惑了\u003c/li\u003e\n\u003cli\u003ePrompt 没有明确指示 LLM \u0026quot;基于以下上下文回答\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e优化手段\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e减少送入的 chunk 数量，只保留 Top-3 而非 Top-10\u003c/li\u003e\n\u003cli\u003e使用 Reranker 提高 Top-K 的精度\u003c/li\u003e\n\u003cli\u003e在 System Prompt 中明确要求：只基于提供的上下文回答，如果上下文不足以回答则明确说明\u003c/li\u003e\n\u003cli\u003e应用 \u0026quot;edges_first\u0026quot; 排布策略（见 8.2 节）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e10.3 幻觉问题\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e症状\u003c/strong\u003e：LLM 编造了上下文中不存在的信息。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e优化手段\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCitation（引用标注）\u003c/strong\u003e：要求 LLM 在回答中标注每个声明的来源：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eCITATION_PROMPT = \u0026quot;\u0026quot;\u0026quot;Based on the provided context, answer the user\u0026#39;s question.\n\nRules:\n1. Only use information from the provided context\n2. For each statement in your answer, add a citation like [Doc 1], [Doc 2]\n3. If the context does not contain enough information, say \u0026quot;I don\u0026#39;t have enough information to answer this\u0026quot;\n4. Never make up information not present in the context\n\nContext:\n{context}\n\nQuestion: {question}\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eGrounding Check（落地检查）\u003c/strong\u003e：生成回答后，用另一次 LLM 调用验证回答中的每个声明是否有上下文支撑。成本高，但在高可靠性场景（医疗、法律、金融）中是必要的。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e11. 完整 Pipeline 集成\u003c/h2\u003e\n\u003cp\u003e将上述所有模块串联起来：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass RAGPipeline:\n    \u0026quot;\u0026quot;\u0026quot;完整的 RAG Pipeline\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(\n        self,\n        embedder: EmbeddingModel,\n        reranker: Reranker,\n        llm_call,  # (prompt: str) -\u0026gt; str\n        chunk_size: int = 512,\n        chunk_overlap: int = 64,\n        retrieve_k: int = 50,\n        rerank_k: int = 5,\n        max_context_tokens: int = 3000,\n    ):\n        self.embedder = embedder\n        self.reranker = reranker\n        self.llm_call = llm_call\n        self.chunk_size = chunk_size\n        self.chunk_overlap = chunk_overlap\n        self.retrieve_k = retrieve_k\n        self.rerank_k = rerank_k\n        self.max_context_tokens = max_context_tokens\n\n        self.bm25: BM25 | None = None\n        self.vector_search = VectorSearch(embedder)\n        self.chunks: list[str] = []\n\n    # ─── Offline: Indexing ───\n\n    def ingest(self, documents: list[Document]):\n        \u0026quot;\u0026quot;\u0026quot;离线索引：文档 → Chunk → Embedding → 索引\u0026quot;\u0026quot;\u0026quot;\n        # 1. Chunking\n        self.chunks = []\n        for doc in documents:\n            cleaned = preprocess(doc.content)\n            doc_chunks = recursive_chunk(cleaned, self.chunk_size)\n            self.chunks.extend(doc_chunks)\n\n        # 2. 构建双路索引\n        self.bm25 = BM25(self.chunks)\n        self.vector_search.index(self.chunks)\n\n        print(f\u0026quot;Indexed {len(documents)} documents → {len(self.chunks)} chunks\u0026quot;)\n\n    # ─── Online: Query ───\n\n    def query(self, question: str) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;在线查询：Query → 检索 → 重排 → 生成\u0026quot;\u0026quot;\u0026quot;\n        assert self.bm25 is not None, \u0026quot;Must call ingest() first\u0026quot;\n\n        # 1. Hybrid Search\n        hybrid = HybridSearch(self.bm25, self.vector_search)\n        retrieval_results = hybrid.search(question, top_k=self.retrieve_k)\n\n        # 2. Reranking\n        candidate_ids = [doc_id for doc_id, _ in retrieval_results]\n        candidate_docs = [self.chunks[doc_id] for doc_id in candidate_ids]\n        reranked = self.reranker.rerank(\n            query=question,\n            documents=candidate_docs,\n            doc_ids=candidate_ids,\n            top_k=self.rerank_k,\n        )\n\n        # 3. Context Packing\n        context = pack_context(reranked, max_tokens=self.max_context_tokens)\n\n        # 4. LLM Generation\n        prompt = CITATION_PROMPT.format(context=context, question=question)\n        answer = self.llm_call(prompt)\n\n        return answer\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码不到 50 行，但串联了 RAG 的所有核心环节。每个环节都可以独立替换和优化——这就是模块化设计的价值。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e12. 工程决策速查表\u003c/h2\u003e\n\u003cp\u003e最后，总结 RAG 系统中的关键工程决策：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e决策点\u003c/th\u003e\n\u003cth\u003e推荐默认值\u003c/th\u003e\n\u003cth\u003e何时调整\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eChunk 大小\u003c/td\u003e\n\u003ctd\u003e512 tokens\u003c/td\u003e\n\u003ctd\u003e法律/长文档增大；FAQ 减小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eChunk 重叠\u003c/td\u003e\n\u003ctd\u003e10-20% of chunk size\u003c/td\u003e\n\u003ctd\u003e语义边界切分时可减少\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEmbedding 维度\u003c/td\u003e\n\u003ctd\u003e1024\u003c/td\u003e\n\u003ctd\u003e存储/延迟敏感时降低\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e检索策略\u003c/td\u003e\n\u003ctd\u003eHybrid (BM25 + Vector)\u003c/td\u003e\n\u003ctd\u003e纯自然语言场景可只用 Vector\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e初步召回数量\u003c/td\u003e\n\u003ctd\u003e50\u003c/td\u003e\n\u003ctd\u003e知识库很大时增加\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRerank Top-K\u003c/td\u003e\n\u003ctd\u003e5\u003c/td\u003e\n\u003ctd\u003eLLM context window 大时可增加\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eContext 排布\u003c/td\u003e\n\u003ctd\u003erelevance_first\u003c/td\u003e\n\u003ctd\u003e上下文很长时用 edges_first\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e融合算法\u003c/td\u003e\n\u003ctd\u003eRRF (k=60)\u003c/td\u003e\n\u003ctd\u003e需要调权时切换加权融合\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e13. 结语与下一步\u003c/h2\u003e\n\u003cp\u003eRAG 给 Agent 提供了 \u003cstrong\u003e\u0026quot;知识\u0026quot;维度的能力\u003c/strong\u003e——让 Agent 不再局限于训练数据，能够接入外部的、实时的、私有的信息。但回过头来看，RAG 本质上是一个\u003cstrong\u003e信息检索工程问题\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e不是模型越大越好，而是\u003cstrong\u003e检索越准越好\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e不是 chunk 越多越好，而是\u003cstrong\u003e信噪比越高越好\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e不是 pipeline 越复杂越好，而是\u003cstrong\u003e每个环节都要可度量、可调优\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在 Agent 架构中，RAG 是 Memory 子系统的核心组件。它回答的是\u0026quot;Agent 知道什么\u0026quot;的问题。但 Agent 光有知识不够——它还需要知道 \u003cstrong\u003e\u0026quot;怎么做\u0026quot;\u003c/strong\u003e（Planning）和 \u003cstrong\u003e\u0026quot;做得对不对\u0026quot;\u003c/strong\u003e（Reflection）。\u003c/p\u003e\n\u003cp\u003e下一篇，我们将进入 Agent 智能的另一个关键维度：\u003cstrong\u003ePlanning and Reflection——从 ReAct 到分层规划与自我纠错。\u003c/strong\u003e 一个能规划、能反思的 Agent，才是真正有\u0026quot;智能\u0026quot;的 Agent。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 09 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/08-Memory%20Architecture\"\u003e08 | Memory Architecture\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/10-Planning%20and%20Reflection\"\u003e10 | Planning and Reflection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"18:T51ba,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e微服务架构的核心难题不是技术选型，而是\u003cstrong\u003e如何找到正确的服务边界\u003c/strong\u003e。拆分得太粗，和单体无异；拆分得太细，分布式的复杂性会吞噬所有收益。领域驱动设计（DDD）提供了一套系统性的方法论，帮助我们从业务本质出发，找到合理的拆分边界。本文将从 DDD 的核心概念出发，结合电商领域的实例，完整展示如何基于 DDD 构建微服务。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e微服务的本质：不是\u0026quot;小\u0026quot;，而是\u0026quot;界限清晰\u0026quot;\u003c/h2\u003e\n\u003cp\u003e微服务中的\u0026quot;微\u0026quot;虽然表示服务的规模，但它并不是微服务架构的核心标准。Adrian Cockcroft 对微服务有一个精炼的定义：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026quot;面向服务的架构由具有\u003cstrong\u003e界限上下文\u003c/strong\u003e、\u003cstrong\u003e松散耦合\u003c/strong\u003e的元素组成。\u0026quot;\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e一个真正的微服务架构应当具备以下特征：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e特征\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e业务边界清晰\u003c/td\u003e\n\u003ctd\u003e服务以业务上下文为中心，而非技术抽象\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e实现细节隐藏\u003c/td\u003e\n\u003ctd\u003e通过意图接口暴露功能，不泄露内部实现\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e数据独立\u003c/td\u003e\n\u003ctd\u003e服务不共享数据库，每个服务拥有自己的数据存储\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e故障快速恢复\u003c/td\u003e\n\u003ctd\u003e具备容错和弹性能力\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e独立部署\u003c/td\u003e\n\u003ctd\u003e团队可以自主、频繁地发布变更\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e自动化文化\u003c/td\u003e\n\u003ctd\u003e自动化测试、持续集成、持续交付\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e归纳起来：\u003cstrong\u003e松散耦合的面向服务架构，每个服务封装在定义良好的界限上下文中，支持快速、频繁且可靠的交付。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e微服务的强大之处在于：\u003cstrong\u003e边界内建立高内聚，边界外建立低耦合\u003c/strong\u003e——倾向于一起改变的事物应该放在一起。但说起来容易做起来难，业务在不断发展，设想也随之改变。因此，\u003cstrong\u003e重构能力\u003c/strong\u003e是设计系统时必须考虑的关键问题。\u003c/p\u003e\n\u003ch2\u003eDDD 核心概念速览\u003c/h2\u003e\n\u003cp\u003e领域驱动设计（Domain-Driven Design）因 Eric Evans 的同名著作而闻名，它是一组思想、原则和模式，帮助我们基于业务领域的底层模型来设计软件系统。\u003c/p\u003e\n\u003ch3\u003e基本术语\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e概念\u003c/th\u003e\n\u003cth\u003e定义\u003c/th\u003e\n\u003cth\u003e示例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e领域（Domain）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e组织所从事的业务范围\u003c/td\u003e\n\u003ctd\u003e零售、电子商务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e子域（Subdomain）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e领域下的业务单元，一个领域由多个子域组成\u003c/td\u003e\n\u003ctd\u003e目录、购物车、履约、支付\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e统一语言（Ubiquitous Language）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e开发人员与领域专家共同使用的、表达业务模型的语言\u003c/td\u003e\n\u003ctd\u003e\u0026quot;商品\u0026quot;、\u0026quot;订单\u0026quot;、\u0026quot;履约\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e界限上下文（Bounded Context）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e模型的有效边界，同一术语在不同上下文中含义不同\u003c/td\u003e\n\u003ctd\u003e见下文详述\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e界限上下文：同一个词，不同的含义\u003c/h3\u003e\n\u003cp\u003e以电商系统中的 \u003cstrong\u003e\u0026quot;Item\u0026quot;（商品）\u003c/strong\u003e 为例，它在不同的上下文中有着截然不同的含义：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e上下文\u003c/th\u003e\n\u003cth\u003e\u0026quot;Item\u0026quot; 的含义\u003c/th\u003e\n\u003cth\u003e关注的属性\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eCatalog（目录）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e可出售的产品\u003c/td\u003e\n\u003ctd\u003e名称、描述、价格、图片、分类\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eCart（购物车）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e客户添加到购物车的商品选项\u003c/td\u003e\n\u003ctd\u003eSKU、数量、选中状态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFulfillment（履约）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e将要运送给客户的仓库物料\u003c/td\u003e\n\u003ctd\u003e仓库位置、重量、物流单号\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e通过将这些模型分离并隔离在各自的边界内，我们可以自由地表达这些模型而不产生歧义。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e子域 vs 界限上下文\u003c/strong\u003e：子域属于\u003cstrong\u003e问题空间\u003c/strong\u003e（业务如何看待问题），界限上下文属于\u003cstrong\u003e解决方案空间\u003c/strong\u003e（如何实现问题的解决方案）。理论上一个子域可以有多个界限上下文，但我们努力做到每个子域只有一个。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e从界限上下文到微服务\u003c/h2\u003e\n\u003ch3\u003e界限上下文 ≠ 微服务\u003c/h3\u003e\n\u003cp\u003e每个界限上下文都能直接映射为一个微服务吗？\u003cstrong\u003e不一定\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e以\u0026quot;定价\u0026quot;界限上下文为例，它可能包含三个不同的模型：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e模型（聚合）\u003c/th\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ePrice（价格）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e管理目录商品的价格\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ePriced Items（定价项）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e计算商品列表的总价\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eDiscounts（折扣）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e管理和应用各类折扣规则\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e如果把这三个模型放在一个服务中，随着时间推移，界限可能变得模糊，职责开始重叠，最终退化为\u0026quot;大泥球\u0026quot;。\u003c/p\u003e\n\u003ch3\u003e聚合（Aggregate）：更精细的拆分单元\u003c/h3\u003e\n\u003cp\u003eDDD 中的\u003cstrong\u003e聚合\u003c/strong\u003e是由相关模型组成的自包含单元，是\u003cstrong\u003e数据变更的原子边界\u003c/strong\u003e。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e聚合是关联对象的集群，被视为数据变更的单元。外部引用仅限于指定聚合的一个成员——\u003cstrong\u003e聚合根（Aggregate Root）\u003c/strong\u003e。在聚合的边界内需应用一组一致性规则。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e聚合的核心约束：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e一致性在单个聚合内保证\u003c/strong\u003e：跨聚合的一致性只能做到最终一致\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e只能通过已发布的接口修改聚合\u003c/strong\u003e：外部不能绕过聚合根直接操作内部对象\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e任何违反这些规则的行为都有让应用退化为大泥球的风险\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e拆分策略：从保守到激进\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e策略\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003cth\u003e优势\u003c/th\u003e\n\u003cth\u003e风险\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e一个界限上下文 = 一个微服务\u003c/td\u003e\n\u003ctd\u003e领域模糊、业务初期\u003c/td\u003e\n\u003ctd\u003e保守安全，避免过早拆分\u003c/td\u003e\n\u003ctd\u003e服务可能过大\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一个聚合 = 一个微服务\u003c/td\u003e\n\u003ctd\u003e领域清晰、边界确定\u003c/td\u003e\n\u003ctd\u003e粒度精细，独立演进\u003c/td\u003e\n\u003ctd\u003e分布式复杂度高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e一个界限上下文 = 多个微服务\u003c/td\u003e\n\u003ctd\u003e上下文内聚合边界清晰\u003c/td\u003e\n\u003ctd\u003e兼顾灵活与可控\u003c/td\u003e\n\u003ctd\u003e需要精确的聚合划分\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e对于不完全了解的业务领域，建议从\u003cstrong\u003e保守策略\u003c/strong\u003e开始：将整个界限上下文及其聚合组成单个微服务。确保聚合之间通过接口充分隔离，后续再拆分的成本会低得多。\u003cstrong\u003e将两个微服务合并为一个的成本远高于将一个微服务拆分为两个\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e上下文映射：精确划分服务边界\u003c/h2\u003e\n\u003cp\u003e上下文映射（Context Mapping）用于识别和定义各种界限上下文和聚合之间的关系。它帮助我们回答一个关键问题：\u003cstrong\u003e这些服务之间应该如何协作？\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003e一个错误的设计示例\u003c/h3\u003e\n\u003cp\u003e以电商支付场景为例，假设有三个服务都需要处理支付：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e服务\u003c/th\u003e\n\u003cth\u003e支付相关操作\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e购物车服务\u003c/td\u003e\n\u003ctd\u003e在线支付授权\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e订单服务\u003c/td\u003e\n\u003ctd\u003e订单履约后结算\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e联络中心服务\u003c/td\u003e\n\u003ctd\u003e支付重试、变更支付方式\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e如果每个服务都内嵌支付聚合并直接对接支付网关，会产生严重问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e一致性不可保证\u003c/strong\u003e：支付聚合分散在多个服务中，无法强制执行不变性\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e并发冲突\u003c/strong\u003e：联络中心更改支付方式时，订单服务可能正在用旧方式结算\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e变更扩散\u003c/strong\u003e：支付网关的任何变更都要改动多个服务、多个团队\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e重新定义服务边界\u003c/h3\u003e\n\u003cp\u003e通过上下文映射，将支付聚合收拢到一个独立的\u003cstrong\u003e支付服务\u003c/strong\u003e中：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e改造项\u003c/th\u003e\n\u003cth\u003e说明\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e支付服务独立\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e支付聚合有了专属的界限上下文，不变量在单个服务边界内管理\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e反腐层（ACL）\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e在支付服务和支付网关之间加入适配层，隔离核心领域模型与第三方数据模型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e购物车→支付\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e同步 API 调用，因为下单时需要即时的支付授权反馈\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e订单→支付\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e异步事件驱动，订单服务发出域事件，支付服务监听并完成结算\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e联络中心→支付\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e异步事件驱动，变更支付方式时发出事件，支付服务撤销旧卡、处理新卡\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e核心原则：\u003cstrong\u003e微服务架构的成败取决于聚合之间的低耦合以及聚合之内的高内聚。\u003c/strong\u003e\u003c/p\u003e\n\u003ch2\u003e事件风暴：协作式的服务边界发现\u003c/h2\u003e\n\u003cp\u003e事件风暴（Event Storming）是 Alberto Brandolini 提出的一种轻量级的协作建模技术，它是识别聚合和微服务边界的另一种必不可少的工具。\u003c/p\u003e\n\u003ch3\u003e什么是事件风暴？\u003c/h3\u003e\n\u003cp\u003e简单来说，事件风暴是团队在一起进行的头脑风暴，目标是识别系统中发生的各种\u003cstrong\u003e领域事件\u003c/strong\u003e和\u003cstrong\u003e业务流程\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e工作方式：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e所有相关团队在同一个房间（物理或虚拟）\u003c/li\u003e\n\u003cli\u003e在白板上用不同颜色的便利贴标记事件、命令、聚合和策略\u003c/li\u003e\n\u003cli\u003e识别重叠概念、模糊的领域语言和冲突的业务流程\u003c/li\u003e\n\u003cli\u003e对相关模型进行分组，重新定义聚合边界\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e便利贴颜色约定\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e颜色\u003c/th\u003e\n\u003cth\u003e含义\u003c/th\u003e\n\u003cth\u003e示例\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e橙色\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e领域事件\u003c/strong\u003e（已发生的事实）\u003c/td\u003e\n\u003ctd\u003e\u0026quot;订单已创建\u0026quot;、\u0026quot;支付已完成\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e蓝色\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e命令\u003c/strong\u003e（触发事件的动作）\u003c/td\u003e\n\u003ctd\u003e\u0026quot;创建订单\u0026quot;、\u0026quot;取消订单\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e黄色\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e聚合\u003c/strong\u003e（命令作用的对象）\u003c/td\u003e\n\u003ctd\u003e\u0026quot;订单\u0026quot;、\u0026quot;支付\u0026quot;、\u0026quot;库存\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e紫色\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e策略/规则\u003c/strong\u003e（事件触发的后续逻辑）\u003c/td\u003e\n\u003ctd\u003e\u0026quot;支付完成后发送确认邮件\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e红色\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e热点/问题\u003c/strong\u003e（需要讨论的疑问）\u003c/td\u003e\n\u003ctd\u003e\u0026quot;退款流程和订单取消是否耦合？\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e事件风暴的产出\u003c/h3\u003e\n\u003cp\u003e一次成功的事件风暴通常会产出：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e重新定义的聚合列表\u003c/strong\u003e：这些可能成为新的微服务\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e领域事件清单\u003c/strong\u003e：需要在微服务之间流动的事件\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e命令清单\u003c/strong\u003e：外部用户或其他服务直接调用的操作\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e团队共识\u003c/strong\u003e：对领域、统一语言和精确服务边界的共同理解\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e微服务间的通信：拥抱最终一致性\u003c/h2\u003e\n\u003ch3\u003e从单体到微服务的一致性挑战\u003c/h3\u003e\n\u003cp\u003e在单体应用中，多个聚合在同一个进程边界内，可以在一个事务中完成：客户下单 → 扣减库存 → 发送邮件。所有操作要么都成功，要么都失败。\u003c/p\u003e\n\u003cp\u003e但微服务化后，这些聚合分散到了不同的分布式系统中。根据 \u003cstrong\u003eCAP 定理\u003c/strong\u003e：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个分布式系统只能同时满足三个特性中的两个：\u003cstrong\u003e一致性（C）\u003c/strong\u003e、\u003cstrong\u003e可用性（A）\u003c/strong\u003e、\u003cstrong\u003e分区容错（P）\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e在现实系统中，分区容错（P）是不可协商的——网络不可靠、虚拟机可以宕机、区域延迟可能恶化。因此我们只能在\u003cstrong\u003e可用性\u003c/strong\u003e和\u003cstrong\u003e一致性\u003c/strong\u003e之间选择。而在现代互联网应用中，牺牲可用性通常也不可接受。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e结论：基于最终一致性设计应用程序。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3\u003e事件驱动架构\u003c/h3\u003e\n\u003cp\u003e微服务可以将聚合上发生的重要变更以\u003cstrong\u003e领域事件（Domain Event）\u003c/strong\u003e 的形式发出，感兴趣的服务监听这些事件并在自己的领域内执行相应操作。\u003c/p\u003e\n\u003cp\u003e以\u0026quot;订单取消\u0026quot;为例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e订单服务发布事件：OrderCancelled\n  → 支付服务监听 → 执行退款\n  → 库存服务监听 → 调整商品库存\n  → 通知服务监听 → 发送取消确认邮件\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这种方式避免了两种耦合：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e耦合类型\u003c/th\u003e\n\u003cth\u003e事件驱动如何避免\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e行为耦合\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e一个领域无需规定其他领域应该做什么\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e时间耦合\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e一个流程的完成不依赖于所有系统同时可用\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e事件驱动的可靠性保障\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e角色\u003c/th\u003e\n\u003cth\u003e保障措施\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e生产者\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e确保事件\u003cstrong\u003e至少发出一次\u003c/strong\u003e（At Least Once），失败时有回退机制重新触发\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e消费者\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e以\u003cstrong\u003e幂等方式\u003c/strong\u003e消费事件，同一事件重复到达不产生副作用\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e事件排序\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e事件可能乱序到达，消费者用时间戳或版本号保证正确性\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e何时仍需同步调用？\u003c/h3\u003e\n\u003cp\u003e并非所有场景都适合事件驱动。当需要\u003cstrong\u003e即时反馈\u003c/strong\u003e时（如购物车→支付授权），仍需同步 API 调用。但要注意：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e同步调用引入了\u003cstrong\u003e行为耦合\u003c/strong\u003e和\u003cstrong\u003e时间耦合\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e被调用服务不可用时，调用方也会受影响\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e缓解策略\u003c/strong\u003e：同步调用作为主路径，辅以基于事件或批处理的异步重试作为降级方案。在用户体验、系统弹性和运营成本之间做好权衡。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e何时应该合并而非拆分？\u003c/strong\u003e 如果发现两个聚合之间需要强 ACID 事务，这是一个强烈的信号——它们可能应该属于同一个聚合。在拆分之前，事件风暴和上下文映射可以帮助我们及早识别这些依赖关系。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003eBFF 模式：解耦前端与领域服务\u003c/h2\u003e\n\u003ch3\u003e问题：服务为了迎合调用者而变形\u003c/h3\u003e\n\u003cp\u003e微服务架构中一个常见的反模式是：\u003cstrong\u003e域服务为了满足前端的特定数据需求而编排其他服务\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e以\u0026quot;订单详情页\u0026quot;为例，页面需要同时展示订单信息和退款信息。如果让订单服务调用退款服务来组装复合响应：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e订单服务的自治性降低：退款聚合的变更会影响订单服务\u003c/li\u003e\n\u003cli\u003e增加故障点：退款服务宕机时订单服务也受影响\u003c/li\u003e\n\u003cli\u003e变更成本高：前端需求变化时需要两个团队同时改动\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e解决方案：Backend for Frontends（BFF）\u003c/h3\u003e\n\u003cp\u003eBFF 是由\u003cstrong\u003e消费者团队\u003c/strong\u003e（前端团队）创建和维护的后端服务，负责：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e对多个域服务进行集成和编排\u003c/li\u003e\n\u003cli\u003e为前端提供定制化的数据契约\u003c/li\u003e\n\u003cli\u003e根据不同终端（Web/Mobile）优化响应格式和体积\u003c/li\u003e\n\u003c/ul\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e对比\u003c/th\u003e\n\u003cth\u003e无 BFF\u003c/th\u003e\n\u003cth\u003e有 BFF\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e数据编排\u003c/td\u003e\n\u003ctd\u003e域服务互相调用，或前端直接调多个服务\u003c/td\u003e\n\u003ctd\u003eBFF 统一编排，域服务保持纯粹\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e变更自主性\u003c/td\u003e\n\u003ctd\u003e前端需求变化要改多个域服务\u003c/td\u003e\n\u003ctd\u003e前端团队自主改 BFF\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e性能优化\u003c/td\u003e\n\u003ctd\u003e移动端可能获取过多冗余数据\u003c/td\u003e\n\u003ctd\u003e可按终端定制负载大小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e技术选型\u003c/td\u003e\n\u003ctd\u003e受域服务 API 限制\u003c/td\u003e\n\u003ctd\u003eBFF 可采用 GraphQL 等灵活方案\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e尽早构建 BFF 服务\u003c/strong\u003e，可以避免两种不良后果：域服务被迫支持跨域编排，或前端不得不直接调用多个后端服务。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e从单体到微服务：拆分路线图\u003c/h2\u003e\n\u003cp\u003e将以上所有工具整合，从单体拆分到微服务的推荐路径：\u003c/p\u003e\n\u003ch3\u003e第一步：战略设计（Strategic Design）\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e识别子域\u003c/strong\u003e：与领域专家一起梳理业务，划分子域\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e定义界限上下文\u003c/strong\u003e：为每个子域确定解决方案的边界\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e建立统一语言\u003c/strong\u003e：在每个上下文内建立一致的业务术语\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e第二步：战术发现（Tactical Discovery）\u003c/h3\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e\u003cstrong\u003e事件风暴\u003c/strong\u003e：跨团队协作，识别领域事件、命令、聚合和热点问题\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e上下文映射\u003c/strong\u003e：绘制上下文之间的依赖关系和协作模式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e识别聚合\u003c/strong\u003e：在每个上下文内找到自包含的数据变更单元\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e第三步：服务划分（Service Decomposition）\u003c/h3\u003e\n\u003col start=\"7\"\u003e\n\u003cli\u003e\u003cstrong\u003e确定服务边界\u003c/strong\u003e：根据聚合和上下文映射，确定每个微服务的边界\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e设计通信方式\u003c/strong\u003e：区分同步调用和异步事件，优先使用事件驱动\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e规划 BFF 层\u003c/strong\u003e：为不同终端设计专属的后端聚合层\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e第四步：渐进式拆分（Incremental Migration）\u003c/h3\u003e\n\u003col start=\"10\"\u003e\n\u003cli\u003e\u003cstrong\u003e从边缘开始\u003c/strong\u003e：先拆分耦合最少、边界最清晰的服务\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e绞杀者模式\u003c/strong\u003e：新功能用微服务实现，老功能逐步迁移\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e持续验证\u003c/strong\u003e：每拆分一个服务，验证边界是否正确，必要时调整\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eDDD 战略设计与战术设计的关系\u003c/h2\u003e\n\u003cp\u003e很多团队在实践 DDD 时过度关注\u003cstrong\u003e战术设计\u003c/strong\u003e（实体、值对象、聚合根、仓储等代码层面的模式），而忽视了\u003cstrong\u003e战略设计\u003c/strong\u003e（子域、界限上下文、上下文映射）。对于微服务架构而言，战略设计的价值远大于战术设计：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003e战略设计\u003c/th\u003e\n\u003cth\u003e战术设计\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e关注点\u003c/td\u003e\n\u003ctd\u003e服务边界、团队协作、系统结构\u003c/td\u003e\n\u003ctd\u003e代码结构、领域模型、设计模式\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e影响范围\u003c/td\u003e\n\u003ctd\u003e整个系统架构\u003c/td\u003e\n\u003ctd\u003e单个服务内部\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e决策成本\u003c/td\u003e\n\u003ctd\u003e错误的边界划分代价极高\u003c/td\u003e\n\u003ctd\u003e内部重构成本相对可控\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用阶段\u003c/td\u003e\n\u003ctd\u003e架构设计初期\u003c/td\u003e\n\u003ctd\u003e服务实现阶段\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e先做对战略设计（找到正确的边界），再做好战术设计（在边界内写好代码）。\u003c/strong\u003e 边界划错了，代码写得再漂亮也是徒劳。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e总结\u003c/h2\u003e\n\u003cp\u003e基于 DDD 构建微服务的核心认知：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e微服务的本质是界限清晰\u003c/strong\u003e，不是规模小。边界内高内聚，边界外低耦合\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e界限上下文是服务拆分的起点\u003c/strong\u003e，但不是终点——聚合才是更精细的拆分单元\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e上下文映射揭示服务间的真实依赖\u003c/strong\u003e，帮助我们避免聚合被错误地分散到多个服务中\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e事件风暴是最有效的协作式建模工具\u003c/strong\u003e，它能让团队在分解前就达成共识\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e拥抱最终一致性\u003c/strong\u003e，优先使用事件驱动架构，减少服务间的行为耦合和时间耦合\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBFF 模式解耦前端与域服务\u003c/strong\u003e，让域服务专注于核心业务逻辑\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e先保守后激进\u003c/strong\u003e：不确定时将整个上下文作为一个服务，确保聚合间接口隔离，后续再拆分\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e合并的成本远高于拆分\u003c/strong\u003e：将两个数据库合并为一个，远比将一个数据库拆为两个要困难\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDDD 不是银弹，它是一种思考方式。它引导我们从业务本质出发，用结构化的方法找到正确的服务边界。在微服务架构中，\u003cstrong\u003e找到正确的边界比选择正确的技术栈重要十倍\u003c/strong\u003e。\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"19:Tf833,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eMulti-Agent Collaboration: 多 Agent 协作模式与架构\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个人可以走得很快，但一群人才能走得很远。Agent 也是如此。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 11 篇。前 10 篇我们一直在讨论单个 Agent 如何更聪明——更好的记忆、更强的工具、更深的规划。这一篇，我们把视角从\u0026quot;个体智能\u0026quot;拉升到\u0026quot;集体智能\u0026quot;：当一个 Agent 不够用时，多个 Agent 如何协作？\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么单 Agent 不够\u003c/h2\u003e\n\u003ch3\u003e1.1 一个类比：从独立开发者到工程团队\u003c/h3\u003e\n\u003cp\u003e想象你是一个全栈工程师，独自完成一个项目。前端、后端、数据库、DevOps、测试、文档——全部一个人扛。小项目可以，但当系统规模增长到一定程度，你会发现：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e注意力是瓶颈\u003c/strong\u003e：你不可能同时想着 CSS 布局和数据库索引优化\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e专业化有上限\u003c/strong\u003e：一个人很难同时成为安全专家、性能专家和 UX 专家\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e效率有天花板\u003c/strong\u003e：就算你是 10x 工程师，你的时间也是串行的\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e单点风险\u003c/strong\u003e：你生病了，整个项目就停了\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这就是人类发明\u0026quot;团队协作\u0026quot;的原因。Agent 面临完全相同的结构性限制。\u003c/p\u003e\n\u003ch3\u003e1.2 Single-Agent 的四个天花板\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e天花板一：Context Window 限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个 Agent 的 System Prompt 需要包含：角色定义、工具描述、输出格式约束、领域知识、示例。当你试图让一个 Agent 同时承担搜索、分析、写作、代码生成、数据可视化等多个职能时，光是工具描述就可能占据数万 token。留给实际任务执行的上下文空间被严重压缩。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e一个\u0026quot;全能\u0026quot; Agent 的 Context 分配：\n\n┌─────────────────────────────────────────────────┐\n│ System Prompt (角色 + 规则)         ~2,000 tokens │\n│ Tool Schemas (15 个工具)            ~6,000 tokens │\n│ 领域知识 (RAG 检索结果)             ~4,000 tokens │\n│ 对话历史                            ~8,000 tokens │\n│ 当前任务 + 中间状态                 ~3,000 tokens │\n├─────────────────────────────────────────────────┤\n│ 剩余可用空间                        ~9,000 tokens │ ← 越来越捉襟见肘\n│ (128K 窗口下比例更好，但工具越多问题越突出)         │\n└─────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e更关键的是，研究表明 LLM 在超长上下文中存在\u0026quot;Lost in the Middle\u0026quot;问题——中间位置的信息检索准确率显著下降。塞得越多，每条信息被有效利用的概率越低。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e天花板二：专业化限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个 System Prompt 很难让 LLM 同时扮演好多个角色。你告诉它\u0026quot;你是一个严谨的数据分析师\u0026quot;，它分析数据时很好；但同一个 prompt 里你又说\u0026quot;你也是一个有创意的文案写手\u0026quot;，这两种人格的行为模式是矛盾的。严谨和创意在同一个 prompt 中互相干扰，最终两个角色都做不好。\u003c/p\u003e\n\u003cp\u003e这不是 prompt engineering 的技巧问题，而是注意力分配的结构性问题——一个 LLM 调用只有一个 attention 分布，强调了分析的严谨性，就必然削弱了文案的创造性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e天花板三：可靠性限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e单 Agent 是一个 Single Point of Failure。如果它在第 5 步推理出错（比如工具调用参数写错），整个任务链路都会受到污染。虽然我们在第 10 篇讨论了 Reflection 和自我纠错，但自我纠错的前提是\u0026quot;能发现自己错了\u0026quot;——而 LLM 对自身错误的检测能力是有限的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e天花板四：并行度限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e单 Agent 的执行是串行的——一次 LLM 调用，等待结果，再进行下一次。如果一个任务可以分解为三个独立子任务（比如同时搜索三个数据源），单 Agent 只能顺序执行，浪费了大量时间。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSingle-Agent 串行执行：\n\n  Task ──→ [Search A] ──→ [Search B] ──→ [Search C] ──→ [Synthesize]\n                                                         Total: ~40s\n\nMulti-Agent 并行执行：\n\n           ┌─→ [Search A] ─┐\n  Task ──→ ├─→ [Search B] ─┼──→ [Synthesize]\n           └─→ [Search C] ─┘\n                              Total: ~15s\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e2. Multi-Agent 的四种协作模式\u003c/h2\u003e\n\u003cp\u003e当我们决定使用多个 Agent 时，第一个架构问题是：\u003cstrong\u003e它们之间的协作关系是什么？\u003c/strong\u003e 不同的关系模式适用于不同的场景，选错模式比用错框架更致命。\u003c/p\u003e\n\u003ch3\u003e2.1 模式一：Supervisor-Worker（上级分配型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌──────────────────┐\n                    │    Supervisor    │\n                    │   (任务分解 +    │\n                    │    结果合成)     │\n                    └──────┬───────────┘\n                           │\n              ┌────────────┼────────────┐\n              │            │            │\n              ▼            ▼            ▼\n       ┌──────────┐ ┌──────────┐ ┌──────────┐\n       │ Worker A │ │ Worker B │ │ Worker C │\n       │ (搜索)   │ │ (分析)   │ │ (写作)   │\n       └──────────┘ └──────────┘ └──────────┘\n              │            │            │\n              └────────────┼────────────┘\n                           │\n                           ▼\n                    ┌──────────────────┐\n                    │    Supervisor    │\n                    │   (收集 + 合成   │\n                    │    最终输出)     │\n                    └──────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSupervisor Agent 接收用户任务\u003c/li\u003e\n\u003cli\u003eSupervisor 将任务分解为子任务，分配给不同的 Worker Agent\u003c/li\u003e\n\u003cli\u003e每个 Worker 独立执行各自的子任务\u003c/li\u003e\n\u003cli\u003eSupervisor 收集所有 Worker 的结果，合成最终输出\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e有一个明确的中央协调者\u003c/li\u003e\n\u003cli\u003eWorker 之间不直接通信，只与 Supervisor 交互\u003c/li\u003e\n\u003cli\u003eSupervisor 负责全局决策，Worker 负责局部执行\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：任务可以明确分解的场景。比如撰写一篇技术调研报告：Search Agent 负责信息搜集，Analyze Agent 负责数据分析，Write Agent 负责报告撰写。Supervisor 负责协调整个流程。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：Supervisor 是单点——如果 Supervisor 对任务的分解不合理，所有 Worker 的努力都会被浪费。此外，Supervisor 本身也是一个 LLM 调用，它对任务的理解能力决定了整个系统的上限。\u003c/p\u003e\n\u003ch3\u003e2.2 模式二：Peer-to-Peer（平等协商型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐          ┌──────────┐\n       │ Agent A  │◀────────▶│ Agent B  │\n       │ (作者)   │          │ (审稿人) │\n       └────┬─────┘          └────┬─────┘\n            │                     │\n            │    ┌──────────┐     │\n            └───▶│ Agent C  │◀────┘\n                 │ (编辑)   │\n                 └──────────┘\n\n       消息流是双向的，没有固定的上下级关系\n       每个 Agent 都可以发起对话、提出意见、做出决策\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e多个 Agent 地位平等，通过消息传递进行协商\u003c/li\u003e\n\u003cli\u003e没有中央协调者——Agent 之间直接通信\u003c/li\u003e\n\u003cli\u003e通过多轮对话达成共识或完成任务\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e去中心化\u003c/li\u003e\n\u003cli\u003eAgent 之间直接消息传递\u003c/li\u003e\n\u003cli\u003e适合需要多视角碰撞的任务\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：辩论式分析（多个 Agent 从不同立场论证）、代码审查（Author Agent 写代码，Reviewer Agent 审查，双方来回沟通直到代码质量达标）、多角度决策（乐观分析师 + 悲观分析师 + 风险评估师共同评估一个投资决策）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：没有中央协调意味着可能出现无限循环（两个 Agent 互相不同意，永远达不成共识）。需要额外的终止机制——最大轮次限制、外部仲裁者、投票制度等。调试也更困难，因为没有一个中心节点可以观察全局状态。\u003c/p\u003e\n\u003ch3\u003e2.3 模式三：Pipeline（流水线型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e  Input                                                          Output\n    │                                                              ▲\n    ▼                                                              │\n┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐\n│ Draft  │───▶│ Review │───▶│  Edit  │───▶│  Fact  │───▶│ Format │\n│ Agent  │    │ Agent  │    │ Agent  │    │ Check  │    │ Agent  │\n│        │    │        │    │        │    │ Agent  │    │        │\n└────────┘    └────────┘    └────────┘    └────────┘    └────────┘\n\n  Stage 1       Stage 2       Stage 3       Stage 4       Stage 5\n  生成初稿      审查质量       修改完善      事实核查       格式化输出\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAgent 按顺序串联，形成流水线\u003c/li\u003e\n\u003cli\u003e上游 Agent 的输出是下游 Agent 的输入\u003c/li\u003e\n\u003cli\u003e每个 Agent 专注于一个处理阶段\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e类似 Unix 管道：\u003ccode\u003ecmd1 | cmd2 | cmd3\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e数据单向流动\u003c/li\u003e\n\u003cli\u003e每个阶段的 Agent 有明确、单一的职责\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：内容生产流水线（起草 -\u0026gt; 审查 -\u0026gt; 编辑 -\u0026gt; 排版）、数据处理管道（提取 -\u0026gt; 清洗 -\u0026gt; 转换 -\u0026gt; 加载）、多阶段审批（初审 -\u0026gt; 复审 -\u0026gt; 终审）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：流水线是严格串行的——上游不完成，下游无法开始。如果中间某个 Agent 输出质量差，后续所有阶段都会受影响（错误传播）。但好处是架构简单、易于理解和调试、每个阶段可以独立优化。\u003c/p\u003e\n\u003ch3\u003e2.4 模式四：Dynamic Routing（动态路由型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌──────────────────┐\n                    │   Router Agent   │\n                    │ (意图识别 + 路由) │\n                    └──────┬───────────┘\n                           │\n              ┌────────────┼────────────┐\n              │            │            │\n              ▼            ▼            ▼\n       ┌──────────┐ ┌──────────┐ ┌──────────┐\n       │ 技术支持  │ │ 售后服务  │ │ 销售咨询  │\n       │ Agent    │ │ Agent    │ │ Agent    │\n       │          │ │          │ │          │\n       │ 处理技术  │ │ 处理退款  │ │ 处理购买  │\n       │ 故障排查  │ │ 换货投诉  │ │ 产品推荐  │\n       └──────────┘ └──────────┘ └──────────┘\n\n  路由依据：用户输入的意图分类\n  每个专家 Agent 有独立的 System Prompt、Tools、知识库\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRouter Agent 接收用户输入\u003c/li\u003e\n\u003cli\u003e根据意图分类，将请求路由到对应的专家 Agent\u003c/li\u003e\n\u003cli\u003e专家 Agent 处理请求并返回结果\u003c/li\u003e\n\u003cli\u003e必要时 Router 可以在专家之间进行二次路由\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一个轻量级的 Router 做决策\u003c/li\u003e\n\u003cli\u003e多个重量级的专家 Agent 做执行\u003c/li\u003e\n\u003cli\u003eRouter 可以用简单模型（快速、便宜），专家用强大模型（准确、深入）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：客服系统（技术问题 -\u0026gt; 技术 Agent，退款问题 -\u0026gt; 售后 Agent）、多领域知识问答（医疗问题 -\u0026gt; 医疗 Agent，法律问题 -\u0026gt; 法律 Agent）、代码助手（Python 问题 -\u0026gt; Python 专家，Rust 问题 -\u0026gt; Rust 专家）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：路由准确率是整个系统的瓶颈——路由错了，后面再专业也没用。模糊意图（\u0026quot;我买的东西有技术问题\u0026quot;——这是技术支持还是售后？）需要特殊处理。一种常见策略是允许 Router 在不确定时同时咨询多个专家，再综合判断。\u003c/p\u003e\n\u003ch3\u003e2.5 四种模式的对比决策\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eSupervisor-Worker\u003c/th\u003e\n\u003cth\u003ePeer-to-Peer\u003c/th\u003e\n\u003cth\u003ePipeline\u003c/th\u003e\n\u003cth\u003eDynamic Routing\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e控制结构\u003c/td\u003e\n\u003ctd\u003e中心化\u003c/td\u003e\n\u003ctd\u003e去中心化\u003c/td\u003e\n\u003ctd\u003e线性\u003c/td\u003e\n\u003ctd\u003e分发型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e通信模式\u003c/td\u003e\n\u003ctd\u003e星形\u003c/td\u003e\n\u003ctd\u003e网状\u003c/td\u003e\n\u003ctd\u003e链式\u003c/td\u003e\n\u003ctd\u003e扇出\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并行度\u003c/td\u003e\n\u003ctd\u003e高（Worker 并行）\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e低（严格串行）\u003c/td\u003e\n\u003ctd\u003e高（请求级并行）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用复杂度\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e低-中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e调试难度\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e典型场景\u003c/td\u003e\n\u003ctd\u003e报告生成、项目规划\u003c/td\u003e\n\u003ctd\u003e辩论、审查\u003c/td\u003e\n\u003ctd\u003e内容流水线\u003c/td\u003e\n\u003ctd\u003e客服、问答路由\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策原则\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e任务可以并行分解 -\u0026gt; Supervisor-Worker\u003c/li\u003e\n\u003cli\u003e需要多视角碰撞 -\u0026gt; Peer-to-Peer\u003c/li\u003e\n\u003cli\u003e处理有明确阶段 -\u0026gt; Pipeline\u003c/li\u003e\n\u003cli\u003e请求类型多样，专家各有擅长 -\u0026gt; Dynamic Routing\u003c/li\u003e\n\u003cli\u003e不确定？先从最简单的 Pipeline 开始，逐步演进\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e3. Agent 间通信机制\u003c/h2\u003e\n\u003cp\u003e多个 Agent 之间需要交换信息，通信机制的选择直接影响系统的可扩展性、耦合度和调试难度。\u003c/p\u003e\n\u003ch3\u003e3.1 共享内存（Blackboard Pattern）\u003c/h3\u003e\n\u003cp\u003e所有 Agent 读写同一个共享状态存储。这是最简单直接的通信方式。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐   ┌──────────┐   ┌──────────┐\n       │ Agent A  │   │ Agent B  │   │ Agent C  │\n       └────┬─────┘   └────┬─────┘   └────┬─────┘\n            │  read/write   │  read/write   │\n            ▼              ▼              ▼\n       ┌──────────────────────────────────────────┐\n       │           Shared Blackboard              │\n       │                                          │\n       │  { \u0026quot;search_results\u0026quot;: [...],              │\n       │    \u0026quot;analysis\u0026quot;: {...},                    │\n       │    \u0026quot;draft\u0026quot;: \u0026quot;...\u0026quot;,                       │\n       │    \u0026quot;status\u0026quot;: {\u0026quot;search\u0026quot;: \u0026quot;done\u0026quot;, ...} }   │\n       └──────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Any\nimport threading\n\n\n@dataclass\nclass Blackboard:\n    \u0026quot;\u0026quot;\u0026quot;共享黑板：所有 Agent 的公共状态空间\u0026quot;\u0026quot;\u0026quot;\n    _state: dict[str, Any] = field(default_factory=dict)\n    _lock: threading.Lock = field(default_factory=threading.Lock)\n    _history: list[dict] = field(default_factory=list)\n\n    def read(self, key: str) -\u0026gt; Any:\n        with self._lock:\n            return self._state.get(key)\n\n    def write(self, key: str, value: Any, author: str = \u0026quot;unknown\u0026quot;):\n        with self._lock:\n            self._history.append({\n                \u0026quot;action\u0026quot;: \u0026quot;write\u0026quot;,\n                \u0026quot;key\u0026quot;: key,\n                \u0026quot;author\u0026quot;: author,\n                \u0026quot;old_value\u0026quot;: self._state.get(key),\n                \u0026quot;new_value\u0026quot;: value,\n            })\n            self._state[key] = value\n\n    def read_all(self) -\u0026gt; dict[str, Any]:\n        with self._lock:\n            return dict(self._state)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：实现简单，Agent 之间完全解耦（不需要知道彼此的存在），天然支持任意读写模式。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：共享状态意味着潜在的竞争条件——两个 Agent 同时写同一个 key 怎么办？需要锁机制或更复杂的冲突解决策略。随着 Agent 数量增加，Blackboard 可能成为瓶颈。\u003c/p\u003e\n\u003ch3\u003e3.2 消息传递（Message Passing）\u003c/h3\u003e\n\u003cp\u003eAgent 之间通过显式的消息进行通信。每个 Agent 有自己的收件箱。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐         ┌──────────┐\n       │ Agent A  │──msg───▶│ Agent B  │\n       │          │◀──msg───│          │\n       └──────────┘         └──────────┘\n            │                     ▲\n            │         msg         │\n            ▼                     │\n       ┌──────────┐              │\n       │ Agent C  │──────msg─────┘\n       └──────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom collections import defaultdict\nfrom queue import Queue\n\n\n@dataclass\nclass Message:\n    sender: str\n    receiver: str\n    content: Any\n    msg_type: str = \u0026quot;default\u0026quot;  # \u0026quot;task\u0026quot;, \u0026quot;result\u0026quot;, \u0026quot;feedback\u0026quot;, \u0026quot;error\u0026quot;\n\n\nclass MessageBus:\n    \u0026quot;\u0026quot;\u0026quot;点对点消息传递\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._queues: dict[str, Queue] = defaultdict(Queue)\n\n    def send(self, message: Message):\n        self._queues[message.receiver].put(message)\n\n    def receive(self, agent_id: str, timeout: float = None) -\u0026gt; Message | None:\n        try:\n            return self._queues[agent_id].get(timeout=timeout)\n        except Exception:\n            return None\n\n    def has_messages(self, agent_id: str) -\u0026gt; bool:\n        return not self._queues[agent_id].empty()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：通信关系显式、可追踪、可审计。每条消息都有明确的发送者和接收者。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：Agent 需要知道其他 Agent 的存在（至少知道 ID），耦合度比 Blackboard 高。如果通信拓扑复杂（多对多），消息管理会变得困难。\u003c/p\u003e\n\u003ch3\u003e3.3 事件驱动（Event Bus）\u003c/h3\u003e\n\u003cp\u003eAgent 通过发布/订阅事件进行间接通信。Agent 不需要知道谁会消费它的事件。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐   ┌──────────┐   ┌──────────┐\n       │ Agent A  │   │ Agent B  │   │ Agent C  │\n       │ pub: X   │   │ sub: X   │   │ sub: X,Y │\n       └────┬─────┘   └────┬─────┘   └────┬─────┘\n            │  publish      │  subscribe   │\n            ▼              ▼              ▼\n       ┌──────────────────────────────────────────┐\n       │              Event Bus                    │\n       │                                          │\n       │  topic \u0026quot;search_done\u0026quot;  → [Agent B, C]     │\n       │  topic \u0026quot;analysis_done\u0026quot; → [Agent C]        │\n       │  topic \u0026quot;error\u0026quot;        → [Supervisor]      │\n       └──────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom collections import defaultdict\nfrom typing import Callable\n\n\nclass EventBus:\n    \u0026quot;\u0026quot;\u0026quot;发布/订阅事件总线\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._subscribers: dict[str, list[Callable]] = defaultdict(list)\n        self._event_log: list[dict] = []\n\n    def subscribe(self, topic: str, handler: Callable):\n        self._subscribers[topic].append(handler)\n\n    def publish(self, topic: str, data: Any, publisher: str = \u0026quot;unknown\u0026quot;):\n        event = {\u0026quot;topic\u0026quot;: topic, \u0026quot;data\u0026quot;: data, \u0026quot;publisher\u0026quot;: publisher}\n        self._event_log.append(event)\n        for handler in self._subscribers.get(topic, []):\n            handler(event)\n\n    def get_event_log(self) -\u0026gt; list[dict]:\n        return list(self._event_log)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：Agent 之间完全解耦——发布者不知道有谁在监听，订阅者不知道事件从哪里来。扩展性好，新增 Agent 只需订阅相关事件。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：事件流难以追踪——\u0026quot;这个事件是谁发的？谁处理了？处理结果在哪里？\u0026quot;调试时需要完整的事件日志。事件顺序可能不确定，需要额外的排序机制。\u003c/p\u003e\n\u003ch3\u003e3.4 通信机制对比\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eBlackboard\u003c/th\u003e\n\u003cth\u003eMessage Passing\u003c/th\u003e\n\u003cth\u003eEvent Bus\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e耦合度\u003c/td\u003e\n\u003ctd\u003e低（通过 key 间接通信）\u003c/td\u003e\n\u003ctd\u003e中（需要知道目标 Agent）\u003c/td\u003e\n\u003ctd\u003e低（通过 topic 间接通信）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e实现复杂度\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e调试友好度\u003c/td\u003e\n\u003ctd\u003e中（看状态快照）\u003c/td\u003e\n\u003ctd\u003e高（消息链路清晰）\u003c/td\u003e\n\u003ctd\u003e低（事件流分散）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并发安全\u003c/td\u003e\n\u003ctd\u003e需要锁/MVCC\u003c/td\u003e\n\u003ctd\u003e天然安全（队列隔离）\u003c/td\u003e\n\u003ctd\u003e需要考虑处理顺序\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用模式\u003c/td\u003e\n\u003ctd\u003eSupervisor-Worker\u003c/td\u003e\n\u003ctd\u003ePeer-to-Peer\u003c/td\u003e\n\u003ctd\u003ePipeline, 事件驱动架构\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可观测性\u003c/td\u003e\n\u003ctd\u003e状态快照\u003c/td\u003e\n\u003ctd\u003e消息轨迹\u003c/td\u003e\n\u003ctd\u003e事件日志\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e实践建议\u003c/strong\u003e：大多数 Multi-Agent 系统可以从 Blackboard 开始——它最简单，且对 Supervisor-Worker 模式特别友好。当系统复杂度增长到需要解耦 Agent 间关系时，再考虑 Event Bus。Message Passing 适合 Agent 之间有明确的、频繁的双向交互的场景。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. 完整实现：Supervisor-Worker 协作框架\u003c/h2\u003e\n\u003cp\u003e下面用 Python 从零实现一个 Supervisor-Worker 框架。这不依赖任何 Agent 框架，完全基于第一性原理构建。\u003c/p\u003e\n\u003ch3\u003e4.1 基础抽象\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nimport asyncio\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom typing import Any\n\n\n# ---- LLM 调用抽象（与具体 SDK 解耦）----\n\nasync def call_llm(\n    messages: list[dict],\n    model: str = \u0026quot;gpt-4o\u0026quot;,\n    response_format: dict | None = None,\n) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;LLM 调用的统一接口（简化版，生产中替换为真实 SDK 调用）\u0026quot;\u0026quot;\u0026quot;\n    import openai\n    client = openai.AsyncOpenAI()\n    kwargs = {\u0026quot;model\u0026quot;: model, \u0026quot;messages\u0026quot;: messages}\n    if response_format:\n        kwargs[\u0026quot;response_format\u0026quot;] = response_format\n    response = await client.chat.completions.create(**kwargs)\n    return response.choices[0].message.content\n\n\n# ---- 任务与结果的数据结构 ----\n\n@dataclass\nclass Task:\n    \u0026quot;\u0026quot;\u0026quot;一个可执行的子任务\u0026quot;\u0026quot;\u0026quot;\n    task_id: str\n    description: str\n    assigned_to: str = \u0026quot;\u0026quot;          # Worker Agent 名称\n    context: dict = field(default_factory=dict)  # 来自上游的上下文\n    status: str = \u0026quot;pending\u0026quot;        # pending | running | done | failed\n    result: str = \u0026quot;\u0026quot;\n    error: str = \u0026quot;\u0026quot;\n\n\n@dataclass\nclass TeamResult:\n    \u0026quot;\u0026quot;\u0026quot;团队执行的最终结果\u0026quot;\u0026quot;\u0026quot;\n    success: bool\n    output: str\n    tasks: list[Task]\n    total_tokens: int = 0\n    total_llm_calls: int = 0\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.2 Worker Agent\u003c/h3\u003e\n\u003cp\u003e每个 Worker 是一个专注于特定领域的 Agent，拥有独立的 System Prompt 和能力边界。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass WorkerAgent:\n    \u0026quot;\u0026quot;\u0026quot;Worker Agent：接收子任务，独立执行，返回结果\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, name: str, system_prompt: str, model: str = \u0026quot;gpt-4o\u0026quot;):\n        self.name = name\n        self.system_prompt = system_prompt\n        self.model = model\n        self._call_count = 0\n\n    async def execute(self, task: Task) -\u0026gt; Task:\n        \u0026quot;\u0026quot;\u0026quot;执行一个子任务\u0026quot;\u0026quot;\u0026quot;\n        task.status = \u0026quot;running\u0026quot;\n        task.assigned_to = self.name\n\n        messages = [\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self.system_prompt},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: self._build_prompt(task)},\n        ]\n\n        try:\n            result = await call_llm(messages, model=self.model)\n            self._call_count += 1\n            task.result = result\n            task.status = \u0026quot;done\u0026quot;\n        except Exception as e:\n            task.error = str(e)\n            task.status = \u0026quot;failed\u0026quot;\n\n        return task\n\n    def _build_prompt(self, task: Task) -\u0026gt; str:\n        prompt = f\u0026quot;## 任务\\n{task.description}\\n\u0026quot;\n        if task.context:\n            prompt += f\u0026quot;\\n## 上下文信息\\n{json.dumps(task.context, ensure_ascii=False, indent=2)}\\n\u0026quot;\n        prompt += \u0026quot;\\n请完成上述任务，直接输出结果。\u0026quot;\n        return prompt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.3 Supervisor Agent\u003c/h3\u003e\n\u003cp\u003eSupervisor 负责三件事：任务分解、任务分配、结果合成。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eDECOMPOSE_PROMPT = \u0026quot;\u0026quot;\u0026quot;你是一个任务分解专家。给定一个复杂任务，将其分解为可以独立执行的子任务。\n\n可用的 Worker 及其能力：\n{workers_description}\n\n请将任务分解为子任务，并指定每个子任务应该分配给哪个 Worker。\n输出 JSON 格式：\n{{\n  \u0026quot;subtasks\u0026quot;: [\n    {{\n      \u0026quot;task_id\u0026quot;: \u0026quot;task_1\u0026quot;,\n      \u0026quot;description\u0026quot;: \u0026quot;具体的子任务描述\u0026quot;,\n      \u0026quot;assigned_to\u0026quot;: \u0026quot;worker 名称\u0026quot;,\n      \u0026quot;depends_on\u0026quot;: []\n    }}\n  ]\n}}\n\n注意：\n- 每个子任务应该足够具体，让 Worker 能独立完成\n- depends_on 标明依赖关系（某个子任务需要等另一个完成后才能开始）\n- 尽可能让子任务并行执行以提高效率\n\u0026quot;\u0026quot;\u0026quot;\n\nSYNTHESIZE_PROMPT = \u0026quot;\u0026quot;\u0026quot;你是一个结果合成专家。多个专业 Agent 已经分别完成了子任务。\n请根据它们的结果，合成一个完整、连贯、高质量的最终输出。\n\n原始任务：{original_task}\n\n各子任务的执行结果：\n{subtask_results}\n\n请整合以上信息，生成最终的完整输出。确保：\n1. 信息完整，没有遗漏\n2. 逻辑连贯，前后一致\n3. 去除重复内容\n4. 保持专业质量\n\u0026quot;\u0026quot;\u0026quot;\n\n\nclass SupervisorAgent:\n    \u0026quot;\u0026quot;\u0026quot;Supervisor Agent：任务分解、分配、合成\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, model: str = \u0026quot;gpt-4o\u0026quot;):\n        self.model = model\n        self._call_count = 0\n\n    async def decompose(\n        self, task: str, workers: dict[str, WorkerAgent]\n    ) -\u0026gt; list[Task]:\n        \u0026quot;\u0026quot;\u0026quot;将复杂任务分解为子任务\u0026quot;\u0026quot;\u0026quot;\n        workers_desc = \u0026quot;\\n\u0026quot;.join(\n            f\u0026quot;- {name}: {w.system_prompt[:200]}\u0026quot;\n            for name, w in workers.items()\n        )\n\n        messages = [\n            {\n                \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                \u0026quot;content\u0026quot;: DECOMPOSE_PROMPT.format(\n                    workers_description=workers_desc\n                ),\n            },\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: task},\n        ]\n\n        result = await call_llm(\n            messages,\n            model=self.model,\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        self._call_count += 1\n\n        parsed = json.loads(result)\n        tasks = []\n        for st in parsed.get(\u0026quot;subtasks\u0026quot;, []):\n            tasks.append(Task(\n                task_id=st[\u0026quot;task_id\u0026quot;],\n                description=st[\u0026quot;description\u0026quot;],\n                assigned_to=st.get(\u0026quot;assigned_to\u0026quot;, \u0026quot;\u0026quot;),\n            ))\n        return tasks\n\n    async def synthesize(\n        self, original_task: str, completed_tasks: list[Task]\n    ) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;合成所有 Worker 的结果\u0026quot;\u0026quot;\u0026quot;\n        results_text = \u0026quot;\\n\\n\u0026quot;.join(\n            f\u0026quot;### {t.task_id} ({t.assigned_to})\\n{t.result}\u0026quot;\n            for t in completed_tasks\n            if t.status == \u0026quot;done\u0026quot;\n        )\n\n        messages = [\n            {\n                \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                \u0026quot;content\u0026quot;: SYNTHESIZE_PROMPT.format(\n                    original_task=original_task,\n                    subtask_results=results_text,\n                ),\n            },\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;请合成最终结果。\u0026quot;},\n        ]\n\n        result = await call_llm(messages, model=self.model)\n        self._call_count += 1\n        return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.4 AgentTeam：编排层\u003c/h3\u003e\n\u003cp\u003eAgentTeam 管理多个 Agent 的生命周期、通信和执行流程。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass AgentTeam:\n    \u0026quot;\u0026quot;\u0026quot;Agent 团队：管理 Supervisor + Workers 的协作\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor: SupervisorAgent):\n        self.supervisor = supervisor\n        self.workers: dict[str, WorkerAgent] = {}\n        self.blackboard = Blackboard()\n        self.execution_log: list[dict] = []\n\n    def add_worker(self, worker: WorkerAgent):\n        self.workers[worker.name] = worker\n\n    async def run(self, task: str, max_retries: int = 2) -\u0026gt; TeamResult:\n        \u0026quot;\u0026quot;\u0026quot;执行完整的 Multi-Agent 协作流程\u0026quot;\u0026quot;\u0026quot;\n        self._log(\u0026quot;team\u0026quot;, f\u0026quot;接收任务: {task[:100]}...\u0026quot;)\n\n        # Phase 1: Supervisor 分解任务\n        self._log(\u0026quot;supervisor\u0026quot;, \u0026quot;开始任务分解\u0026quot;)\n        subtasks = await self.supervisor.decompose(task, self.workers)\n        self._log(\u0026quot;supervisor\u0026quot;, f\u0026quot;分解为 {len(subtasks)} 个子任务\u0026quot;)\n\n        for st in subtasks:\n            self._log(\u0026quot;supervisor\u0026quot;, f\u0026quot;  {st.task_id} -\u0026gt; {st.assigned_to}: {st.description[:80]}\u0026quot;)\n\n        # Phase 2: Workers 并行执行（考虑依赖关系）\n        completed = await self._execute_tasks(subtasks, max_retries)\n\n        # Phase 3: Supervisor 合成结果\n        self._log(\u0026quot;supervisor\u0026quot;, \u0026quot;开始合成结果\u0026quot;)\n        final_output = await self.supervisor.synthesize(task, completed)\n        self._log(\u0026quot;supervisor\u0026quot;, \u0026quot;合成完成\u0026quot;)\n\n        # 汇总统计\n        total_calls = self.supervisor._call_count + sum(\n            w._call_count for w in self.workers.values()\n        )\n\n        return TeamResult(\n            success=all(t.status == \u0026quot;done\u0026quot; for t in completed),\n            output=final_output,\n            tasks=completed,\n            total_llm_calls=total_calls,\n        )\n\n    async def _execute_tasks(\n        self, tasks: list[Task], max_retries: int\n    ) -\u0026gt; list[Task]:\n        \u0026quot;\u0026quot;\u0026quot;执行子任务，支持并行和重试\u0026quot;\u0026quot;\u0026quot;\n        completed = []\n        pending = list(tasks)\n\n        while pending:\n            # 找出当前可以执行的任务（依赖已满足）\n            ready = []\n            still_pending = []\n            completed_ids = {t.task_id for t in completed}\n\n            for task in pending:\n                deps = task.context.get(\u0026quot;depends_on\u0026quot;, [])\n                if all(d in completed_ids for d in deps):\n                    ready.append(task)\n                else:\n                    still_pending.append(task)\n\n            if not ready:\n                # 没有可执行的任务但还有待处理的 -\u0026gt; 可能存在循环依赖\n                self._log(\u0026quot;team\u0026quot;, \u0026quot;警告: 检测到无法满足的依赖关系\u0026quot;)\n                break\n\n            # 并行执行所有就绪的任务\n            results = await asyncio.gather(*[\n                self._execute_single(task, max_retries)\n                for task in ready\n            ])\n\n            for task in results:\n                completed.append(task)\n                # 将结果写入 Blackboard，供后续任务使用\n                if task.status == \u0026quot;done\u0026quot;:\n                    self.blackboard.write(\n                        task.task_id, task.result, author=task.assigned_to\n                    )\n\n            pending = still_pending\n\n        return completed\n\n    async def _execute_single(\n        self, task: Task, max_retries: int\n    ) -\u0026gt; Task:\n        \u0026quot;\u0026quot;\u0026quot;执行单个任务，带重试\u0026quot;\u0026quot;\u0026quot;\n        worker = self.workers.get(task.assigned_to)\n        if not worker:\n            task.status = \u0026quot;failed\u0026quot;\n            task.error = f\u0026quot;未找到 Worker: {task.assigned_to}\u0026quot;\n            return task\n\n        # 将 Blackboard 上的相关信息注入任务上下文\n        task.context[\u0026quot;blackboard\u0026quot;] = self.blackboard.read_all()\n\n        for attempt in range(max_retries + 1):\n            self._log(worker.name, f\u0026quot;执行 {task.task_id} (尝试 {attempt + 1})\u0026quot;)\n            result = await worker.execute(task)\n\n            if result.status == \u0026quot;done\u0026quot;:\n                self._log(worker.name, f\u0026quot;{task.task_id} 完成\u0026quot;)\n                return result\n\n            self._log(worker.name, f\u0026quot;{task.task_id} 失败: {result.error}\u0026quot;)\n\n            if attempt \u0026lt; max_retries:\n                self._log(worker.name, f\u0026quot;准备重试 {task.task_id}\u0026quot;)\n\n        return result\n\n    def _log(self, source: str, message: str):\n        entry = {\u0026quot;source\u0026quot;: source, \u0026quot;message\u0026quot;: message}\n        self.execution_log.append(entry)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.5 组装示例：技术调研报告\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def main():\n    \u0026quot;\u0026quot;\u0026quot;示例：用 Multi-Agent 团队撰写一篇技术调研报告\u0026quot;\u0026quot;\u0026quot;\n\n    # 创建 Supervisor\n    supervisor = SupervisorAgent(model=\u0026quot;gpt-4o\u0026quot;)\n\n    # 创建专业化的 Worker Agent\n    search_agent = WorkerAgent(\n        name=\u0026quot;searcher\u0026quot;,\n        system_prompt=(\n            \u0026quot;你是一个信息搜索专家。你的任务是根据给定的主题，\u0026quot;\n            \u0026quot;整理出全面的信息摘要，包括关键事实、数据、案例。\u0026quot;\n            \u0026quot;输出结构化的搜索结果，标注来源和可信度。\u0026quot;\n        ),\n    )\n\n    analyze_agent = WorkerAgent(\n        name=\u0026quot;analyst\u0026quot;,\n        system_prompt=(\n            \u0026quot;你是一个技术分析专家。你的任务是根据搜索结果和原始数据，\u0026quot;\n            \u0026quot;进行深度分析，提炼洞察，识别趋势、风险和机会。\u0026quot;\n            \u0026quot;输出包含数据支撑的分析报告。\u0026quot;\n        ),\n    )\n\n    write_agent = WorkerAgent(\n        name=\u0026quot;writer\u0026quot;,\n        system_prompt=(\n            \u0026quot;你是一个技术写作专家。你的任务是根据分析结果，\u0026quot;\n            \u0026quot;撰写结构清晰、逻辑严谨、可读性强的技术报告。\u0026quot;\n            \u0026quot;确保使用专业术语，并配有合适的章节结构。\u0026quot;\n        ),\n    )\n\n    # 组建团队\n    team = AgentTeam(supervisor=supervisor)\n    team.add_worker(search_agent)\n    team.add_worker(analyze_agent)\n    team.add_worker(write_agent)\n\n    # 执行任务\n    result = await team.run(\n        \u0026quot;撰写一篇关于 LLM Agent 在企业客服场景落地的技术调研报告，\u0026quot;\n        \u0026quot;包括行业现状、主流技术方案对比、落地挑战和建议。\u0026quot;\n    )\n\n    print(f\u0026quot;成功: {result.success}\u0026quot;)\n    print(f\u0026quot;LLM 调用次数: {result.total_llm_calls}\u0026quot;)\n    print(f\u0026quot;\\n最终输出:\\n{result.output[:500]}...\u0026quot;)\n\n    # 查看执行日志\n    print(\u0026quot;\\n执行链路:\u0026quot;)\n    for entry in team.execution_log:\n        print(f\u0026quot;  [{entry[\u0026#39;source\u0026#39;]}] {entry[\u0026#39;message\u0026#39;]}\u0026quot;)\n\n\n# asyncio.run(main())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码展示了核心的协作模式。生产系统中还需要补充：Token 用量追踪、超时控制、Worker 健康检查、结果缓存等。但架构骨架已经清晰——Supervisor 负责全局调度，Worker 负责局部执行，Blackboard 负责状态共享，AgentTeam 负责生命周期管理。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 状态管理的复杂性\u003c/h2\u003e\n\u003cp\u003eMulti-Agent 系统的状态管理比 Single-Agent 复杂一个数量级。核心难题在于：多个 Agent 同时操作状态，如何保证一致性。\u003c/p\u003e\n\u003ch3\u003e5.1 共享状态 vs 独立状态\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e方案 A：共享状态                     方案 B：独立状态\n┌─────────────────┐                ┌──────────┐  ┌──────────┐  ┌──────────┐\n│  Global State   │                │ State A  │  │ State B  │  │ State C  │\n│                 │                │ (Agent A │  │ (Agent B │  │ (Agent C │\n│ Agent A ──write │                │  独占)   │  │  独占)   │  │  独占)   │\n│ Agent B ──write │                └──────────┘  └──────────┘  └──────────┘\n│ Agent C ──write │                      │              │              │\n└─────────────────┘                      └──────────────┼──────────────┘\n                                                        ▼\n                                                  合并/同步层\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e共享状态\u003c/strong\u003e的优点是 Agent 之间信息同步即时，任何 Agent 都能看到最新全局状态。缺点是需要处理并发冲突。适合 Supervisor-Worker 模式——Supervisor 需要看到所有 Worker 的进度。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e独立状态\u003c/strong\u003e的优点是无并发问题，每个 Agent 完全自主。缺点是 Agent 之间信息同步有延迟，需要显式的合并机制。适合 Pipeline 模式——每个阶段独立处理，只在交接时传递状态。\u003c/p\u003e\n\u003ch3\u003e5.2 冲突解决策略\u003c/h3\u003e\n\u003cp\u003e当两个 Agent 同时修改同一个状态时，需要冲突解决。常见策略：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ConflictResolver:\n    \u0026quot;\u0026quot;\u0026quot;状态冲突解决器\u0026quot;\u0026quot;\u0026quot;\n\n    @staticmethod\n    def last_writer_wins(old_value, new_value_a, new_value_b, timestamp_a, timestamp_b):\n        \u0026quot;\u0026quot;\u0026quot;最后写入者胜出——简单但可能丢失数据\u0026quot;\u0026quot;\u0026quot;\n        return new_value_a if timestamp_a \u0026gt; timestamp_b else new_value_b\n\n    @staticmethod\n    def merge_append(old_value, new_value_a, new_value_b):\n        \u0026quot;\u0026quot;\u0026quot;合并追加——适用于列表类型的状态\u0026quot;\u0026quot;\u0026quot;\n        if isinstance(old_value, list):\n            merged = list(old_value)\n            if isinstance(new_value_a, list):\n                merged.extend(new_value_a)\n            if isinstance(new_value_b, list):\n                merged.extend(new_value_b)\n            return merged\n        return new_value_b  # fallback\n\n    @staticmethod\n    async def llm_resolve(old_value, new_value_a, new_value_b, context: str):\n        \u0026quot;\u0026quot;\u0026quot;用 LLM 判断如何合并冲突——最灵活但最贵\u0026quot;\u0026quot;\u0026quot;\n        prompt = (\n            f\u0026quot;两个 Agent 同时修改了同一个状态。\\n\u0026quot;\n            f\u0026quot;原始值: {old_value}\\n\u0026quot;\n            f\u0026quot;Agent A 的修改: {new_value_a}\\n\u0026quot;\n            f\u0026quot;Agent B 的修改: {new_value_b}\\n\u0026quot;\n            f\u0026quot;上下文: {context}\\n\u0026quot;\n            f\u0026quot;请决定最终值应该是什么，并解释原因。\u0026quot;\n        )\n        return await call_llm([{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: prompt}])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实践中，大多数 Multi-Agent 系统通过架构设计来避免冲突，而不是在运行时解决冲突。最有效的方法是\u003cstrong\u003e状态分区\u003c/strong\u003e——每个 Agent 只写自己负责的状态区域，避免多 Agent 写同一个 key。这也是 Supervisor-Worker 模式天然的优势：每个 Worker 写自己的结果 key，只有 Supervisor 读所有 key。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 错误处理与容错\u003c/h2\u003e\n\u003cp\u003eMulti-Agent 系统的错误处理比 Single-Agent 更复杂，因为错误的传播路径更多。\u003c/p\u003e\n\u003ch3\u003e6.1 Worker 失败\u003c/h3\u003e\n\u003cp\u003eWorker 失败是最常见的情况。处理策略按优先级：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eWorker 失败处理决策树：\n\n  Worker 执行失败\n       │\n       ▼\n  ┌─ 是否可重试？ ─── 是 ──→ 重试（最多 N 次）──→ 成功？──→ 继续\n  │      │                                          │\n  │     否                                         否\n  │      │                                          │\n  │      ▼                                          ▼\n  │  ┌─ 有替代 Worker？ ─── 是 ──→ 分配给替代 Worker\n  │  │      │\n  │  │     否\n  │  │      │\n  │  │      ▼\n  │  │  ┌─ 该子任务是关键路径？\n  │  │  │      │            │\n  │  │  │     是           否\n  │  │  │      │            │\n  │  │  │      ▼            ▼\n  │  │  │  整体任务失败   降级处理（跳过该子任务，\n  │  │  │                 标记结果为不完整）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ResilientAgentTeam(AgentTeam):\n    \u0026quot;\u0026quot;\u0026quot;增强容错能力的 Agent 团队\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor: SupervisorAgent):\n        super().__init__(supervisor)\n        self.fallback_workers: dict[str, list[str]] = {}  # Worker 降级链\n\n    def set_fallback(self, worker_name: str, fallbacks: list[str]):\n        \u0026quot;\u0026quot;\u0026quot;设置 Worker 的降级替代链\u0026quot;\u0026quot;\u0026quot;\n        self.fallback_workers[worker_name] = fallbacks\n\n    async def _execute_single(self, task: Task, max_retries: int) -\u0026gt; Task:\n        \u0026quot;\u0026quot;\u0026quot;增强版：支持 Worker 降级\u0026quot;\u0026quot;\u0026quot;\n        # 尝试主 Worker\n        result = await super()._execute_single(task, max_retries)\n        if result.status == \u0026quot;done\u0026quot;:\n            return result\n\n        # 主 Worker 失败，尝试降级 Worker\n        fallbacks = self.fallback_workers.get(task.assigned_to, [])\n        for fb_name in fallbacks:\n            self._log(\u0026quot;team\u0026quot;, f\u0026quot;降级: {task.assigned_to} -\u0026gt; {fb_name}\u0026quot;)\n            task.assigned_to = fb_name\n            task.status = \u0026quot;pending\u0026quot;\n            task.error = \u0026quot;\u0026quot;\n            result = await super()._execute_single(task, max_retries=1)\n            if result.status == \u0026quot;done\u0026quot;:\n                return result\n\n        return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.2 Supervisor 失败\u003c/h3\u003e\n\u003cp\u003eSupervisor 失败更严重——它是中央协调者，失败意味着整个任务无法继续。处理策略：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e外部监控\u003c/strong\u003e：在 AgentTeam 之上设置一个非 LLM 的监控层，检测 Supervisor 的健康状态\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSupervisor 冗余\u003c/strong\u003e：准备一个备用 Supervisor（可以用不同的模型），主 Supervisor 失败时切换\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCheckpoint 机制\u003c/strong\u003e：Supervisor 在每个决策点保存状态快照，失败后从最近的 Checkpoint 恢复\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def run_with_checkpoint(self, task: str) -\u0026gt; TeamResult:\n    \u0026quot;\u0026quot;\u0026quot;带 Checkpoint 的执行流程\u0026quot;\u0026quot;\u0026quot;\n    checkpoint = {\u0026quot;phase\u0026quot;: \u0026quot;init\u0026quot;, \u0026quot;subtasks\u0026quot;: [], \u0026quot;completed\u0026quot;: []}\n\n    try:\n        # Phase 1: 分解\n        checkpoint[\u0026quot;phase\u0026quot;] = \u0026quot;decompose\u0026quot;\n        subtasks = await self.supervisor.decompose(task, self.workers)\n        checkpoint[\u0026quot;subtasks\u0026quot;] = subtasks\n\n        # Phase 2: 执行\n        checkpoint[\u0026quot;phase\u0026quot;] = \u0026quot;execute\u0026quot;\n        completed = await self._execute_tasks(subtasks, max_retries=2)\n        checkpoint[\u0026quot;completed\u0026quot;] = completed\n\n        # Phase 3: 合成\n        checkpoint[\u0026quot;phase\u0026quot;] = \u0026quot;synthesize\u0026quot;\n        output = await self.supervisor.synthesize(task, completed)\n\n        return TeamResult(success=True, output=output, tasks=completed)\n\n    except Exception as e:\n        self._log(\u0026quot;team\u0026quot;, f\u0026quot;失败于阶段 {checkpoint[\u0026#39;phase\u0026#39;]}: {e}\u0026quot;)\n        # 可以从 checkpoint 恢复，跳过已完成的阶段\n        return TeamResult(\n            success=False,\n            output=f\u0026quot;任务在 {checkpoint[\u0026#39;phase\u0026#39;]} 阶段失败: {e}\u0026quot;,\n            tasks=checkpoint.get(\u0026quot;completed\u0026quot;, []),\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.3 死锁检测\u003c/h3\u003e\n\u003cp\u003e在 Peer-to-Peer 模式中，两个 Agent 可能互相等待对方的回复，形成死锁。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e死锁场景：\n\n  Agent A: \u0026quot;请 Agent B 先确认方案\u0026quot;\n           ↓ 等待 B\n  Agent B: \u0026quot;请 Agent A 先提供数据\u0026quot;\n           ↓ 等待 A\n  → 无限等待\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e解决方案：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass DeadlockDetector:\n    \u0026quot;\u0026quot;\u0026quot;简单的死锁检测器\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, timeout_seconds: float = 60):\n        self.timeout = timeout_seconds\n        self._waiting: dict[str, str] = {}  # agent_id -\u0026gt; waiting_for_agent_id\n\n    def register_wait(self, agent_id: str, waiting_for: str):\n        self._waiting[agent_id] = waiting_for\n        # 检测环形等待\n        if self._has_cycle(agent_id):\n            raise DeadlockError(\n                f\u0026quot;检测到死锁: {self._trace_cycle(agent_id)}\u0026quot;\n            )\n\n    def _has_cycle(self, start: str) -\u0026gt; bool:\n        visited = set()\n        current = start\n        while current in self._waiting:\n            if current in visited:\n                return True\n            visited.add(current)\n            current = self._waiting[current]\n        return False\n\n    def _trace_cycle(self, start: str) -\u0026gt; str:\n        chain = [start]\n        current = self._waiting.get(start, \u0026quot;\u0026quot;)\n        while current != start and current:\n            chain.append(current)\n            current = self._waiting.get(current, \u0026quot;\u0026quot;)\n        chain.append(start)\n        return \u0026quot; -\u0026gt; \u0026quot;.join(chain)\n\n\nclass DeadlockError(Exception):\n    pass\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Multi-Agent 的成本问题\u003c/h2\u003e\n\u003cp\u003e成本是 Multi-Agent 系统必须正视的问题。它不只是\u0026quot;贵一点\u0026quot;的问题——可能是\u0026quot;贵一个数量级\u0026quot;的问题。\u003c/p\u003e\n\u003ch3\u003e7.1 成本模型\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eSingle-Agent 执行一个任务的 Token 消耗：\n\n  1 x System Prompt   +  N x (Context + Response)\n  ~1,000 tokens          ~3,000 tokens x 5 iterations\n                         = ~16,000 tokens\n\n\nMulti-Agent (Supervisor + 3 Workers) 的 Token 消耗：\n\n  Supervisor 分解:   ~4,000 tokens   (System Prompt + 任务分解)\n  Worker A 执行:     ~8,000 tokens   (System Prompt + 执行)\n  Worker B 执行:     ~8,000 tokens   (System Prompt + 执行)\n  Worker C 执行:     ~8,000 tokens   (System Prompt + 执行)\n  Supervisor 合成:   ~6,000 tokens   (收集所有结果 + 合成)\n                     ──────────────\n  Total:             ~34,000 tokens   ← 约 2x Single-Agent\n\n  如果 Worker 内部也有多轮迭代，消耗会更高。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.2 什么时候 Multi-Agent 的收益大于成本\u003c/h3\u003e\n\u003cp\u003e不是所有场景都值得用 Multi-Agent。一个简单的决策框架：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                        任务复杂度\n                    低 ─────────── 高\n                    │               │\n  专业化需求  低    │  Single-Agent │  Single-Agent\n              │    │  (够用)       │  + Better Prompt\n              │    │               │\n              高    │  Single-Agent │  Multi-Agent ✓\n                    │  + Tools      │  (值得投入)\n                    │               │\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMulti-Agent 在以下条件下收益最大：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e任务天然可并行\u003c/strong\u003e：子任务之间独立性高，Multi-Agent 通过并行执行缩短总耗时，即使 token 消耗增加，时间成本下降\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e专业化收益显著\u003c/strong\u003e：专家 Agent 在自己的领域比通用 Agent 的输出质量显著更高，质量提升值得额外成本\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSingle-Agent 已经到达能力瓶颈\u003c/strong\u003e：Context Window 不够、单个 prompt 角色冲突、输出质量不稳定\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e任务的商业价值足够高\u003c/strong\u003e：生成一份价值数万元的分析报告，多花几美元的 API 费用是可以接受的\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e7.3 成本优化策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass CostAwareTeam(AgentTeam):\n    \u0026quot;\u0026quot;\u0026quot;成本感知的 Agent 团队\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor, token_budget: int = 100_000):\n        super().__init__(supervisor)\n        self.token_budget = token_budget\n        self.token_used = 0\n\n    def _select_model_for_task(self, task: Task) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;根据任务复杂度选择模型——不是所有子任务都需要最强模型\u0026quot;\u0026quot;\u0026quot;\n        if task.context.get(\u0026quot;complexity\u0026quot;) == \u0026quot;low\u0026quot;:\n            return \u0026quot;gpt-4o-mini\u0026quot;     # 简单任务用小模型\n        elif task.context.get(\u0026quot;complexity\u0026quot;) == \u0026quot;high\u0026quot;:\n            return \u0026quot;gpt-4o\u0026quot;          # 复杂任务用大模型\n        else:\n            return \u0026quot;gpt-4o-mini\u0026quot;     # 默认用小模型，够用即可\n\n    def _should_continue(self) -\u0026gt; bool:\n        \u0026quot;\u0026quot;\u0026quot;预算检查\u0026quot;\u0026quot;\u0026quot;\n        if self.token_used \u0026gt;= self.token_budget:\n            self._log(\u0026quot;team\u0026quot;, f\u0026quot;Token 预算耗尽 ({self.token_used}/{self.token_budget})\u0026quot;)\n            return False\n        return True\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键原则：\u003cstrong\u003eRouter 和 Supervisor 可以用轻量模型，只有需要深度推理的 Worker 才用重量级模型。\u003c/strong\u003e 这类似人类组织中，项目经理不需要是技术最强的人，但专家必须在各自领域足够专业。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e8. Multi-Agent 的调试挑战\u003c/h2\u003e\n\u003cp\u003eMulti-Agent 系统的调试难度是 Single-Agent 的平方级增长——不仅每个 Agent 内部可能出错，Agent 之间的交互也可能出错。\u003c/p\u003e\n\u003ch3\u003e8.1 执行链路追踪\u003c/h3\u003e\n\u003cp\u003e每次 Multi-Agent 执行都应该生成一个完整的 Trace，记录每个 Agent 的每次 LLM 调用、输入、输出和耗时。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport time\nimport uuid\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass Span:\n    \u0026quot;\u0026quot;\u0026quot;一个执行跨度（对应一次 Agent 操作）\u0026quot;\u0026quot;\u0026quot;\n    span_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])\n    parent_id: str = \u0026quot;\u0026quot;\n    agent_name: str = \u0026quot;\u0026quot;\n    operation: str = \u0026quot;\u0026quot;          # \u0026quot;decompose\u0026quot;, \u0026quot;execute\u0026quot;, \u0026quot;synthesize\u0026quot;\n    input_summary: str = \u0026quot;\u0026quot;\n    output_summary: str = \u0026quot;\u0026quot;\n    start_time: float = 0.0\n    end_time: float = 0.0\n    token_count: int = 0\n    status: str = \u0026quot;running\u0026quot;      # running | done | failed\n    children: list = field(default_factory=list)\n\n    @property\n    def duration_ms(self) -\u0026gt; float:\n        return (self.end_time - self.start_time) * 1000\n\n\nclass Tracer:\n    \u0026quot;\u0026quot;\u0026quot;Multi-Agent 执行链路追踪器\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self.root_span: Span | None = None\n        self._span_stack: list[Span] = []\n\n    def start_span(self, agent_name: str, operation: str, input_summary: str = \u0026quot;\u0026quot;) -\u0026gt; Span:\n        span = Span(\n            agent_name=agent_name,\n            operation=operation,\n            input_summary=input_summary[:200],\n            start_time=time.time(),\n        )\n        if self._span_stack:\n            parent = self._span_stack[-1]\n            span.parent_id = parent.span_id\n            parent.children.append(span)\n        else:\n            self.root_span = span\n\n        self._span_stack.append(span)\n        return span\n\n    def end_span(self, output_summary: str = \u0026quot;\u0026quot;, status: str = \u0026quot;done\u0026quot;):\n        if self._span_stack:\n            span = self._span_stack.pop()\n            span.end_time = time.time()\n            span.output_summary = output_summary[:200]\n            span.status = status\n\n    def print_trace(self, span: Span = None, indent: int = 0):\n        \u0026quot;\u0026quot;\u0026quot;打印可视化的执行链路\u0026quot;\u0026quot;\u0026quot;\n        span = span or self.root_span\n        if not span:\n            return\n\n        prefix = \u0026quot;  \u0026quot; * indent\n        status_icon = \u0026quot;OK\u0026quot; if span.status == \u0026quot;done\u0026quot; else \u0026quot;FAIL\u0026quot;\n        print(\n            f\u0026quot;{prefix}[{status_icon}] {span.agent_name}.{span.operation} \u0026quot;\n            f\u0026quot;({span.duration_ms:.0f}ms)\u0026quot;\n        )\n        if span.input_summary:\n            print(f\u0026quot;{prefix}  IN:  {span.input_summary[:80]}\u0026quot;)\n        if span.output_summary:\n            print(f\u0026quot;{prefix}  OUT: {span.output_summary[:80]}\u0026quot;)\n\n        for child in span.children:\n            self.print_trace(child, indent + 1)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e输出示例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e[OK] supervisor.decompose (2340ms)\n  IN:  撰写一篇关于 LLM Agent 在企业客服场景落地的技术调研报告...\n  OUT: {\u0026quot;subtasks\u0026quot;: [{\u0026quot;task_id\u0026quot;: \u0026quot;task_1\u0026quot;, ...}, ...]}\n  [OK] searcher.execute (5120ms)\n    IN:  搜索 LLM Agent 客服场景的行业现状和主流方案...\n    OUT: ## 行业现状\\n1. 2024 年全球智能客服市场规模...\n  [OK] analyst.execute (4800ms)\n    IN:  分析搜索结果，提炼关键洞察和趋势...\n    OUT: ## 分析结论\\n1. 技术成熟度：LLM 客服处于...\n  [OK] writer.execute (6200ms)\n    IN:  根据分析结果撰写完整的技术调研报告...\n    OUT: # LLM Agent 企业客服落地技术调研报告\\n\\n## 1. 执行摘要...\n[OK] supervisor.synthesize (3100ms)\n  IN:  请合成最终结果。\n  OUT: # LLM Agent 企业客服落地技术调研报告（终稿）...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.2 Bug 复现\u003c/h3\u003e\n\u003cp\u003eMulti-Agent 场景的 bug 复现特别困难，因为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLM 输出是非确定性的——相同输入可能产生不同输出\u003c/li\u003e\n\u003cli\u003eAgent 之间的交互是动态的——执行路径取决于中间结果\u003c/li\u003e\n\u003cli\u003e并发执行的时序不确定——Worker A 和 B 谁先完成可能影响最终结果\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e应对策略：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e记录完整的 LLM 输入/输出\u003c/strong\u003e：在 Trace 中保存每次 LLM 调用的完整 messages 和 response，不只是摘要\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDeterministic Replay\u003c/strong\u003e：用固定的 seed 和 temperature=0 复现执行，或者直接 mock LLM 响应\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e快照式调试\u003c/strong\u003e：在每个 Agent 决策点保存完整的 Blackboard 状态快照，出问题时可以回溯到任意时间点\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ReplayableTeam(AgentTeam):\n    \u0026quot;\u0026quot;\u0026quot;可回放的 Agent 团队——记录完整的 LLM 交互供复现\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor):\n        super().__init__(supervisor)\n        self._llm_recordings: list[dict] = []\n\n    def record_llm_call(self, agent_name: str, messages: list[dict], response: str):\n        self._llm_recordings.append({\n            \u0026quot;agent\u0026quot;: agent_name,\n            \u0026quot;messages\u0026quot;: messages,\n            \u0026quot;response\u0026quot;: response,\n            \u0026quot;timestamp\u0026quot;: time.time(),\n        })\n\n    def save_recording(self, path: str):\n        \u0026quot;\u0026quot;\u0026quot;保存录制数据，用于后续回放和调试\u0026quot;\u0026quot;\u0026quot;\n        with open(path, \u0026quot;w\u0026quot;) as f:\n            json.dump(self._llm_recordings, f, ensure_ascii=False, indent=2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.3 可观测性设计\u003c/h3\u003e\n\u003cp\u003e一个生产级 Multi-Agent 系统至少需要以下可观测性指标：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e指标类别\u003c/th\u003e\n\u003cth\u003e具体指标\u003c/th\u003e\n\u003cth\u003e目的\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个 Agent 的执行时间、端到端总时间\u003c/td\u003e\n\u003ctd\u003e定位性能瓶颈\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e成本\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个 Agent 的 Token 消耗、总消耗\u003c/td\u003e\n\u003ctd\u003e成本监控和预算控制\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e质量\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e任务成功率、重试次数、降级次数\u003c/td\u003e\n\u003ctd\u003e评估系统可靠性\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e链路\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e完整的 Trace（Agent、操作、输入、输出）\u003c/td\u003e\n\u003ctd\u003e问题排查\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e状态\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eBlackboard 的状态变更历史\u003c/td\u003e\n\u003ctd\u003e数据流追踪\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e通信\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eAgent 间消息数量、消息大小\u003c/td\u003e\n\u003ctd\u003e通信效率分析\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 设计 Multi-Agent 系统的决策清单\u003c/h2\u003e\n\u003cp\u003e在你决定构建 Multi-Agent 系统之前，逐一回答以下问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e必要性验证\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e单个 Agent 真的不够吗？是否尝试过优化 prompt、增加工具、使用更强的模型？\u003c/li\u003e\n\u003cli\u003e任务是否天然需要多角色/多视角？还是只是因为你觉得\u0026quot;多 Agent 更酷\u0026quot;？\u003c/li\u003e\n\u003cli\u003e团队的 LLM API 预算能否支撑多 Agent 的额外消耗？\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e架构选择\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e任务结构更接近哪种模式？Supervisor-Worker / Peer-to-Peer / Pipeline / Dynamic Routing？\u003c/li\u003e\n\u003cli\u003eAgent 之间需要什么样的通信？单向传递 / 双向协商 / 广播通知？\u003c/li\u003e\n\u003cli\u003e状态应该共享还是独立？冲突解决策略是什么？\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e工程保障\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每个 Agent 的失败影响范围是什么？有降级方案吗？\u003c/li\u003e\n\u003cli\u003e如何追踪一个请求在多个 Agent 之间的完整执行链路？\u003c/li\u003e\n\u003cli\u003e如何测试多 Agent 协作的正确性——单元测试（单个 Agent）+ 集成测试（Agent 交互）？\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 结语与展望\u003c/h2\u003e\n\u003cp\u003e本文是 Phase 3（How to Scale Agent Intelligence）的最后一篇。在 Phase 3 的四篇文章中，我们从单个 Agent 的四个维度进行了升级：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePhase 3 知识路线：\n\n  第 08 篇 Memory       → Agent 有了\u0026quot;记忆\u0026quot;\n  第 09 篇 RAG          → Agent 有了\u0026quot;外部知识\u0026quot;\n  第 10 篇 Planning     → Agent 有了\u0026quot;规划和反思\u0026quot;\n  第 11 篇 Multi-Agent  → Agent 有了\u0026quot;团队协作\u0026quot;（本文）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e至此，我们已经拥有构建一个\u0026quot;聪明的\u0026quot; Agent 系统所需的全部核心概念。但\u0026quot;聪明\u0026quot;不等于\u0026quot;可用\u0026quot;。一个在本地跑通 demo 的 Multi-Agent 系统，距离生产环境还有巨大的鸿沟——框架选型、协议标准化、可观测性、安全性、成本控制、评估体系。\u003c/p\u003e\n\u003cp\u003e这正是 Phase 4（How to Ship Agents to Production）要解决的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e下一篇（12）\u003c/strong\u003e：LangChain vs LangGraph —— 你应该用框架还是自己写？框架的价值边界在哪里？我们会从 Chain 和 Graph 两种抽象出发，讨论框架在什么时候是加速器，什么时候是束缚。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 13 篇\u003c/strong\u003e：MCP and Tool Protocol —— Agent 的工具需要标准化。MCP 协议如何让不同 Agent 共享工具？工具的发现、声明、权限控制。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 14 篇\u003c/strong\u003e：Production-Grade Agent Systems —— 最后一篇，打通最后一公里：评估、安全、成本、灰度、监控。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e进一步思考\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e关于协作模式的演化\u003c/strong\u003e：本文介绍的四种模式是\u0026quot;纯模式\u0026quot;。真实系统中，你很可能需要混合模式——比如 Supervisor-Worker 的 Worker 内部用 Pipeline，或者 Dynamic Routing 的专家 Agent 内部用 Peer-to-Peer 辩论。如何设计这种嵌套的多层协作结构，是一个值得深入探索的方向。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于 Agent 的涌现行为\u003c/strong\u003e：当多个 Agent 协作时，是否会出现超越单个 Agent 能力的\u0026quot;涌现行为\u0026quot;？还是说 Multi-Agent 的上限永远被最强的那个 Agent 决定？这个问题在学术界尚无定论，但从实践角度看，好的协作架构确实能产出超越任何单个 Agent 的结果——正如一个好的工程团队能完成任何个人都无法独自完成的项目。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于 Human-in-the-Loop\u003c/strong\u003e：本文讨论的全是 Agent-to-Agent 的协作。但在生产环境中，最重要的\u0026quot;Agent\u0026quot;可能是人类。如何设计一个 Multi-Agent 系统，让人类能在关键节点介入、审核和纠正？Human-Agent 协作可能比 Agent-Agent 协作更有实用价值，也更有挑战性。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 11 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/10-Planning%20and%20Reflection\"\u003e10 | Planning and Reflection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/12-LangChain%20vs%20LangGraph\"\u003e12 | LangChain vs LangGraph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-1 text-sm mb-4\",\"children\":[[\"$\",\"$L13\",null,{\"href\":\"/blog/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"博客\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"Engineering\"}],[[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L13\",null,{\"href\":\"/blog/category/engineering/agentic/page/1\",\"className\":\"text-blue-600 hover:text-blue-700 transition-colors\",\"children\":\"Agentic 系统\"}]]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center mb-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-4 h-4 mr-2 text-gray-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z\"}]}],[\"$\",\"time\",null,{\"dateTime\":\"2026-01-12\",\"children\":\"2026年01月12日\"}]]}]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-6 text-center\",\"children\":\"Planning and Reflection: 从 ReAct 到分层规划与自我纠错\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6 justify-center\",\"children\":[[\"$\",\"$L13\",\"Agentic\",{\"href\":\"/blog/tag/Agentic/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Agentic\"}],[\"$\",\"$L13\",\"AI Engineering\",{\"href\":\"/blog/tag/AI%20Engineering/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"AI Engineering\"}],[\"$\",\"$L13\",\"Planning\",{\"href\":\"/blog/tag/Planning/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Planning\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto\",\"children\":[\"$\",\"$L14\",null,{\"content\":\"$15\"}]}],[\"$\",\"$10\",null,{\"fallback\":[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":\"加载导航中...\"}],\"children\":[\"$\",\"$L16\",null,{\"globalNav\":{\"prev\":{\"slug\":\"engineering/agentic/09-RAG as Cognitive Memory\",\"title\":\"RAG as Cognitive Memory: 检索增强生成的工程实践\",\"description\":\"RAG 不是搜索+拼接，而是 Agent 的认知记忆系统。本文从 Ingestion、Chunking、Embedding、Hybrid Retrieval、Reranking 到 Context Packing，逐层拆解 RAG Pipeline 的工程实践与决策 Trade-off。核心观点：检索质量 \u003e 模型大小。\",\"pubDate\":\"2026-01-07\",\"tags\":[\"Agentic\",\"AI Engineering\",\"RAG\"],\"heroImage\":\"$undefined\",\"content\":\"$17\"},\"next\":{\"slug\":\"engineering/domain/基于DDD构建微服务：从战略设计到落地实践\",\"title\":\"基于DDD构建微服务：从战略设计到落地实践\",\"description\":\"深入探讨领域驱动设计（DDD）如何指导微服务的拆分与设计。从界限上下文、聚合、上下文映射到事件风暴，系统性地阐述 DDD 的战略设计工具如何帮助我们找到正确的服务边界，并通过事件驱动架构和 BFF 模式解决微服务间的通信与协作问题。\",\"pubDate\":\"2026-01-15\",\"tags\":[\"DDD\",\"微服务\",\"领域驱动设计\",\"架构设计\",\"事件驱动\"],\"heroImage\":\"$undefined\",\"content\":\"$18\"}},\"tagNav\":{\"Agentic\":{\"prev\":\"$5:props:children:props:children:props:children:2:props:children:props:globalNav:prev\",\"next\":{\"slug\":\"engineering/agentic/11-Multi-Agent Collaboration\",\"title\":\"Multi-Agent Collaboration: 多 Agent 协作模式与架构\",\"description\":\"单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。\",\"pubDate\":\"2026-01-17\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Multi-Agent\"],\"heroImage\":\"$undefined\",\"content\":\"$19\"}},\"AI Engineering\":{\"prev\":\"$5:props:children:props:children:props:children:2:props:children:props:globalNav:prev\",\"next\":\"$5:props:children:props:children:props:children:2:props:children:props:tagNav:Agentic:next\"},\"Planning\":{\"prev\":null,\"next\":null}}}]}],[\"$\",\"$L1a\",null,{}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"8:null\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"a:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Planning and Reflection: 从 ReAct 到分层规划与自我纠错 - Skyfalling Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Planning and Reflection: 从 ReAct 到分层规划与自我纠错\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"5\",{\"property\":\"article:published_time\",\"content\":\"2026-01-12\"}],[\"$\",\"meta\",\"6\",{\"property\":\"article:author\",\"content\":\"Skyfalling\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Planning and Reflection: 从 ReAct 到分层规划与自我纠错\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。\"}],[\"$\",\"link\",\"10\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"13\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":\"$a:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>