<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/0458d6941a120cde.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42d55485b4428e47.js"/><script src="/_next/static/chunks/4bd1b696-8ec333fca6b38e39.js" async=""></script><script src="/_next/static/chunks/1684-a2aac8a674e5d38c.js" async=""></script><script src="/_next/static/chunks/main-app-2791dc86ed05573e.js" async=""></script><script src="/_next/static/chunks/6874-7791217feaf05c17.js" async=""></script><script src="/_next/static/chunks/app/layout-51baccc14cf1da9e.js" async=""></script><script src="/_next/static/chunks/968-d7155a2506e36f1d.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js" async=""></script><meta name="next-size-adjust" content=""/><title>Multi-Agent Collaboration: 多 Agent 协作模式与架构 - Skyfalling Blog</title><meta name="description" content="单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。"/><meta property="og:title" content="Multi-Agent Collaboration: 多 Agent 协作模式与架构"/><meta property="og:description" content="单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。"/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-01-17"/><meta property="article:author" content="Skyfalling"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Multi-Agent Collaboration: 多 Agent 协作模式与架构"/><meta name="twitter:description" content="单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。"/><link rel="shortcut icon" href="/favicon.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/favicon.png"/><link rel="apple-touch-icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen flex flex-col"><header class="bg-[var(--background)]"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a class="-m-1.5 p-1.5" href="/"><span class="sr-only">Skyfalling Blog</span><span class="text-2xl font-bold text-gray-900">Skyfalling</span></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">打开主菜单</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/">首页</a><a class="text-base font-semibold leading-6 transition-colors text-blue-600 border-b-2 border-blue-600 pb-1" href="/blog/">博客</a><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/about/">关于</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/contact/">联系 <span aria-hidden="true">→</span></a></div></nav></header><main class="flex-1"><article class="min-h-screen"><div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8"><div class="rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12"><header class="mb-8"><div class="flex items-center mb-6"><div class="inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal"><svg class="w-4 h-4 mr-2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2026-01-17">2026年01月17日</time></div></div><h1 class="text-4xl font-bold text-gray-900 mb-6 text-center">Multi-Agent Collaboration: 多 Agent 协作模式与架构</h1><div class="flex flex-wrap gap-2 mb-6 justify-center"><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Agentic/page/1/">Agentic</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/AI%20Engineering/page/1/">AI Engineering</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/Multi-Agent/page/1/">Multi-Agent</a></div></header><div class="max-w-5xl mx-auto"><div class="prose prose-lg prose-gray mx-auto max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:text-blue-700 prose-strong:text-gray-900 prose-strong:font-semibold prose-li:text-gray-700 prose-hr:border-gray-300"><h1>Multi-Agent Collaboration: 多 Agent 协作模式与架构</h1>
<blockquote>
<p>一个人可以走得很快，但一群人才能走得很远。Agent 也是如此。</p>
<p>本文是 Agentic 系列第 11 篇。前 10 篇我们一直在讨论单个 Agent 如何更聪明——更好的记忆、更强的工具、更深的规划。这一篇，我们把视角从&quot;个体智能&quot;拉升到&quot;集体智能&quot;：当一个 Agent 不够用时，多个 Agent 如何协作？</p>
</blockquote>
<hr>
<h2>1. 为什么单 Agent 不够</h2>
<h3>1.1 一个类比：从独立开发者到工程团队</h3>
<p>想象你是一个全栈工程师，独自完成一个项目。前端、后端、数据库、DevOps、测试、文档——全部一个人扛。小项目可以，但当系统规模增长到一定程度，你会发现：</p>
<ul>
<li><strong>注意力是瓶颈</strong>：你不可能同时想着 CSS 布局和数据库索引优化</li>
<li><strong>专业化有上限</strong>：一个人很难同时成为安全专家、性能专家和 UX 专家</li>
<li><strong>效率有天花板</strong>：就算你是 10x 工程师，你的时间也是串行的</li>
<li><strong>单点风险</strong>：你生病了，整个项目就停了</li>
</ul>
<p>这就是人类发明&quot;团队协作&quot;的原因。Agent 面临完全相同的结构性限制。</p>
<h3>1.2 Single-Agent 的四个天花板</h3>
<p><strong>天花板一：Context Window 限制</strong></p>
<p>一个 Agent 的 System Prompt 需要包含：角色定义、工具描述、输出格式约束、领域知识、示例。当你试图让一个 Agent 同时承担搜索、分析、写作、代码生成、数据可视化等多个职能时，光是工具描述就可能占据数万 token。留给实际任务执行的上下文空间被严重压缩。</p>
<pre><code>一个&quot;全能&quot; Agent 的 Context 分配：

┌─────────────────────────────────────────────────┐
│ System Prompt (角色 + 规则)         ~2,000 tokens │
│ Tool Schemas (15 个工具)            ~6,000 tokens │
│ 领域知识 (RAG 检索结果)             ~4,000 tokens │
│ 对话历史                            ~8,000 tokens │
│ 当前任务 + 中间状态                 ~3,000 tokens │
├─────────────────────────────────────────────────┤
│ 剩余可用空间                        ~9,000 tokens │ ← 越来越捉襟见肘
│ (128K 窗口下比例更好，但工具越多问题越突出)         │
└─────────────────────────────────────────────────┘
</code></pre>
<p>更关键的是，研究表明 LLM 在超长上下文中存在&quot;Lost in the Middle&quot;问题——中间位置的信息检索准确率显著下降。塞得越多，每条信息被有效利用的概率越低。</p>
<p><strong>天花板二：专业化限制</strong></p>
<p>一个 System Prompt 很难让 LLM 同时扮演好多个角色。你告诉它&quot;你是一个严谨的数据分析师&quot;，它分析数据时很好；但同一个 prompt 里你又说&quot;你也是一个有创意的文案写手&quot;，这两种人格的行为模式是矛盾的。严谨和创意在同一个 prompt 中互相干扰，最终两个角色都做不好。</p>
<p>这不是 prompt engineering 的技巧问题，而是注意力分配的结构性问题——一个 LLM 调用只有一个 attention 分布，强调了分析的严谨性，就必然削弱了文案的创造性。</p>
<p><strong>天花板三：可靠性限制</strong></p>
<p>单 Agent 是一个 Single Point of Failure。如果它在第 5 步推理出错（比如工具调用参数写错），整个任务链路都会受到污染。虽然我们在第 10 篇讨论了 Reflection 和自我纠错，但自我纠错的前提是&quot;能发现自己错了&quot;——而 LLM 对自身错误的检测能力是有限的。</p>
<p><strong>天花板四：并行度限制</strong></p>
<p>单 Agent 的执行是串行的——一次 LLM 调用，等待结果，再进行下一次。如果一个任务可以分解为三个独立子任务（比如同时搜索三个数据源），单 Agent 只能顺序执行，浪费了大量时间。</p>
<pre><code>Single-Agent 串行执行：

  Task ──→ [Search A] ──→ [Search B] ──→ [Search C] ──→ [Synthesize]
                                                         Total: ~40s

Multi-Agent 并行执行：

           ┌─→ [Search A] ─┐
  Task ──→ ├─→ [Search B] ─┼──→ [Synthesize]
           └─→ [Search C] ─┘
                              Total: ~15s
</code></pre>
<hr>
<h2>2. Multi-Agent 的四种协作模式</h2>
<p>当我们决定使用多个 Agent 时，第一个架构问题是：<strong>它们之间的协作关系是什么？</strong> 不同的关系模式适用于不同的场景，选错模式比用错框架更致命。</p>
<h3>2.1 模式一：Supervisor-Worker（上级分配型）</h3>
<pre><code>                    ┌──────────────────┐
                    │    Supervisor    │
                    │   (任务分解 +    │
                    │    结果合成)     │
                    └──────┬───────────┘
                           │
              ┌────────────┼────────────┐
              │            │            │
              ▼            ▼            ▼
       ┌──────────┐ ┌──────────┐ ┌──────────┐
       │ Worker A │ │ Worker B │ │ Worker C │
       │ (搜索)   │ │ (分析)   │ │ (写作)   │
       └──────────┘ └──────────┘ └──────────┘
              │            │            │
              └────────────┼────────────┘
                           │
                           ▼
                    ┌──────────────────┐
                    │    Supervisor    │
                    │   (收集 + 合成   │
                    │    最终输出)     │
                    └──────────────────┘
</code></pre>
<p><strong>工作流程</strong>：</p>
<ol>
<li>Supervisor Agent 接收用户任务</li>
<li>Supervisor 将任务分解为子任务，分配给不同的 Worker Agent</li>
<li>每个 Worker 独立执行各自的子任务</li>
<li>Supervisor 收集所有 Worker 的结果，合成最终输出</li>
</ol>
<p><strong>核心特征</strong>：</p>
<ul>
<li>有一个明确的中央协调者</li>
<li>Worker 之间不直接通信，只与 Supervisor 交互</li>
<li>Supervisor 负责全局决策，Worker 负责局部执行</li>
</ul>
<p><strong>适用场景</strong>：任务可以明确分解的场景。比如撰写一篇技术调研报告：Search Agent 负责信息搜集，Analyze Agent 负责数据分析，Write Agent 负责报告撰写。Supervisor 负责协调整个流程。</p>
<p><strong>Trade-off</strong>：Supervisor 是单点——如果 Supervisor 对任务的分解不合理，所有 Worker 的努力都会被浪费。此外，Supervisor 本身也是一个 LLM 调用，它对任务的理解能力决定了整个系统的上限。</p>
<h3>2.2 模式二：Peer-to-Peer（平等协商型）</h3>
<pre><code>       ┌──────────┐          ┌──────────┐
       │ Agent A  │◀────────▶│ Agent B  │
       │ (作者)   │          │ (审稿人) │
       └────┬─────┘          └────┬─────┘
            │                     │
            │    ┌──────────┐     │
            └───▶│ Agent C  │◀────┘
                 │ (编辑)   │
                 └──────────┘

       消息流是双向的，没有固定的上下级关系
       每个 Agent 都可以发起对话、提出意见、做出决策
</code></pre>
<p><strong>工作流程</strong>：</p>
<ol>
<li>多个 Agent 地位平等，通过消息传递进行协商</li>
<li>没有中央协调者——Agent 之间直接通信</li>
<li>通过多轮对话达成共识或完成任务</li>
</ol>
<p><strong>核心特征</strong>：</p>
<ul>
<li>去中心化</li>
<li>Agent 之间直接消息传递</li>
<li>适合需要多视角碰撞的任务</li>
</ul>
<p><strong>适用场景</strong>：辩论式分析（多个 Agent 从不同立场论证）、代码审查（Author Agent 写代码，Reviewer Agent 审查，双方来回沟通直到代码质量达标）、多角度决策（乐观分析师 + 悲观分析师 + 风险评估师共同评估一个投资决策）。</p>
<p><strong>Trade-off</strong>：没有中央协调意味着可能出现无限循环（两个 Agent 互相不同意，永远达不成共识）。需要额外的终止机制——最大轮次限制、外部仲裁者、投票制度等。调试也更困难，因为没有一个中心节点可以观察全局状态。</p>
<h3>2.3 模式三：Pipeline（流水线型）</h3>
<pre><code>  Input                                                          Output
    │                                                              ▲
    ▼                                                              │
┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐
│ Draft  │───▶│ Review │───▶│  Edit  │───▶│  Fact  │───▶│ Format │
│ Agent  │    │ Agent  │    │ Agent  │    │ Check  │    │ Agent  │
│        │    │        │    │        │    │ Agent  │    │        │
└────────┘    └────────┘    └────────┘    └────────┘    └────────┘

  Stage 1       Stage 2       Stage 3       Stage 4       Stage 5
  生成初稿      审查质量       修改完善      事实核查       格式化输出
</code></pre>
<p><strong>工作流程</strong>：</p>
<ol>
<li>Agent 按顺序串联，形成流水线</li>
<li>上游 Agent 的输出是下游 Agent 的输入</li>
<li>每个 Agent 专注于一个处理阶段</li>
</ol>
<p><strong>核心特征</strong>：</p>
<ul>
<li>类似 Unix 管道：<code>cmd1 | cmd2 | cmd3</code></li>
<li>数据单向流动</li>
<li>每个阶段的 Agent 有明确、单一的职责</li>
</ul>
<p><strong>适用场景</strong>：内容生产流水线（起草 -&gt; 审查 -&gt; 编辑 -&gt; 排版）、数据处理管道（提取 -&gt; 清洗 -&gt; 转换 -&gt; 加载）、多阶段审批（初审 -&gt; 复审 -&gt; 终审）。</p>
<p><strong>Trade-off</strong>：流水线是严格串行的——上游不完成，下游无法开始。如果中间某个 Agent 输出质量差，后续所有阶段都会受影响（错误传播）。但好处是架构简单、易于理解和调试、每个阶段可以独立优化。</p>
<h3>2.4 模式四：Dynamic Routing（动态路由型）</h3>
<pre><code>                    ┌──────────────────┐
                    │   Router Agent   │
                    │ (意图识别 + 路由) │
                    └──────┬───────────┘
                           │
              ┌────────────┼────────────┐
              │            │            │
              ▼            ▼            ▼
       ┌──────────┐ ┌──────────┐ ┌──────────┐
       │ 技术支持  │ │ 售后服务  │ │ 销售咨询  │
       │ Agent    │ │ Agent    │ │ Agent    │
       │          │ │          │ │          │
       │ 处理技术  │ │ 处理退款  │ │ 处理购买  │
       │ 故障排查  │ │ 换货投诉  │ │ 产品推荐  │
       └──────────┘ └──────────┘ └──────────┘

  路由依据：用户输入的意图分类
  每个专家 Agent 有独立的 System Prompt、Tools、知识库
</code></pre>
<p><strong>工作流程</strong>：</p>
<ol>
<li>Router Agent 接收用户输入</li>
<li>根据意图分类，将请求路由到对应的专家 Agent</li>
<li>专家 Agent 处理请求并返回结果</li>
<li>必要时 Router 可以在专家之间进行二次路由</li>
</ol>
<p><strong>核心特征</strong>：</p>
<ul>
<li>一个轻量级的 Router 做决策</li>
<li>多个重量级的专家 Agent 做执行</li>
<li>Router 可以用简单模型（快速、便宜），专家用强大模型（准确、深入）</li>
</ul>
<p><strong>适用场景</strong>：客服系统（技术问题 -&gt; 技术 Agent，退款问题 -&gt; 售后 Agent）、多领域知识问答（医疗问题 -&gt; 医疗 Agent，法律问题 -&gt; 法律 Agent）、代码助手（Python 问题 -&gt; Python 专家，Rust 问题 -&gt; Rust 专家）。</p>
<p><strong>Trade-off</strong>：路由准确率是整个系统的瓶颈——路由错了，后面再专业也没用。模糊意图（&quot;我买的东西有技术问题&quot;——这是技术支持还是售后？）需要特殊处理。一种常见策略是允许 Router 在不确定时同时咨询多个专家，再综合判断。</p>
<h3>2.5 四种模式的对比决策</h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>Supervisor-Worker</th>
<th>Peer-to-Peer</th>
<th>Pipeline</th>
<th>Dynamic Routing</th>
</tr>
</thead>
<tbody><tr>
<td>控制结构</td>
<td>中心化</td>
<td>去中心化</td>
<td>线性</td>
<td>分发型</td>
</tr>
<tr>
<td>通信模式</td>
<td>星形</td>
<td>网状</td>
<td>链式</td>
<td>扇出</td>
</tr>
<tr>
<td>并行度</td>
<td>高（Worker 并行）</td>
<td>中</td>
<td>低（严格串行）</td>
<td>高（请求级并行）</td>
</tr>
<tr>
<td>适用复杂度</td>
<td>高</td>
<td>中</td>
<td>中</td>
<td>低-中</td>
</tr>
<tr>
<td>调试难度</td>
<td>中</td>
<td>高</td>
<td>低</td>
<td>低</td>
</tr>
<tr>
<td>典型场景</td>
<td>报告生成、项目规划</td>
<td>辩论、审查</td>
<td>内容流水线</td>
<td>客服、问答路由</td>
</tr>
</tbody></table>
<p><strong>决策原则</strong>：</p>
<ul>
<li>任务可以并行分解 -&gt; Supervisor-Worker</li>
<li>需要多视角碰撞 -&gt; Peer-to-Peer</li>
<li>处理有明确阶段 -&gt; Pipeline</li>
<li>请求类型多样，专家各有擅长 -&gt; Dynamic Routing</li>
<li>不确定？先从最简单的 Pipeline 开始，逐步演进</li>
</ul>
<hr>
<h2>3. Agent 间通信机制</h2>
<p>多个 Agent 之间需要交换信息，通信机制的选择直接影响系统的可扩展性、耦合度和调试难度。</p>
<h3>3.1 共享内存（Blackboard Pattern）</h3>
<p>所有 Agent 读写同一个共享状态存储。这是最简单直接的通信方式。</p>
<pre><code>       ┌──────────┐   ┌──────────┐   ┌──────────┐
       │ Agent A  │   │ Agent B  │   │ Agent C  │
       └────┬─────┘   └────┬─────┘   └────┬─────┘
            │  read/write   │  read/write   │
            ▼              ▼              ▼
       ┌──────────────────────────────────────────┐
       │           Shared Blackboard              │
       │                                          │
       │  { &quot;search_results&quot;: [...],              │
       │    &quot;analysis&quot;: {...},                    │
       │    &quot;draft&quot;: &quot;...&quot;,                       │
       │    &quot;status&quot;: {&quot;search&quot;: &quot;done&quot;, ...} }   │
       └──────────────────────────────────────────┘
</code></pre>
<pre><code class="language-python">from dataclasses import dataclass, field
from typing import Any
import threading


@dataclass
class Blackboard:
    &quot;&quot;&quot;共享黑板：所有 Agent 的公共状态空间&quot;&quot;&quot;
    _state: dict[str, Any] = field(default_factory=dict)
    _lock: threading.Lock = field(default_factory=threading.Lock)
    _history: list[dict] = field(default_factory=list)

    def read(self, key: str) -&gt; Any:
        with self._lock:
            return self._state.get(key)

    def write(self, key: str, value: Any, author: str = &quot;unknown&quot;):
        with self._lock:
            self._history.append({
                &quot;action&quot;: &quot;write&quot;,
                &quot;key&quot;: key,
                &quot;author&quot;: author,
                &quot;old_value&quot;: self._state.get(key),
                &quot;new_value&quot;: value,
            })
            self._state[key] = value

    def read_all(self) -&gt; dict[str, Any]:
        with self._lock:
            return dict(self._state)
</code></pre>
<p><strong>优点</strong>：实现简单，Agent 之间完全解耦（不需要知道彼此的存在），天然支持任意读写模式。</p>
<p><strong>缺点</strong>：共享状态意味着潜在的竞争条件——两个 Agent 同时写同一个 key 怎么办？需要锁机制或更复杂的冲突解决策略。随着 Agent 数量增加，Blackboard 可能成为瓶颈。</p>
<h3>3.2 消息传递（Message Passing）</h3>
<p>Agent 之间通过显式的消息进行通信。每个 Agent 有自己的收件箱。</p>
<pre><code>       ┌──────────┐         ┌──────────┐
       │ Agent A  │──msg───▶│ Agent B  │
       │          │◀──msg───│          │
       └──────────┘         └──────────┘
            │                     ▲
            │         msg         │
            ▼                     │
       ┌──────────┐              │
       │ Agent C  │──────msg─────┘
       └──────────┘
</code></pre>
<pre><code class="language-python">from dataclasses import dataclass, field
from collections import defaultdict
from queue import Queue


@dataclass
class Message:
    sender: str
    receiver: str
    content: Any
    msg_type: str = &quot;default&quot;  # &quot;task&quot;, &quot;result&quot;, &quot;feedback&quot;, &quot;error&quot;


class MessageBus:
    &quot;&quot;&quot;点对点消息传递&quot;&quot;&quot;

    def __init__(self):
        self._queues: dict[str, Queue] = defaultdict(Queue)

    def send(self, message: Message):
        self._queues[message.receiver].put(message)

    def receive(self, agent_id: str, timeout: float = None) -&gt; Message | None:
        try:
            return self._queues[agent_id].get(timeout=timeout)
        except Exception:
            return None

    def has_messages(self, agent_id: str) -&gt; bool:
        return not self._queues[agent_id].empty()
</code></pre>
<p><strong>优点</strong>：通信关系显式、可追踪、可审计。每条消息都有明确的发送者和接收者。</p>
<p><strong>缺点</strong>：Agent 需要知道其他 Agent 的存在（至少知道 ID），耦合度比 Blackboard 高。如果通信拓扑复杂（多对多），消息管理会变得困难。</p>
<h3>3.3 事件驱动（Event Bus）</h3>
<p>Agent 通过发布/订阅事件进行间接通信。Agent 不需要知道谁会消费它的事件。</p>
<pre><code>       ┌──────────┐   ┌──────────┐   ┌──────────┐
       │ Agent A  │   │ Agent B  │   │ Agent C  │
       │ pub: X   │   │ sub: X   │   │ sub: X,Y │
       └────┬─────┘   └────┬─────┘   └────┬─────┘
            │  publish      │  subscribe   │
            ▼              ▼              ▼
       ┌──────────────────────────────────────────┐
       │              Event Bus                    │
       │                                          │
       │  topic &quot;search_done&quot;  → [Agent B, C]     │
       │  topic &quot;analysis_done&quot; → [Agent C]        │
       │  topic &quot;error&quot;        → [Supervisor]      │
       └──────────────────────────────────────────┘
</code></pre>
<pre><code class="language-python">from collections import defaultdict
from typing import Callable


class EventBus:
    &quot;&quot;&quot;发布/订阅事件总线&quot;&quot;&quot;

    def __init__(self):
        self._subscribers: dict[str, list[Callable]] = defaultdict(list)
        self._event_log: list[dict] = []

    def subscribe(self, topic: str, handler: Callable):
        self._subscribers[topic].append(handler)

    def publish(self, topic: str, data: Any, publisher: str = &quot;unknown&quot;):
        event = {&quot;topic&quot;: topic, &quot;data&quot;: data, &quot;publisher&quot;: publisher}
        self._event_log.append(event)
        for handler in self._subscribers.get(topic, []):
            handler(event)

    def get_event_log(self) -&gt; list[dict]:
        return list(self._event_log)
</code></pre>
<p><strong>优点</strong>：Agent 之间完全解耦——发布者不知道有谁在监听，订阅者不知道事件从哪里来。扩展性好，新增 Agent 只需订阅相关事件。</p>
<p><strong>缺点</strong>：事件流难以追踪——&quot;这个事件是谁发的？谁处理了？处理结果在哪里？&quot;调试时需要完整的事件日志。事件顺序可能不确定，需要额外的排序机制。</p>
<h3>3.4 通信机制对比</h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>Blackboard</th>
<th>Message Passing</th>
<th>Event Bus</th>
</tr>
</thead>
<tbody><tr>
<td>耦合度</td>
<td>低（通过 key 间接通信）</td>
<td>中（需要知道目标 Agent）</td>
<td>低（通过 topic 间接通信）</td>
</tr>
<tr>
<td>实现复杂度</td>
<td>低</td>
<td>中</td>
<td>中</td>
</tr>
<tr>
<td>调试友好度</td>
<td>中（看状态快照）</td>
<td>高（消息链路清晰）</td>
<td>低（事件流分散）</td>
</tr>
<tr>
<td>并发安全</td>
<td>需要锁/MVCC</td>
<td>天然安全（队列隔离）</td>
<td>需要考虑处理顺序</td>
</tr>
<tr>
<td>适用模式</td>
<td>Supervisor-Worker</td>
<td>Peer-to-Peer</td>
<td>Pipeline, 事件驱动架构</td>
</tr>
<tr>
<td>可观测性</td>
<td>状态快照</td>
<td>消息轨迹</td>
<td>事件日志</td>
</tr>
</tbody></table>
<p><strong>实践建议</strong>：大多数 Multi-Agent 系统可以从 Blackboard 开始——它最简单，且对 Supervisor-Worker 模式特别友好。当系统复杂度增长到需要解耦 Agent 间关系时，再考虑 Event Bus。Message Passing 适合 Agent 之间有明确的、频繁的双向交互的场景。</p>
<hr>
<h2>4. 完整实现：Supervisor-Worker 协作框架</h2>
<p>下面用 Python 从零实现一个 Supervisor-Worker 框架。这不依赖任何 Agent 框架，完全基于第一性原理构建。</p>
<h3>4.1 基础抽象</h3>
<pre><code class="language-python">import json
import asyncio
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any


# ---- LLM 调用抽象（与具体 SDK 解耦）----

async def call_llm(
    messages: list[dict],
    model: str = &quot;gpt-4o&quot;,
    response_format: dict | None = None,
) -&gt; str:
    &quot;&quot;&quot;LLM 调用的统一接口（简化版，生产中替换为真实 SDK 调用）&quot;&quot;&quot;
    import openai
    client = openai.AsyncOpenAI()
    kwargs = {&quot;model&quot;: model, &quot;messages&quot;: messages}
    if response_format:
        kwargs[&quot;response_format&quot;] = response_format
    response = await client.chat.completions.create(**kwargs)
    return response.choices[0].message.content


# ---- 任务与结果的数据结构 ----

@dataclass
class Task:
    &quot;&quot;&quot;一个可执行的子任务&quot;&quot;&quot;
    task_id: str
    description: str
    assigned_to: str = &quot;&quot;          # Worker Agent 名称
    context: dict = field(default_factory=dict)  # 来自上游的上下文
    status: str = &quot;pending&quot;        # pending | running | done | failed
    result: str = &quot;&quot;
    error: str = &quot;&quot;


@dataclass
class TeamResult:
    &quot;&quot;&quot;团队执行的最终结果&quot;&quot;&quot;
    success: bool
    output: str
    tasks: list[Task]
    total_tokens: int = 0
    total_llm_calls: int = 0
</code></pre>
<h3>4.2 Worker Agent</h3>
<p>每个 Worker 是一个专注于特定领域的 Agent，拥有独立的 System Prompt 和能力边界。</p>
<pre><code class="language-python">class WorkerAgent:
    &quot;&quot;&quot;Worker Agent：接收子任务，独立执行，返回结果&quot;&quot;&quot;

    def __init__(self, name: str, system_prompt: str, model: str = &quot;gpt-4o&quot;):
        self.name = name
        self.system_prompt = system_prompt
        self.model = model
        self._call_count = 0

    async def execute(self, task: Task) -&gt; Task:
        &quot;&quot;&quot;执行一个子任务&quot;&quot;&quot;
        task.status = &quot;running&quot;
        task.assigned_to = self.name

        messages = [
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: self.system_prompt},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: self._build_prompt(task)},
        ]

        try:
            result = await call_llm(messages, model=self.model)
            self._call_count += 1
            task.result = result
            task.status = &quot;done&quot;
        except Exception as e:
            task.error = str(e)
            task.status = &quot;failed&quot;

        return task

    def _build_prompt(self, task: Task) -&gt; str:
        prompt = f&quot;## 任务\n{task.description}\n&quot;
        if task.context:
            prompt += f&quot;\n## 上下文信息\n{json.dumps(task.context, ensure_ascii=False, indent=2)}\n&quot;
        prompt += &quot;\n请完成上述任务，直接输出结果。&quot;
        return prompt
</code></pre>
<h3>4.3 Supervisor Agent</h3>
<p>Supervisor 负责三件事：任务分解、任务分配、结果合成。</p>
<pre><code class="language-python">DECOMPOSE_PROMPT = &quot;&quot;&quot;你是一个任务分解专家。给定一个复杂任务，将其分解为可以独立执行的子任务。

可用的 Worker 及其能力：
{workers_description}

请将任务分解为子任务，并指定每个子任务应该分配给哪个 Worker。
输出 JSON 格式：
{{
  &quot;subtasks&quot;: [
    {{
      &quot;task_id&quot;: &quot;task_1&quot;,
      &quot;description&quot;: &quot;具体的子任务描述&quot;,
      &quot;assigned_to&quot;: &quot;worker 名称&quot;,
      &quot;depends_on&quot;: []
    }}
  ]
}}

注意：
- 每个子任务应该足够具体，让 Worker 能独立完成
- depends_on 标明依赖关系（某个子任务需要等另一个完成后才能开始）
- 尽可能让子任务并行执行以提高效率
&quot;&quot;&quot;

SYNTHESIZE_PROMPT = &quot;&quot;&quot;你是一个结果合成专家。多个专业 Agent 已经分别完成了子任务。
请根据它们的结果，合成一个完整、连贯、高质量的最终输出。

原始任务：{original_task}

各子任务的执行结果：
{subtask_results}

请整合以上信息，生成最终的完整输出。确保：
1. 信息完整，没有遗漏
2. 逻辑连贯，前后一致
3. 去除重复内容
4. 保持专业质量
&quot;&quot;&quot;


class SupervisorAgent:
    &quot;&quot;&quot;Supervisor Agent：任务分解、分配、合成&quot;&quot;&quot;

    def __init__(self, model: str = &quot;gpt-4o&quot;):
        self.model = model
        self._call_count = 0

    async def decompose(
        self, task: str, workers: dict[str, WorkerAgent]
    ) -&gt; list[Task]:
        &quot;&quot;&quot;将复杂任务分解为子任务&quot;&quot;&quot;
        workers_desc = &quot;\n&quot;.join(
            f&quot;- {name}: {w.system_prompt[:200]}&quot;
            for name, w in workers.items()
        )

        messages = [
            {
                &quot;role&quot;: &quot;system&quot;,
                &quot;content&quot;: DECOMPOSE_PROMPT.format(
                    workers_description=workers_desc
                ),
            },
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: task},
        ]

        result = await call_llm(
            messages,
            model=self.model,
            response_format={&quot;type&quot;: &quot;json_object&quot;},
        )
        self._call_count += 1

        parsed = json.loads(result)
        tasks = []
        for st in parsed.get(&quot;subtasks&quot;, []):
            tasks.append(Task(
                task_id=st[&quot;task_id&quot;],
                description=st[&quot;description&quot;],
                assigned_to=st.get(&quot;assigned_to&quot;, &quot;&quot;),
            ))
        return tasks

    async def synthesize(
        self, original_task: str, completed_tasks: list[Task]
    ) -&gt; str:
        &quot;&quot;&quot;合成所有 Worker 的结果&quot;&quot;&quot;
        results_text = &quot;\n\n&quot;.join(
            f&quot;### {t.task_id} ({t.assigned_to})\n{t.result}&quot;
            for t in completed_tasks
            if t.status == &quot;done&quot;
        )

        messages = [
            {
                &quot;role&quot;: &quot;system&quot;,
                &quot;content&quot;: SYNTHESIZE_PROMPT.format(
                    original_task=original_task,
                    subtask_results=results_text,
                ),
            },
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请合成最终结果。&quot;},
        ]

        result = await call_llm(messages, model=self.model)
        self._call_count += 1
        return result
</code></pre>
<h3>4.4 AgentTeam：编排层</h3>
<p>AgentTeam 管理多个 Agent 的生命周期、通信和执行流程。</p>
<pre><code class="language-python">class AgentTeam:
    &quot;&quot;&quot;Agent 团队：管理 Supervisor + Workers 的协作&quot;&quot;&quot;

    def __init__(self, supervisor: SupervisorAgent):
        self.supervisor = supervisor
        self.workers: dict[str, WorkerAgent] = {}
        self.blackboard = Blackboard()
        self.execution_log: list[dict] = []

    def add_worker(self, worker: WorkerAgent):
        self.workers[worker.name] = worker

    async def run(self, task: str, max_retries: int = 2) -&gt; TeamResult:
        &quot;&quot;&quot;执行完整的 Multi-Agent 协作流程&quot;&quot;&quot;
        self._log(&quot;team&quot;, f&quot;接收任务: {task[:100]}...&quot;)

        # Phase 1: Supervisor 分解任务
        self._log(&quot;supervisor&quot;, &quot;开始任务分解&quot;)
        subtasks = await self.supervisor.decompose(task, self.workers)
        self._log(&quot;supervisor&quot;, f&quot;分解为 {len(subtasks)} 个子任务&quot;)

        for st in subtasks:
            self._log(&quot;supervisor&quot;, f&quot;  {st.task_id} -&gt; {st.assigned_to}: {st.description[:80]}&quot;)

        # Phase 2: Workers 并行执行（考虑依赖关系）
        completed = await self._execute_tasks(subtasks, max_retries)

        # Phase 3: Supervisor 合成结果
        self._log(&quot;supervisor&quot;, &quot;开始合成结果&quot;)
        final_output = await self.supervisor.synthesize(task, completed)
        self._log(&quot;supervisor&quot;, &quot;合成完成&quot;)

        # 汇总统计
        total_calls = self.supervisor._call_count + sum(
            w._call_count for w in self.workers.values()
        )

        return TeamResult(
            success=all(t.status == &quot;done&quot; for t in completed),
            output=final_output,
            tasks=completed,
            total_llm_calls=total_calls,
        )

    async def _execute_tasks(
        self, tasks: list[Task], max_retries: int
    ) -&gt; list[Task]:
        &quot;&quot;&quot;执行子任务，支持并行和重试&quot;&quot;&quot;
        completed = []
        pending = list(tasks)

        while pending:
            # 找出当前可以执行的任务（依赖已满足）
            ready = []
            still_pending = []
            completed_ids = {t.task_id for t in completed}

            for task in pending:
                deps = task.context.get(&quot;depends_on&quot;, [])
                if all(d in completed_ids for d in deps):
                    ready.append(task)
                else:
                    still_pending.append(task)

            if not ready:
                # 没有可执行的任务但还有待处理的 -&gt; 可能存在循环依赖
                self._log(&quot;team&quot;, &quot;警告: 检测到无法满足的依赖关系&quot;)
                break

            # 并行执行所有就绪的任务
            results = await asyncio.gather(*[
                self._execute_single(task, max_retries)
                for task in ready
            ])

            for task in results:
                completed.append(task)
                # 将结果写入 Blackboard，供后续任务使用
                if task.status == &quot;done&quot;:
                    self.blackboard.write(
                        task.task_id, task.result, author=task.assigned_to
                    )

            pending = still_pending

        return completed

    async def _execute_single(
        self, task: Task, max_retries: int
    ) -&gt; Task:
        &quot;&quot;&quot;执行单个任务，带重试&quot;&quot;&quot;
        worker = self.workers.get(task.assigned_to)
        if not worker:
            task.status = &quot;failed&quot;
            task.error = f&quot;未找到 Worker: {task.assigned_to}&quot;
            return task

        # 将 Blackboard 上的相关信息注入任务上下文
        task.context[&quot;blackboard&quot;] = self.blackboard.read_all()

        for attempt in range(max_retries + 1):
            self._log(worker.name, f&quot;执行 {task.task_id} (尝试 {attempt + 1})&quot;)
            result = await worker.execute(task)

            if result.status == &quot;done&quot;:
                self._log(worker.name, f&quot;{task.task_id} 完成&quot;)
                return result

            self._log(worker.name, f&quot;{task.task_id} 失败: {result.error}&quot;)

            if attempt &lt; max_retries:
                self._log(worker.name, f&quot;准备重试 {task.task_id}&quot;)

        return result

    def _log(self, source: str, message: str):
        entry = {&quot;source&quot;: source, &quot;message&quot;: message}
        self.execution_log.append(entry)
</code></pre>
<h3>4.5 组装示例：技术调研报告</h3>
<pre><code class="language-python">async def main():
    &quot;&quot;&quot;示例：用 Multi-Agent 团队撰写一篇技术调研报告&quot;&quot;&quot;

    # 创建 Supervisor
    supervisor = SupervisorAgent(model=&quot;gpt-4o&quot;)

    # 创建专业化的 Worker Agent
    search_agent = WorkerAgent(
        name=&quot;searcher&quot;,
        system_prompt=(
            &quot;你是一个信息搜索专家。你的任务是根据给定的主题，&quot;
            &quot;整理出全面的信息摘要，包括关键事实、数据、案例。&quot;
            &quot;输出结构化的搜索结果，标注来源和可信度。&quot;
        ),
    )

    analyze_agent = WorkerAgent(
        name=&quot;analyst&quot;,
        system_prompt=(
            &quot;你是一个技术分析专家。你的任务是根据搜索结果和原始数据，&quot;
            &quot;进行深度分析，提炼洞察，识别趋势、风险和机会。&quot;
            &quot;输出包含数据支撑的分析报告。&quot;
        ),
    )

    write_agent = WorkerAgent(
        name=&quot;writer&quot;,
        system_prompt=(
            &quot;你是一个技术写作专家。你的任务是根据分析结果，&quot;
            &quot;撰写结构清晰、逻辑严谨、可读性强的技术报告。&quot;
            &quot;确保使用专业术语，并配有合适的章节结构。&quot;
        ),
    )

    # 组建团队
    team = AgentTeam(supervisor=supervisor)
    team.add_worker(search_agent)
    team.add_worker(analyze_agent)
    team.add_worker(write_agent)

    # 执行任务
    result = await team.run(
        &quot;撰写一篇关于 LLM Agent 在企业客服场景落地的技术调研报告，&quot;
        &quot;包括行业现状、主流技术方案对比、落地挑战和建议。&quot;
    )

    print(f&quot;成功: {result.success}&quot;)
    print(f&quot;LLM 调用次数: {result.total_llm_calls}&quot;)
    print(f&quot;\n最终输出:\n{result.output[:500]}...&quot;)

    # 查看执行日志
    print(&quot;\n执行链路:&quot;)
    for entry in team.execution_log:
        print(f&quot;  [{entry[&#39;source&#39;]}] {entry[&#39;message&#39;]}&quot;)


# asyncio.run(main())
</code></pre>
<p>这段代码展示了核心的协作模式。生产系统中还需要补充：Token 用量追踪、超时控制、Worker 健康检查、结果缓存等。但架构骨架已经清晰——Supervisor 负责全局调度，Worker 负责局部执行，Blackboard 负责状态共享，AgentTeam 负责生命周期管理。</p>
<hr>
<h2>5. 状态管理的复杂性</h2>
<p>Multi-Agent 系统的状态管理比 Single-Agent 复杂一个数量级。核心难题在于：多个 Agent 同时操作状态，如何保证一致性。</p>
<h3>5.1 共享状态 vs 独立状态</h3>
<pre><code>方案 A：共享状态                     方案 B：独立状态
┌─────────────────┐                ┌──────────┐  ┌──────────┐  ┌──────────┐
│  Global State   │                │ State A  │  │ State B  │  │ State C  │
│                 │                │ (Agent A │  │ (Agent B │  │ (Agent C │
│ Agent A ──write │                │  独占)   │  │  独占)   │  │  独占)   │
│ Agent B ──write │                └──────────┘  └──────────┘  └──────────┘
│ Agent C ──write │                      │              │              │
└─────────────────┘                      └──────────────┼──────────────┘
                                                        ▼
                                                  合并/同步层
</code></pre>
<p><strong>共享状态</strong>的优点是 Agent 之间信息同步即时，任何 Agent 都能看到最新全局状态。缺点是需要处理并发冲突。适合 Supervisor-Worker 模式——Supervisor 需要看到所有 Worker 的进度。</p>
<p><strong>独立状态</strong>的优点是无并发问题，每个 Agent 完全自主。缺点是 Agent 之间信息同步有延迟，需要显式的合并机制。适合 Pipeline 模式——每个阶段独立处理，只在交接时传递状态。</p>
<h3>5.2 冲突解决策略</h3>
<p>当两个 Agent 同时修改同一个状态时，需要冲突解决。常见策略：</p>
<pre><code class="language-python">class ConflictResolver:
    &quot;&quot;&quot;状态冲突解决器&quot;&quot;&quot;

    @staticmethod
    def last_writer_wins(old_value, new_value_a, new_value_b, timestamp_a, timestamp_b):
        &quot;&quot;&quot;最后写入者胜出——简单但可能丢失数据&quot;&quot;&quot;
        return new_value_a if timestamp_a &gt; timestamp_b else new_value_b

    @staticmethod
    def merge_append(old_value, new_value_a, new_value_b):
        &quot;&quot;&quot;合并追加——适用于列表类型的状态&quot;&quot;&quot;
        if isinstance(old_value, list):
            merged = list(old_value)
            if isinstance(new_value_a, list):
                merged.extend(new_value_a)
            if isinstance(new_value_b, list):
                merged.extend(new_value_b)
            return merged
        return new_value_b  # fallback

    @staticmethod
    async def llm_resolve(old_value, new_value_a, new_value_b, context: str):
        &quot;&quot;&quot;用 LLM 判断如何合并冲突——最灵活但最贵&quot;&quot;&quot;
        prompt = (
            f&quot;两个 Agent 同时修改了同一个状态。\n&quot;
            f&quot;原始值: {old_value}\n&quot;
            f&quot;Agent A 的修改: {new_value_a}\n&quot;
            f&quot;Agent B 的修改: {new_value_b}\n&quot;
            f&quot;上下文: {context}\n&quot;
            f&quot;请决定最终值应该是什么，并解释原因。&quot;
        )
        return await call_llm([{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}])
</code></pre>
<p>实践中，大多数 Multi-Agent 系统通过架构设计来避免冲突，而不是在运行时解决冲突。最有效的方法是<strong>状态分区</strong>——每个 Agent 只写自己负责的状态区域，避免多 Agent 写同一个 key。这也是 Supervisor-Worker 模式天然的优势：每个 Worker 写自己的结果 key，只有 Supervisor 读所有 key。</p>
<hr>
<h2>6. 错误处理与容错</h2>
<p>Multi-Agent 系统的错误处理比 Single-Agent 更复杂，因为错误的传播路径更多。</p>
<h3>6.1 Worker 失败</h3>
<p>Worker 失败是最常见的情况。处理策略按优先级：</p>
<pre><code>Worker 失败处理决策树：

  Worker 执行失败
       │
       ▼
  ┌─ 是否可重试？ ─── 是 ──→ 重试（最多 N 次）──→ 成功？──→ 继续
  │      │                                          │
  │     否                                         否
  │      │                                          │
  │      ▼                                          ▼
  │  ┌─ 有替代 Worker？ ─── 是 ──→ 分配给替代 Worker
  │  │      │
  │  │     否
  │  │      │
  │  │      ▼
  │  │  ┌─ 该子任务是关键路径？
  │  │  │      │            │
  │  │  │     是           否
  │  │  │      │            │
  │  │  │      ▼            ▼
  │  │  │  整体任务失败   降级处理（跳过该子任务，
  │  │  │                 标记结果为不完整）
</code></pre>
<pre><code class="language-python">class ResilientAgentTeam(AgentTeam):
    &quot;&quot;&quot;增强容错能力的 Agent 团队&quot;&quot;&quot;

    def __init__(self, supervisor: SupervisorAgent):
        super().__init__(supervisor)
        self.fallback_workers: dict[str, list[str]] = {}  # Worker 降级链

    def set_fallback(self, worker_name: str, fallbacks: list[str]):
        &quot;&quot;&quot;设置 Worker 的降级替代链&quot;&quot;&quot;
        self.fallback_workers[worker_name] = fallbacks

    async def _execute_single(self, task: Task, max_retries: int) -&gt; Task:
        &quot;&quot;&quot;增强版：支持 Worker 降级&quot;&quot;&quot;
        # 尝试主 Worker
        result = await super()._execute_single(task, max_retries)
        if result.status == &quot;done&quot;:
            return result

        # 主 Worker 失败，尝试降级 Worker
        fallbacks = self.fallback_workers.get(task.assigned_to, [])
        for fb_name in fallbacks:
            self._log(&quot;team&quot;, f&quot;降级: {task.assigned_to} -&gt; {fb_name}&quot;)
            task.assigned_to = fb_name
            task.status = &quot;pending&quot;
            task.error = &quot;&quot;
            result = await super()._execute_single(task, max_retries=1)
            if result.status == &quot;done&quot;:
                return result

        return result
</code></pre>
<h3>6.2 Supervisor 失败</h3>
<p>Supervisor 失败更严重——它是中央协调者，失败意味着整个任务无法继续。处理策略：</p>
<ul>
<li><strong>外部监控</strong>：在 AgentTeam 之上设置一个非 LLM 的监控层，检测 Supervisor 的健康状态</li>
<li><strong>Supervisor 冗余</strong>：准备一个备用 Supervisor（可以用不同的模型），主 Supervisor 失败时切换</li>
<li><strong>Checkpoint 机制</strong>：Supervisor 在每个决策点保存状态快照，失败后从最近的 Checkpoint 恢复</li>
</ul>
<pre><code class="language-python">async def run_with_checkpoint(self, task: str) -&gt; TeamResult:
    &quot;&quot;&quot;带 Checkpoint 的执行流程&quot;&quot;&quot;
    checkpoint = {&quot;phase&quot;: &quot;init&quot;, &quot;subtasks&quot;: [], &quot;completed&quot;: []}

    try:
        # Phase 1: 分解
        checkpoint[&quot;phase&quot;] = &quot;decompose&quot;
        subtasks = await self.supervisor.decompose(task, self.workers)
        checkpoint[&quot;subtasks&quot;] = subtasks

        # Phase 2: 执行
        checkpoint[&quot;phase&quot;] = &quot;execute&quot;
        completed = await self._execute_tasks(subtasks, max_retries=2)
        checkpoint[&quot;completed&quot;] = completed

        # Phase 3: 合成
        checkpoint[&quot;phase&quot;] = &quot;synthesize&quot;
        output = await self.supervisor.synthesize(task, completed)

        return TeamResult(success=True, output=output, tasks=completed)

    except Exception as e:
        self._log(&quot;team&quot;, f&quot;失败于阶段 {checkpoint[&#39;phase&#39;]}: {e}&quot;)
        # 可以从 checkpoint 恢复，跳过已完成的阶段
        return TeamResult(
            success=False,
            output=f&quot;任务在 {checkpoint[&#39;phase&#39;]} 阶段失败: {e}&quot;,
            tasks=checkpoint.get(&quot;completed&quot;, []),
        )
</code></pre>
<h3>6.3 死锁检测</h3>
<p>在 Peer-to-Peer 模式中，两个 Agent 可能互相等待对方的回复，形成死锁。</p>
<pre><code>死锁场景：

  Agent A: &quot;请 Agent B 先确认方案&quot;
           ↓ 等待 B
  Agent B: &quot;请 Agent A 先提供数据&quot;
           ↓ 等待 A
  → 无限等待
</code></pre>
<p>解决方案：</p>
<pre><code class="language-python">class DeadlockDetector:
    &quot;&quot;&quot;简单的死锁检测器&quot;&quot;&quot;

    def __init__(self, timeout_seconds: float = 60):
        self.timeout = timeout_seconds
        self._waiting: dict[str, str] = {}  # agent_id -&gt; waiting_for_agent_id

    def register_wait(self, agent_id: str, waiting_for: str):
        self._waiting[agent_id] = waiting_for
        # 检测环形等待
        if self._has_cycle(agent_id):
            raise DeadlockError(
                f&quot;检测到死锁: {self._trace_cycle(agent_id)}&quot;
            )

    def _has_cycle(self, start: str) -&gt; bool:
        visited = set()
        current = start
        while current in self._waiting:
            if current in visited:
                return True
            visited.add(current)
            current = self._waiting[current]
        return False

    def _trace_cycle(self, start: str) -&gt; str:
        chain = [start]
        current = self._waiting.get(start, &quot;&quot;)
        while current != start and current:
            chain.append(current)
            current = self._waiting.get(current, &quot;&quot;)
        chain.append(start)
        return &quot; -&gt; &quot;.join(chain)


class DeadlockError(Exception):
    pass
</code></pre>
<hr>
<h2>7. Multi-Agent 的成本问题</h2>
<p>成本是 Multi-Agent 系统必须正视的问题。它不只是&quot;贵一点&quot;的问题——可能是&quot;贵一个数量级&quot;的问题。</p>
<h3>7.1 成本模型</h3>
<pre><code>Single-Agent 执行一个任务的 Token 消耗：

  1 x System Prompt   +  N x (Context + Response)
  ~1,000 tokens          ~3,000 tokens x 5 iterations
                         = ~16,000 tokens


Multi-Agent (Supervisor + 3 Workers) 的 Token 消耗：

  Supervisor 分解:   ~4,000 tokens   (System Prompt + 任务分解)
  Worker A 执行:     ~8,000 tokens   (System Prompt + 执行)
  Worker B 执行:     ~8,000 tokens   (System Prompt + 执行)
  Worker C 执行:     ~8,000 tokens   (System Prompt + 执行)
  Supervisor 合成:   ~6,000 tokens   (收集所有结果 + 合成)
                     ──────────────
  Total:             ~34,000 tokens   ← 约 2x Single-Agent

  如果 Worker 内部也有多轮迭代，消耗会更高。
</code></pre>
<h3>7.2 什么时候 Multi-Agent 的收益大于成本</h3>
<p>不是所有场景都值得用 Multi-Agent。一个简单的决策框架：</p>
<pre><code>                        任务复杂度
                    低 ─────────── 高
                    │               │
  专业化需求  低    │  Single-Agent │  Single-Agent
              │    │  (够用)       │  + Better Prompt
              │    │               │
              高    │  Single-Agent │  Multi-Agent ✓
                    │  + Tools      │  (值得投入)
                    │               │
</code></pre>
<p>Multi-Agent 在以下条件下收益最大：</p>
<ol>
<li><strong>任务天然可并行</strong>：子任务之间独立性高，Multi-Agent 通过并行执行缩短总耗时，即使 token 消耗增加，时间成本下降</li>
<li><strong>专业化收益显著</strong>：专家 Agent 在自己的领域比通用 Agent 的输出质量显著更高，质量提升值得额外成本</li>
<li><strong>Single-Agent 已经到达能力瓶颈</strong>：Context Window 不够、单个 prompt 角色冲突、输出质量不稳定</li>
<li><strong>任务的商业价值足够高</strong>：生成一份价值数万元的分析报告，多花几美元的 API 费用是可以接受的</li>
</ol>
<h3>7.3 成本优化策略</h3>
<pre><code class="language-python">class CostAwareTeam(AgentTeam):
    &quot;&quot;&quot;成本感知的 Agent 团队&quot;&quot;&quot;

    def __init__(self, supervisor, token_budget: int = 100_000):
        super().__init__(supervisor)
        self.token_budget = token_budget
        self.token_used = 0

    def _select_model_for_task(self, task: Task) -&gt; str:
        &quot;&quot;&quot;根据任务复杂度选择模型——不是所有子任务都需要最强模型&quot;&quot;&quot;
        if task.context.get(&quot;complexity&quot;) == &quot;low&quot;:
            return &quot;gpt-4o-mini&quot;     # 简单任务用小模型
        elif task.context.get(&quot;complexity&quot;) == &quot;high&quot;:
            return &quot;gpt-4o&quot;          # 复杂任务用大模型
        else:
            return &quot;gpt-4o-mini&quot;     # 默认用小模型，够用即可

    def _should_continue(self) -&gt; bool:
        &quot;&quot;&quot;预算检查&quot;&quot;&quot;
        if self.token_used &gt;= self.token_budget:
            self._log(&quot;team&quot;, f&quot;Token 预算耗尽 ({self.token_used}/{self.token_budget})&quot;)
            return False
        return True
</code></pre>
<p>关键原则：<strong>Router 和 Supervisor 可以用轻量模型，只有需要深度推理的 Worker 才用重量级模型。</strong> 这类似人类组织中，项目经理不需要是技术最强的人，但专家必须在各自领域足够专业。</p>
<hr>
<h2>8. Multi-Agent 的调试挑战</h2>
<p>Multi-Agent 系统的调试难度是 Single-Agent 的平方级增长——不仅每个 Agent 内部可能出错，Agent 之间的交互也可能出错。</p>
<h3>8.1 执行链路追踪</h3>
<p>每次 Multi-Agent 执行都应该生成一个完整的 Trace，记录每个 Agent 的每次 LLM 调用、输入、输出和耗时。</p>
<pre><code class="language-python">import time
import uuid
from dataclasses import dataclass, field


@dataclass
class Span:
    &quot;&quot;&quot;一个执行跨度（对应一次 Agent 操作）&quot;&quot;&quot;
    span_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    parent_id: str = &quot;&quot;
    agent_name: str = &quot;&quot;
    operation: str = &quot;&quot;          # &quot;decompose&quot;, &quot;execute&quot;, &quot;synthesize&quot;
    input_summary: str = &quot;&quot;
    output_summary: str = &quot;&quot;
    start_time: float = 0.0
    end_time: float = 0.0
    token_count: int = 0
    status: str = &quot;running&quot;      # running | done | failed
    children: list = field(default_factory=list)

    @property
    def duration_ms(self) -&gt; float:
        return (self.end_time - self.start_time) * 1000


class Tracer:
    &quot;&quot;&quot;Multi-Agent 执行链路追踪器&quot;&quot;&quot;

    def __init__(self):
        self.root_span: Span | None = None
        self._span_stack: list[Span] = []

    def start_span(self, agent_name: str, operation: str, input_summary: str = &quot;&quot;) -&gt; Span:
        span = Span(
            agent_name=agent_name,
            operation=operation,
            input_summary=input_summary[:200],
            start_time=time.time(),
        )
        if self._span_stack:
            parent = self._span_stack[-1]
            span.parent_id = parent.span_id
            parent.children.append(span)
        else:
            self.root_span = span

        self._span_stack.append(span)
        return span

    def end_span(self, output_summary: str = &quot;&quot;, status: str = &quot;done&quot;):
        if self._span_stack:
            span = self._span_stack.pop()
            span.end_time = time.time()
            span.output_summary = output_summary[:200]
            span.status = status

    def print_trace(self, span: Span = None, indent: int = 0):
        &quot;&quot;&quot;打印可视化的执行链路&quot;&quot;&quot;
        span = span or self.root_span
        if not span:
            return

        prefix = &quot;  &quot; * indent
        status_icon = &quot;OK&quot; if span.status == &quot;done&quot; else &quot;FAIL&quot;
        print(
            f&quot;{prefix}[{status_icon}] {span.agent_name}.{span.operation} &quot;
            f&quot;({span.duration_ms:.0f}ms)&quot;
        )
        if span.input_summary:
            print(f&quot;{prefix}  IN:  {span.input_summary[:80]}&quot;)
        if span.output_summary:
            print(f&quot;{prefix}  OUT: {span.output_summary[:80]}&quot;)

        for child in span.children:
            self.print_trace(child, indent + 1)
</code></pre>
<p>输出示例：</p>
<pre><code>[OK] supervisor.decompose (2340ms)
  IN:  撰写一篇关于 LLM Agent 在企业客服场景落地的技术调研报告...
  OUT: {&quot;subtasks&quot;: [{&quot;task_id&quot;: &quot;task_1&quot;, ...}, ...]}
  [OK] searcher.execute (5120ms)
    IN:  搜索 LLM Agent 客服场景的行业现状和主流方案...
    OUT: ## 行业现状\n1. 2024 年全球智能客服市场规模...
  [OK] analyst.execute (4800ms)
    IN:  分析搜索结果，提炼关键洞察和趋势...
    OUT: ## 分析结论\n1. 技术成熟度：LLM 客服处于...
  [OK] writer.execute (6200ms)
    IN:  根据分析结果撰写完整的技术调研报告...
    OUT: # LLM Agent 企业客服落地技术调研报告\n\n## 1. 执行摘要...
[OK] supervisor.synthesize (3100ms)
  IN:  请合成最终结果。
  OUT: # LLM Agent 企业客服落地技术调研报告（终稿）...
</code></pre>
<h3>8.2 Bug 复现</h3>
<p>Multi-Agent 场景的 bug 复现特别困难，因为：</p>
<ul>
<li>LLM 输出是非确定性的——相同输入可能产生不同输出</li>
<li>Agent 之间的交互是动态的——执行路径取决于中间结果</li>
<li>并发执行的时序不确定——Worker A 和 B 谁先完成可能影响最终结果</li>
</ul>
<p>应对策略：</p>
<ol>
<li><strong>记录完整的 LLM 输入/输出</strong>：在 Trace 中保存每次 LLM 调用的完整 messages 和 response，不只是摘要</li>
<li><strong>Deterministic Replay</strong>：用固定的 seed 和 temperature=0 复现执行，或者直接 mock LLM 响应</li>
<li><strong>快照式调试</strong>：在每个 Agent 决策点保存完整的 Blackboard 状态快照，出问题时可以回溯到任意时间点</li>
</ol>
<pre><code class="language-python">class ReplayableTeam(AgentTeam):
    &quot;&quot;&quot;可回放的 Agent 团队——记录完整的 LLM 交互供复现&quot;&quot;&quot;

    def __init__(self, supervisor):
        super().__init__(supervisor)
        self._llm_recordings: list[dict] = []

    def record_llm_call(self, agent_name: str, messages: list[dict], response: str):
        self._llm_recordings.append({
            &quot;agent&quot;: agent_name,
            &quot;messages&quot;: messages,
            &quot;response&quot;: response,
            &quot;timestamp&quot;: time.time(),
        })

    def save_recording(self, path: str):
        &quot;&quot;&quot;保存录制数据，用于后续回放和调试&quot;&quot;&quot;
        with open(path, &quot;w&quot;) as f:
            json.dump(self._llm_recordings, f, ensure_ascii=False, indent=2)
</code></pre>
<h3>8.3 可观测性设计</h3>
<p>一个生产级 Multi-Agent 系统至少需要以下可观测性指标：</p>
<table>
<thead>
<tr>
<th>指标类别</th>
<th>具体指标</th>
<th>目的</th>
</tr>
</thead>
<tbody><tr>
<td><strong>延迟</strong></td>
<td>每个 Agent 的执行时间、端到端总时间</td>
<td>定位性能瓶颈</td>
</tr>
<tr>
<td><strong>成本</strong></td>
<td>每个 Agent 的 Token 消耗、总消耗</td>
<td>成本监控和预算控制</td>
</tr>
<tr>
<td><strong>质量</strong></td>
<td>任务成功率、重试次数、降级次数</td>
<td>评估系统可靠性</td>
</tr>
<tr>
<td><strong>链路</strong></td>
<td>完整的 Trace（Agent、操作、输入、输出）</td>
<td>问题排查</td>
</tr>
<tr>
<td><strong>状态</strong></td>
<td>Blackboard 的状态变更历史</td>
<td>数据流追踪</td>
</tr>
<tr>
<td><strong>通信</strong></td>
<td>Agent 间消息数量、消息大小</td>
<td>通信效率分析</td>
</tr>
</tbody></table>
<hr>
<h2>9. 设计 Multi-Agent 系统的决策清单</h2>
<p>在你决定构建 Multi-Agent 系统之前，逐一回答以下问题：</p>
<p><strong>必要性验证</strong>：</p>
<ul>
<li>单个 Agent 真的不够吗？是否尝试过优化 prompt、增加工具、使用更强的模型？</li>
<li>任务是否天然需要多角色/多视角？还是只是因为你觉得&quot;多 Agent 更酷&quot;？</li>
<li>团队的 LLM API 预算能否支撑多 Agent 的额外消耗？</li>
</ul>
<p><strong>架构选择</strong>：</p>
<ul>
<li>任务结构更接近哪种模式？Supervisor-Worker / Peer-to-Peer / Pipeline / Dynamic Routing？</li>
<li>Agent 之间需要什么样的通信？单向传递 / 双向协商 / 广播通知？</li>
<li>状态应该共享还是独立？冲突解决策略是什么？</li>
</ul>
<p><strong>工程保障</strong>：</p>
<ul>
<li>每个 Agent 的失败影响范围是什么？有降级方案吗？</li>
<li>如何追踪一个请求在多个 Agent 之间的完整执行链路？</li>
<li>如何测试多 Agent 协作的正确性——单元测试（单个 Agent）+ 集成测试（Agent 交互）？</li>
</ul>
<hr>
<h2>10. 结语与展望</h2>
<p>本文是 Phase 3（How to Scale Agent Intelligence）的最后一篇。在 Phase 3 的四篇文章中，我们从单个 Agent 的四个维度进行了升级：</p>
<pre><code>Phase 3 知识路线：

  第 08 篇 Memory       → Agent 有了&quot;记忆&quot;
  第 09 篇 RAG          → Agent 有了&quot;外部知识&quot;
  第 10 篇 Planning     → Agent 有了&quot;规划和反思&quot;
  第 11 篇 Multi-Agent  → Agent 有了&quot;团队协作&quot;（本文）
</code></pre>
<p>至此，我们已经拥有构建一个&quot;聪明的&quot; Agent 系统所需的全部核心概念。但&quot;聪明&quot;不等于&quot;可用&quot;。一个在本地跑通 demo 的 Multi-Agent 系统，距离生产环境还有巨大的鸿沟——框架选型、协议标准化、可观测性、安全性、成本控制、评估体系。</p>
<p>这正是 Phase 4（How to Ship Agents to Production）要解决的问题：</p>
<ul>
<li><strong>下一篇（12）</strong>：LangChain vs LangGraph —— 你应该用框架还是自己写？框架的价值边界在哪里？我们会从 Chain 和 Graph 两种抽象出发，讨论框架在什么时候是加速器，什么时候是束缚。</li>
<li><strong>第 13 篇</strong>：MCP and Tool Protocol —— Agent 的工具需要标准化。MCP 协议如何让不同 Agent 共享工具？工具的发现、声明、权限控制。</li>
<li><strong>第 14 篇</strong>：Production-Grade Agent Systems —— 最后一篇，打通最后一公里：评估、安全、成本、灰度、监控。</li>
</ul>
<h3>进一步思考</h3>
<p><strong>关于协作模式的演化</strong>：本文介绍的四种模式是&quot;纯模式&quot;。真实系统中，你很可能需要混合模式——比如 Supervisor-Worker 的 Worker 内部用 Pipeline，或者 Dynamic Routing 的专家 Agent 内部用 Peer-to-Peer 辩论。如何设计这种嵌套的多层协作结构，是一个值得深入探索的方向。</p>
<p><strong>关于 Agent 的涌现行为</strong>：当多个 Agent 协作时，是否会出现超越单个 Agent 能力的&quot;涌现行为&quot;？还是说 Multi-Agent 的上限永远被最强的那个 Agent 决定？这个问题在学术界尚无定论，但从实践角度看，好的协作架构确实能产出超越任何单个 Agent 的结果——正如一个好的工程团队能完成任何个人都无法独自完成的项目。</p>
<p><strong>关于 Human-in-the-Loop</strong>：本文讨论的全是 Agent-to-Agent 的协作。但在生产环境中，最重要的&quot;Agent&quot;可能是人类。如何设计一个 Multi-Agent 系统，让人类能在关键节点介入、审核和纠正？Human-Agent 协作可能比 Agent-Agent 协作更有实用价值，也更有挑战性。</p>
<hr>
<blockquote>
<p><strong>系列导航</strong>：本文是 Agentic 系列的第 11 篇。</p>
<ul>
<li>上一篇：<a href="/blog/engineering/agentic/10-Planning%20and%20Reflection">10 | Planning and Reflection</a></li>
<li>下一篇：<a href="/blog/engineering/agentic/12-LangChain%20vs%20LangGraph">12 | LangChain vs LangGraph</a></li>
<li>完整目录：<a href="/blog/engineering/agentic/01-From%20LLM%20to%20Agent">01 | From LLM to Agent</a></li>
</ul>
</blockquote>
</div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="mt-12 pt-8 border-t border-gray-200">加载导航中...</div><!--/$--><div class="mt-16 border-t border-gray-200 pt-8"><div class="mx-auto max-w-3xl"><h3 class="text-2xl font-bold text-gray-900 mb-8">评论</h3></div></div></div></div></article><!--$--><!--/$--></main><footer class="bg-[var(--background)]"><div class="mx-auto max-w-7xl px-6 py-12 md:flex md:items-center md:justify-between lg:px-8"><div class="flex justify-center space-x-6 md:order-2"><a class="text-gray-600 hover:text-gray-800" href="/about/">关于</a><a class="text-gray-600 hover:text-gray-800" href="/blog/">博客</a><a class="text-gray-600 hover:text-gray-800" href="/contact/">联系</a></div><div class="mt-8 md:order-1 md:mt-0"><p class="text-center text-xs leading-5 text-gray-600">© 2024 Skyfalling Blog. All rights reserved.</p></div></div></footer></div><script src="/_next/static/chunks/webpack-42d55485b4428e47.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[10616,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"7177\",\"static/chunks/app/layout-51baccc14cf1da9e.js\"],\"default\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n5:I[6874,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"\"]\n7:I[59665,[],\"OutletBoundary\"]\na:I[74911,[],\"AsyncMetadataOutlet\"]\nc:I[59665,[],\"ViewportBoundary\"]\ne:I[59665,[],\"MetadataBoundary\"]\n10:I[26614,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/0458d6941a120cde.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"8CSEQRRrJyhjI8sSOwcIy\",\"p\":\"\",\"c\":[\"\",\"blog\",\"engineering\",\"agentic\",\"11-Multi-Agent%20Collaboration\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"engineering/agentic/11-Multi-Agent%20Collaboration\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/0458d6941a120cde.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-[var(--background)]\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-6 py-12 md:flex md:items-center md:justify-between lg:px-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex justify-center space-x-6 md:order-2\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/about\",\"className\":\"text-gray-600 hover:text-gray-800\",\"children\":\"关于\"}],[\"$\",\"$L5\",null,{\"href\":\"/blog\",\"className\":\"text-gray-600 hover:text-gray-800\",\"children\":\"博客\"}],[\"$\",\"$L5\",null,{\"href\":\"/contact\",\"className\":\"text-gray-600 hover:text-gray-800\",\"children\":\"联系\"}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 md:order-1 md:mt-0\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs leading-5 text-gray-600\",\"children\":\"© 2024 Skyfalling Blog. All rights reserved.\"}]}]]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"engineering/agentic/11-Multi-Agent%20Collaboration\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L6\",null,[\"$\",\"$L7\",null,{\"children\":[\"$L8\",\"$L9\",[\"$\",\"$La\",null,{\"promise\":\"$@b\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"5fPdDST3Z-jgYCLfY28a3v\",{\"children\":[[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$10\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:\"$Sreact.suspense\"\n12:I[74911,[],\"AsyncMetadata\"]\n14:I[32923,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n16:I[40780,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n19:I[85300,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\nf:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$11\",null,{\"fallback\":null,\"children\":[\"$\",\"$L12\",null,{\"promise\":\"$@13\"}]}]}]\n15:Tf833,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eMulti-Agent Collaboration: 多 Agent 协作模式与架构\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e一个人可以走得很快，但一群人才能走得很远。Agent 也是如此。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 11 篇。前 10 篇我们一直在讨论单个 Agent 如何更聪明——更好的记忆、更强的工具、更深的规划。这一篇，我们把视角从\u0026quot;个体智能\u0026quot;拉升到\u0026quot;集体智能\u0026quot;：当一个 Agent 不够用时，多个 Agent 如何协作？\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么单 Agent 不够\u003c/h2\u003e\n\u003ch3\u003e1.1 一个类比：从独立开发者到工程团队\u003c/h3\u003e\n\u003cp\u003e想象你是一个全栈工程师，独自完成一个项目。前端、后端、数据库、DevOps、测试、文档——全部一个人扛。小项目可以，但当系统规模增长到一定程度，你会发现：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e注意力是瓶颈\u003c/strong\u003e：你不可能同时想着 CSS 布局和数据库索引优化\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e专业化有上限\u003c/strong\u003e：一个人很难同时成为安全专家、性能专家和 UX 专家\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e效率有天花板\u003c/strong\u003e：就算你是 10x 工程师，你的时间也是串行的\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e单点风险\u003c/strong\u003e：你生病了，整个项目就停了\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这就是人类发明\u0026quot;团队协作\u0026quot;的原因。Agent 面临完全相同的结构性限制。\u003c/p\u003e\n\u003ch3\u003e1.2 Single-Agent 的四个天花板\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e天花板一：Context Window 限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个 Agent 的 System Prompt 需要包含：角色定义、工具描述、输出格式约束、领域知识、示例。当你试图让一个 Agent 同时承担搜索、分析、写作、代码生成、数据可视化等多个职能时，光是工具描述就可能占据数万 token。留给实际任务执行的上下文空间被严重压缩。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e一个\u0026quot;全能\u0026quot; Agent 的 Context 分配：\n\n┌─────────────────────────────────────────────────┐\n│ System Prompt (角色 + 规则)         ~2,000 tokens │\n│ Tool Schemas (15 个工具)            ~6,000 tokens │\n│ 领域知识 (RAG 检索结果)             ~4,000 tokens │\n│ 对话历史                            ~8,000 tokens │\n│ 当前任务 + 中间状态                 ~3,000 tokens │\n├─────────────────────────────────────────────────┤\n│ 剩余可用空间                        ~9,000 tokens │ ← 越来越捉襟见肘\n│ (128K 窗口下比例更好，但工具越多问题越突出)         │\n└─────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e更关键的是，研究表明 LLM 在超长上下文中存在\u0026quot;Lost in the Middle\u0026quot;问题——中间位置的信息检索准确率显著下降。塞得越多，每条信息被有效利用的概率越低。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e天花板二：专业化限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e一个 System Prompt 很难让 LLM 同时扮演好多个角色。你告诉它\u0026quot;你是一个严谨的数据分析师\u0026quot;，它分析数据时很好；但同一个 prompt 里你又说\u0026quot;你也是一个有创意的文案写手\u0026quot;，这两种人格的行为模式是矛盾的。严谨和创意在同一个 prompt 中互相干扰，最终两个角色都做不好。\u003c/p\u003e\n\u003cp\u003e这不是 prompt engineering 的技巧问题，而是注意力分配的结构性问题——一个 LLM 调用只有一个 attention 分布，强调了分析的严谨性，就必然削弱了文案的创造性。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e天花板三：可靠性限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e单 Agent 是一个 Single Point of Failure。如果它在第 5 步推理出错（比如工具调用参数写错），整个任务链路都会受到污染。虽然我们在第 10 篇讨论了 Reflection 和自我纠错，但自我纠错的前提是\u0026quot;能发现自己错了\u0026quot;——而 LLM 对自身错误的检测能力是有限的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e天花板四：并行度限制\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e单 Agent 的执行是串行的——一次 LLM 调用，等待结果，再进行下一次。如果一个任务可以分解为三个独立子任务（比如同时搜索三个数据源），单 Agent 只能顺序执行，浪费了大量时间。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSingle-Agent 串行执行：\n\n  Task ──→ [Search A] ──→ [Search B] ──→ [Search C] ──→ [Synthesize]\n                                                         Total: ~40s\n\nMulti-Agent 并行执行：\n\n           ┌─→ [Search A] ─┐\n  Task ──→ ├─→ [Search B] ─┼──→ [Synthesize]\n           └─→ [Search C] ─┘\n                              Total: ~15s\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e2. Multi-Agent 的四种协作模式\u003c/h2\u003e\n\u003cp\u003e当我们决定使用多个 Agent 时，第一个架构问题是：\u003cstrong\u003e它们之间的协作关系是什么？\u003c/strong\u003e 不同的关系模式适用于不同的场景，选错模式比用错框架更致命。\u003c/p\u003e\n\u003ch3\u003e2.1 模式一：Supervisor-Worker（上级分配型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌──────────────────┐\n                    │    Supervisor    │\n                    │   (任务分解 +    │\n                    │    结果合成)     │\n                    └──────┬───────────┘\n                           │\n              ┌────────────┼────────────┐\n              │            │            │\n              ▼            ▼            ▼\n       ┌──────────┐ ┌──────────┐ ┌──────────┐\n       │ Worker A │ │ Worker B │ │ Worker C │\n       │ (搜索)   │ │ (分析)   │ │ (写作)   │\n       └──────────┘ └──────────┘ └──────────┘\n              │            │            │\n              └────────────┼────────────┘\n                           │\n                           ▼\n                    ┌──────────────────┐\n                    │    Supervisor    │\n                    │   (收集 + 合成   │\n                    │    最终输出)     │\n                    └──────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSupervisor Agent 接收用户任务\u003c/li\u003e\n\u003cli\u003eSupervisor 将任务分解为子任务，分配给不同的 Worker Agent\u003c/li\u003e\n\u003cli\u003e每个 Worker 独立执行各自的子任务\u003c/li\u003e\n\u003cli\u003eSupervisor 收集所有 Worker 的结果，合成最终输出\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e有一个明确的中央协调者\u003c/li\u003e\n\u003cli\u003eWorker 之间不直接通信，只与 Supervisor 交互\u003c/li\u003e\n\u003cli\u003eSupervisor 负责全局决策，Worker 负责局部执行\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：任务可以明确分解的场景。比如撰写一篇技术调研报告：Search Agent 负责信息搜集，Analyze Agent 负责数据分析，Write Agent 负责报告撰写。Supervisor 负责协调整个流程。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：Supervisor 是单点——如果 Supervisor 对任务的分解不合理，所有 Worker 的努力都会被浪费。此外，Supervisor 本身也是一个 LLM 调用，它对任务的理解能力决定了整个系统的上限。\u003c/p\u003e\n\u003ch3\u003e2.2 模式二：Peer-to-Peer（平等协商型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐          ┌──────────┐\n       │ Agent A  │◀────────▶│ Agent B  │\n       │ (作者)   │          │ (审稿人) │\n       └────┬─────┘          └────┬─────┘\n            │                     │\n            │    ┌──────────┐     │\n            └───▶│ Agent C  │◀────┘\n                 │ (编辑)   │\n                 └──────────┘\n\n       消息流是双向的，没有固定的上下级关系\n       每个 Agent 都可以发起对话、提出意见、做出决策\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e多个 Agent 地位平等，通过消息传递进行协商\u003c/li\u003e\n\u003cli\u003e没有中央协调者——Agent 之间直接通信\u003c/li\u003e\n\u003cli\u003e通过多轮对话达成共识或完成任务\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e去中心化\u003c/li\u003e\n\u003cli\u003eAgent 之间直接消息传递\u003c/li\u003e\n\u003cli\u003e适合需要多视角碰撞的任务\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：辩论式分析（多个 Agent 从不同立场论证）、代码审查（Author Agent 写代码，Reviewer Agent 审查，双方来回沟通直到代码质量达标）、多角度决策（乐观分析师 + 悲观分析师 + 风险评估师共同评估一个投资决策）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：没有中央协调意味着可能出现无限循环（两个 Agent 互相不同意，永远达不成共识）。需要额外的终止机制——最大轮次限制、外部仲裁者、投票制度等。调试也更困难，因为没有一个中心节点可以观察全局状态。\u003c/p\u003e\n\u003ch3\u003e2.3 模式三：Pipeline（流水线型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e  Input                                                          Output\n    │                                                              ▲\n    ▼                                                              │\n┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐\n│ Draft  │───▶│ Review │───▶│  Edit  │───▶│  Fact  │───▶│ Format │\n│ Agent  │    │ Agent  │    │ Agent  │    │ Check  │    │ Agent  │\n│        │    │        │    │        │    │ Agent  │    │        │\n└────────┘    └────────┘    └────────┘    └────────┘    └────────┘\n\n  Stage 1       Stage 2       Stage 3       Stage 4       Stage 5\n  生成初稿      审查质量       修改完善      事实核查       格式化输出\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAgent 按顺序串联，形成流水线\u003c/li\u003e\n\u003cli\u003e上游 Agent 的输出是下游 Agent 的输入\u003c/li\u003e\n\u003cli\u003e每个 Agent 专注于一个处理阶段\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e类似 Unix 管道：\u003ccode\u003ecmd1 | cmd2 | cmd3\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e数据单向流动\u003c/li\u003e\n\u003cli\u003e每个阶段的 Agent 有明确、单一的职责\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：内容生产流水线（起草 -\u0026gt; 审查 -\u0026gt; 编辑 -\u0026gt; 排版）、数据处理管道（提取 -\u0026gt; 清洗 -\u0026gt; 转换 -\u0026gt; 加载）、多阶段审批（初审 -\u0026gt; 复审 -\u0026gt; 终审）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：流水线是严格串行的——上游不完成，下游无法开始。如果中间某个 Agent 输出质量差，后续所有阶段都会受影响（错误传播）。但好处是架构简单、易于理解和调试、每个阶段可以独立优化。\u003c/p\u003e\n\u003ch3\u003e2.4 模式四：Dynamic Routing（动态路由型）\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e                    ┌──────────────────┐\n                    │   Router Agent   │\n                    │ (意图识别 + 路由) │\n                    └──────┬───────────┘\n                           │\n              ┌────────────┼────────────┐\n              │            │            │\n              ▼            ▼            ▼\n       ┌──────────┐ ┌──────────┐ ┌──────────┐\n       │ 技术支持  │ │ 售后服务  │ │ 销售咨询  │\n       │ Agent    │ │ Agent    │ │ Agent    │\n       │          │ │          │ │          │\n       │ 处理技术  │ │ 处理退款  │ │ 处理购买  │\n       │ 故障排查  │ │ 换货投诉  │ │ 产品推荐  │\n       └──────────┘ └──────────┘ └──────────┘\n\n  路由依据：用户输入的意图分类\n  每个专家 Agent 有独立的 System Prompt、Tools、知识库\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e工作流程\u003c/strong\u003e：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRouter Agent 接收用户输入\u003c/li\u003e\n\u003cli\u003e根据意图分类，将请求路由到对应的专家 Agent\u003c/li\u003e\n\u003cli\u003e专家 Agent 处理请求并返回结果\u003c/li\u003e\n\u003cli\u003e必要时 Router 可以在专家之间进行二次路由\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003e核心特征\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e一个轻量级的 Router 做决策\u003c/li\u003e\n\u003cli\u003e多个重量级的专家 Agent 做执行\u003c/li\u003e\n\u003cli\u003eRouter 可以用简单模型（快速、便宜），专家用强大模型（准确、深入）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e适用场景\u003c/strong\u003e：客服系统（技术问题 -\u0026gt; 技术 Agent，退款问题 -\u0026gt; 售后 Agent）、多领域知识问答（医疗问题 -\u0026gt; 医疗 Agent，法律问题 -\u0026gt; 法律 Agent）、代码助手（Python 问题 -\u0026gt; Python 专家，Rust 问题 -\u0026gt; Rust 专家）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTrade-off\u003c/strong\u003e：路由准确率是整个系统的瓶颈——路由错了，后面再专业也没用。模糊意图（\u0026quot;我买的东西有技术问题\u0026quot;——这是技术支持还是售后？）需要特殊处理。一种常见策略是允许 Router 在不确定时同时咨询多个专家，再综合判断。\u003c/p\u003e\n\u003ch3\u003e2.5 四种模式的对比决策\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eSupervisor-Worker\u003c/th\u003e\n\u003cth\u003ePeer-to-Peer\u003c/th\u003e\n\u003cth\u003ePipeline\u003c/th\u003e\n\u003cth\u003eDynamic Routing\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e控制结构\u003c/td\u003e\n\u003ctd\u003e中心化\u003c/td\u003e\n\u003ctd\u003e去中心化\u003c/td\u003e\n\u003ctd\u003e线性\u003c/td\u003e\n\u003ctd\u003e分发型\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e通信模式\u003c/td\u003e\n\u003ctd\u003e星形\u003c/td\u003e\n\u003ctd\u003e网状\u003c/td\u003e\n\u003ctd\u003e链式\u003c/td\u003e\n\u003ctd\u003e扇出\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并行度\u003c/td\u003e\n\u003ctd\u003e高（Worker 并行）\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e低（严格串行）\u003c/td\u003e\n\u003ctd\u003e高（请求级并行）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用复杂度\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e低-中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e调试难度\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e高\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e典型场景\u003c/td\u003e\n\u003ctd\u003e报告生成、项目规划\u003c/td\u003e\n\u003ctd\u003e辩论、审查\u003c/td\u003e\n\u003ctd\u003e内容流水线\u003c/td\u003e\n\u003ctd\u003e客服、问答路由\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e决策原则\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e任务可以并行分解 -\u0026gt; Supervisor-Worker\u003c/li\u003e\n\u003cli\u003e需要多视角碰撞 -\u0026gt; Peer-to-Peer\u003c/li\u003e\n\u003cli\u003e处理有明确阶段 -\u0026gt; Pipeline\u003c/li\u003e\n\u003cli\u003e请求类型多样，专家各有擅长 -\u0026gt; Dynamic Routing\u003c/li\u003e\n\u003cli\u003e不确定？先从最简单的 Pipeline 开始，逐步演进\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e3. Agent 间通信机制\u003c/h2\u003e\n\u003cp\u003e多个 Agent 之间需要交换信息，通信机制的选择直接影响系统的可扩展性、耦合度和调试难度。\u003c/p\u003e\n\u003ch3\u003e3.1 共享内存（Blackboard Pattern）\u003c/h3\u003e\n\u003cp\u003e所有 Agent 读写同一个共享状态存储。这是最简单直接的通信方式。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐   ┌──────────┐   ┌──────────┐\n       │ Agent A  │   │ Agent B  │   │ Agent C  │\n       └────┬─────┘   └────┬─────┘   └────┬─────┘\n            │  read/write   │  read/write   │\n            ▼              ▼              ▼\n       ┌──────────────────────────────────────────┐\n       │           Shared Blackboard              │\n       │                                          │\n       │  { \u0026quot;search_results\u0026quot;: [...],              │\n       │    \u0026quot;analysis\u0026quot;: {...},                    │\n       │    \u0026quot;draft\u0026quot;: \u0026quot;...\u0026quot;,                       │\n       │    \u0026quot;status\u0026quot;: {\u0026quot;search\u0026quot;: \u0026quot;done\u0026quot;, ...} }   │\n       └──────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom typing import Any\nimport threading\n\n\n@dataclass\nclass Blackboard:\n    \u0026quot;\u0026quot;\u0026quot;共享黑板：所有 Agent 的公共状态空间\u0026quot;\u0026quot;\u0026quot;\n    _state: dict[str, Any] = field(default_factory=dict)\n    _lock: threading.Lock = field(default_factory=threading.Lock)\n    _history: list[dict] = field(default_factory=list)\n\n    def read(self, key: str) -\u0026gt; Any:\n        with self._lock:\n            return self._state.get(key)\n\n    def write(self, key: str, value: Any, author: str = \u0026quot;unknown\u0026quot;):\n        with self._lock:\n            self._history.append({\n                \u0026quot;action\u0026quot;: \u0026quot;write\u0026quot;,\n                \u0026quot;key\u0026quot;: key,\n                \u0026quot;author\u0026quot;: author,\n                \u0026quot;old_value\u0026quot;: self._state.get(key),\n                \u0026quot;new_value\u0026quot;: value,\n            })\n            self._state[key] = value\n\n    def read_all(self) -\u0026gt; dict[str, Any]:\n        with self._lock:\n            return dict(self._state)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：实现简单，Agent 之间完全解耦（不需要知道彼此的存在），天然支持任意读写模式。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：共享状态意味着潜在的竞争条件——两个 Agent 同时写同一个 key 怎么办？需要锁机制或更复杂的冲突解决策略。随着 Agent 数量增加，Blackboard 可能成为瓶颈。\u003c/p\u003e\n\u003ch3\u003e3.2 消息传递（Message Passing）\u003c/h3\u003e\n\u003cp\u003eAgent 之间通过显式的消息进行通信。每个 Agent 有自己的收件箱。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐         ┌──────────┐\n       │ Agent A  │──msg───▶│ Agent B  │\n       │          │◀──msg───│          │\n       └──────────┘         └──────────┘\n            │                     ▲\n            │         msg         │\n            ▼                     │\n       ┌──────────┐              │\n       │ Agent C  │──────msg─────┘\n       └──────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\nfrom collections import defaultdict\nfrom queue import Queue\n\n\n@dataclass\nclass Message:\n    sender: str\n    receiver: str\n    content: Any\n    msg_type: str = \u0026quot;default\u0026quot;  # \u0026quot;task\u0026quot;, \u0026quot;result\u0026quot;, \u0026quot;feedback\u0026quot;, \u0026quot;error\u0026quot;\n\n\nclass MessageBus:\n    \u0026quot;\u0026quot;\u0026quot;点对点消息传递\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._queues: dict[str, Queue] = defaultdict(Queue)\n\n    def send(self, message: Message):\n        self._queues[message.receiver].put(message)\n\n    def receive(self, agent_id: str, timeout: float = None) -\u0026gt; Message | None:\n        try:\n            return self._queues[agent_id].get(timeout=timeout)\n        except Exception:\n            return None\n\n    def has_messages(self, agent_id: str) -\u0026gt; bool:\n        return not self._queues[agent_id].empty()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：通信关系显式、可追踪、可审计。每条消息都有明确的发送者和接收者。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：Agent 需要知道其他 Agent 的存在（至少知道 ID），耦合度比 Blackboard 高。如果通信拓扑复杂（多对多），消息管理会变得困难。\u003c/p\u003e\n\u003ch3\u003e3.3 事件驱动（Event Bus）\u003c/h3\u003e\n\u003cp\u003eAgent 通过发布/订阅事件进行间接通信。Agent 不需要知道谁会消费它的事件。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e       ┌──────────┐   ┌──────────┐   ┌──────────┐\n       │ Agent A  │   │ Agent B  │   │ Agent C  │\n       │ pub: X   │   │ sub: X   │   │ sub: X,Y │\n       └────┬─────┘   └────┬─────┘   └────┬─────┘\n            │  publish      │  subscribe   │\n            ▼              ▼              ▼\n       ┌──────────────────────────────────────────┐\n       │              Event Bus                    │\n       │                                          │\n       │  topic \u0026quot;search_done\u0026quot;  → [Agent B, C]     │\n       │  topic \u0026quot;analysis_done\u0026quot; → [Agent C]        │\n       │  topic \u0026quot;error\u0026quot;        → [Supervisor]      │\n       └──────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom collections import defaultdict\nfrom typing import Callable\n\n\nclass EventBus:\n    \u0026quot;\u0026quot;\u0026quot;发布/订阅事件总线\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self._subscribers: dict[str, list[Callable]] = defaultdict(list)\n        self._event_log: list[dict] = []\n\n    def subscribe(self, topic: str, handler: Callable):\n        self._subscribers[topic].append(handler)\n\n    def publish(self, topic: str, data: Any, publisher: str = \u0026quot;unknown\u0026quot;):\n        event = {\u0026quot;topic\u0026quot;: topic, \u0026quot;data\u0026quot;: data, \u0026quot;publisher\u0026quot;: publisher}\n        self._event_log.append(event)\n        for handler in self._subscribers.get(topic, []):\n            handler(event)\n\n    def get_event_log(self) -\u0026gt; list[dict]:\n        return list(self._event_log)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：Agent 之间完全解耦——发布者不知道有谁在监听，订阅者不知道事件从哪里来。扩展性好，新增 Agent 只需订阅相关事件。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：事件流难以追踪——\u0026quot;这个事件是谁发的？谁处理了？处理结果在哪里？\u0026quot;调试时需要完整的事件日志。事件顺序可能不确定，需要额外的排序机制。\u003c/p\u003e\n\u003ch3\u003e3.4 通信机制对比\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eBlackboard\u003c/th\u003e\n\u003cth\u003eMessage Passing\u003c/th\u003e\n\u003cth\u003eEvent Bus\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e耦合度\u003c/td\u003e\n\u003ctd\u003e低（通过 key 间接通信）\u003c/td\u003e\n\u003ctd\u003e中（需要知道目标 Agent）\u003c/td\u003e\n\u003ctd\u003e低（通过 topic 间接通信）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e实现复杂度\u003c/td\u003e\n\u003ctd\u003e低\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e调试友好度\u003c/td\u003e\n\u003ctd\u003e中（看状态快照）\u003c/td\u003e\n\u003ctd\u003e高（消息链路清晰）\u003c/td\u003e\n\u003ctd\u003e低（事件流分散）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e并发安全\u003c/td\u003e\n\u003ctd\u003e需要锁/MVCC\u003c/td\u003e\n\u003ctd\u003e天然安全（队列隔离）\u003c/td\u003e\n\u003ctd\u003e需要考虑处理顺序\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e适用模式\u003c/td\u003e\n\u003ctd\u003eSupervisor-Worker\u003c/td\u003e\n\u003ctd\u003ePeer-to-Peer\u003c/td\u003e\n\u003ctd\u003ePipeline, 事件驱动架构\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e可观测性\u003c/td\u003e\n\u003ctd\u003e状态快照\u003c/td\u003e\n\u003ctd\u003e消息轨迹\u003c/td\u003e\n\u003ctd\u003e事件日志\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e实践建议\u003c/strong\u003e：大多数 Multi-Agent 系统可以从 Blackboard 开始——它最简单，且对 Supervisor-Worker 模式特别友好。当系统复杂度增长到需要解耦 Agent 间关系时，再考虑 Event Bus。Message Passing 适合 Agent 之间有明确的、频繁的双向交互的场景。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. 完整实现：Supervisor-Worker 协作框架\u003c/h2\u003e\n\u003cp\u003e下面用 Python 从零实现一个 Supervisor-Worker 框架。这不依赖任何 Agent 框架，完全基于第一性原理构建。\u003c/p\u003e\n\u003ch3\u003e4.1 基础抽象\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nimport asyncio\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom typing import Any\n\n\n# ---- LLM 调用抽象（与具体 SDK 解耦）----\n\nasync def call_llm(\n    messages: list[dict],\n    model: str = \u0026quot;gpt-4o\u0026quot;,\n    response_format: dict | None = None,\n) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;LLM 调用的统一接口（简化版，生产中替换为真实 SDK 调用）\u0026quot;\u0026quot;\u0026quot;\n    import openai\n    client = openai.AsyncOpenAI()\n    kwargs = {\u0026quot;model\u0026quot;: model, \u0026quot;messages\u0026quot;: messages}\n    if response_format:\n        kwargs[\u0026quot;response_format\u0026quot;] = response_format\n    response = await client.chat.completions.create(**kwargs)\n    return response.choices[0].message.content\n\n\n# ---- 任务与结果的数据结构 ----\n\n@dataclass\nclass Task:\n    \u0026quot;\u0026quot;\u0026quot;一个可执行的子任务\u0026quot;\u0026quot;\u0026quot;\n    task_id: str\n    description: str\n    assigned_to: str = \u0026quot;\u0026quot;          # Worker Agent 名称\n    context: dict = field(default_factory=dict)  # 来自上游的上下文\n    status: str = \u0026quot;pending\u0026quot;        # pending | running | done | failed\n    result: str = \u0026quot;\u0026quot;\n    error: str = \u0026quot;\u0026quot;\n\n\n@dataclass\nclass TeamResult:\n    \u0026quot;\u0026quot;\u0026quot;团队执行的最终结果\u0026quot;\u0026quot;\u0026quot;\n    success: bool\n    output: str\n    tasks: list[Task]\n    total_tokens: int = 0\n    total_llm_calls: int = 0\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.2 Worker Agent\u003c/h3\u003e\n\u003cp\u003e每个 Worker 是一个专注于特定领域的 Agent，拥有独立的 System Prompt 和能力边界。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass WorkerAgent:\n    \u0026quot;\u0026quot;\u0026quot;Worker Agent：接收子任务，独立执行，返回结果\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, name: str, system_prompt: str, model: str = \u0026quot;gpt-4o\u0026quot;):\n        self.name = name\n        self.system_prompt = system_prompt\n        self.model = model\n        self._call_count = 0\n\n    async def execute(self, task: Task) -\u0026gt; Task:\n        \u0026quot;\u0026quot;\u0026quot;执行一个子任务\u0026quot;\u0026quot;\u0026quot;\n        task.status = \u0026quot;running\u0026quot;\n        task.assigned_to = self.name\n\n        messages = [\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self.system_prompt},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: self._build_prompt(task)},\n        ]\n\n        try:\n            result = await call_llm(messages, model=self.model)\n            self._call_count += 1\n            task.result = result\n            task.status = \u0026quot;done\u0026quot;\n        except Exception as e:\n            task.error = str(e)\n            task.status = \u0026quot;failed\u0026quot;\n\n        return task\n\n    def _build_prompt(self, task: Task) -\u0026gt; str:\n        prompt = f\u0026quot;## 任务\\n{task.description}\\n\u0026quot;\n        if task.context:\n            prompt += f\u0026quot;\\n## 上下文信息\\n{json.dumps(task.context, ensure_ascii=False, indent=2)}\\n\u0026quot;\n        prompt += \u0026quot;\\n请完成上述任务，直接输出结果。\u0026quot;\n        return prompt\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.3 Supervisor Agent\u003c/h3\u003e\n\u003cp\u003eSupervisor 负责三件事：任务分解、任务分配、结果合成。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eDECOMPOSE_PROMPT = \u0026quot;\u0026quot;\u0026quot;你是一个任务分解专家。给定一个复杂任务，将其分解为可以独立执行的子任务。\n\n可用的 Worker 及其能力：\n{workers_description}\n\n请将任务分解为子任务，并指定每个子任务应该分配给哪个 Worker。\n输出 JSON 格式：\n{{\n  \u0026quot;subtasks\u0026quot;: [\n    {{\n      \u0026quot;task_id\u0026quot;: \u0026quot;task_1\u0026quot;,\n      \u0026quot;description\u0026quot;: \u0026quot;具体的子任务描述\u0026quot;,\n      \u0026quot;assigned_to\u0026quot;: \u0026quot;worker 名称\u0026quot;,\n      \u0026quot;depends_on\u0026quot;: []\n    }}\n  ]\n}}\n\n注意：\n- 每个子任务应该足够具体，让 Worker 能独立完成\n- depends_on 标明依赖关系（某个子任务需要等另一个完成后才能开始）\n- 尽可能让子任务并行执行以提高效率\n\u0026quot;\u0026quot;\u0026quot;\n\nSYNTHESIZE_PROMPT = \u0026quot;\u0026quot;\u0026quot;你是一个结果合成专家。多个专业 Agent 已经分别完成了子任务。\n请根据它们的结果，合成一个完整、连贯、高质量的最终输出。\n\n原始任务：{original_task}\n\n各子任务的执行结果：\n{subtask_results}\n\n请整合以上信息，生成最终的完整输出。确保：\n1. 信息完整，没有遗漏\n2. 逻辑连贯，前后一致\n3. 去除重复内容\n4. 保持专业质量\n\u0026quot;\u0026quot;\u0026quot;\n\n\nclass SupervisorAgent:\n    \u0026quot;\u0026quot;\u0026quot;Supervisor Agent：任务分解、分配、合成\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, model: str = \u0026quot;gpt-4o\u0026quot;):\n        self.model = model\n        self._call_count = 0\n\n    async def decompose(\n        self, task: str, workers: dict[str, WorkerAgent]\n    ) -\u0026gt; list[Task]:\n        \u0026quot;\u0026quot;\u0026quot;将复杂任务分解为子任务\u0026quot;\u0026quot;\u0026quot;\n        workers_desc = \u0026quot;\\n\u0026quot;.join(\n            f\u0026quot;- {name}: {w.system_prompt[:200]}\u0026quot;\n            for name, w in workers.items()\n        )\n\n        messages = [\n            {\n                \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                \u0026quot;content\u0026quot;: DECOMPOSE_PROMPT.format(\n                    workers_description=workers_desc\n                ),\n            },\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: task},\n        ]\n\n        result = await call_llm(\n            messages,\n            model=self.model,\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        self._call_count += 1\n\n        parsed = json.loads(result)\n        tasks = []\n        for st in parsed.get(\u0026quot;subtasks\u0026quot;, []):\n            tasks.append(Task(\n                task_id=st[\u0026quot;task_id\u0026quot;],\n                description=st[\u0026quot;description\u0026quot;],\n                assigned_to=st.get(\u0026quot;assigned_to\u0026quot;, \u0026quot;\u0026quot;),\n            ))\n        return tasks\n\n    async def synthesize(\n        self, original_task: str, completed_tasks: list[Task]\n    ) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;合成所有 Worker 的结果\u0026quot;\u0026quot;\u0026quot;\n        results_text = \u0026quot;\\n\\n\u0026quot;.join(\n            f\u0026quot;### {t.task_id} ({t.assigned_to})\\n{t.result}\u0026quot;\n            for t in completed_tasks\n            if t.status == \u0026quot;done\u0026quot;\n        )\n\n        messages = [\n            {\n                \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n                \u0026quot;content\u0026quot;: SYNTHESIZE_PROMPT.format(\n                    original_task=original_task,\n                    subtask_results=results_text,\n                ),\n            },\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;请合成最终结果。\u0026quot;},\n        ]\n\n        result = await call_llm(messages, model=self.model)\n        self._call_count += 1\n        return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.4 AgentTeam：编排层\u003c/h3\u003e\n\u003cp\u003eAgentTeam 管理多个 Agent 的生命周期、通信和执行流程。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass AgentTeam:\n    \u0026quot;\u0026quot;\u0026quot;Agent 团队：管理 Supervisor + Workers 的协作\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor: SupervisorAgent):\n        self.supervisor = supervisor\n        self.workers: dict[str, WorkerAgent] = {}\n        self.blackboard = Blackboard()\n        self.execution_log: list[dict] = []\n\n    def add_worker(self, worker: WorkerAgent):\n        self.workers[worker.name] = worker\n\n    async def run(self, task: str, max_retries: int = 2) -\u0026gt; TeamResult:\n        \u0026quot;\u0026quot;\u0026quot;执行完整的 Multi-Agent 协作流程\u0026quot;\u0026quot;\u0026quot;\n        self._log(\u0026quot;team\u0026quot;, f\u0026quot;接收任务: {task[:100]}...\u0026quot;)\n\n        # Phase 1: Supervisor 分解任务\n        self._log(\u0026quot;supervisor\u0026quot;, \u0026quot;开始任务分解\u0026quot;)\n        subtasks = await self.supervisor.decompose(task, self.workers)\n        self._log(\u0026quot;supervisor\u0026quot;, f\u0026quot;分解为 {len(subtasks)} 个子任务\u0026quot;)\n\n        for st in subtasks:\n            self._log(\u0026quot;supervisor\u0026quot;, f\u0026quot;  {st.task_id} -\u0026gt; {st.assigned_to}: {st.description[:80]}\u0026quot;)\n\n        # Phase 2: Workers 并行执行（考虑依赖关系）\n        completed = await self._execute_tasks(subtasks, max_retries)\n\n        # Phase 3: Supervisor 合成结果\n        self._log(\u0026quot;supervisor\u0026quot;, \u0026quot;开始合成结果\u0026quot;)\n        final_output = await self.supervisor.synthesize(task, completed)\n        self._log(\u0026quot;supervisor\u0026quot;, \u0026quot;合成完成\u0026quot;)\n\n        # 汇总统计\n        total_calls = self.supervisor._call_count + sum(\n            w._call_count for w in self.workers.values()\n        )\n\n        return TeamResult(\n            success=all(t.status == \u0026quot;done\u0026quot; for t in completed),\n            output=final_output,\n            tasks=completed,\n            total_llm_calls=total_calls,\n        )\n\n    async def _execute_tasks(\n        self, tasks: list[Task], max_retries: int\n    ) -\u0026gt; list[Task]:\n        \u0026quot;\u0026quot;\u0026quot;执行子任务，支持并行和重试\u0026quot;\u0026quot;\u0026quot;\n        completed = []\n        pending = list(tasks)\n\n        while pending:\n            # 找出当前可以执行的任务（依赖已满足）\n            ready = []\n            still_pending = []\n            completed_ids = {t.task_id for t in completed}\n\n            for task in pending:\n                deps = task.context.get(\u0026quot;depends_on\u0026quot;, [])\n                if all(d in completed_ids for d in deps):\n                    ready.append(task)\n                else:\n                    still_pending.append(task)\n\n            if not ready:\n                # 没有可执行的任务但还有待处理的 -\u0026gt; 可能存在循环依赖\n                self._log(\u0026quot;team\u0026quot;, \u0026quot;警告: 检测到无法满足的依赖关系\u0026quot;)\n                break\n\n            # 并行执行所有就绪的任务\n            results = await asyncio.gather(*[\n                self._execute_single(task, max_retries)\n                for task in ready\n            ])\n\n            for task in results:\n                completed.append(task)\n                # 将结果写入 Blackboard，供后续任务使用\n                if task.status == \u0026quot;done\u0026quot;:\n                    self.blackboard.write(\n                        task.task_id, task.result, author=task.assigned_to\n                    )\n\n            pending = still_pending\n\n        return completed\n\n    async def _execute_single(\n        self, task: Task, max_retries: int\n    ) -\u0026gt; Task:\n        \u0026quot;\u0026quot;\u0026quot;执行单个任务，带重试\u0026quot;\u0026quot;\u0026quot;\n        worker = self.workers.get(task.assigned_to)\n        if not worker:\n            task.status = \u0026quot;failed\u0026quot;\n            task.error = f\u0026quot;未找到 Worker: {task.assigned_to}\u0026quot;\n            return task\n\n        # 将 Blackboard 上的相关信息注入任务上下文\n        task.context[\u0026quot;blackboard\u0026quot;] = self.blackboard.read_all()\n\n        for attempt in range(max_retries + 1):\n            self._log(worker.name, f\u0026quot;执行 {task.task_id} (尝试 {attempt + 1})\u0026quot;)\n            result = await worker.execute(task)\n\n            if result.status == \u0026quot;done\u0026quot;:\n                self._log(worker.name, f\u0026quot;{task.task_id} 完成\u0026quot;)\n                return result\n\n            self._log(worker.name, f\u0026quot;{task.task_id} 失败: {result.error}\u0026quot;)\n\n            if attempt \u0026lt; max_retries:\n                self._log(worker.name, f\u0026quot;准备重试 {task.task_id}\u0026quot;)\n\n        return result\n\n    def _log(self, source: str, message: str):\n        entry = {\u0026quot;source\u0026quot;: source, \u0026quot;message\u0026quot;: message}\n        self.execution_log.append(entry)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.5 组装示例：技术调研报告\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def main():\n    \u0026quot;\u0026quot;\u0026quot;示例：用 Multi-Agent 团队撰写一篇技术调研报告\u0026quot;\u0026quot;\u0026quot;\n\n    # 创建 Supervisor\n    supervisor = SupervisorAgent(model=\u0026quot;gpt-4o\u0026quot;)\n\n    # 创建专业化的 Worker Agent\n    search_agent = WorkerAgent(\n        name=\u0026quot;searcher\u0026quot;,\n        system_prompt=(\n            \u0026quot;你是一个信息搜索专家。你的任务是根据给定的主题，\u0026quot;\n            \u0026quot;整理出全面的信息摘要，包括关键事实、数据、案例。\u0026quot;\n            \u0026quot;输出结构化的搜索结果，标注来源和可信度。\u0026quot;\n        ),\n    )\n\n    analyze_agent = WorkerAgent(\n        name=\u0026quot;analyst\u0026quot;,\n        system_prompt=(\n            \u0026quot;你是一个技术分析专家。你的任务是根据搜索结果和原始数据，\u0026quot;\n            \u0026quot;进行深度分析，提炼洞察，识别趋势、风险和机会。\u0026quot;\n            \u0026quot;输出包含数据支撑的分析报告。\u0026quot;\n        ),\n    )\n\n    write_agent = WorkerAgent(\n        name=\u0026quot;writer\u0026quot;,\n        system_prompt=(\n            \u0026quot;你是一个技术写作专家。你的任务是根据分析结果，\u0026quot;\n            \u0026quot;撰写结构清晰、逻辑严谨、可读性强的技术报告。\u0026quot;\n            \u0026quot;确保使用专业术语，并配有合适的章节结构。\u0026quot;\n        ),\n    )\n\n    # 组建团队\n    team = AgentTeam(supervisor=supervisor)\n    team.add_worker(search_agent)\n    team.add_worker(analyze_agent)\n    team.add_worker(write_agent)\n\n    # 执行任务\n    result = await team.run(\n        \u0026quot;撰写一篇关于 LLM Agent 在企业客服场景落地的技术调研报告，\u0026quot;\n        \u0026quot;包括行业现状、主流技术方案对比、落地挑战和建议。\u0026quot;\n    )\n\n    print(f\u0026quot;成功: {result.success}\u0026quot;)\n    print(f\u0026quot;LLM 调用次数: {result.total_llm_calls}\u0026quot;)\n    print(f\u0026quot;\\n最终输出:\\n{result.output[:500]}...\u0026quot;)\n\n    # 查看执行日志\n    print(\u0026quot;\\n执行链路:\u0026quot;)\n    for entry in team.execution_log:\n        print(f\u0026quot;  [{entry[\u0026#39;source\u0026#39;]}] {entry[\u0026#39;message\u0026#39;]}\u0026quot;)\n\n\n# asyncio.run(main())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码展示了核心的协作模式。生产系统中还需要补充：Token 用量追踪、超时控制、Worker 健康检查、结果缓存等。但架构骨架已经清晰——Supervisor 负责全局调度，Worker 负责局部执行，Blackboard 负责状态共享，AgentTeam 负责生命周期管理。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 状态管理的复杂性\u003c/h2\u003e\n\u003cp\u003eMulti-Agent 系统的状态管理比 Single-Agent 复杂一个数量级。核心难题在于：多个 Agent 同时操作状态，如何保证一致性。\u003c/p\u003e\n\u003ch3\u003e5.1 共享状态 vs 独立状态\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e方案 A：共享状态                     方案 B：独立状态\n┌─────────────────┐                ┌──────────┐  ┌──────────┐  ┌──────────┐\n│  Global State   │                │ State A  │  │ State B  │  │ State C  │\n│                 │                │ (Agent A │  │ (Agent B │  │ (Agent C │\n│ Agent A ──write │                │  独占)   │  │  独占)   │  │  独占)   │\n│ Agent B ──write │                └──────────┘  └──────────┘  └──────────┘\n│ Agent C ──write │                      │              │              │\n└─────────────────┘                      └──────────────┼──────────────┘\n                                                        ▼\n                                                  合并/同步层\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e共享状态\u003c/strong\u003e的优点是 Agent 之间信息同步即时，任何 Agent 都能看到最新全局状态。缺点是需要处理并发冲突。适合 Supervisor-Worker 模式——Supervisor 需要看到所有 Worker 的进度。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e独立状态\u003c/strong\u003e的优点是无并发问题，每个 Agent 完全自主。缺点是 Agent 之间信息同步有延迟，需要显式的合并机制。适合 Pipeline 模式——每个阶段独立处理，只在交接时传递状态。\u003c/p\u003e\n\u003ch3\u003e5.2 冲突解决策略\u003c/h3\u003e\n\u003cp\u003e当两个 Agent 同时修改同一个状态时，需要冲突解决。常见策略：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ConflictResolver:\n    \u0026quot;\u0026quot;\u0026quot;状态冲突解决器\u0026quot;\u0026quot;\u0026quot;\n\n    @staticmethod\n    def last_writer_wins(old_value, new_value_a, new_value_b, timestamp_a, timestamp_b):\n        \u0026quot;\u0026quot;\u0026quot;最后写入者胜出——简单但可能丢失数据\u0026quot;\u0026quot;\u0026quot;\n        return new_value_a if timestamp_a \u0026gt; timestamp_b else new_value_b\n\n    @staticmethod\n    def merge_append(old_value, new_value_a, new_value_b):\n        \u0026quot;\u0026quot;\u0026quot;合并追加——适用于列表类型的状态\u0026quot;\u0026quot;\u0026quot;\n        if isinstance(old_value, list):\n            merged = list(old_value)\n            if isinstance(new_value_a, list):\n                merged.extend(new_value_a)\n            if isinstance(new_value_b, list):\n                merged.extend(new_value_b)\n            return merged\n        return new_value_b  # fallback\n\n    @staticmethod\n    async def llm_resolve(old_value, new_value_a, new_value_b, context: str):\n        \u0026quot;\u0026quot;\u0026quot;用 LLM 判断如何合并冲突——最灵活但最贵\u0026quot;\u0026quot;\u0026quot;\n        prompt = (\n            f\u0026quot;两个 Agent 同时修改了同一个状态。\\n\u0026quot;\n            f\u0026quot;原始值: {old_value}\\n\u0026quot;\n            f\u0026quot;Agent A 的修改: {new_value_a}\\n\u0026quot;\n            f\u0026quot;Agent B 的修改: {new_value_b}\\n\u0026quot;\n            f\u0026quot;上下文: {context}\\n\u0026quot;\n            f\u0026quot;请决定最终值应该是什么，并解释原因。\u0026quot;\n        )\n        return await call_llm([{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: prompt}])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实践中，大多数 Multi-Agent 系统通过架构设计来避免冲突，而不是在运行时解决冲突。最有效的方法是\u003cstrong\u003e状态分区\u003c/strong\u003e——每个 Agent 只写自己负责的状态区域，避免多 Agent 写同一个 key。这也是 Supervisor-Worker 模式天然的优势：每个 Worker 写自己的结果 key，只有 Supervisor 读所有 key。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 错误处理与容错\u003c/h2\u003e\n\u003cp\u003eMulti-Agent 系统的错误处理比 Single-Agent 更复杂，因为错误的传播路径更多。\u003c/p\u003e\n\u003ch3\u003e6.1 Worker 失败\u003c/h3\u003e\n\u003cp\u003eWorker 失败是最常见的情况。处理策略按优先级：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eWorker 失败处理决策树：\n\n  Worker 执行失败\n       │\n       ▼\n  ┌─ 是否可重试？ ─── 是 ──→ 重试（最多 N 次）──→ 成功？──→ 继续\n  │      │                                          │\n  │     否                                         否\n  │      │                                          │\n  │      ▼                                          ▼\n  │  ┌─ 有替代 Worker？ ─── 是 ──→ 分配给替代 Worker\n  │  │      │\n  │  │     否\n  │  │      │\n  │  │      ▼\n  │  │  ┌─ 该子任务是关键路径？\n  │  │  │      │            │\n  │  │  │     是           否\n  │  │  │      │            │\n  │  │  │      ▼            ▼\n  │  │  │  整体任务失败   降级处理（跳过该子任务，\n  │  │  │                 标记结果为不完整）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ResilientAgentTeam(AgentTeam):\n    \u0026quot;\u0026quot;\u0026quot;增强容错能力的 Agent 团队\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor: SupervisorAgent):\n        super().__init__(supervisor)\n        self.fallback_workers: dict[str, list[str]] = {}  # Worker 降级链\n\n    def set_fallback(self, worker_name: str, fallbacks: list[str]):\n        \u0026quot;\u0026quot;\u0026quot;设置 Worker 的降级替代链\u0026quot;\u0026quot;\u0026quot;\n        self.fallback_workers[worker_name] = fallbacks\n\n    async def _execute_single(self, task: Task, max_retries: int) -\u0026gt; Task:\n        \u0026quot;\u0026quot;\u0026quot;增强版：支持 Worker 降级\u0026quot;\u0026quot;\u0026quot;\n        # 尝试主 Worker\n        result = await super()._execute_single(task, max_retries)\n        if result.status == \u0026quot;done\u0026quot;:\n            return result\n\n        # 主 Worker 失败，尝试降级 Worker\n        fallbacks = self.fallback_workers.get(task.assigned_to, [])\n        for fb_name in fallbacks:\n            self._log(\u0026quot;team\u0026quot;, f\u0026quot;降级: {task.assigned_to} -\u0026gt; {fb_name}\u0026quot;)\n            task.assigned_to = fb_name\n            task.status = \u0026quot;pending\u0026quot;\n            task.error = \u0026quot;\u0026quot;\n            result = await super()._execute_single(task, max_retries=1)\n            if result.status == \u0026quot;done\u0026quot;:\n                return result\n\n        return result\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.2 Supervisor 失败\u003c/h3\u003e\n\u003cp\u003eSupervisor 失败更严重——它是中央协调者，失败意味着整个任务无法继续。处理策略：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e外部监控\u003c/strong\u003e：在 AgentTeam 之上设置一个非 LLM 的监控层，检测 Supervisor 的健康状态\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSupervisor 冗余\u003c/strong\u003e：准备一个备用 Supervisor（可以用不同的模型），主 Supervisor 失败时切换\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCheckpoint 机制\u003c/strong\u003e：Supervisor 在每个决策点保存状态快照，失败后从最近的 Checkpoint 恢复\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003easync def run_with_checkpoint(self, task: str) -\u0026gt; TeamResult:\n    \u0026quot;\u0026quot;\u0026quot;带 Checkpoint 的执行流程\u0026quot;\u0026quot;\u0026quot;\n    checkpoint = {\u0026quot;phase\u0026quot;: \u0026quot;init\u0026quot;, \u0026quot;subtasks\u0026quot;: [], \u0026quot;completed\u0026quot;: []}\n\n    try:\n        # Phase 1: 分解\n        checkpoint[\u0026quot;phase\u0026quot;] = \u0026quot;decompose\u0026quot;\n        subtasks = await self.supervisor.decompose(task, self.workers)\n        checkpoint[\u0026quot;subtasks\u0026quot;] = subtasks\n\n        # Phase 2: 执行\n        checkpoint[\u0026quot;phase\u0026quot;] = \u0026quot;execute\u0026quot;\n        completed = await self._execute_tasks(subtasks, max_retries=2)\n        checkpoint[\u0026quot;completed\u0026quot;] = completed\n\n        # Phase 3: 合成\n        checkpoint[\u0026quot;phase\u0026quot;] = \u0026quot;synthesize\u0026quot;\n        output = await self.supervisor.synthesize(task, completed)\n\n        return TeamResult(success=True, output=output, tasks=completed)\n\n    except Exception as e:\n        self._log(\u0026quot;team\u0026quot;, f\u0026quot;失败于阶段 {checkpoint[\u0026#39;phase\u0026#39;]}: {e}\u0026quot;)\n        # 可以从 checkpoint 恢复，跳过已完成的阶段\n        return TeamResult(\n            success=False,\n            output=f\u0026quot;任务在 {checkpoint[\u0026#39;phase\u0026#39;]} 阶段失败: {e}\u0026quot;,\n            tasks=checkpoint.get(\u0026quot;completed\u0026quot;, []),\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.3 死锁检测\u003c/h3\u003e\n\u003cp\u003e在 Peer-to-Peer 模式中，两个 Agent 可能互相等待对方的回复，形成死锁。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e死锁场景：\n\n  Agent A: \u0026quot;请 Agent B 先确认方案\u0026quot;\n           ↓ 等待 B\n  Agent B: \u0026quot;请 Agent A 先提供数据\u0026quot;\n           ↓ 等待 A\n  → 无限等待\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e解决方案：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass DeadlockDetector:\n    \u0026quot;\u0026quot;\u0026quot;简单的死锁检测器\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, timeout_seconds: float = 60):\n        self.timeout = timeout_seconds\n        self._waiting: dict[str, str] = {}  # agent_id -\u0026gt; waiting_for_agent_id\n\n    def register_wait(self, agent_id: str, waiting_for: str):\n        self._waiting[agent_id] = waiting_for\n        # 检测环形等待\n        if self._has_cycle(agent_id):\n            raise DeadlockError(\n                f\u0026quot;检测到死锁: {self._trace_cycle(agent_id)}\u0026quot;\n            )\n\n    def _has_cycle(self, start: str) -\u0026gt; bool:\n        visited = set()\n        current = start\n        while current in self._waiting:\n            if current in visited:\n                return True\n            visited.add(current)\n            current = self._waiting[current]\n        return False\n\n    def _trace_cycle(self, start: str) -\u0026gt; str:\n        chain = [start]\n        current = self._waiting.get(start, \u0026quot;\u0026quot;)\n        while current != start and current:\n            chain.append(current)\n            current = self._waiting.get(current, \u0026quot;\u0026quot;)\n        chain.append(start)\n        return \u0026quot; -\u0026gt; \u0026quot;.join(chain)\n\n\nclass DeadlockError(Exception):\n    pass\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Multi-Agent 的成本问题\u003c/h2\u003e\n\u003cp\u003e成本是 Multi-Agent 系统必须正视的问题。它不只是\u0026quot;贵一点\u0026quot;的问题——可能是\u0026quot;贵一个数量级\u0026quot;的问题。\u003c/p\u003e\n\u003ch3\u003e7.1 成本模型\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eSingle-Agent 执行一个任务的 Token 消耗：\n\n  1 x System Prompt   +  N x (Context + Response)\n  ~1,000 tokens          ~3,000 tokens x 5 iterations\n                         = ~16,000 tokens\n\n\nMulti-Agent (Supervisor + 3 Workers) 的 Token 消耗：\n\n  Supervisor 分解:   ~4,000 tokens   (System Prompt + 任务分解)\n  Worker A 执行:     ~8,000 tokens   (System Prompt + 执行)\n  Worker B 执行:     ~8,000 tokens   (System Prompt + 执行)\n  Worker C 执行:     ~8,000 tokens   (System Prompt + 执行)\n  Supervisor 合成:   ~6,000 tokens   (收集所有结果 + 合成)\n                     ──────────────\n  Total:             ~34,000 tokens   ← 约 2x Single-Agent\n\n  如果 Worker 内部也有多轮迭代，消耗会更高。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.2 什么时候 Multi-Agent 的收益大于成本\u003c/h3\u003e\n\u003cp\u003e不是所有场景都值得用 Multi-Agent。一个简单的决策框架：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                        任务复杂度\n                    低 ─────────── 高\n                    │               │\n  专业化需求  低    │  Single-Agent │  Single-Agent\n              │    │  (够用)       │  + Better Prompt\n              │    │               │\n              高    │  Single-Agent │  Multi-Agent ✓\n                    │  + Tools      │  (值得投入)\n                    │               │\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMulti-Agent 在以下条件下收益最大：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e任务天然可并行\u003c/strong\u003e：子任务之间独立性高，Multi-Agent 通过并行执行缩短总耗时，即使 token 消耗增加，时间成本下降\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e专业化收益显著\u003c/strong\u003e：专家 Agent 在自己的领域比通用 Agent 的输出质量显著更高，质量提升值得额外成本\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSingle-Agent 已经到达能力瓶颈\u003c/strong\u003e：Context Window 不够、单个 prompt 角色冲突、输出质量不稳定\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e任务的商业价值足够高\u003c/strong\u003e：生成一份价值数万元的分析报告，多花几美元的 API 费用是可以接受的\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e7.3 成本优化策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass CostAwareTeam(AgentTeam):\n    \u0026quot;\u0026quot;\u0026quot;成本感知的 Agent 团队\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor, token_budget: int = 100_000):\n        super().__init__(supervisor)\n        self.token_budget = token_budget\n        self.token_used = 0\n\n    def _select_model_for_task(self, task: Task) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;根据任务复杂度选择模型——不是所有子任务都需要最强模型\u0026quot;\u0026quot;\u0026quot;\n        if task.context.get(\u0026quot;complexity\u0026quot;) == \u0026quot;low\u0026quot;:\n            return \u0026quot;gpt-4o-mini\u0026quot;     # 简单任务用小模型\n        elif task.context.get(\u0026quot;complexity\u0026quot;) == \u0026quot;high\u0026quot;:\n            return \u0026quot;gpt-4o\u0026quot;          # 复杂任务用大模型\n        else:\n            return \u0026quot;gpt-4o-mini\u0026quot;     # 默认用小模型，够用即可\n\n    def _should_continue(self) -\u0026gt; bool:\n        \u0026quot;\u0026quot;\u0026quot;预算检查\u0026quot;\u0026quot;\u0026quot;\n        if self.token_used \u0026gt;= self.token_budget:\n            self._log(\u0026quot;team\u0026quot;, f\u0026quot;Token 预算耗尽 ({self.token_used}/{self.token_budget})\u0026quot;)\n            return False\n        return True\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e关键原则：\u003cstrong\u003eRouter 和 Supervisor 可以用轻量模型，只有需要深度推理的 Worker 才用重量级模型。\u003c/strong\u003e 这类似人类组织中，项目经理不需要是技术最强的人，但专家必须在各自领域足够专业。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e8. Multi-Agent 的调试挑战\u003c/h2\u003e\n\u003cp\u003eMulti-Agent 系统的调试难度是 Single-Agent 的平方级增长——不仅每个 Agent 内部可能出错，Agent 之间的交互也可能出错。\u003c/p\u003e\n\u003ch3\u003e8.1 执行链路追踪\u003c/h3\u003e\n\u003cp\u003e每次 Multi-Agent 执行都应该生成一个完整的 Trace，记录每个 Agent 的每次 LLM 调用、输入、输出和耗时。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport time\nimport uuid\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass Span:\n    \u0026quot;\u0026quot;\u0026quot;一个执行跨度（对应一次 Agent 操作）\u0026quot;\u0026quot;\u0026quot;\n    span_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])\n    parent_id: str = \u0026quot;\u0026quot;\n    agent_name: str = \u0026quot;\u0026quot;\n    operation: str = \u0026quot;\u0026quot;          # \u0026quot;decompose\u0026quot;, \u0026quot;execute\u0026quot;, \u0026quot;synthesize\u0026quot;\n    input_summary: str = \u0026quot;\u0026quot;\n    output_summary: str = \u0026quot;\u0026quot;\n    start_time: float = 0.0\n    end_time: float = 0.0\n    token_count: int = 0\n    status: str = \u0026quot;running\u0026quot;      # running | done | failed\n    children: list = field(default_factory=list)\n\n    @property\n    def duration_ms(self) -\u0026gt; float:\n        return (self.end_time - self.start_time) * 1000\n\n\nclass Tracer:\n    \u0026quot;\u0026quot;\u0026quot;Multi-Agent 执行链路追踪器\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self):\n        self.root_span: Span | None = None\n        self._span_stack: list[Span] = []\n\n    def start_span(self, agent_name: str, operation: str, input_summary: str = \u0026quot;\u0026quot;) -\u0026gt; Span:\n        span = Span(\n            agent_name=agent_name,\n            operation=operation,\n            input_summary=input_summary[:200],\n            start_time=time.time(),\n        )\n        if self._span_stack:\n            parent = self._span_stack[-1]\n            span.parent_id = parent.span_id\n            parent.children.append(span)\n        else:\n            self.root_span = span\n\n        self._span_stack.append(span)\n        return span\n\n    def end_span(self, output_summary: str = \u0026quot;\u0026quot;, status: str = \u0026quot;done\u0026quot;):\n        if self._span_stack:\n            span = self._span_stack.pop()\n            span.end_time = time.time()\n            span.output_summary = output_summary[:200]\n            span.status = status\n\n    def print_trace(self, span: Span = None, indent: int = 0):\n        \u0026quot;\u0026quot;\u0026quot;打印可视化的执行链路\u0026quot;\u0026quot;\u0026quot;\n        span = span or self.root_span\n        if not span:\n            return\n\n        prefix = \u0026quot;  \u0026quot; * indent\n        status_icon = \u0026quot;OK\u0026quot; if span.status == \u0026quot;done\u0026quot; else \u0026quot;FAIL\u0026quot;\n        print(\n            f\u0026quot;{prefix}[{status_icon}] {span.agent_name}.{span.operation} \u0026quot;\n            f\u0026quot;({span.duration_ms:.0f}ms)\u0026quot;\n        )\n        if span.input_summary:\n            print(f\u0026quot;{prefix}  IN:  {span.input_summary[:80]}\u0026quot;)\n        if span.output_summary:\n            print(f\u0026quot;{prefix}  OUT: {span.output_summary[:80]}\u0026quot;)\n\n        for child in span.children:\n            self.print_trace(child, indent + 1)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e输出示例：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e[OK] supervisor.decompose (2340ms)\n  IN:  撰写一篇关于 LLM Agent 在企业客服场景落地的技术调研报告...\n  OUT: {\u0026quot;subtasks\u0026quot;: [{\u0026quot;task_id\u0026quot;: \u0026quot;task_1\u0026quot;, ...}, ...]}\n  [OK] searcher.execute (5120ms)\n    IN:  搜索 LLM Agent 客服场景的行业现状和主流方案...\n    OUT: ## 行业现状\\n1. 2024 年全球智能客服市场规模...\n  [OK] analyst.execute (4800ms)\n    IN:  分析搜索结果，提炼关键洞察和趋势...\n    OUT: ## 分析结论\\n1. 技术成熟度：LLM 客服处于...\n  [OK] writer.execute (6200ms)\n    IN:  根据分析结果撰写完整的技术调研报告...\n    OUT: # LLM Agent 企业客服落地技术调研报告\\n\\n## 1. 执行摘要...\n[OK] supervisor.synthesize (3100ms)\n  IN:  请合成最终结果。\n  OUT: # LLM Agent 企业客服落地技术调研报告（终稿）...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.2 Bug 复现\u003c/h3\u003e\n\u003cp\u003eMulti-Agent 场景的 bug 复现特别困难，因为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLM 输出是非确定性的——相同输入可能产生不同输出\u003c/li\u003e\n\u003cli\u003eAgent 之间的交互是动态的——执行路径取决于中间结果\u003c/li\u003e\n\u003cli\u003e并发执行的时序不确定——Worker A 和 B 谁先完成可能影响最终结果\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e应对策略：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e记录完整的 LLM 输入/输出\u003c/strong\u003e：在 Trace 中保存每次 LLM 调用的完整 messages 和 response，不只是摘要\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDeterministic Replay\u003c/strong\u003e：用固定的 seed 和 temperature=0 复现执行，或者直接 mock LLM 响应\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e快照式调试\u003c/strong\u003e：在每个 Agent 决策点保存完整的 Blackboard 状态快照，出问题时可以回溯到任意时间点\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass ReplayableTeam(AgentTeam):\n    \u0026quot;\u0026quot;\u0026quot;可回放的 Agent 团队——记录完整的 LLM 交互供复现\u0026quot;\u0026quot;\u0026quot;\n\n    def __init__(self, supervisor):\n        super().__init__(supervisor)\n        self._llm_recordings: list[dict] = []\n\n    def record_llm_call(self, agent_name: str, messages: list[dict], response: str):\n        self._llm_recordings.append({\n            \u0026quot;agent\u0026quot;: agent_name,\n            \u0026quot;messages\u0026quot;: messages,\n            \u0026quot;response\u0026quot;: response,\n            \u0026quot;timestamp\u0026quot;: time.time(),\n        })\n\n    def save_recording(self, path: str):\n        \u0026quot;\u0026quot;\u0026quot;保存录制数据，用于后续回放和调试\u0026quot;\u0026quot;\u0026quot;\n        with open(path, \u0026quot;w\u0026quot;) as f:\n            json.dump(self._llm_recordings, f, ensure_ascii=False, indent=2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.3 可观测性设计\u003c/h3\u003e\n\u003cp\u003e一个生产级 Multi-Agent 系统至少需要以下可观测性指标：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e指标类别\u003c/th\u003e\n\u003cth\u003e具体指标\u003c/th\u003e\n\u003cth\u003e目的\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e延迟\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个 Agent 的执行时间、端到端总时间\u003c/td\u003e\n\u003ctd\u003e定位性能瓶颈\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e成本\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e每个 Agent 的 Token 消耗、总消耗\u003c/td\u003e\n\u003ctd\u003e成本监控和预算控制\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e质量\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e任务成功率、重试次数、降级次数\u003c/td\u003e\n\u003ctd\u003e评估系统可靠性\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e链路\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e完整的 Trace（Agent、操作、输入、输出）\u003c/td\u003e\n\u003ctd\u003e问题排查\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e状态\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eBlackboard 的状态变更历史\u003c/td\u003e\n\u003ctd\u003e数据流追踪\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e通信\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eAgent 间消息数量、消息大小\u003c/td\u003e\n\u003ctd\u003e通信效率分析\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 设计 Multi-Agent 系统的决策清单\u003c/h2\u003e\n\u003cp\u003e在你决定构建 Multi-Agent 系统之前，逐一回答以下问题：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e必要性验证\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e单个 Agent 真的不够吗？是否尝试过优化 prompt、增加工具、使用更强的模型？\u003c/li\u003e\n\u003cli\u003e任务是否天然需要多角色/多视角？还是只是因为你觉得\u0026quot;多 Agent 更酷\u0026quot;？\u003c/li\u003e\n\u003cli\u003e团队的 LLM API 预算能否支撑多 Agent 的额外消耗？\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e架构选择\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e任务结构更接近哪种模式？Supervisor-Worker / Peer-to-Peer / Pipeline / Dynamic Routing？\u003c/li\u003e\n\u003cli\u003eAgent 之间需要什么样的通信？单向传递 / 双向协商 / 广播通知？\u003c/li\u003e\n\u003cli\u003e状态应该共享还是独立？冲突解决策略是什么？\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e工程保障\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e每个 Agent 的失败影响范围是什么？有降级方案吗？\u003c/li\u003e\n\u003cli\u003e如何追踪一个请求在多个 Agent 之间的完整执行链路？\u003c/li\u003e\n\u003cli\u003e如何测试多 Agent 协作的正确性——单元测试（单个 Agent）+ 集成测试（Agent 交互）？\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 结语与展望\u003c/h2\u003e\n\u003cp\u003e本文是 Phase 3（How to Scale Agent Intelligence）的最后一篇。在 Phase 3 的四篇文章中，我们从单个 Agent 的四个维度进行了升级：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ePhase 3 知识路线：\n\n  第 08 篇 Memory       → Agent 有了\u0026quot;记忆\u0026quot;\n  第 09 篇 RAG          → Agent 有了\u0026quot;外部知识\u0026quot;\n  第 10 篇 Planning     → Agent 有了\u0026quot;规划和反思\u0026quot;\n  第 11 篇 Multi-Agent  → Agent 有了\u0026quot;团队协作\u0026quot;（本文）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e至此，我们已经拥有构建一个\u0026quot;聪明的\u0026quot; Agent 系统所需的全部核心概念。但\u0026quot;聪明\u0026quot;不等于\u0026quot;可用\u0026quot;。一个在本地跑通 demo 的 Multi-Agent 系统，距离生产环境还有巨大的鸿沟——框架选型、协议标准化、可观测性、安全性、成本控制、评估体系。\u003c/p\u003e\n\u003cp\u003e这正是 Phase 4（How to Ship Agents to Production）要解决的问题：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e下一篇（12）\u003c/strong\u003e：LangChain vs LangGraph —— 你应该用框架还是自己写？框架的价值边界在哪里？我们会从 Chain 和 Graph 两种抽象出发，讨论框架在什么时候是加速器，什么时候是束缚。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 13 篇\u003c/strong\u003e：MCP and Tool Protocol —— Agent 的工具需要标准化。MCP 协议如何让不同 Agent 共享工具？工具的发现、声明、权限控制。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e第 14 篇\u003c/strong\u003e：Production-Grade Agent Systems —— 最后一篇，打通最后一公里：评估、安全、成本、灰度、监控。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e进一步思考\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e关于协作模式的演化\u003c/strong\u003e：本文介绍的四种模式是\u0026quot;纯模式\u0026quot;。真实系统中，你很可能需要混合模式——比如 Supervisor-Worker 的 Worker 内部用 Pipeline，或者 Dynamic Routing 的专家 Agent 内部用 Peer-to-Peer 辩论。如何设计这种嵌套的多层协作结构，是一个值得深入探索的方向。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于 Agent 的涌现行为\u003c/strong\u003e：当多个 Agent 协作时，是否会出现超越单个 Agent 能力的\u0026quot;涌现行为\u0026quot;？还是说 Multi-Agent 的上限永远被最强的那个 Agent 决定？这个问题在学术界尚无定论，但从实践角度看，好的协作架构确实能产出超越任何单个 Agent 的结果——正如一个好的工程团队能完成任何个人都无法独自完成的项目。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于 Human-in-the-Loop\u003c/strong\u003e：本文讨论的全是 Agent-to-Agent 的协作。但在生产环境中，最重要的\u0026quot;Agent\u0026quot;可能是人类。如何设计一个 Multi-Agent 系统，让人类能在关键节点介入、审核和纠正？Human-Agent 协作可能比 Agent-Agent 协作更有实用价值，也更有挑战性。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 11 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/10-Planning%20and%20Reflection\"\u003e10 | Planning and Reflection\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/12-LangChain%20vs%20LangGraph\"\u003e12 | LangChain vs LangGraph\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"17:T9ed3,"])</script><script>self.__next_f.push([1,"\u003ch1\u003ePlanning and Reflection: 从 ReAct 到分层规划与自我纠错\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLLM 的 next-token prediction 天生是\u0026quot;短视\u0026quot;的——它只看到当前 token 的概率分布，不会思考十步之后的结局。规划（Planning）让 Agent 具备\u0026quot;远视\u0026quot;能力，反思（Reflection）让 Agent 具备\u0026quot;纠错\u0026quot;能力。二者结合，是 Agent 从\u0026quot;工具调用器\u0026quot;进化为\u0026quot;问题解决者\u0026quot;的关键。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列的第 10 篇。我们将从规划范式的演进出发，深入分析 ReAct、Plan-and-Execute、Tree-of-Thought、Hierarchical Planning 四种规划模式，再系统探讨 Reflection 机制的设计与陷阱。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 为什么 Agent 需要规划和反思\u003c/h2\u003e\n\u003cp\u003eLLM 的核心训练目标是 next-token prediction：给定前文，预测最可能的下一个 token。这种机制天然缺乏两种能力：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e前瞻（Lookahead）\u003c/strong\u003e：生成第一步时不会考虑\u0026quot;这个决定在第五步会导致什么后果\u0026quot;——每一步都选局部最优，但局部最优的叠加不等于全局最优。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e回溯（Backtrack）\u003c/strong\u003e：一旦生成了一段文本就不会主动回头修正，即使中间步骤出了错，后续 token 也会基于错误的前提继续生成。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e规划（Planning）\u003c/strong\u003e 弥补前瞻缺陷——在执行前把大目标拆成子目标，考虑步骤间的依赖和顺序。\u003cstrong\u003e反思（Reflection）\u003c/strong\u003e 弥补回溯缺陷——在执行后检查结果、分析错误、决定重试或调整。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e没有规划的 Agent：走一步看一步（Greedy, Reactive）\n有规划的 Agent：先想好路线再出发（Deliberate, Proactive）\n有反思的 Agent：走错了能发现、能纠正（Self-correcting）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e二者结合，Agent 才能从\u0026quot;工具调用器\u0026quot;进化为\u0026quot;问题解决者\u0026quot;。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 规划范式的演进\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e   2022              2023 early         2023 mid            2023+ now\n    │                    │                  │                    │\n    ▼                    ▼                  ▼                    ▼\n┌────────┐      ┌──────────────┐    ┌──────────────┐   ┌────────────────┐\n│No Plan │─────▶│    ReAct     │───▶│Plan-and-Exec │──▶│ Hierarchical   │\n│直接回答 │      │Thought-Act-  │    │先规划再执行   │   │  Planning      │\n└────────┘      │Observation   │    └──────────────┘   │ 多层级分解     │\n                └──────┬───────┘                       └────────────────┘\n                       │           ┌──────────────┐           ▲\n                       └──────────▶│Tree-of-Thought│──────────┘\n                                   │多路径搜索     │\n                                   └──────────────┘\n\n能力维度：单步回答 ──▶ 逐步推理 ──▶ 全局规划 ──▶ 多路径探索 ──▶ 递归分解\n\u003c/code\u003e\u003c/pre\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e范式\u003c/th\u003e\n\u003cth\u003e核心思想\u003c/th\u003e\n\u003cth\u003e解决了什么\u003c/th\u003e\n\u003cth\u003e新的问题\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003eNo Planning\u003c/td\u003e\n\u003ctd\u003eLLM 直接回答\u003c/td\u003e\n\u003ctd\u003e—\u003c/td\u003e\n\u003ctd\u003e无法处理多步任务\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eReAct\u003c/td\u003e\n\u003ctd\u003e交替 Thought-Action-Observation\u003c/td\u003e\n\u003ctd\u003e多步推理+行动\u003c/td\u003e\n\u003ctd\u003eGreedy，缺乏全局视野\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePlan-and-Execute\u003c/td\u003e\n\u003ctd\u003e先规划再逐步执行\u003c/td\u003e\n\u003ctd\u003e全局视野，可追踪\u003c/td\u003e\n\u003ctd\u003e计划可能过时，修正成本高\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eTree-of-Thought\u003c/td\u003e\n\u003ctd\u003e多条路径搜索选优\u003c/td\u003e\n\u003ctd\u003e探索多种可能性\u003c/td\u003e\n\u003ctd\u003e成本倍增\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHierarchical\u003c/td\u003e\n\u003ctd\u003e多层级递归分解\u003c/td\u003e\n\u003ctd\u003e处理真正复杂的任务\u003c/td\u003e\n\u003ctd\u003e架构复杂，调试困难\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003chr\u003e\n\u003ch2\u003e3. ReAct 深入分析\u003c/h2\u003e\n\u003ch3\u003e3.1 原理：Reason + Act 交替进行\u003c/h3\u003e\n\u003cp\u003eReAct（Yao et al., 2022）让 LLM 在推理（Thought）和行动（Action）之间交替，每次行动后观察结果（Observation），再基于观察继续推理。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eUser Question\n     │\n     ▼\n┌──────────┐     ┌──────────┐     ┌──────────────┐\n│ Thought  │────▶│  Action  │────▶│ Observation  │\n│ (推理)   │     │ (行动)   │     │ (观察结果)    │\n└──────────┘     └──────────┘     └──────┬───────┘\n     ▲                                    │\n     └────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.2 ReAct Prompt 模板\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eREACT_SYSTEM_PROMPT = \u0026quot;\u0026quot;\u0026quot;You operate in a loop of Thought, Action, Observation.\n\n- Thought: Analyze the situation and decide the next step.\n- Action: Call a tool. Format: Action: tool_name({\u0026quot;param\u0026quot;: \u0026quot;value\u0026quot;})\n- Observation: Review the tool\u0026#39;s result.\n\nWhen ready, respond: Final Answer: \u0026lt;your answer\u0026gt;\n\nAvailable tools:\n{tool_descriptions}\n\nRules:\n1. Always think before acting.\n2. If a tool fails, analyze why and try differently.\n3. Do not fabricate information — use only tool results.\n\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.3 优点与缺点\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e优点\u003c/strong\u003e：灵活自适应（每步可根据 Observation 调整）、实现简单（while 循环 + prompt）、可解释性强（Thought 暴露推理过程）、容错好（失败后下一步可换策略）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e缺点\u003c/strong\u003e：Greedy / 短视（不考虑长期后果）、效率低（每步完整 LLM 调用）、上下文膨胀（步骤越多 token 越多）、容易循环（重复同一失败策略）。\u003c/p\u003e\n\u003ch3\u003e3.4 Python 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nfrom dataclasses import dataclass\nfrom typing import Callable\nimport openai\n\n@dataclass\nclass Tool:\n    name: str\n    description: str\n    parameters: dict\n    function: Callable\n\nclass ReActAgent:\n    def __init__(self, model: str = \u0026quot;gpt-4o\u0026quot;, tools: list[Tool] | None = None,\n                 max_iterations: int = 10):\n        self.model = model\n        self.tools = {t.name: t for t in (tools or [])}\n        self.max_iterations = max_iterations\n        self.client = openai.OpenAI()\n\n    def _build_system_prompt(self) -\u0026gt; str:\n        tool_desc = \u0026quot;\\n\u0026quot;.join(\n            f\u0026quot;- {t.name}: {t.description}\u0026quot; for t in self.tools.values()\n        )\n        return REACT_SYSTEM_PROMPT.format(tool_descriptions=tool_desc)\n\n    def _parse_action(self, text: str) -\u0026gt; tuple[str, dict] | None:\n        for line in text.split(\u0026quot;\\n\u0026quot;):\n            if line.strip().startswith(\u0026quot;Action:\u0026quot;):\n                action_str = line.strip()[len(\u0026quot;Action:\u0026quot;):].strip()\n                paren = action_str.find(\u0026quot;(\u0026quot;)\n                if paren == -1:\n                    return None\n                name = action_str[:paren].strip()\n                params_str = action_str[paren + 1:].rstrip(\u0026quot;)\u0026quot;)\n                params = json.loads(params_str) if params_str else {}\n                return name, params\n        return None\n\n    def _execute_tool(self, name: str, params: dict) -\u0026gt; str:\n        if name not in self.tools:\n            return f\u0026quot;Error: Unknown tool \u0026#39;{name}\u0026#39;\u0026quot;\n        try:\n            return str(self.tools[name].function(**params))\n        except Exception as e:\n            return f\u0026quot;Error: {e}\u0026quot;\n\n    def run(self, query: str) -\u0026gt; str:\n        messages = [\n            {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: self._build_system_prompt()},\n            {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: query},\n        ]\n        for _ in range(self.max_iterations):\n            resp = self.client.chat.completions.create(\n                model=self.model, messages=messages, temperature=0.0,\n            )\n            text = resp.choices[0].message.content\n            messages.append({\u0026quot;role\u0026quot;: \u0026quot;assistant\u0026quot;, \u0026quot;content\u0026quot;: text})\n\n            if \u0026quot;Final Answer:\u0026quot; in text:\n                return text.split(\u0026quot;Final Answer:\u0026quot;)[-1].strip()\n\n            action = self._parse_action(text)\n            if action is None:\n                messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\n                                 \u0026quot;content\u0026quot;: \u0026quot;Provide a valid Action or Final Answer.\u0026quot;})\n                continue\n\n            observation = self._execute_tool(*action)\n            messages.append({\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;Observation: {observation}\u0026quot;})\n\n        return \u0026quot;Reached max iterations without final answer.\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意：随着迭代增加 \u003ccode\u003emessages\u003c/code\u003e 不断膨胀，token 消耗呈线性增长。超过 5-6 步的任务需要考虑上下文压缩（如摘要历史步骤）。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. Plan-and-Execute 模式\u003c/h2\u003e\n\u003ch3\u003e4.1 原理：先规划再执行\u003c/h3\u003e\n\u003cp\u003ePlan-and-Execute 将规划与执行分离：先用一次 LLM 调用生成完整计划，再逐个执行子任务，必要时触发 Replanning。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌────────────┐       Plan: [S1, S2, S3]      ┌────────────┐\n│  Planner   │──────────────────────────────▶│  Executor  │\n│ (全局规划)  │                                │ (逐步执行)  │\n└────────────┘                                └─────┬──────┘\n      ▲                                             │ 执行失败\n      │            ┌─────────────┐                  │\n      └────────────│  Replanner  │◀─────────────────┘\n                   │ (动态修正)   │\n                   └─────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.2 Planner / Executor 分离的优势\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e关注点分离\u003c/strong\u003e：Planner 负责\u0026quot;做什么\u0026quot;，Executor 负责\u0026quot;怎么做\u0026quot;，可以分别用不同模型优化\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可并行\u003c/strong\u003e：无依赖的步骤可以并行执行\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可追踪\u003c/strong\u003e：计划本身是结构化数据，便于监控和审计\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e可中断恢复\u003c/strong\u003e：执行到一半中断后可从某一步重启\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e4.3 计划的动态修正\u003c/h3\u003e\n\u003cp\u003e三种 Replan 策略：\u003cstrong\u003e完全重新规划\u003c/strong\u003e（全局优化但可能丢弃已有成果）、\u003cstrong\u003e局部修正\u003c/strong\u003e（成本低但可能保留错误前提）、\u003cstrong\u003e条件触发\u003c/strong\u003e（仅在步骤失败或偏差超阈值时 Replan）。生产中通常用条件触发 + 局部修正的组合。\u003c/p\u003e\n\u003ch3\u003e4.4 Python 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom dataclasses import dataclass, field\n\n@dataclass\nclass PlanStep:\n    id: int\n    description: str\n    tool: str | None = None\n    depends_on: list[int] = field(default_factory=list)\n    status: str = \u0026quot;pending\u0026quot;   # pending / completed / failed\n    result: str | None = None\n\nPLANNER_PROMPT = \u0026quot;\u0026quot;\u0026quot;Decompose the goal into concrete steps (max 7).\nAvailable tools: {tool_names}\nOutput JSON: {{\u0026quot;goal\u0026quot;: \u0026quot;...\u0026quot;, \u0026quot;steps\u0026quot;: [{{\u0026quot;id\u0026quot;: 1, \u0026quot;description\u0026quot;: \u0026quot;...\u0026quot;,\n\u0026quot;tool\u0026quot;: \u0026quot;tool_name or null\u0026quot;, \u0026quot;depends_on\u0026quot;: []}}]}}\u0026quot;\u0026quot;\u0026quot;\n\nclass PlanAndExecuteAgent:\n    def __init__(self, tools: dict[str, Tool],\n                 planner_model: str = \u0026quot;gpt-4o\u0026quot;,\n                 executor_model: str = \u0026quot;gpt-4o-mini\u0026quot;,\n                 max_replans: int = 3):\n        self.tools = tools\n        self.planner_model = planner_model\n        self.executor_model = executor_model\n        self.max_replans = max_replans\n        self.client = openai.OpenAI()\n\n    def _create_plan(self, goal: str) -\u0026gt; list[PlanStep]:\n        resp = self.client.chat.completions.create(\n            model=self.planner_model,\n            messages=[\n                {\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;: PLANNER_PROMPT.format(\n                    tool_names=\u0026quot;, \u0026quot;.join(self.tools.keys()))},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: goal},\n            ],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return [PlanStep(**s) for s in data[\u0026quot;steps\u0026quot;]]\n\n    def _execute_step(self, step: PlanStep, context: dict) -\u0026gt; str:\n        if step.tool and step.tool in self.tools:\n            param_resp = self.client.chat.completions.create(\n                model=self.executor_model,\n                messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                    f\u0026quot;Call tool \u0026#39;{step.tool}\u0026#39; for: {step.description}\\n\u0026quot;\n                    f\u0026quot;Context: {json.dumps(context)}\\nReturn JSON params only.\u0026quot;}],\n                response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n            )\n            params = json.loads(param_resp.choices[0].message.content)\n            return str(self.tools[step.tool].function(**params))\n        resp = self.client.chat.completions.create(\n            model=self.executor_model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\n                       \u0026quot;content\u0026quot;: f\u0026quot;Task: {step.description}\\nContext: {json.dumps(context)}\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\n    def run(self, goal: str) -\u0026gt; str:\n        steps = self._create_plan(goal)\n        context = {}\n        for replan in range(self.max_replans + 1):\n            for step in steps:\n                if step.status == \u0026quot;completed\u0026quot;:\n                    continue\n                deps_met = all(\n                    any(s.id == d and s.status == \u0026quot;completed\u0026quot; for s in steps)\n                    for d in step.depends_on\n                )\n                if not deps_met:\n                    continue\n                try:\n                    step.result = self._execute_step(step, context)\n                    step.status = \u0026quot;completed\u0026quot;\n                    context[f\u0026quot;step_{step.id}\u0026quot;] = step.result\n                except Exception as e:\n                    step.status = \u0026quot;failed\u0026quot;\n                    step.result = str(e)\n                    steps = self._replan(goal, steps, step)\n                    break\n            if all(s.status == \u0026quot;completed\u0026quot; for s in steps):\n                return self._synthesize(goal, context)\n        return \u0026quot;Exceeded max replans.\u0026quot;\n\n    def _replan(self, goal, steps, failed) -\u0026gt; list[PlanStep]:\n        # 将已完成步骤 + 失败信息交给 Planner 重新规划\n        completed = [{\u0026quot;id\u0026quot;: s.id, \u0026quot;result\u0026quot;: s.result}\n                     for s in steps if s.status == \u0026quot;completed\u0026quot;]\n        resp = self.client.chat.completions.create(\n            model=self.planner_model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Replan. Goal: {goal}\\nCompleted: {json.dumps(completed)}\\n\u0026quot;\n                f\u0026quot;Failed step: {failed.description} -\u0026gt; {failed.result}\u0026quot;}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return [PlanStep(**s) for s in data[\u0026quot;steps\u0026quot;]]\n\n    def _synthesize(self, goal, context):\n        resp = self.client.chat.completions.create(\n            model=self.planner_model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\n                       \u0026quot;content\u0026quot;: f\u0026quot;Goal: {goal}\\nResults: {json.dumps(context)}\\n\u0026quot;\n                       \u0026quot;Synthesize a final answer.\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePlanner 用 \u003ccode\u003egpt-4o\u003c/code\u003e（强规划），Executor 用 \u003ccode\u003egpt-4o-mini\u003c/code\u003e（快执行）——这是生产中常见的成本优化手段。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. Tree-of-Thought\u003c/h2\u003e\n\u003ch3\u003e5.1 原理\u003c/h3\u003e\n\u003cp\u003eTree-of-Thought（ToT，Yao et al. 2023）模拟人类\u0026quot;深思熟虑\u0026quot;：同时考虑多条推理路径，评估每条的前景，选择最优的继续深入。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                       Root (问题)\n                      /     |     \\\n                   Th1     Th2    Th3      ← 生成多个候选 Thought\n                  /   \\     |    /   \\\n               T1a   T1b  T2a  T3a  T3b   ← 继续展开\n                ✗      ✓    ✗    ✓    ✗    ← 评估函数打分，剪枝\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e三个核心组件：\u003cstrong\u003eThought Generator\u003c/strong\u003e（每步生成 k 个候选）、\u003cstrong\u003eState Evaluator\u003c/strong\u003e（对候选打分）、\u003cstrong\u003eSearch Algorithm\u003c/strong\u003e（BFS 或 DFS）。\u003c/p\u003e\n\u003ch3\u003e5.2 BFS vs DFS\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBFS\u003c/strong\u003e：每层展开 k 个，评估后保留 top-k 进入下一层。适合步骤少、每步选择多的问题。总调用 ≈ k x depth x 2（生成+评估）。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDFS\u003c/strong\u003e：选当前最优一路深入，死胡同时回溯。适合步骤多、每步选择少的问题。最好 O(depth)，最坏 O(k^depth)。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e5.3 评估函数设计\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLLM 自评\u003c/strong\u003e：让 LLM 对每个 Thought 打分。简单但可能有系统性偏见。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e投票法\u003c/strong\u003e：多次评估取多数。更稳健但成本更高。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e外部验证\u003c/strong\u003e：可验证的问题（数学/代码）用外部工具检查。最可靠但适用范围有限。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e5.4 Trade-off：质量 vs 成本\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e方法           LLM 调用次数      质量    适用场景\n─────────────  ──────────────   ─────   ──────────\nReAct(单路径)   O(steps)         基准    大多数任务\nToT-BFS        O(k * d * 2)     高      创意/数学/方案选型\nToT-DFS        O(k^d) 最坏      中-高   深度推理\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ek=3, d=3 时 ToT 可能需要 40+ 次 LLM 调用，ReAct 只需 5-6 次——\u003cstrong\u003e8-10 倍成本差距\u003c/strong\u003e。只有当正确性要求高且存在多条有意义的推理路径时，ToT 的投入才有回报。\u003c/p\u003e\n\u003ch3\u003e5.5 Python 实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport json\nfrom dataclasses import dataclass, field\nimport openai\n\n@dataclass\nclass ThoughtNode:\n    \u0026quot;\u0026quot;\u0026quot;搜索树中的节点，每个节点代表一条推理路径的当前状态\u0026quot;\u0026quot;\u0026quot;\n    state: str                           # 当前推理状态（累积的 thought 文本）\n    score: float = 0.0                   # 评估函数打分\n    depth: int = 0\n    children: list[\u0026quot;ThoughtNode\u0026quot;] = field(default_factory=list)\n\nclass TreeOfThought:\n    def __init__(self, model: str = \u0026quot;gpt-4o\u0026quot;, k: int = 3, max_depth: int = 3):\n        \u0026quot;\u0026quot;\u0026quot;\n        k: 每层生成的候选 thought 数量（BFS 宽度）\n        max_depth: 搜索树最大深度\n        \u0026quot;\u0026quot;\u0026quot;\n        self.model = model\n        self.k = k\n        self.max_depth = max_depth\n        self.client = openai.OpenAI()\n\n    def generate_thoughts(self, problem: str, current_state: str) -\u0026gt; list[str]:\n        \u0026quot;\u0026quot;\u0026quot;生成 k 个候选 thought\u0026quot;\u0026quot;\u0026quot;\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Given the problem and current reasoning state, \u0026quot;\n                f\u0026quot;generate exactly {self.k} distinct next-step thoughts.\\n\u0026quot;\n                f\u0026#39;Return JSON: {{\u0026quot;thoughts\u0026quot;: [\u0026quot;thought1\u0026quot;, \u0026quot;thought2\u0026quot;, ...]}}\u0026#39;},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Problem: {problem}\\nCurrent state: {current_state or \u0026#39;(start)\u0026#39;}\u0026quot;}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return data[\u0026quot;thoughts\u0026quot;][:self.k]\n\n    def evaluate_thought(self, problem: str, state: str) -\u0026gt; float:\n        \u0026quot;\u0026quot;\u0026quot;评估当前推理状态的前景，返回 0-1 分数\u0026quot;\u0026quot;\u0026quot;\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                \u0026quot;Evaluate how promising this reasoning state is for solving the problem.\\n\u0026quot;\n                \u0026#39;Return JSON: {\u0026quot;score\u0026quot;: 0.0-1.0, \u0026quot;reason\u0026quot;: \u0026quot;...\u0026quot;}\u0026#39;},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Problem: {problem}\\nReasoning so far: {state}\u0026quot;}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        data = json.loads(resp.choices[0].message.content)\n        return float(data[\u0026quot;score\u0026quot;])\n\n    def solve(self, problem: str) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;BFS 搜索：每层生成 k 个候选，评估后保留 top-k 进入下一层\u0026quot;\u0026quot;\u0026quot;\n        # 初始化：根节点\n        current_level = [ThoughtNode(state=\u0026quot;\u0026quot;, depth=0)]\n\n        for depth in range(self.max_depth):\n            candidates: list[ThoughtNode] = []\n\n            for node in current_level:\n                # 为每个节点生成 k 个候选 thought\n                thoughts = self.generate_thoughts(problem, node.state)\n                for thought in thoughts:\n                    new_state = f\u0026quot;{node.state}\\nStep {depth+1}: {thought}\u0026quot;.strip()\n                    score = self.evaluate_thought(problem, new_state)\n                    child = ThoughtNode(state=new_state, score=score, depth=depth+1)\n                    node.children.append(child)\n                    candidates.append(child)\n\n            # 保留 top-k 进入下一层（BFS 剪枝）\n            candidates.sort(key=lambda n: n.score, reverse=True)\n            current_level = candidates[:self.k]\n\n        # 返回最终得分最高的推理路径\n        best = max(current_level, key=lambda n: n.score)\n        return best.state\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e核心观察：BFS 宽度 \u003ccode\u003ek\u003c/code\u003e 和搜索深度 \u003ccode\u003emax_depth\u003c/code\u003e 共同控制质量-成本的 trade-off。\u003ccode\u003ek\u003c/code\u003e 越大，每层探索的候选越多，找到好路径的概率越高，但 LLM 调用次数以 O(k² × d) 增长（每层 k 个节点各生成 k 个候选 + k 次评估）。实践中 k=2\u003cdel\u003e3、depth=2\u003c/del\u003e3 是较好的起点，可根据任务复杂度动态调整。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 分层规划（Hierarchical Planning）\u003c/h2\u003e\n\u003cp\u003e当任务复杂到\u0026quot;设计并实现用户权限系统\u0026quot;这种级别时，一层计划无法覆盖从架构到实现的所有粒度。分层规划通过\u003cstrong\u003e递归分解\u003c/strong\u003e解决：高层拆子目标，低层拆具体动作。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e高层规划器 (Strategic)\n├─ 子目标1: 设计数据模型\n│   └─ 低层规划器 (Tactical)\n│       ├─ Action: 分析需求\n│       ├─ Action: 设计 ER 图\n│       └─ Action: 定义 API Schema\n├─ 子目标2: 实现认证模块\n│   └─ 低层规划器\n│       ├─ Action: 实现 JWT 签发\n│       └─ Action: 编写测试\n└─ 子目标3: 实现授权模块\n    └─ 低层规划器\n        ├─ Action: 实现 RBAC\n        └─ Action: 集成测试\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6.1 递归分解的终止条件\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e原子性\u003c/strong\u003e：任务可用单次工具调用完成 → 停止分解\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e深度限制\u003c/strong\u003e：最大 2-3 层，防止过度分解\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e预算约束\u003c/strong\u003e：剩余 token 预算不足以继续分解 → 当前粒度直接执行\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eclass HierarchicalPlanner:\n    def __init__(self, client: openai.OpenAI, model=\u0026quot;gpt-4o\u0026quot;, max_depth=3):\n        self.client, self.model, self.max_depth = client, model, max_depth\n\n    def decompose(self, goal: str, depth: int = 0) -\u0026gt; dict:\n        if depth \u0026gt;= self.max_depth:\n            return {\u0026quot;type\u0026quot;: \u0026quot;action\u0026quot;, \u0026quot;description\u0026quot;: goal}\n\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;, \u0026quot;content\u0026quot;:\n                \u0026quot;Decide if this goal is atomic or compound.\\n\u0026quot;\n                \u0026#39;Atomic: {\u0026quot;type\u0026quot;:\u0026quot;action\u0026quot;,\u0026quot;description\u0026quot;:\u0026quot;...\u0026quot;}\\n\u0026#39;\n                \u0026#39;Compound: {\u0026quot;type\u0026quot;:\u0026quot;goal\u0026quot;,\u0026quot;description\u0026quot;:\u0026quot;...\u0026quot;,\u0026quot;subgoals\u0026quot;:[\u0026quot;...\u0026quot;,]}\u0026#39;},\n                {\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: goal}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        node = json.loads(resp.choices[0].message.content)\n        if node[\u0026quot;type\u0026quot;] == \u0026quot;action\u0026quot;:\n            return node\n        node[\u0026quot;children\u0026quot;] = [self.decompose(sg, depth+1) for sg in node.get(\u0026quot;subgoals\u0026quot;,[])]\n        return node\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e实践中 2 层（Strategic + Tactical）通常够用。3 层以上的调试成本会快速失控。\u003c/p\u003e\n\u003ch3\u003e6.2 执行层：递归执行分解后的计划\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eHierarchicalPlanner\u003c/code\u003e 只负责分解，执行需要单独的 Executor。核心逻辑：叶节点（type=\u0026quot;action\u0026quot;）直接调用 LLM 或工具执行，分支节点（type=\u0026quot;goal\u0026quot;）递归执行所有子节点并聚合结果。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ExecutionResult:\n    description: str\n    output: str\n    success: bool\n    children: list[\u0026quot;ExecutionResult\u0026quot;] = field(default_factory=list)\n\nclass HierarchicalExecutor:\n    def __init__(self, client: openai.OpenAI, model: str = \u0026quot;gpt-4o-mini\u0026quot;,\n                 tools: dict[str, Callable] | None = None):\n        self.client = client\n        self.model = model\n        self.tools = tools or {}\n\n    def execute(self, node: dict) -\u0026gt; ExecutionResult:\n        \u0026quot;\u0026quot;\u0026quot;递归执行分解后的计划树\u0026quot;\u0026quot;\u0026quot;\n        desc = node.get(\u0026quot;description\u0026quot;, \u0026quot;\u0026quot;)\n\n        # 叶节点：直接执行\n        if node[\u0026quot;type\u0026quot;] == \u0026quot;action\u0026quot;:\n            output = self._execute_action(desc)\n            return ExecutionResult(description=desc, output=output, success=True)\n\n        # 分支节点：递归执行所有子节点\n        child_results = [self.execute(child) for child in node.get(\u0026quot;children\u0026quot;, [])]\n        all_success = all(r.success for r in child_results)\n\n        # 聚合子节点结果\n        summary = self._aggregate(desc, child_results)\n        return ExecutionResult(\n            description=desc, output=summary,\n            success=all_success, children=child_results,\n        )\n\n    def _execute_action(self, action: str) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;执行单个原子动作——优先使用工具，否则 fallback 到 LLM\u0026quot;\u0026quot;\u0026quot;\n        for tool_name, tool_fn in self.tools.items():\n            if tool_name.lower() in action.lower():\n                return str(tool_fn(action))\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: f\u0026quot;Execute this task: {action}\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\n    def _aggregate(self, goal: str, results: list[ExecutionResult]) -\u0026gt; str:\n        \u0026quot;\u0026quot;\u0026quot;将子节点执行结果聚合为父目标的总结\u0026quot;\u0026quot;\u0026quot;\n        parts = \u0026quot;\\n\u0026quot;.join(f\u0026quot;- {r.description}: {r.output[:200]}\u0026quot; for r in results)\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;:\n                f\u0026quot;Goal: {goal}\\nSub-results:\\n{parts}\\nSummarize the overall outcome.\u0026quot;}],\n        )\n        return resp.choices[0].message.content\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e分解与执行分离的好处：\u003ccode\u003eHierarchicalPlanner\u003c/code\u003e 可以用强模型（gpt-4o）做规划，\u003ccode\u003eHierarchicalExecutor\u003c/code\u003e 用快模型（gpt-4o-mini）做执行，兼顾规划质量和执行成本。同时，执行层可以独立替换——例如将 \u003ccode\u003e_execute_action\u003c/code\u003e 改为调用真实 API 或 Code Interpreter，而不影响规划逻辑。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. Reflection（反思）机制\u003c/h2\u003e\n\u003ch3\u003e7.1 为什么需要反思\u003c/h3\u003e\n\u003cp\u003eAgent 有三类常见失败：LLM 输出错误（幻觉/逻辑错误）、工具执行失败（超时/参数错误）、计划不可行（前提假设不成立）。没有反思，错误会\u003cstrong\u003e无意识地传播\u003c/strong\u003e——第 2 步的错成为第 3 步的输入，错误不断累积。\u003c/p\u003e\n\u003ch3\u003e7.2 Self-Critique\u003c/h3\u003e\n\u003cp\u003e用同一个 LLM 评估自己的输出。理论支持：LLM 在\u003cstrong\u003e验证\u003c/strong\u003e上通常比\u003cstrong\u003e生成\u003c/strong\u003e更强（就像检查别人的代码比自己写更容易）。但盲区在于：LLM 的系统性偏见在生成和评估中是一致的。\u003c/p\u003e\n\u003ch3\u003e7.3 结构化反思\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ReflectionResult:\n    what_went_well: list[str]\n    what_went_wrong: list[str]\n    root_cause: str\n    what_to_do_next: str\n    should_retry: bool\n    confidence: float  # 0-1\n\nREFLECTION_PROMPT = \u0026quot;\u0026quot;\u0026quot;Analyze this execution result.\nGoal: {goal} | Steps: {steps} | Result: {result}\nReturn JSON: {{\u0026quot;what_went_well\u0026quot;:[], \u0026quot;what_went_wrong\u0026quot;:[], \u0026quot;root_cause\u0026quot;:\u0026quot;\u0026quot;,\n\u0026quot;what_to_do_next\u0026quot;:\u0026quot;\u0026quot;, \u0026quot;should_retry\u0026quot;: bool, \u0026quot;confidence\u0026quot;: 0.0-1.0}}\u0026quot;\u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7.4 Retry Budget 与 Stop Condition\u003c/h3\u003e\n\u003cp\u003e反思不能无限循环。必须有 Stop Condition：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                  反思完成\n                     │\n          ┌──────────▼──────────┐   是\n          │ 质量 \u0026gt;= 阈值？       │─────▶ 返回结果\n          └──────────┬──────────┘\n                     │ 否\n          ┌──────────▼──────────┐   是\n          │ 达到最大重试？       │─────▶ 返回最好的结果\n          └──────────┬──────────┘\n                     │ 否\n          ┌──────────▼──────────┐   是\n          │ 改进幅度 \u0026lt; 阈值？    │─────▶ 停止（再试也没用）\n          └──────────┬──────────┘\n                     │ 否\n          ┌──────────▼──────────┐   是\n          │ 成本超出预算？       │─────▶ 返回当前结果\n          └──────────┬──────────┘\n                     │ 否\n                  继续重试\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e四个条件形成\u003cstrong\u003e多层安全网\u003c/strong\u003e：质量达标是正常退出，最大重试和成本预算是硬性保底，改进幅度检测是\u0026quot;聪明的\u0026quot;提前退出。\u003c/p\u003e\n\u003ch3\u003e7.5 代码实现\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e@dataclass\nclass ReflectionPolicy:\n    max_retries: int = 3\n    quality_threshold: float = 0.7\n    improvement_threshold: float = 0.1\n    cost_limit_tokens: int = 10000\n\nclass ReflectiveAgent:\n    def __init__(self, base_agent: ReActAgent, policy: ReflectionPolicy,\n                 model: str = \u0026quot;gpt-4o-mini\u0026quot;):\n        self.base_agent = base_agent\n        self.policy = policy\n        self.model = model\n        self.client = openai.OpenAI()\n\n    def _reflect(self, goal, steps, result) -\u0026gt; ReflectionResult:\n        resp = self.client.chat.completions.create(\n            model=self.model,\n            messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: REFLECTION_PROMPT.format(\n                goal=goal, steps=json.dumps(steps), result=result)}],\n            response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n        )\n        return ReflectionResult(**json.loads(resp.choices[0].message.content))\n\n    def run(self, goal: str) -\u0026gt; str:\n        best_result, best_score = None, 0.0\n        history = []\n\n        for attempt in range(self.policy.max_retries + 1):\n            # 执行（重试时注入反思结论）\n            if attempt == 0:\n                result = self.base_agent.run(goal)\n            else:\n                enhanced = (f\u0026quot;{goal}\\n\\nPrevious issues: {reflection.what_went_wrong}\u0026quot;\n                           f\u0026quot;\\nRoot cause: {reflection.root_cause}\u0026quot;\n                           f\u0026quot;\\nSuggestion: {reflection.what_to_do_next}\u0026quot;)\n                result = self.base_agent.run(enhanced)\n\n            reflection = self._reflect(goal, history, result)\n\n            # Stop conditions\n            if reflection.confidence \u0026gt;= self.policy.quality_threshold:\n                best_result, best_score = result, reflection.confidence\n                break\n            if not reflection.should_retry:\n                break\n            if attempt \u0026gt; 0 and (reflection.confidence - best_score) \u0026lt; self.policy.improvement_threshold:\n                break  # 改进幅度不足，再试也没用\n\n            # 更新最优结果（放在 stop condition 之后，避免 improvement 检查失效）\n            if reflection.confidence \u0026gt; best_score:\n                best_result, best_score = result, reflection.confidence\n\n            history.append({\u0026quot;attempt\u0026quot;: attempt, \u0026quot;issues\u0026quot;: reflection.what_went_wrong})\n\n        return best_result or result\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e8. Reflection 的陷阱\u003c/h2\u003e\n\u003ch3\u003e8.1 无限循环\u003c/h3\u003e\n\u003cp\u003eAgent 不断反思但不改进——反思发现了问题却没有提供有效的改进方向。解法：\u003ccode\u003eimprovement_threshold\u003c/code\u003e 检测，连续两轮质量差距 \u0026lt; 0.1 直接停止。\u003c/p\u003e\n\u003ch3\u003e8.2 过度反思\u003c/h3\u003e\n\u003cp\u003e简单任务（\u0026quot;今天天气怎么样\u0026quot;）也要三轮反思，浪费 3-4 倍 token。解法：引入复杂度判断，简单任务跳过反思。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef needs_reflection(task: str, result: str) -\u0026gt; bool:\n    \u0026quot;\u0026quot;\u0026quot;简单任务不值得反思\u0026quot;\u0026quot;\u0026quot;\n    if len(result) \u0026lt; 100:  # 结果很短 → 可能是简单查询\n        return False\n    simple_patterns = [\u0026quot;什么是\u0026quot;, \u0026quot;查一下\u0026quot;, \u0026quot;告诉我\u0026quot;]\n    return not any(p in task for p in simple_patterns)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8.3 成本爆炸\u003c/h3\u003e\n\u003cp\u003e每次反思是完整 LLM 调用，包含完整上下文。对策：(1) 反思用小模型（GPT-4o-mini）；(2) 压缩上下文传摘要版本；(3) 采样反思（30% 的执行触发反思而非 100%）。\u003c/p\u003e\n\u003ch3\u003e8.4 合理的 Reflection 策略\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eQ1: 任务的错误成本高吗？\n  高 → 启用反思    低 → 跳过\n\nQ2: 错误可自动检测吗？\n  是（代码可测试） → 外部验证（更可靠更便宜）\n  否（文案质量）   → LLM Self-Critique\n\nQ3: 预算够吗？\n  够   → 结构化反思 + 多轮重试\n  不够 → 单轮 Self-Critique\n\nQ4: 延迟敏感吗？\n  是 → 最多一轮，超时直接返回\n  否 → 多轮直到质量达标\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 规划模式选型指南\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e场景\u003c/th\u003e\n\u003cth\u003e推荐模式\u003c/th\u003e\n\u003cth\u003e原因\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e简单工具调用（查天气、算术）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eReAct\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e1-2 步完成，规划是过度设计\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e多步研究（竞品分析、技术调研）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePlan-and-Execute\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e需要全局视野和步骤追踪\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e创意/数学/代码\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eTree-of-Thought\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e需探索多条路径并选最优\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e复杂项目（系统设计）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eHierarchical\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e粒度跨度大，需递归分解\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e高可靠（金融/法律）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003ePlan-and-Execute + Reflection\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e全局规划 + 结果验证\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e实时交互（客服/对话）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eReAct\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e延迟敏感，逐步响应\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e长时任务（数据管道）\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003eHierarchical + Plan-Exec\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e可中断、可恢复、可并行\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e二维决策矩阵：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                  任务步骤少            任务步骤多\n             ┌──────────────────┬──────────────────┐\n 确定性高    │  ReAct            │  Plan-and-Exec   │\n (路径清晰)  │ (甚至不需要Agent)  │                  │\n             ├──────────────────┼──────────────────┤\n 确定性低    │  Tree-of-Thought  │  Hierarchical    │\n (需要探索)  │                   │  + Reflection    │\n             └──────────────────┴──────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e模式组合\u003c/strong\u003e在生产中很常见：Hierarchical + Plan-and-Execute（高层分解子目标，内部用 Plan-Exec 执行）；ReAct + Reflection（逐步执行，每 N 步检查方向）。关键原则：\u003cstrong\u003e从 ReAct 开始，只有当它的局限性确实成为瓶颈时再升级。\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e10. 结语：规划的边界与 Multi-Agent 的必要性\u003c/h2\u003e\n\u003cp\u003e规划和反思让单个 Agent 从\u0026quot;走一步看一步\u0026quot;进化到\u0026quot;先想后做再检查\u0026quot;。但单 Agent 的规划能力终有上限：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e上下文窗口限制\u003c/strong\u003e：任务涉及的知识和状态超出 context window 时，单 Agent 力不从心\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e专业性限制\u003c/strong\u003e：一个 Agent 很难同时擅长编码、写作和数据分析——就像一个人很难同时是程序员、设计师和产品经理\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e执行效率限制\u003c/strong\u003e：单 Agent 串行执行，即使计划中的步骤可以并行\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当这些限制成为瓶颈，你需要的不是更好的规划算法，而是\u003cstrong\u003e多个 Agent 的协作\u003c/strong\u003e——每个 Agent 专注于擅长领域，由 Orchestrator 协调。这正是下一篇的主题：\u003cstrong\u003eMulti-Agent Collaboration: 多 Agent 协作模式与架构。\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e进一步思考：\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e规划质量高度依赖 LLM 对任务域的理解。如果 LLM 从未见过某类任务，能否通过 few-shot examples 注入领域知识来提升规划质量？\u003c/li\u003e\n\u003cli\u003e\u0026quot;LLM 评估 LLM\u0026quot; 的反思机制在多大程度上可靠？是否能引入外部验证信号（代码测试、人类反馈）来补强？\u003c/li\u003e\n\u003cli\u003eTree-of-Thought 的搜索空间是指数级的。能否借鉴 AlphaGo 的 MCTS 来更高效搜索？Reasoning model（如 o1、o3）是否已在内部做了类似的事情？\u003c/li\u003e\n\u003cli\u003e规划和反思的 token 成本显著。能否缓存和复用已有的计划，为相似任务跳过规划阶段？\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 10 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/09-RAG%20as%20Cognitive%20Memory\"\u003e09 | RAG as Cognitive Memory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/11-Multi-Agent%20Collaboration\"\u003e11 | Multi-Agent Collaboration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"18:Td1b4,"])</script><script>self.__next_f.push([1,"\u003ch1\u003eLangChain vs LangGraph: 框架的价值与边界\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e框架是加速器，不是必需品。它替你做了决策——有些决策是好的，有些会在深夜的生产事故中反噬你。\u003c/p\u003e\n\u003cp\u003e本文是 Agentic 系列第 12 篇。前面 11 篇我们从零构建了 Agent 的每一个组件——控制循环、工具调用、记忆、规划、多 Agent 协作。现在是时候回过头来，以工程师的视角冷静审视：框架提供了什么，隐藏了什么，限制了什么。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003e1. 开篇：你真的需要框架吗？\u003c/h2\u003e\n\u003cp\u003e这个问题的答案不是\u0026quot;需要\u0026quot;或\u0026quot;不需要\u0026quot;，而是\u0026quot;取决于\u0026quot;。\u003c/p\u003e\n\u003cp\u003e如果你已经读完本系列前 7 篇文章（从控制循环到自研 Runtime），你已经具备了从零构建一个 Agent 系统的能力。你知道 Tool Calling 的 JSON Schema 契约，知道控制循环的 Observe-Think-Plan-Act-Reflect-Update 六阶段，知道 Memory 的短期/长期分层，知道 Planner 的 ReAct 与分层规划。\u003c/p\u003e\n\u003cp\u003e这时候你面临一个决策：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e选择 A：自己实现所有组件，完全掌控\n选择 B：使用框架，快速启动，接受其抽象和约束\n选择 C：理解框架的实现，选择性地借鉴或使用其部分模块\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e大多数成熟的工程团队最终会走向选择 C。但要做到选择 C，你必须先深入理解框架到底在做什么。这就是本文的目的。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e2. 为什么需要框架\u003c/h2\u003e\n\u003cp\u003e框架存在是有道理的。在深入批判之前，先公正地承认它们解决了哪些真实的工程问题。\u003c/p\u003e\n\u003ch3\u003e2.1 减少重复代码\u003c/h3\u003e\n\u003cp\u003e每一个 Agent 系统都需要处理以下样板代码：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e工具注册与调度\u003c/strong\u003e：维护一个 \u003ccode\u003etool_name → callable\u003c/code\u003e 的映射表，处理参数校验和错误捕获\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e消息格式管理\u003c/strong\u003e：构造和维护 \u003ccode\u003emessages\u003c/code\u003e 列表，处理不同角色（system/user/assistant/tool）的消息格式\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLLM 调用封装\u003c/strong\u003e：处理 API 差异（OpenAI、Anthropic、本地模型的接口都不同）、流式输出、重试、降级\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e状态序列化\u003c/strong\u003e：将 Agent 的运行状态持久化到数据库或文件系统\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这些代码在每个项目中高度相似，但又充满细节（比如 OpenAI 的 \u003ccode\u003etool_calls\u003c/code\u003e 和 Anthropic 的 \u003ccode\u003etool_use\u003c/code\u003e 格式差异）。框架把这些细节屏蔽了。\u003c/p\u003e\n\u003ch3\u003e2.2 社区生态\u003c/h3\u003e\n\u003cp\u003e成熟框架最大的资产不是代码，而是生态：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e预置 Tool 集成\u003c/strong\u003e：搜索引擎（Tavily、SerpAPI）、数据库（SQL、MongoDB）、文件系统、浏览器等，开箱即用\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e预置 Retriever\u003c/strong\u003e：支持各种向量数据库（Pinecone、Weaviate、Chroma、FAISS）的统一接口\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e文档与教程\u003c/strong\u003e：从入门到进阶的学习路径\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e社区问答\u003c/strong\u003e：遇到问题时有人讨论、有 issue 可以搜索\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2.3 最佳实践封装\u003c/h3\u003e\n\u003cp\u003e框架将社区沉淀的设计模式编码为默认行为：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReAct 模式的标准实现\u003c/li\u003e\n\u003cli\u003eRetrieval-Augmented Generation 的标准 pipeline\u003c/li\u003e\n\u003cli\u003e对话记忆的滑动窗口管理\u003c/li\u003e\n\u003cli\u003e工具调用的错误处理和重试\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e对于刚接触 Agent 开发的团队，这些封装可以避免很多常见的设计错误。\u003c/p\u003e\n\u003ch3\u003e2.4 快速原型验证\u003c/h3\u003e\n\u003cp\u003e当你需要在两天内验证一个想法是否可行时，框架的价值最大化。10 行代码就能跑通一个带工具调用的 Agent 原型，比从零实现快一个数量级。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 10 行代码验证一个想法——这是框架的甜蜜点\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_tool_calling_agent, AgentExecutor\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_community.tools.tavily_search import TavilySearchResults\n\nllm = ChatOpenAI(model=\u0026quot;gpt-4o\u0026quot;)\ntools = [TavilySearchResults(max_results=3)]\nprompt = ChatPromptTemplate.from_messages([\n    (\u0026quot;system\u0026quot;, \u0026quot;You are a helpful research assistant.\u0026quot;),\n    (\u0026quot;human\u0026quot;, \u0026quot;{input}\u0026quot;),\n    (\u0026quot;placeholder\u0026quot;, \u0026quot;{agent_scratchpad}\u0026quot;),\n])\nagent = create_tool_calling_agent(llm, tools, prompt)\nexecutor = AgentExecutor(agent=agent, tools=tools, verbose=True)\nresult = executor.invoke({\u0026quot;input\u0026quot;: \u0026quot;2025 年 AI Agent 领域有哪些重要进展？\u0026quot;})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这段代码在 5 分钟内就能跑通。但如果你打算把它部署到生产环境——请继续往下读。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e3. LangChain 深入分析\u003c/h2\u003e\n\u003cp\u003eLangChain 是 AI Agent 领域生态最大的框架，也是争议最多的框架。我们不吹不黑，从架构和工程两个维度来分析。\u003c/p\u003e\n\u003ch3\u003e3.1 核心抽象\u003c/h3\u003e\n\u003cp\u003eLangChain 的设计围绕四个核心抽象：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e抽象\u003c/th\u003e\n\u003cth\u003e本质\u003c/th\u003e\n\u003cth\u003e职责\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eChain\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e链式调用\u003c/td\u003e\n\u003ctd\u003e将多个步骤串联为顺序执行的管道\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAgent\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e工具选择 + 循环\u003c/td\u003e\n\u003ctd\u003eLLM 自主决定调用哪个工具，循环直到完成\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eMemory\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e对话状态管理\u003c/td\u003e\n\u003ctd\u003e维护对话历史，支持滑动窗口、摘要等策略\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eRetriever\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e知识检索\u003c/td\u003e\n\u003ctd\u003e从向量数据库或其他数据源检索相关文档\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e这四个抽象之间的关系可以用下图表示：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────┐\n│                    LangChain Architecture                │\n├─────────────────────────────────────────────────────────┤\n│                                                         │\n│   ┌──────────┐    ┌──────────┐    ┌──────────────────┐  │\n│   │  Chain   │    │  Agent   │    │  AgentExecutor   │  │\n│   │          │    │          │    │  (Control Loop)  │  │\n│   │ step1 →  │    │ LLM +   │    │                  │  │\n│   │ step2 →  │    │ Tools +  │    │  while not done: │  │\n│   │ step3    │    │ Prompt   │    │    plan()        │  │\n│   └────┬─────┘    └────┬─────┘    │    execute()     │  │\n│        │               │          │    observe()     │  │\n│        │               └──────────┤                  │  │\n│        │                          └────────┬─────────┘  │\n│        │                                   │            │\n│   ┌────▼───────────────────────────────────▼─────────┐  │\n│   │              LLM Abstraction Layer               │  │\n│   │  ChatOpenAI │ ChatAnthropic │ ChatOllama │ ...   │  │\n│   └────────────────────┬─────────────────────────────┘  │\n│                        │                                │\n│   ┌────────────────────▼─────────────────────────────┐  │\n│   │                  Memory                          │  │\n│   │  ConversationBufferMemory │ ConversationSummary  │  │\n│   │  VectorStoreMemory │ EntityMemory │ ...          │  │\n│   └──────────────────────────────────────────────────┘  │\n│                                                         │\n│   ┌──────────────────────────────────────────────────┐  │\n│   │                  Retriever                       │  │\n│   │  VectorStoreRetriever │ BM25 │ MultiQuery │ ... │  │\n│   └──────────────────────────────────────────────────┘  │\n│                                                         │\n│   ┌──────────────────────────────────────────────────┐  │\n│   │                  Tools                           │  │\n│   │  Search │ Calculator │ SQL │ FileSystem │ ...    │  │\n│   └──────────────────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3.2 代码示例：用 LangChain 实现工具调用 Agent\u003c/h3\u003e\n\u003cp\u003e下面用 LangChain 实现一个能查天气和创建日程的 Agent，同时标注每一层抽象的存在：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_tool_calling_agent, AgentExecutor\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.tools import tool\n\n# --- 第 1 层抽象：@tool 装饰器 ---\n# LangChain 用装饰器将普通函数包装为 Tool 对象\n# 自动从类型注解和 docstring 生成 JSON Schema\n@tool\ndef get_weather(city: str, date: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;获取指定城市在指定日期的天气预报。\n\n    Args:\n        city: 城市名称，例如 \u0026quot;北京\u0026quot;\n        date: 日期，格式 YYYY-MM-DD\n    \u0026quot;\u0026quot;\u0026quot;\n    # 实际调用天气 API\n    return f\u0026#39;{{\u0026quot;city\u0026quot;: \u0026quot;{city}\u0026quot;, \u0026quot;date\u0026quot;: \u0026quot;{date}\u0026quot;, \u0026quot;temp\u0026quot;: \u0026quot;31°C\u0026quot;, \u0026quot;condition\u0026quot;: \u0026quot;多云转雷阵雨\u0026quot;}}\u0026#39;\n\n@tool\ndef create_reminder(title: str, time: str, note: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;创建一个日程提醒。\n\n    Args:\n        title: 提醒标题\n        time: 提醒时间，ISO 8601 格式\n        note: 提醒备注内容\n    \u0026quot;\u0026quot;\u0026quot;\n    return f\u0026#39;{{\u0026quot;status\u0026quot;: \u0026quot;created\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;{title}\u0026quot;, \u0026quot;time\u0026quot;: \u0026quot;{time}\u0026quot;}}\u0026#39;\n\n# --- 第 2 层抽象：LLM 封装 ---\n# ChatOpenAI 封装了 OpenAI API 的调用细节\nllm = ChatOpenAI(model=\u0026quot;gpt-4o\u0026quot;, temperature=0)\n\n# --- 第 3 层抽象：Prompt Template ---\n# ChatPromptTemplate 管理消息的组装逻辑\nprompt = ChatPromptTemplate.from_messages([\n    (\u0026quot;system\u0026quot;, \u0026quot;你是一个智能助手，可以查询天气和管理日程。今天是 2025-09-01。\u0026quot;),\n    (\u0026quot;human\u0026quot;, \u0026quot;{input}\u0026quot;),\n    MessagesPlaceholder(variable_name=\u0026quot;agent_scratchpad\u0026quot;),  # Agent 的工作记忆\n])\n\n# --- 第 4 层抽象：Agent 构造 ---\n# create_tool_calling_agent 将 LLM + Tools + Prompt 组合为一个 Agent\ntools = [get_weather, create_reminder]\nagent = create_tool_calling_agent(llm, tools, prompt)\n\n# --- 第 5 层抽象：AgentExecutor ---\n# AgentExecutor 提供控制循环：调用 Agent → 执行工具 → 反馈结果 → 循环\nexecutor = AgentExecutor(\n    agent=agent,\n    tools=tools,\n    verbose=True,       # 输出每一步的推理过程\n    max_iterations=10,  # 最大循环次数\n    handle_parsing_errors=True,  # 自动处理 LLM 输出格式错误\n)\n\n# --- 运行 ---\nresult = executor.invoke({\u0026quot;input\u0026quot;: \u0026quot;帮我查看明天北京的天气，然后创建一个提醒\u0026quot;})\nprint(result[\u0026quot;output\u0026quot;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e数一数：从你的业务逻辑（两个工具函数）到最终执行，经过了 \u003cstrong\u003e5 层抽象\u003c/strong\u003e。每一层都在\u0026quot;帮你做决策\u0026quot;——消息格式、工具注册方式、控制循环策略、错误处理逻辑、输出解析方式。\u003c/p\u003e\n\u003ch3\u003e3.3 优点\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e1. 生态最大、集成最多\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e截至 2025 年，LangChain 拥有 AI Agent 框架领域最庞大的集成生态：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e70+ LLM 提供商（OpenAI、Anthropic、Google、Mistral、本地模型等）\u003c/li\u003e\n\u003cli\u003e50+ 向量数据库\u003c/li\u003e\n\u003cli\u003e100+ 预置工具\u003c/li\u003e\n\u003cli\u003e30+ Document Loader（PDF、HTML、CSV、Notion、Confluence 等）\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e2. 社区活跃\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eGitHub 上最活跃的 AI 项目之一。遇到问题时，StackOverflow 和 GitHub Issues 中大概率能找到讨论。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. 上手快\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e对于 PoC（Proof of Concept）和原型验证，LangChain 能让你在几小时内从零到一跑通一个完整的 Agent。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. 抽象统一\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e不同 LLM 提供商的 API 差异被封装在统一接口下。切换 OpenAI → Anthropic 只需要换一行代码（理论上如此，实际上有细微差异）。\u003c/p\u003e\n\u003ch3\u003e3.4 问题\u003c/h3\u003e\n\u003cp\u003e以下不是主观吐槽，而是在生产环境中反复遇到的工程问题。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题 1：过度抽象——简单的事情被包了太多层\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e考虑一个最基本的需求：调用 LLM 并获取结构化输出。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 不用框架：3 行代码，直白清晰\nimport openai\nresponse = openai.chat.completions.create(\n    model=\u0026quot;gpt-4o\u0026quot;,\n    messages=[{\u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;, \u0026quot;content\u0026quot;: \u0026quot;分析这段文本的情感\u0026quot;}],\n    response_format={\u0026quot;type\u0026quot;: \u0026quot;json_object\u0026quot;},\n)\nresult = json.loads(response.choices[0].message.content)\n\n# 用 LangChain：需要理解 ChatOpenAI、BaseOutputParser、RunnableSequence、\n# StrOutputParser vs JsonOutputParser、LCEL 管道语法...\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nprompt = ChatPromptTemplate.from_template(\u0026quot;分析这段文本的情感: {text}\u0026quot;)\nllm = ChatOpenAI(model=\u0026quot;gpt-4o\u0026quot;)\nparser = JsonOutputParser()\nchain = prompt | llm | parser  # LCEL 管道语法\nresult = chain.invoke({\u0026quot;text\u0026quot;: \u0026quot;这个产品太棒了\u0026quot;})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLangChain 版本代码量更多不是问题——问题在于它引入了多个你需要理解的新概念（\u003ccode\u003eChatPromptTemplate\u003c/code\u003e、\u003ccode\u003eJsonOutputParser\u003c/code\u003e、LCEL 管道操作符 \u003ccode\u003e|\u003c/code\u003e），而这些概念只是在封装原本就很简单的操作。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题 2：调试困难——错误信息穿过多层封装后难以定位\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e当 LangChain 链条中的某一环出错时，错误堆栈可能长达 20-30 层，涉及 \u003ccode\u003eRunnableSequence\u003c/code\u003e、\u003ccode\u003eRunnableParallel\u003c/code\u003e、\u003ccode\u003eRunnableLambda\u003c/code\u003e 等内部抽象。你需要在这些框架内部类之间导航，才能找到真正的错误源。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# 真实场景中的错误堆栈（简化版）\nTraceback:\n  langchain_core/runnables/base.py      RunnableSequence.invoke()\n  langchain_core/runnables/base.py      RunnableSequence._invoke()\n  langchain_core/runnables/base.py      Runnable.invoke()\n  langchain_core/runnables/base.py      RunnableLambda.invoke()\n  langchain/agents/output_parsers.py    ToolsAgentOutputParser.parse()\n  ...\n  # 15 层之后...\n  你的代码.py                            你的函数()   ← 真正的问题在这里\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e在生产环境的 3 AM 报警中，这种调试体验是痛苦的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题 3：版本混乱——API 变动频繁\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLangChain 在快速迭代中经历了多次重大 API 变更：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003elangchain\u003c/code\u003e → \u003ccode\u003elangchain-core\u003c/code\u003e + \u003ccode\u003elangchain-community\u003c/code\u003e 的包拆分\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eLLMChain\u003c/code\u003e → LCEL（LangChain Expression Language）的范式转换\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003einitialize_agent\u003c/code\u003e → \u003ccode\u003ecreate_tool_calling_agent\u003c/code\u003e 的 Agent 创建方式变更\u003c/li\u003e\n\u003cli\u003eMemory 接口的多次重构\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e6 个月前写的代码，今天大概率跑不通。网上的教程和 StackOverflow 答案大量过时。对于需要长期维护的生产系统，这是一个严重的风险。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题 4：\u0026quot;Chain\u0026quot; 思维的局限——线性链无法表达复杂的分支和循环\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLangChain 的核心抽象是 \u0026quot;Chain\u0026quot;——链式调用。这个模型对于线性流水线（A → B → C）非常优雅，但现实中的 Agent 逻辑往往是非线性的：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e线性 Chain 能表达的：\n\n    A ──→ B ──→ C ──→ D\n    (检索)  (摘要)  (格式化) (输出)\n\n\n现实中 Agent 需要的：\n\n    A ──→ B ──→ C ──→ D\n    │     │     ▲     │\n    │     ├─→ E ─┘     │     ← 条件分支\n    │     │             │\n    │     └─→ F ──→ G ──┘     ← 并行执行\n    │           │\n    └───────────┘              ← 循环重试\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLangChain 的 LCEL 可以通过 \u003ccode\u003eRunnableBranch\u003c/code\u003e 和 \u003ccode\u003eRunnableParallel\u003c/code\u003e 实现一些分支和并行，但语法变得复杂且不直观。这正是 LangGraph 诞生的原因。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e4. LangGraph 深入分析\u003c/h2\u003e\n\u003cp\u003eLangGraph 是 LangChain 团队推出的下一代框架，核心思想是用\u003cstrong\u003e有向图（Directed Graph）\u003c/strong\u003e 替代\u003cstrong\u003e链（Chain）\u003c/strong\u003e 作为基础抽象。这不是一个小改动——它从根本上改变了 Agent 逻辑的表达方式。\u003c/p\u003e\n\u003ch3\u003e4.1 核心抽象\u003c/h3\u003e\n\u003cp\u003eLangGraph 的设计围绕四个概念：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e抽象\u003c/th\u003e\n\u003cth\u003e本质\u003c/th\u003e\n\u003cth\u003e对应的计算模型\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eState\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e共享状态对象\u003c/td\u003e\n\u003ctd\u003e状态机的 State\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eNode\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e一个函数\u003c/td\u003e\n\u003ctd\u003e状态机的 State Handler\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eEdge\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e节点间的连接\u003c/td\u003e\n\u003ctd\u003e状态机的 Transition\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eGraph\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e节点和边的组合\u003c/td\u003e\n\u003ctd\u003e有限状态机（FSM）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e核心思想：\u003cstrong\u003eAgent 的执行流程就是一个状态机。\u003c/strong\u003e 每个节点是一个处理函数，每条边是一个转移条件，整个图定义了 Agent 的所有可能执行路径。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────────────────┐\n│                   LangGraph State Machine                    │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│   ┌─────────────────────────────────────────────────────┐   │\n│   │                  Shared State                       │   │\n│   │  {messages: [...], tool_results: {...}, plan: [...]} │   │\n│   └────────────────────────┬────────────────────────────┘   │\n│                            │                                │\n│               ┌────────────▼────────────┐                   │\n│               │       START             │                   │\n│               └────────────┬────────────┘                   │\n│                            │                                │\n│               ┌────────────▼────────────┐                   │\n│               │      agent_node         │                   │\n│               │   (LLM Reasoning)       │                   │\n│               └────────────┬────────────┘                   │\n│                            │                                │\n│               ┌────────────▼────────────┐                   │\n│              ╱    should_continue?       ╲                   │\n│             ╱  (Conditional Edge)         ╲                  │\n│            ╱                               ╲                 │\n│      tool_calls?                      no tool_calls?        │\n│           │                                │                │\n│  ┌────────▼─────────┐          ┌──────────▼──────────┐     │\n│  │    tool_node      │          │       END            │     │\n│  │  (Execute Tools)  │          │   (Return Result)    │     │\n│  └────────┬──────────┘          └─────────────────────┘     │\n│           │                                                 │\n│           └──────────────────┐                              │\n│                              │ (feed tool results back)     │\n│               ┌──────────────▼──────────┐                   │\n│               │      agent_node         │ ← 回到推理节点    │\n│               └─────────────────────────┘                   │\n│                                                             │\n└─────────────────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这个图可以清晰地表达：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e循环\u003c/strong\u003e：\u003ccode\u003eagent_node → tool_node → agent_node\u003c/code\u003e（工具调用循环）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e分支\u003c/strong\u003e：\u003ccode\u003eshould_continue?\u003c/code\u003e 条件路由\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e终止\u003c/strong\u003e：到达 \u003ccode\u003eEND\u003c/code\u003e 节点时退出\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e4.2 代码示例：用 LangGraph 实现同一个 Agent\u003c/h3\u003e\n\u003cp\u003e用 LangGraph 实现与上文 LangChain 相同的天气查询 + 日程创建 Agent：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom typing import Annotated, TypedDict\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\nfrom langchain_core.messages import BaseMessage, HumanMessage, AIMessage\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode\n\n\n# ============================================================\n# Step 1: 定义共享状态（State）\n# ============================================================\n# 这是 LangGraph 与 LangChain 的核心差异：\n# 显式定义 Agent 的完整状态结构\nclass AgentState(TypedDict):\n    messages: Annotated[list[BaseMessage], add_messages]  # 消息列表，自动追加\n\n\n# ============================================================\n# Step 2: 定义工具（和 LangChain 相同）\n# ============================================================\n@tool\ndef get_weather(city: str, date: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;获取指定城市在指定日期的天气预报。\u0026quot;\u0026quot;\u0026quot;\n    return f\u0026#39;{{\u0026quot;city\u0026quot;: \u0026quot;{city}\u0026quot;, \u0026quot;date\u0026quot;: \u0026quot;{date}\u0026quot;, \u0026quot;temp\u0026quot;: \u0026quot;31°C\u0026quot;, \u0026quot;condition\u0026quot;: \u0026quot;多云转雷阵雨\u0026quot;}}\u0026#39;\n\n@tool\ndef create_reminder(title: str, time: str, note: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;创建一个日程提醒。\u0026quot;\u0026quot;\u0026quot;\n    return f\u0026#39;{{\u0026quot;status\u0026quot;: \u0026quot;created\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;{title}\u0026quot;, \u0026quot;time\u0026quot;: \u0026quot;{time}\u0026quot;}}\u0026#39;\n\ntools = [get_weather, create_reminder]\n\n\n# ============================================================\n# Step 3: 定义节点（Node）\n# ============================================================\nllm = ChatOpenAI(model=\u0026quot;gpt-4o\u0026quot;, temperature=0).bind_tools(tools)\n\ndef agent_node(state: AgentState) -\u0026gt; dict:\n    \u0026quot;\u0026quot;\u0026quot;推理节点：LLM 根据当前状态决定下一步\u0026quot;\u0026quot;\u0026quot;\n    system_message = {\n        \u0026quot;role\u0026quot;: \u0026quot;system\u0026quot;,\n        \u0026quot;content\u0026quot;: \u0026quot;你是一个智能助手，可以查询天气和管理日程。今天是 2025-09-01。\u0026quot;\n    }\n    messages = [system_message] + state[\u0026quot;messages\u0026quot;]\n    response = llm.invoke(messages)\n    return {\u0026quot;messages\u0026quot;: [response]}\n\n# ToolNode 是 LangGraph 的内置节点，自动执行工具调用\ntool_node = ToolNode(tools)\n\n\n# ============================================================\n# Step 4: 定义边（Edge）—— 条件路由\n# ============================================================\ndef should_continue(state: AgentState) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;条件路由：检查最后一条消息是否包含工具调用\u0026quot;\u0026quot;\u0026quot;\n    last_message = state[\u0026quot;messages\u0026quot;][-1]\n    if hasattr(last_message, \u0026quot;tool_calls\u0026quot;) and last_message.tool_calls:\n        return \u0026quot;tools\u0026quot;     # 有工具调用 → 去 tool_node\n    return \u0026quot;end\u0026quot;           # 无工具调用 → 任务完成\n\n\n# ============================================================\n# Step 5: 构建图（Graph）\n# ============================================================\ngraph_builder = StateGraph(AgentState)\n\n# 添加节点\ngraph_builder.add_node(\u0026quot;agent\u0026quot;, agent_node)\ngraph_builder.add_node(\u0026quot;tools\u0026quot;, tool_node)\n\n# 添加边\ngraph_builder.add_edge(START, \u0026quot;agent\u0026quot;)                        # 入口 → 推理\ngraph_builder.add_conditional_edges(\u0026quot;agent\u0026quot;, should_continue, {\n    \u0026quot;tools\u0026quot;: \u0026quot;tools\u0026quot;,                                         # 推理 → 工具执行\n    \u0026quot;end\u0026quot;: END,                                               # 推理 → 结束\n})\ngraph_builder.add_edge(\u0026quot;tools\u0026quot;, \u0026quot;agent\u0026quot;)                      # 工具执行 → 回到推理\n\n# 编译图\ngraph = graph_builder.compile()\n\n\n# ============================================================\n# Step 6: 运行\n# ============================================================\nresult = graph.invoke({\n    \u0026quot;messages\u0026quot;: [HumanMessage(content=\u0026quot;帮我查看明天北京的天气，然后创建一个提醒\u0026quot;)]\n})\n\n# 输出最终结果\nfor message in result[\u0026quot;messages\u0026quot;]:\n    print(f\u0026quot;[{message.type}] {message.content}\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e对比 LangChain 版本，LangGraph 的关键差异：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e显式状态定义\u003c/strong\u003e：\u003ccode\u003eAgentState\u003c/code\u003e 明确声明了 Agent 运行时的完整状态\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e显式控制流\u003c/strong\u003e：\u003ccode\u003eadd_edge\u003c/code\u003e 和 \u003ccode\u003eadd_conditional_edges\u003c/code\u003e 让执行路径一目了然\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e图可视化\u003c/strong\u003e：编译后的 \u003ccode\u003egraph\u003c/code\u003e 可以直接渲染为流程图，便于理解和调试\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e没有隐藏的循环\u003c/strong\u003e：循环通过 \u003ccode\u003etools → agent\u003c/code\u003e 的边显式定义，而不是藏在 \u003ccode\u003eAgentExecutor\u003c/code\u003e 内部\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e4.3 优点\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e1. 状态机模型比 Chain 更强大\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eChain 只能表达线性流水线。Graph 可以表达任意拓扑——分支、循环、并行、条件汇聚。这与现实中 Agent 的执行逻辑天然匹配。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. 确定性的控制流 + 非确定性的 LLM 决策\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e这是 LangGraph 最精妙的设计哲学：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e确定性（代码定义）：            非确定性（LLM 决定）：\n├── 有哪些节点                 ├── 每个节点内部的推理\n├── 节点间如何连接              ├── 工具选择和参数\n├── 条件路由的判断逻辑          ├── 是否继续循环\n└── 状态的数据结构              └── 最终输出内容\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e图的拓扑结构是确定性的（你在编译时就知道所有可能的执行路径），但每一步走哪条路径是 LLM 在运行时决定的。这实现了\u003cstrong\u003e可预测的系统行为\u003c/strong\u003e与\u003cstrong\u003e灵活的智能决策\u003c/strong\u003e之间的平衡。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Checkpoint 支持——暂停、恢复、Time-Travel\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLangGraph 内置了状态检查点机制。这意味着：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom langgraph.checkpoint.memory import MemorySaver\n\n# 带 checkpoint 的图\ncheckpointer = MemorySaver()\ngraph = graph_builder.compile(checkpointer=checkpointer)\n\n# 运行时传入 thread_id\nconfig = {\u0026quot;configurable\u0026quot;: {\u0026quot;thread_id\u0026quot;: \u0026quot;user-123\u0026quot;}}\nresult = graph.invoke({\u0026quot;messages\u0026quot;: [HumanMessage(content=\u0026quot;查天气\u0026quot;)]}, config)\n\n# 可以暂停、恢复、回放\n# - 暂停：interrupt_before=[\u0026quot;tool_node\u0026quot;] 在工具执行前暂停，等待人类审批\n# - 恢复：再次 invoke 同一个 thread_id，从上次中断点继续\n# - Time-travel：回滚到任意 checkpoint，重新执行\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这在 Human-in-the-Loop（人机协作）场景中极其有价值——Agent 可以在执行敏感操作前暂停，等待人类确认。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. 可以表达复杂的多 Agent 架构\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e上一篇我们讨论的 Supervisor/Worker 模式、并行 Agent 协作，在 LangGraph 中可以自然地表达为图结构：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                 ┌──────────────┐\n                 │  Supervisor  │\n                 └──────┬───────┘\n                        │\n              ┌─────────┼─────────┐\n              ▼         ▼         ▼\n        ┌──────────┐ ┌──────┐ ┌──────────┐\n        │ Researcher│ │Coder │ │ Reviewer │\n        └──────────┘ └──────┘ └──────────┘\n              │         │         │\n              └─────────┼─────────┘\n                        ▼\n                 ┌──────────────┐\n                 │  Supervisor  │ ← 回到 Supervisor 决定是否继续\n                 └──────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4.4 问题\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e问题 1：学习曲线较陡\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLangGraph 要求你理解状态机、有向图、条件路由等概念。对于习惯了\u0026quot;调用一个函数就能跑\u0026quot;的开发者来说，需要一段适应期。\u003c/p\u003e\n\u003cp\u003e特别是 \u003ccode\u003eAnnotated[list[BaseMessage], add_messages]\u003c/code\u003e 这样的状态定义语法（使用 \u003ccode\u003eAnnotated\u003c/code\u003e 类型指定 reducer 函数），对 Python 类型系统不熟悉的开发者可能感到困惑。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题 2：状态定义需要提前规划\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e在 LangChain 中，你可以随意传递数据，框架会帮你管理。在 LangGraph 中，所有状态必须在 \u003ccode\u003eAgentState\u003c/code\u003e 中预先定义。这意味着你需要在写代码之前就想清楚 Agent 需要哪些状态。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 如果开发到一半发现需要新的状态字段，\n# 你需要修改 State 定义，并确保所有节点兼容\nclass AgentState(TypedDict):\n    messages: Annotated[list[BaseMessage], add_messages]\n    plan: list[str]                    # 后来加的\n    current_step: int                  # 后来加的\n    tool_results: dict[str, str]       # 后来加的\n    retry_count: int                   # 后来加的\n    # ... 状态会越来越复杂\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e对于探索性的开发来说，这种\u0026quot;先定义后使用\u0026quot;的约束会拖慢迭代速度。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e问题 3：小任务过度工程化\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e如果你的 Agent 逻辑就是\u0026quot;调用 LLM → 可能调用工具 → 返回结果\u0026quot;这个简单循环，用 LangGraph 定义 State、Node、Edge、Conditional Edge 就像是用大炮打蚊子。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 一个简单的 ReAct Agent，用 LangGraph 需要 40+ 行图定义代码\n# 用原生 Python 只需要一个 while 循环：\nwhile True:\n    response = llm.chat(messages, tools=tools)\n    if not response.tool_calls:\n        return response.content\n    for tc in response.tool_calls:\n        result = execute_tool(tc)\n        messages.append(tool_message(tc.id, result))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e当你的 Agent 逻辑不涉及复杂的分支和并行时，LangGraph 的开销不值得。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e5. 其他框架概览\u003c/h2\u003e\n\u003cp\u003e除了 LangChain 和 LangGraph，AI Agent 领域还有多个值得关注的框架。以下不深入展开，重点给出定位和适用场景。\u003c/p\u003e\n\u003ch3\u003e5.1 框架定位速览\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e框架\u003c/th\u003e\n\u003cth\u003e开发者\u003c/th\u003e\n\u003cth\u003e核心抽象\u003c/th\u003e\n\u003cth\u003e定位\u003c/th\u003e\n\u003cth\u003e适用场景\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eLangChain\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eLangChain Inc.\u003c/td\u003e\n\u003ctd\u003eChain（链式调用）\u003c/td\u003e\n\u003ctd\u003e通用 AI 应用框架\u003c/td\u003e\n\u003ctd\u003e原型验证、RAG、简单 Agent\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eLangGraph\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eLangChain Inc.\u003c/td\u003e\n\u003ctd\u003eGraph（状态机）\u003c/td\u003e\n\u003ctd\u003e复杂 Agent 编排\u003c/td\u003e\n\u003ctd\u003e多步推理、Human-in-the-Loop、多 Agent\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eCrewAI\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCrewAI Inc.\u003c/td\u003e\n\u003ctd\u003eCrew + Agent + Task\u003c/td\u003e\n\u003ctd\u003e多 Agent 协作\u003c/td\u003e\n\u003ctd\u003e角色扮演式多 Agent 工作流\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAutoGen\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eMicrosoft\u003c/td\u003e\n\u003ctd\u003eAgent + Conversation\u003c/td\u003e\n\u003ctd\u003e多 Agent 对话\u003c/td\u003e\n\u003ctd\u003e研究型多 Agent 系统、代码生成\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eSemantic Kernel\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eMicrosoft\u003c/td\u003e\n\u003ctd\u003eKernel + Plugin + Planner\u003c/td\u003e\n\u003ctd\u003e企业级 AI 编排\u003c/td\u003e\n\u003ctd\u003e企业应用集成、.NET 生态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eHaystack\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003edeepset\u003c/td\u003e\n\u003ctd\u003ePipeline + Component\u003c/td\u003e\n\u003ctd\u003eRAG 专用\u003c/td\u003e\n\u003ctd\u003e文档检索、知识问答\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eDSPy\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eStanford NLP\u003c/td\u003e\n\u003ctd\u003eModule + Signature + Optimizer\u003c/td\u003e\n\u003ctd\u003ePrompt 优化\u003c/td\u003e\n\u003ctd\u003e需要自动调优 Prompt 的系统\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e5.2 简要点评\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCrewAI\u003c/strong\u003e 的核心思路是\u0026quot;角色扮演\u0026quot;——你定义多个 Agent，每个 Agent 有一个角色（Researcher、Writer、Reviewer），然后把一个任务分配给这个\u0026quot;团队\u0026quot;。这个抽象直观好懂，但在复杂场景中角色定义和任务分配的灵活性不足。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# CrewAI 的核心抽象：角色 + 任务 + 团队\nfrom crewai import Agent, Task, Crew\n\nresearcher = Agent(role=\u0026quot;Researcher\u0026quot;, goal=\u0026quot;查找相关信息\u0026quot;, ...)\nwriter = Agent(role=\u0026quot;Writer\u0026quot;, goal=\u0026quot;撰写报告\u0026quot;, ...)\ntask1 = Task(description=\u0026quot;研究 AI Agent 的最新进展\u0026quot;, agent=researcher)\ntask2 = Task(description=\u0026quot;基于研究结果撰写报告\u0026quot;, agent=writer)\ncrew = Crew(agents=[researcher, writer], tasks=[task1, task2])\nresult = crew.kickoff()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eAutoGen\u003c/strong\u003e（Microsoft）强调多 Agent 之间的对话作为协作机制。Agent 之间通过消息传递交互，可以构建复杂的对话流程。适合研究和实验性项目，生产部署的工程支持较弱。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSemantic Kernel\u003c/strong\u003e（Microsoft）面向企业用户，强调与现有企业系统的集成。如果你的技术栈是 .NET/C#，或者需要与 Microsoft 365/Azure 深度集成，Semantic Kernel 是更自然的选择。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHaystack\u003c/strong\u003e（deepset）不试图做通用 Agent 框架，而是专注于 RAG pipeline。如果你的核心需求是文档检索和知识问答（而不是 Agent 的自主决策和工具调用），Haystack 的 Pipeline 抽象比 LangChain 更干净。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDSPy\u003c/strong\u003e（Stanford NLP）走了一条完全不同的路——它不是一个 Agent 运行时框架，而是一个 Prompt 优化框架。核心思想是把 Prompt 当作可学习的参数，通过编译和优化自动找到最佳 Prompt。适合对 Prompt 质量有极高要求的场景。\u003c/p\u003e\n\u003ch3\u003e5.3 框架选型决策树\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e你的核心需求是什么？\n│\n├─── 快速原型 / PoC\n│    └─→ LangChain（生态最大，上手最快）\n│\n├─── 复杂 Agent 逻辑（分支/循环/并行）\n│    └─→ LangGraph（状态机模型天然适合）\n│\n├─── 多 Agent 协作\n│    ├─── 角色扮演式 → CrewAI\n│    ├─── 对话式协作 → AutoGen\n│    └─── 图编排式   → LangGraph\n│\n├─── RAG / 知识问答\n│    ├─── 需要灵活性  → LangChain + Retriever\n│    └─── 需要干净抽象 → Haystack\n│\n├─── 企业级集成（.NET / Azure）\n│    └─→ Semantic Kernel\n│\n├─── Prompt 自动优化\n│    └─→ DSPy\n│\n└─── 生产系统（需要精细控制）\n     └─→ 自研，或只使用框架的底层模块\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e6. 框架 vs 自研的决策矩阵\u003c/h2\u003e\n\u003cp\u003e这是本文最重要的一节。不存在\u0026quot;框架一定好\u0026quot;或\u0026quot;自研一定好\u0026quot;的结论——关键是根据你的具体场景做出理性决策。\u003c/p\u003e\n\u003ch3\u003e6.1 决策矩阵\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e考量因素\u003c/th\u003e\n\u003cth\u003e倾向选框架\u003c/th\u003e\n\u003cth\u003e倾向选自研\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e项目阶段\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e原型验证、MVP\u003c/td\u003e\n\u003ctd\u003e生产系统、需要长期维护\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e团队规模\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e1-3 人小团队\u003c/td\u003e\n\u003ctd\u003e5+ 人专职 AI 团队\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e定制化程度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e标准 ReAct/RAG 模式\u003c/td\u003e\n\u003ctd\u003e有独特的控制流或状态管理需求\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e调试要求\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e能接受黑盒\u003c/td\u003e\n\u003ctd\u003e需要完全可观测、可追踪\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e性能要求\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e对 latency 不敏感\u003c/td\u003e\n\u003ctd\u003e需要极致优化每一毫秒\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e依赖容忍度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e能接受第三方依赖的版本变化\u003c/td\u003e\n\u003ctd\u003e需要完全掌控依赖\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e上线时间\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e2 周内上线\u003c/td\u003e\n\u003ctd\u003e3 个月以上的工程周期\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e团队 AI 经验\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e初次接触 Agent 开发\u003c/td\u003e\n\u003ctd\u003e对 Agent 架构有深入理解\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003ch3\u003e6.2 常见场景分析\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e场景 1：初创团队做 AI 产品的 MVP\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e推荐：LangChain（快速原型）→ 验证产品方向 → 决定是否重写\u003c/p\u003e\n\u003cp\u003e理由：此时最大的风险不是技术债，而是方向错误。花 3 个月自研一个完美的 Agent Runtime，结果发现用户不需要 Agent——这才是最大的浪费。用框架在 2 周内验证想法，确认方向后再决定技术路线。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e场景 2：大厂 AI 平台团队\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e推荐：自研核心 Runtime + 选择性使用框架的底层模块\u003c/p\u003e\n\u003cp\u003e理由：大厂有足够的工程资源，且对可靠性、可观测性、安全性的要求远超框架的默认支持。自研 Runtime 可以完全掌控控制循环、状态管理、错误处理、日志追踪。但可以借鉴框架的设计模式，或使用框架的工具集成层（比如 LangChain 的 Tool/Retriever 集成）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e场景 3：企业内部的 AI 助手\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e推荐：LangGraph（如果逻辑复杂）或 LangChain（如果逻辑简单）\u003c/p\u003e\n\u003cp\u003e理由：企业内部项目通常有明确的需求边界和合理的 SLA 要求，框架能满足大部分需求。LangGraph 的 Human-in-the-Loop 支持对企业审批流程特别有用。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e场景 4：研究实验\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e推荐：AutoGen 或自研轻量框架\u003c/p\u003e\n\u003cp\u003e理由：研究需要最大的灵活性来尝试新想法。框架的抽象可能限制实验空间。但如果实验涉及多 Agent 交互，AutoGen 的对话式抽象可以减少样板代码。\u003c/p\u003e\n\u003ch3\u003e6.3 一个务实的折中方案\u003c/h3\u003e\n\u003cp\u003e在实践中，最常见的成熟方案是\u003cstrong\u003e分层使用框架\u003c/strong\u003e：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e┌─────────────────────────────────────────────────┐\n│              你的应用层代码                        │\n│         (业务逻辑、API 接口、用户交互)              │\n├─────────────────────────────────────────────────┤\n│              自研 Agent Runtime                    │\n│    (控制循环、状态管理、错误处理、可观测性)          │\n├───────────────┬─────────────────────────────────┤\n│  自研工具调度   │   框架的集成模块（可选使用）       │\n│  自研消息管理   │   LangChain Tool/Retriever       │\n│  自研状态存储   │   LangChain Document Loader      │\n│               │   LangChain Embedding 接口        │\n├───────────────┴─────────────────────────────────┤\n│              LLM Provider SDK                     │\n│         (openai, anthropic, etc.)                 │\n└─────────────────────────────────────────────────┘\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e核心思路：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e控制循环自研\u003c/strong\u003e：这是 Agent 最核心的逻辑，也是最需要定制的部分。用 40-60 行 Python 就能实现一个健壮的控制循环（回顾第 07 篇）\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLLM 调用用原生 SDK\u003c/strong\u003e：OpenAI SDK 和 Anthropic SDK 本身就很好用，不需要再包一层\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e工具集成可以借用框架\u003c/strong\u003e：LangChain 的 Tool 生态确实强大。你可以只 \u003ccode\u003epip install langchain-community\u003c/code\u003e 来使用其预置工具，而不用采纳整个框架\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e状态管理自研\u003c/strong\u003e：根据你的持久化需求（Redis、PostgreSQL、内存）定制\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e这个方案的好处是：你在最关键的层面保留了完全掌控力，同时在最不需要掌控的层面（第三方服务的集成）借助了框架的生态。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e7. 框架的正确使用姿势\u003c/h2\u003e\n\u003cp\u003e无论你最终选择什么方案，以下原则都适用。\u003c/p\u003e\n\u003ch3\u003e7.1 理解原理再用框架\u003c/h3\u003e\n\u003cp\u003e这正是本系列前 7 篇文章的价值。当你理解了控制循环的六个阶段、Tool Calling 的 JSON Schema 契约、Memory 的分层架构之后，框架在你眼中就不再是黑盒——它只是这些原理的一种实现。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e不理解原理时使用框架：\n    框架 = 黑魔法（出错时手足无措）\n\n理解原理后使用框架：\n    框架 = 已知原理的一种实现（出错时知道去哪里找原因）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e具体来说：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e当 LangChain 的 \u003ccode\u003eAgentExecutor\u003c/code\u003e 出错时，你知道它内部在跑一个控制循环，可以猜测问题出在哪个阶段\u003c/li\u003e\n\u003cli\u003e当 LangGraph 的状态转移出现异常时，你知道这本质上是一个状态机的转移条件判断错误\u003c/li\u003e\n\u003cli\u003e当框架的 Memory 管理不符合你的需求时，你知道自己需要什么样的记忆架构，可以替换或扩展\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e7.2 不要被框架限制思维\u003c/h3\u003e\n\u003cp\u003e框架提供了一组默认的设计模式。这些模式覆盖了 80% 的常见场景，但你的场景可能落在剩下的 20%。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e反模式\u003c/strong\u003e：为了适配框架的抽象而扭曲自己的业务逻辑。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 反模式：业务逻辑需要 Agent 在两个工具的结果之间做比较，\n# 但框架不直接支持，于是你\u0026quot;发明\u0026quot;了一个假工具来绕过限制\n\n@tool\ndef compare_results(result_a: str, result_b: str) -\u0026gt; str:\n    \u0026quot;\u0026quot;\u0026quot;比较两个结果（实际上这应该是 Agent 内部的推理逻辑，不是工具）\u0026quot;\u0026quot;\u0026quot;\n    # 这不应该是一个 Tool —— 这是把框架的抽象当成了唯一的解法\n    return llm.invoke(f\u0026quot;比较: {result_a} vs {result_b}\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e正确做法\u003c/strong\u003e：框架不支持的逻辑，用原生代码实现，然后插入到框架的流程中（或者干脆不用框架处理这部分）。\u003c/p\u003e\n\u003ch3\u003e7.3 框架代码是最好的学习材料\u003c/h3\u003e\n\u003cp\u003e即使你决定自研，框架的源码仍然是宝贵的学习资源。以下是几个值得阅读的代码文件：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLangGraph 的 \u003ccode\u003eStateGraph\u003c/code\u003e\u003c/strong\u003e：理解如何用 Python 实现一个状态机运行时\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLangChain 的 \u003ccode\u003eToolNode\u003c/code\u003e\u003c/strong\u003e：理解如何将 LLM 的 tool_call 输出映射为实际的函数调用\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLangChain 的 \u003ccode\u003eChatOpenAI\u003c/code\u003e\u003c/strong\u003e：理解如何封装 LLM Provider 的 API 差异\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLangGraph 的 \u003ccode\u003eMemorySaver\u003c/code\u003e\u003c/strong\u003e：理解 checkpoint 和状态持久化的实现\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e阅读源码时，关注的不是具体的 API，而是\u003cstrong\u003e设计决策\u003c/strong\u003e：为什么这样抽象？这个 trade-off 是什么？有没有更好的方案？\u003c/p\u003e\n\u003ch3\u003e7.4 随时准备好替换或去掉框架\u003c/h3\u003e\n\u003cp\u003e一个健康的架构应该允许你在不重写业务逻辑的情况下替换底层框架。实现方式：\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# 定义你自己的接口（不依赖任何框架）\nfrom abc import ABC, abstractmethod\n\nclass BaseLLM(ABC):\n    @abstractmethod\n    def chat(self, messages: list[dict], tools: list[dict] | None = None) -\u0026gt; dict:\n        ...\n\nclass BaseToolExecutor(ABC):\n    @abstractmethod\n    def execute(self, tool_name: str, args: dict) -\u0026gt; str:\n        ...\n\nclass BaseMemory(ABC):\n    @abstractmethod\n    def get_messages(self, limit: int = 20) -\u0026gt; list[dict]:\n        ...\n    @abstractmethod\n    def add_message(self, message: dict) -\u0026gt; None:\n        ...\n\n\n# 框架实现（可替换）\nclass LangChainLLM(BaseLLM):\n    def __init__(self):\n        from langchain_openai import ChatOpenAI\n        self._llm = ChatOpenAI(model=\u0026quot;gpt-4o\u0026quot;)\n\n    def chat(self, messages, tools=None):\n        # 将你的接口适配为 LangChain 接口\n        ...\n\n# 原生实现（可替换）\nclass NativeLLM(BaseLLM):\n    def __init__(self):\n        import openai\n        self._client = openai.OpenAI()\n\n    def chat(self, messages, tools=None):\n        response = self._client.chat.completions.create(\n            model=\u0026quot;gpt-4o\u0026quot;, messages=messages, tools=tools\n        )\n        ...\n\n\n# 你的 Agent 代码只依赖自己的接口\nclass MyAgent:\n    def __init__(self, llm: BaseLLM, tools: BaseToolExecutor, memory: BaseMemory):\n        self.llm = llm\n        self.tools = tools\n        self.memory = memory\n\n    def run(self, user_input: str) -\u0026gt; str:\n        # 业务逻辑不依赖任何框架\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e这不是过度设计——这是\u003cstrong\u003e依赖倒置原则\u003c/strong\u003e在 Agent 架构中的直接应用。当框架发生 breaking change（LangChain 几乎每季度都有）时，你只需要修改适配层，而不是重写整个系统。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e8. LangChain vs LangGraph：直接对比\u003c/h2\u003e\n\u003cp\u003e最后，用一张表格直接对比 LangChain 和 LangGraph 在各维度的差异：\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e维度\u003c/th\u003e\n\u003cth\u003eLangChain\u003c/th\u003e\n\u003cth\u003eLangGraph\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e核心抽象\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eChain（线性管道）\u003c/td\u003e\n\u003ctd\u003eGraph（有向状态机）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e控制流表达\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e线性为主，分支/循环需要 hack\u003c/td\u003e\n\u003ctd\u003e天然支持分支、循环、并行\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e状态管理\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e隐式（框架内部管理）\u003c/td\u003e\n\u003ctd\u003e显式（开发者定义 State 类型）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e学习曲线\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e低（上手快）\u003c/td\u003e\n\u003ctd\u003e中等（需要理解状态机概念）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e调试体验\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e差（多层抽象遮蔽错误源）\u003c/td\u003e\n\u003ctd\u003e中等（图结构可视化，但状态流转需追踪）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e适合场景\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e简单 Agent、RAG、原型验证\u003c/td\u003e\n\u003ctd\u003e复杂 Agent、多 Agent、Human-in-the-Loop\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e生态集成\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e最丰富\u003c/td\u003e\n\u003ctd\u003e继承 LangChain 生态\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eHuman-in-the-Loop\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e不原生支持\u003c/td\u003e\n\u003ctd\u003e原生 Checkpoint + Interrupt 支持\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e多 Agent\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e需要自行编排\u003c/td\u003e\n\u003ctd\u003e原生支持子图嵌套\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e生产就绪度\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e中等（需要大量自定义）\u003c/td\u003e\n\u003ctd\u003e较高（状态持久化、检查点内置）\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e灵活性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e框架约束多，突破框架难\u003c/td\u003e\n\u003ctd\u003e图定义灵活，但需要提前规划\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e版本稳定性\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e差（API 频繁变更）\u003c/td\u003e\n\u003ctd\u003e较好（API 相对稳定）\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e：如果 LangChain 是一条\u003cstrong\u003e传送带\u003c/strong\u003e（把东西从 A 运到 B），那么 LangGraph 就是一张\u003cstrong\u003e铁路网\u003c/strong\u003e（可以在任意站点之间调度列车）。传送带简单高效，铁路网灵活强大——选哪个取决于你要运的东西有多复杂。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e9. 结语与进一步思考\u003c/h2\u003e\n\u003ch3\u003e核心立场回顾\u003c/h3\u003e\n\u003cp\u003e本文的核心立场可以用三句话概括：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e框架是加速器，不是必需品。\u003c/strong\u003e 它加速了开发，但也隐藏了复杂性。当隐藏的复杂性成为你的瓶颈时，框架就从加速器变成了减速器。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e理解原理比掌握框架更重要。\u003c/strong\u003e 框架会变（LangChain 已经经历了多次 API 大改），但控制循环、状态管理、工具调用的基本原理不会变。前 7 篇文章构建的知识，是你评估和使用任何框架的基础。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e最好的架构是\u0026quot;框架可替换\u0026quot;的架构。\u003c/strong\u003e 把框架当作可插拔的实现层，而不是系统的骨架。你的业务逻辑应该依赖自己定义的接口，而不是某个框架的 API。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e框架解决了\u0026quot;怎么写\u0026quot;，协议解决\u0026quot;怎么连接\u0026quot;\u003c/h3\u003e\n\u003cp\u003e框架帮你解决了一个 Agent 内部的组件编排问题：如何组织 LLM 调用、工具执行、状态管理。但当你有多个 Agent、多个工具提供者、多个模型时，一个更根本的问题浮现出来：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这些组件之间用什么协议通信？工具如何被发现和注册？能力如何被声明和协商？\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e这不是框架能解决的问题——这需要\u003cstrong\u003e协议（Protocol）\u003c/strong\u003e。下一篇我们将讨论 MCP（Model Context Protocol），看看 Agent 工具生态的协议化未来。\u003c/p\u003e\n\u003ch3\u003e留给读者的思考\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e关于框架的未来\u003c/strong\u003e：LLM 本身的能力在快速增强。当模型原生支持复杂的多步推理（如 o1/o3 的 chain-of-thought）、原生支持长对话记忆（如 Gemini 的长上下文窗口）、原生支持工具调用时，框架的价值会被压缩还是放大？换句话说——当 LLM 足够强时，我们还需要框架在中间做多少事？\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于抽象的代价\u003c/strong\u003e：每一层抽象都在隐藏复杂性。隐藏复杂性是好事（让你专注于业务逻辑），但也是坏事（让你在出问题时无法理解系统行为）。在 Agent 这样本身就充满不确定性的系统中，你能接受多少\u0026quot;隐藏的复杂性\u0026quot;？\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e关于生态锁定\u003c/strong\u003e：选择一个框架意味着接受它的抽象、它的生态、它的更新节奏、它的设计理念。当框架的方向与你的需求分叉时，迁移的成本有多高？这个成本是否在你的决策时被低估了？\u003c/p\u003e\n\u003cp\u003e这些问题没有标准答案。但作为 AI 工程师，能够清晰地提出这些问题，本身就是一种重要的能力。\u003c/p\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e系列导航\u003c/strong\u003e：本文是 Agentic 系列的第 12 篇。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e上一篇：\u003ca href=\"/blog/engineering/agentic/11-Multi-Agent%20Collaboration\"\u003e11 | Multi-Agent Collaboration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e下一篇：\u003ca href=\"/blog/engineering/agentic/13-MCP%20and%20Tool%20Protocol\"\u003e13 | MCP and Tool Protocol\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e完整目录：\u003ca href=\"/blog/engineering/agentic/01-From%20LLM%20to%20Agent\"\u003e01 | From LLM to Agent\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"article\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center mb-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-4 h-4 mr-2 text-gray-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z\"}]}],[\"$\",\"time\",null,{\"dateTime\":\"2026-01-17\",\"children\":\"2026年01月17日\"}]]}]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-6 text-center\",\"children\":\"Multi-Agent Collaboration: 多 Agent 协作模式与架构\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6 justify-center\",\"children\":[[\"$\",\"$L5\",\"Agentic\",{\"href\":\"/blog/tag/Agentic/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Agentic\"}],[\"$\",\"$L5\",\"AI Engineering\",{\"href\":\"/blog/tag/AI%20Engineering/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"AI Engineering\"}],[\"$\",\"$L5\",\"Multi-Agent\",{\"href\":\"/blog/tag/Multi-Agent/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"Multi-Agent\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto\",\"children\":[\"$\",\"$L14\",null,{\"content\":\"$15\"}]}],[\"$\",\"$11\",null,{\"fallback\":[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":\"加载导航中...\"}],\"children\":[\"$\",\"$L16\",null,{\"globalNav\":{\"prev\":{\"slug\":\"engineering/agentic/10-Planning and Reflection\",\"title\":\"Planning and Reflection: 从 ReAct 到分层规划与自我纠错\",\"description\":\"Agentic 系列第 10 篇。深入剖析 Agent 规划（Planning）与反思（Reflection）的核心机制——从 ReAct 的交替推理、Plan-and-Execute 的全局视野、Tree-of-Thought 的多路径搜索，到分层规划的递归分解，再到结构化反思与自我纠错。包含完整 Python 实现、决策分析与 trade-off 讨论。\",\"pubDate\":\"2026-01-12\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Planning\"],\"heroImage\":\"$undefined\",\"content\":\"$17\"},\"next\":{\"slug\":\"engineering/agentic/12-LangChain vs LangGraph\",\"title\":\"LangChain vs LangGraph: 框架的价值与边界\",\"description\":\"Agentic 系列第 12 篇。客观审视 AI Agent 框架的价值与局限。深入分析 LangChain 的抽象模型与陷阱、LangGraph 的状态机优势与学习曲线，横向对比 CrewAI、AutoGen、Semantic Kernel 等框架，最终给出框架 vs 自研的决策矩阵。核心立场：理解原理再用框架，框架是加速器而非必需品。\",\"pubDate\":\"2026-01-22\",\"tags\":[\"Agentic\",\"AI Engineering\",\"Framework\"],\"heroImage\":\"$undefined\",\"content\":\"$18\"}},\"tagNav\":{\"Agentic\":{\"prev\":\"$6:props:children:props:children:props:children:2:props:children:props:globalNav:prev\",\"next\":\"$6:props:children:props:children:props:children:2:props:children:props:globalNav:next\"},\"AI Engineering\":{\"prev\":\"$6:props:children:props:children:props:children:2:props:children:props:globalNav:prev\",\"next\":\"$6:props:children:props:children:props:children:2:props:children:props:globalNav:next\"},\"Multi-Agent\":{\"prev\":null,\"next\":null}}}]}],[\"$\",\"$L19\",null,{}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"9:null\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n8:null\n"])</script><script>self.__next_f.push([1,"b:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Multi-Agent Collaboration: 多 Agent 协作模式与架构 - Skyfalling Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Multi-Agent Collaboration: 多 Agent 协作模式与架构\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"5\",{\"property\":\"article:published_time\",\"content\":\"2026-01-17\"}],[\"$\",\"meta\",\"6\",{\"property\":\"article:author\",\"content\":\"Skyfalling\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Multi-Agent Collaboration: 多 Agent 协作模式与架构\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"单个 Agent 的能力有天花板——Context Window 有限、专业化受限、单点故障、串行瓶颈。本文系统拆解多 Agent 协作的四种核心模式（Supervisor-Worker、Peer-to-Peer、Pipeline、Dynamic Routing），深入 Agent 间通信机制、状态管理、错误处理与成本控制，并用 Python 从零实现一个 Supervisor-Worker 协作框架。\"}],[\"$\",\"link\",\"10\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"13\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"13:{\"metadata\":\"$b:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>