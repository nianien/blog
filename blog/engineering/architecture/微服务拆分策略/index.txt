1:"$Sreact.fragment"
2:I[10616,["6874","static/chunks/6874-7791217feaf05c17.js","7177","static/chunks/app/layout-142e67ac4336647c.js"],"default"]
3:I[87555,[],""]
4:I[31295,[],""]
6:I[59665,[],"OutletBoundary"]
9:I[74911,[],"AsyncMetadataOutlet"]
b:I[59665,[],"ViewportBoundary"]
d:I[59665,[],"MetadataBoundary"]
f:I[26614,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/129144073acbb2fa.css","style"]
0:{"P":null,"b":"6jwsMkq47CAcxpAFlh3iK","p":"","c":["","blog","engineering","architecture","%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%E7%AD%96%E7%95%A5",""],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","engineering/architecture/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%E7%AD%96%E7%95%A5","c"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/129144073acbb2fa.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"zh-CN","children":["$","body",null,{"className":"__className_f367f3","children":["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"bg-[var(--background)]","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 py-12 lg:px-8","children":["$","p",null,{"className":"text-center text-xs leading-5 text-gray-400","children":["© ",2026," Skyfalling"]}]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","engineering/architecture/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%E7%AD%96%E7%95%A5","c"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5",null,["$","$L6",null,{"children":["$L7","$L8",["$","$L9",null,{"promise":"$@a"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","WOt08499Rh0N4CtoUlL0hv",{"children":[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Ld",null,{"children":"$Le"}]]}],false]],"m":"$undefined","G":["$f","$undefined"],"s":false,"S":true}
10:"$Sreact.suspense"
11:I[74911,[],"AsyncMetadata"]
13:I[6874,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],""]
14:I[32923,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
16:I[40780,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
1b:I[85300,["6874","static/chunks/6874-7791217feaf05c17.js","968","static/chunks/968-d7155a2506e36f1d.js","6909","static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js"],"default"]
e:["$","div",null,{"hidden":true,"children":["$","$10",null,{"fallback":null,"children":["$","$L11",null,{"promise":"$@12"}]}]}]
15:T22ab,<p>前面我们学习了微服务的全景架构，了解到相对于传统单体架构，微服务的优势，以及系统服务化的发展趋势。</p>
<p>对于新启动的项目，我们在权衡之后可以大方的使用微服务架构。但其实大部分情况下，我们还要去维护一些以前研发的单体系统，这些系统可能因为访问流量的膨胀、功能的扩张而显得非常臃肿不堪，急需要向微服务架构迁移。</p>
<h3>1 微服务迁移准备  <a href="#scroller-1" id="scroller-1"></a></h3>
<p>1、需对业务充分了解，这是服务拆分，通信设计，资源整合的必要前提。</p>
<p>2、适应微服务架构设计原则：小版本，高速迭代。</p>
<p>3、快速的环境提供能力：依赖于云计算、容器技术，快速交付环境。</p>
<p>4、服务合理拆分：需符合团队结构或能逆向影响，能对组织架构进行微调并划分职责。（康威定律和逆康威定律）</p>
<p>5、基本的监控能力：包括基础的技术监控和业务监控。</p>
<p>6、快速的应用部署能力：需要部署管道提供快速的部署能力。</p>
<p>7、DevOps 自动化运维能力：需要具有良好的持续集成和持续交付能力，还需要对问题、故障的快速响应能力，开发、测试和运维能协同工作。</p>
<h3>2 微服务颗粒的拆分策略 <a href="#scroller-2" id="scroller-2"></a></h3>
<p>前面两篇文章我们学习了What &amp; Why（什么是微服务和为什么需要做微服务架构），这一章我们就来探讨如何做微服务架构的拆分（How）。</p>
<p>微服务拆分没有一个绝对的标准答案，服务拆分的粒度需要根据业务场景来规划，而随着业务的发展，原先的架构方案也需要做调整。</p>
<p>虽然没有固定的套路，但是我们在业务实践过程中总结的一些经验，以做参考。</p>
<h4>2.1 基于业务逻辑拆分 <a href="#scroller-3" id="scroller-3"></a></h4>
<p>基于业务逻辑拆分相对好理解一点，典型的单一职责原则，我们将功能相近的业务整合到一个服务颗粒上。比如一个办公领域系统，考勤、工作流、音视频会议是是三个截然不同的业务领域，这可能就是我们拆分的一个入手点。</p>
<p><strong>2.1.1 领域模型拆分</strong></p>
<p>领域驱动设计DDD（Domain-Driven Design 领域驱动设计）是一个很简单的概念，表示我们对系统的划分是基于领域的，也即是基于业务方向去思考的。</p>
<p>举一个典型的电商业务例子。电商的业务体系庞大，涉及各方面的细节。但是我们大概能够根据业务的职能做一个拆分，比如阿里的电商中台业务，包含 用户账号子系统、商品子系统、订单子系统、客户子系统、物流子系统 等。</p>
<p>因为职能不同，这些领域之间包含清晰的界限，所以我们可以按照这个方向将服务于不同领域（商品域和订单域）的子系统拆成独立的服务颗粒。如下图：</p>
<p><img src="/images/blog/engineering/microservice-image_6_7.png" alt="image_6_7.png"></p>
<p><strong>2.1.2 用户群体拆分</strong></p>
<p>根据用户群体做拆分，我们首先要了解自己的系统业务里的用户角色领域是否没有功能耦合，有清晰的领域界限。</p>
<p>比如教育信息化系统，教师的业务场景和学生的业务场景，基本比较独立，而且拆分后流量上有明显的削弱，这时候结合具体的业务分析，看是否有价值。如下图所示：</p>
<p><img src="/images/blog/engineering/microservice-image_4_2.png" alt="image_4_2.png"></p>
<h4>2.2 基于可扩展拆分  <a href="#scroller-6" id="scroller-6"></a></h4>
<p>这个需要区分系统中变与不变的部分，不变的部分一般是成熟的、通用的服务功能，变的部分一般是改动比较多、满足业务迭代扩展性需要的功能，我们可以将不变的部分拆分出来，作为共用的服务，将变的部分独立出来满足个性化扩展需要。同时根据二八原则，系统中经常变动的部分大约只占 20%，而剩下的 80% 基本不变或极少变化，这样的拆分也解决了发布频率过多而影响成熟服务稳定性的问题。比如一个电商领域的系统，用户信息、基本商品信息、物流信息 等模块的管理能力和视图界面，一般是比较稳定的；而类似运营活动的功能和页面一般是经常变化的（520、618、双11），会有不同的活动策略和视图界面，需要经常迭代发布。如下图所示</p>
<p><img src="/images/blog/engineering/microservice-image_4_3.png" alt="image_4_3.png"></p>
<h4>2.3 基于可靠性拆分 <a href="#scroller-7" id="scroller-7"></a></h4>
<p><strong>2.3.1 核心模块拆分</strong></p>
<p>我们团队在做MySQL数据库和Redis集群拆分的时候，总会把一些重要的模块独立放在一个集群上，不与其他模块混用，而这个独立的集群，服务机性能要是最好的。这样做的目的是，当重要度较低的模块发生故障时，不会影响重要度高的模块。</p>
<p>同要的道理，我们会将  账号信息、登录信息、服务中心等重要度最高的要害模块单独拆分在一个服务颗粒上（因为这类模块不可用之后，整个系统基本完全瘫痪），再做成服务集群，来保障它的高可用。 如下图所示：</p>
<p><img src="/images/blog/engineering/microservice-image_4_4.png" alt="image_4_4.png"></p>
<p><strong>2.3.2 主次链路拆分</strong></p>
<p>在各个业务系统中，其实都会有主次业务链路。主业务链条，完成了业务系统中最核心的那部分工作。而次链路是保证其他基础功能的稳定运行。</p>
<p>以电商为例子：商品搜索-&gt;商品详情页-&gt;购物车模块-&gt;订单结算-&gt;支付业务，就是一条最简单的主链路。主链路是整个系统的核心主战场，最好的资源跟火力都要放在这里，保证不失守。</p>
<p>一个系统一般有多条核心链路和多条次链路，互相支持构成一个完整的系统。而我们将主次链路进行拆分，主要为了以下几个目标。</p>
<p><strong>异常容错</strong></p>
<p>为主链路建立层次化的降级策略（多级降级），以及合理的熔断策略，这部分我们将在Hystrix服务容错降级的文章中详细解释。</p>
<p><strong>计算资源分配</strong></p>
<p>主链路通常来讲都是高频场景，自然需要更多的计算资源，最主要的体现就是集群里分配的虚机数量多。比如电商场景中特惠专场抢购等。</p>
<p>但是无论是虚机的分配，还是kubernetes的动态扩缩容，应该都需要单独优待，如资源分配倾斜，独立治理等。</p>
<p><strong>服务隔离</strong></p>
<p>主链路是高频且核心的主业务模块，把主链路的服务与其他起辅助作用的业务服务隔离开来，避免次链路服务的异常情况影响到主链路服务。</p>
<p><img src="/images/blog/engineering/microservice-image_4_5.png" alt="image_4_5.png"></p>
<h4>2.4 基于性能需求拆分 <a href="#scroller-10" id="scroller-10"></a></h4>
<p>根据性能需求来进行拆分。简单来说就是访问量特别大，访问频率特别高的业务，又要保证高效的响应能力，这些业务对性能的要求特别高。比如积分竞拍、低价秒杀、限量抢购。</p>
<p>我们要识别出某些超高并发量的业务，尽可能把这部分业务独立拆分出来。这么做的原因非常简单，一个保证满足高性能业务需求，另一个保证业务的独立性，不互相影响。</p>
<p>类似积分竞拍、超低价秒杀、限量抢购，对瞬间峰值和计算性能要求是非常高的。这部分的业务如果跟其他通用业务放在一块，一个是可能互相影响，比如某个链路阻塞，会导致雪崩沿调用链向上传递。</p>
<p>另外一个是如果多个业务耦合在一块，发布频率变高、服务扩缩容变难、维护复杂度变高。</p>
<p><img src="/images/blog/engineering/microservice-image_4_6.png" alt="image_4_6.png"></p>
<h3>3 总结拆分原则 <a href="#scroller-11" id="scroller-11"></a></h3>
<ul>
<li>先少后多（微服务数量）、先粗后细(粒度)</li>
<li>基于业务逻辑进行拆分（用户群体、业务领域等模型）</li>
<li>基于可靠性（核心模块独立化、主次链路隔离）</li>
<li>基于性能拆分（独立拆分高性能场景）</li>
<li>接口需保证幂等</li>
<li>接口数据定义严禁内嵌，透传</li>
<li>规范化工程结构，符合微服务风格</li>
<li>不止对计算服务记性拆分，服务层 -&gt; 缓存层 -&gt; 数据层 的逐步拆解，才能发挥最大功效。</li>
</ul>
17:T4fc2,<h3>1 微服务优势与挑战 <a href="#scroller-1" id="scroller-1"></a></h3>
<h4>1.1 微服务的优势 <a href="#scroller-2" id="scroller-2"></a></h4>
<p><strong>1.1.1 单一职责</strong></p>
<p>微服务架构中的每个节点高度服务化，都是具有业务逻辑的，符合高内聚、低耦合原则以及单一职责原则的单元，包括数据库和数据模型；不同的服务通过“管道”的方式灵活组合，从而构建出庞大的系统。</p>
<p><strong>1.1.2 轻量级通信</strong></p>
<p>通过REST API模式或者RPC框架，事件流和消息代理的组合相互通信，实现服务间互相协作的轻量级通信机制。</p>
<p><strong>1.1.3 独立性</strong></p>
<p>在微服务架构中，每个服务都是独立的业务单元，与其他服务高度解耦，只需要改变当前服务本身，就可以完成独立的开发、测试、部署、运维。</p>
<p><strong>1.1.4 进程隔离</strong></p>
<p>在微服务架构中，应用程序由多个服务组成，每个服务都是高度自治的独立业务实体，可以运行在独立的进程中，不同的服务能非常容易地部署到不同的主机上，实现高度自治和高度隔离。进程的隔离，还能保证服务达到动态扩缩容的能力，业务高峰期自动增加服务资源以提升并发能力，业务低谷期则可自动释放服务资源以节省开销。</p>
<p><strong>1.1.5 混合技术栈和混合部署方式</strong></p>
<p>团队可以为不同的服务组件使用不同的技术栈和不同的部署方式（公有云、私有云、混合云）。</p>
<p><strong>1.1.6 简化治理</strong></p>
<p>组件可以彼此独立地进行缩放，从而减少了因必须缩放整个应用程序而产生的浪费和成本，独立的发布、服务治理。</p>
<p><strong>1.1.7 安全可靠，可维护。</strong></p>
<p>从架构上对运维提供友好的支撑，在安全、可维护的基础上规范化发布流程，支持数据存储容灾、业务模块隔离、访问权限控制、编码安全检测等。</p>
<h4>1.2 面临的挑战 <a href="#scroller-10" id="scroller-10"></a></h4>
<p><strong>1.2.1 分布式固有复杂性</strong></p>
<p>微服务架构是基于分布式的系统，而构建分布式系统必然会带来额外的开销。</p>
<ul>
<li>性能： 分布式系统是跨进程、跨网络的调用，受网络延迟和带宽的影响。</li>
<li>可靠性： 由于高度依赖于网络状况，任何一次的远程调用都有可能失败，随着服务的增多还会出现更多的潜在故障点。因此，如何提高系统的可靠性、降低因网络引起的故障率，是系统构建的一大挑战。</li>
<li>分布式通信： 分布式通信大大增加了功能实现的复杂度，并且伴随着定位难、调试难等问题。</li>
<li>数据一致性： 需要保证分布式系统的数据强一致性，即在 C（一致性）A（可用性）P（分区容错性） 三者之间做出权衡。这块可以参考我的这篇《<a href="https://www.cnblogs.com/wzh2010/p/15311142.html">分布式事务</a>》。</li>
</ul>
<p><strong>1.2.2 服务的依赖管理和测试</strong></p>
<p>在单体应用中，通常使用集成测试来验证依赖是否正常。而在微服务架构中，服务数量众多，每个服务都是独立的业务单元，服务主要通过接口进行交互，如何保证它的正常，是测试面临的主要挑战。</p>
<p>所以单元测试和单个服务链路的可用性非常重要。</p>
<p><strong>1.2.3 有效的配置版本管理</strong></p>
<p>在单体系统中，配置可以写在yaml文件，分布式系统中需要统一进行配置管理，同一个服务在不同的场景下对配置的值要求还可能不一样，所以需要引入配置的版本管理、环境管理。</p>
<p><strong>1.2.4 自动化的部署流程</strong></p>
<p>在微服务架构中，每个服务都独立部署，交付周期短且频率高，人工部署已经无法适应业务的快速变化。有效地构建自动化部署体系，配合服务网格、容器技术，是微服务面临的另一个挑战。</p>
<p><strong>1.2.5 对于DevOps更高的要求</strong></p>
<p>在微服务架构的实施过程中，开发人员和运维人员的角色发生了变化，开发者也将承担起整个服务的生命周期的责任，包括部署、链路追踪、监控；因此，按需调整组织架构、构建全功能的团队，也是一个不小的挑战。</p>
<p><strong>1.2.6 运维成本</strong></p>
<p>运维主要包括配置、部署、监控与告警和日志收集四大方面。微服务架构中，每个服务都需要独立地配置、部署、监控和收集日志，成本呈指数级增长。</p>
<p>服务化粒度越细，运维成本越高。</p>
<p>怎样去解决这些问题，是微服务架构必须面临的挑战。</p>
<h3>2 微服务全景架构 <a href="#scroller-17" id="scroller-17"></a></h3>
<p><img src="/images/blog/engineering/microservice-image_1_1.png" alt="image_1_1.png"></p>
<h3>3 微服务核心组件 <a href="#scroller-19" id="scroller-19"></a></h3>
<p>微服务架构核心组件包括：</p>
<table>
<thead>
<tr>
<th><strong>组件名</strong></th>
</tr>
</thead>
<tbody><tr>
<td>服务注册与发现</td>
</tr>
<tr>
<td>API 网关服务</td>
</tr>
<tr>
<td>分布式配置中心</td>
</tr>
<tr>
<td>服务通信</td>
</tr>
<tr>
<td>服务治理</td>
</tr>
<tr>
<td>服务监控</td>
</tr>
<tr>
<td>分布式服务追踪</td>
</tr>
</tbody></table>
<h4>3.1 服务注册与发现 <a href="#scroller-20" id="scroller-20"></a></h4>
<p><strong>3.1.1 原理图</strong></p>
<p><img src="/images/blog/engineering/microservice-image_1_2.png" alt="image_1_2.png"></p>
<p>服务注册与发现三要素：</p>
<ul>
<li>Provider：服务的提供方</li>
<li>Consumer：调用远程服务的服务消费方</li>
<li>Registry：服务注册和发现的注册中心</li>
</ul>
<p><strong>3.1.2 注册中心的原理、流程</strong></p>
<p>1、 Provider(服务提供者)绑定指定端口并启动服务</p>
<p>2、提供者连接注册中心，并发本机 IP、端口、应用信息和服务信息发送至注册中心存储</p>
<p>3、Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心</p>
<p>4、注册中心根据消费者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。</p>
<p>5、Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。</p>
<p>6、Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer设计的原因：</p>
<p>Consumer 与 Provider 解偶，双方都可以横向增减节点数。注册中心对本身可做对等集群，可动态增减节点，并且任意一台宕掉后，将自动切换到另一台</p>
<p>7、去中心化，双方不直接依赖注册中心，即使注册中心全部宕机短时间内也不会影响服务的调用（Consumer应用缓存中保留提供者 Provider 列表）</p>
<p>8、服务提供者无状态，任意一台宕掉后，不影响使用</p>
<p>注册中心包含如下功能：注册中心、服务注册和反注册、心跳监测与汇报、服务订阅、服务变更查询、集群部署、服务健康状态检测、服务状态变更通知 等</p>
<p>我们有很多种注册中心的技术，Zookeeper、Etcd、Consul、Eureka 4种比较常用，如下</p>
<table>
<thead>
<tr>
<th></th>
<th>Zookeeper</th>
<th>Etcd</th>
<th>Consul</th>
<th>Eureka</th>
</tr>
</thead>
<tbody><tr>
<td>CAP模型</td>
<td>CP</td>
<td>CP</td>
<td>CP</td>
<td>AP</td>
</tr>
<tr>
<td>数据一致性算法</td>
<td>ZAB</td>
<td>Raft</td>
<td>Raft</td>
<td>❌</td>
</tr>
<tr>
<td>多数据中心</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>多语言支持</td>
<td>客户端</td>
<td>Http/gRPC</td>
<td>Http/DNS</td>
<td>Http</td>
</tr>
<tr>
<td>Watch</td>
<td>TCP</td>
<td>Long Polling</td>
<td>Long Polling</td>
<td>Long Polling</td>
</tr>
<tr>
<td>KV存储</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>服务健康检查</td>
<td>心跳</td>
<td>心跳</td>
<td><p>服务状态，<br>内存，硬盘等</p></td>
<td>自定义</td>
</tr>
<tr>
<td>自身监控</td>
<td>❌</td>
<td>metrics</td>
<td>metrics</td>
<td>metrics</td>
</tr>
<tr>
<td>SpringCloud 支持</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>自身开发语言</td>
<td>Java</td>
<td>Go</td>
<td>Go</td>
<td>Java</td>
</tr>
</tbody></table>
<p>分布式系统中CAP模型3者不可兼得。由于网络的原因，分布式系统中P是必备的，意味着只能选择 AP 或者 CP。CP 代表数据一致性是第一位的，AP 代表可用性是第一位的。</p>
<p>Zookeeper、Etcd、Consul 是 CP 型注册中心，牺牲可用性来保证数据强一致性</p>
<p>Eureka 是 AP 型注册中心，牺牲一致性来保证可用性</p>
<h4>3.2 API 网关服务 <a href="#scroller-23" id="scroller-23"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_1_3.png" alt="image_1_3.png"></p>
<p>上面是Api网关服务的基本架构：用户的请求经过统一的Api网关来访问微服务里具体的服务颗粒，并且可能产生串联的链路服务调用。</p>
<p>有很多耳熟能详的API网关技术，比如 Zuul、Kong、Tyk等，提供了服务路由在内的很多通用功能，后面会有专门的章节来说这个。</p>
<p>Tyk：Tyk是一个开放源码的API网关，它是快速、可扩展和现代的。Tyk提供了一个API管理平台，其中包括API网关、API分析、开发人员门户和API管理面板。Try 是一个基于Go实现的网关服务。</p>
<p>Kong：Kong是一个可扩展的开放源码API Layer(也称为API网关或API中间件)。Kong 在任何RESTful API的前面运行，通过插件扩展，它提供了超越核心平台的额外功能和服务。</p>
<p>Netflix zuul：Zuul是一种提供动态路由、监视、弹性、安全性等功能的边缘服务。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。</p>
<p>除了路由之外，Api网关服务还包含：认证和授权，重试、熔断、降级，负载均衡，日志、监控、链路追踪，灰度发布，ABTesting 等功能。</p>
<h4>3.3 配置中心 <a href="#scroller-24" id="scroller-24"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_1_4.png" alt="image_1_4.png"></p>
<p>上面这个是携程的开源配置中心Apollo系统的架构设计，我们从下往上进行分析：</p>
<p>1、Config Service提供配置的读取、推送等功能，服务对象是Apollo客户端</p>
<p>2、Admin Service提供配置的修改、发布等功能，服务对象是Apollo Portal（管理界面）</p>
<p>3、Config Service和Admin Service都是多实例、无状态部署，所以需要将自己注册到Eureka中并保持心跳，支持注册、更新、删除能力</p>
<p>4、在Eureka之上我们架了一层Meta Server用于封装Eureka的服务发现接口</p>
<p>5、Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做load balance、错误重试</p>
<p>6、Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做load balance、错误重试</p>
<p>7、为了简化部署，我们实际上会把Config Service、Eureka和Meta Server三个逻辑角色部署在同一个JVM进程中</p>
<p>上面的架构体现了如下特点：</p>
<p>•高可用：配置服务为多实例部署，访问层保证 load balance、错误重试 •弱依赖：使用了Eureka来做配置中心的服务注册，如果出现问题或者网络出现问题的时候，服务应该可以依赖于它本身所缓存的配置来提供正常的服务</p>
<h4>3.4 服务通信 <a href="#scroller-25" id="scroller-25"></a></h4>
<p>分布式系统一般是由多个微服务颗粒组成的，微服务与微服务之前存在互相调用，甚至多个链路访问的情况。所以他们之间是需要通信的，通信方式继承于SOA，包含同步与异步两种模式。</p>
<p><strong>3.4.1 同步访问方式</strong></p>
<p>1、RPC 访问模式</p>
<p>Remote Procedure Call Protocol，远程过程调用协议，一般使用在分布式业务或者微服务架构风格中。像调用本地函数一样，去调用一个远端服务。本质上是请求链的底层，维护同一个端口，进行socket通信。常见的RPC技术包含 gRPC、Dubbo、Thrift 等。</p>
<p><img src="/images/blog/engineering/microservice-image_1_5.png" alt="image_1_5.png"></p>
<p>2、REST 访问模式</p>
<p>这个应该大家最常用，可以通过一套统一风格的接口模式，为Web，iOS和Android等提供接口服务。</p>
<p><strong>3.4.2 异步访问方式</strong></p>
<p>消息中间件：RabbitMQ、Kafka、RocketMQ之类，对于实时性要求不那么严格的服务请求和计算。</p>
<h4>3.5 服务治理 <a href="#scroller-28" id="scroller-28"></a></h4>
<p>常见的服务治理手段有如下几种：</p>
<p><strong>3.5.1 节点管理</strong></p>
<p>服务调用失败时可能是服务提供者自身出现，也可能是网络发生故障，我们一般有两种处理手段。</p>
<p>1. 注册中心主动摘除机制 这种机制要求服务提供者定时向注册中心汇报心跳，如果超时，就认为服务提供者出现问题，并将节点从服务列表中摘除。</p>
<p>2. 服务消费者摘除机制 当服务提供者网络出现异常，服务消费者调用就会失败，如果持续错误就可以将它从服务提供者节点列表中移除。</p>
<p><strong>3.5.2 负载均衡</strong></p>
<p>服务消费者在从服务列表中选取可用节点时，如果能让性能较好的服务机多承担一些流量的话，就能充分利用机器的性能。这就需要对负载均衡算法做一些调整。</p>
<p>常用的负载均衡算法主要包括以下几种：</p>
<p>1. Radom 随机算法 从可用的服务节点中随机选取一个节点。一般情况下，随机算法是均匀的，也就是说后端服务节点无论配置好坏，最终得到的调用量都差不多。</p>
<p>2. Round Robin 轮询算法（加权重） 就是按照固定的权重，对可用服务节点进行轮询。如果所有服务节点的权重都是相同的，则每个节点的调用量也是差不多的。但可以给性能较好的节点的权重调大些，充分发挥其性能优势，提高整体调用的平均性能。</p>
<p>3. Least Conn 最少活跃调用算法 这种算法是在服务消费者这一端的内存里动态维护着同每一个服务节点之间的连接数，选择连接数最小的节点发起调用，也就是选择了调用量最小的服务节点，性能理论上也是最优的。</p>
<p>4. 一致性 Hash 算法 指相同参数的请求总是发到同一服务节点。当某一个服务节点出现故障时，原本发往该节点的请求，基于虚拟节点机制，平摊到其他节点上，不会引起剧烈变动。</p>
<p><strong>3.5.3 服务路由</strong></p>
<p>所谓的路由规则，就是通过一定的规则如条件表达式或者正则表达式来限定服务节点的选择范围。</p>
<p>制定路由规则主要有两个原因。</p>
<p>1. 业务存在灰度发布、多版本ABTesting的需求</p>
<p>功能逐步开放发布或者灰度测试的场景。</p>
<p>2. 多机房就近访问的需求</p>
<p>一般可以通过 IP 段规则来控制访问，在选择服务节点时，优先选择同一 IP 段的节点。这个也是算力靠近的优先原则。</p>
<p><strong>3.5.4 服务容错</strong></p>
<p>在分布式系统中，分区容错性是很重要的一个话题，要知道，服务间的调用调用并不总是成功，服务提供者程序bug、异常退出 或者 消费者与提供者之间的网络故障。而服务调用失败之后，我们需要一些方法来保证调用的正常。</p>
<p>常用的方式有以下几种：</p>
<p>FailOver 失败自动切换。就是服务消费者发现调用失败或者超时后，自动从可用的服务节点列表中选择下一个节点重新发起调用，也可以设置重试的次数。</p>
<p>FailBack 失败通知。就是服务消费者调用失败或者超时后，不再重试，而是根据失败的详细信息，来决定后续的执行策略。</p>
<p>FailCache 失败缓存。就是服务消费者调用失败或者超时后，不立即发起重试，而是隔一段时间后再次尝试发起调用。</p>
<p>FailFast 快速失败。就是服务消费者调用一次失败后，不再重试。</p>
<p>服务治理的手段是从不同角度来确保服务调用的成功率。节点管理是从服务节点健康状态角度来考虑，负载均衡和服务路由是从服务节点访问优先级角度来考虑，而服务容错是从调用的健康状态角度来考虑。</p>
<h4>3.6 服务监控 <a href="#scroller-33" id="scroller-33"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_1_6.png" alt="image_1_6.png"></p>
<p>常见的开发监控报警技术有 ELK、InfluxData的TICK、Promethues 等。</p>
<p>在分布式系统中，微服务一般都具有复杂的链路调用，对于链路之间的状态、服务可用性、调用情况的监控，是需要一套完整的服务监控系统去保障的。</p>
<p>如我们上面的那个图所示， 服务系统主要由哪几部分构成：</p>
<p>1、数据采集部分，包含性能指标信息、日志信息（一般是服务埋点日志或者sidecar的inbound、outbound信息）、端到端的Trace信息。</p>
<p>2、采集上来的监控数据通过传输系统，或者使用消息中间件来异步传输，或者调用服务端接口推送监控数据。并把这些数据持久化到我们的数据服务层中。</p>
<p>3、制定一套规则，对于采集到的数据进行清理、计算、分级等，处理好的数据，通过提前设置好的报警策略，来判断它是否触发了这些报警。</p>
<p>4、梳理完的数据可以进行查询展示（有一个日志查询界面）、分级报警、分析趋势报表推送等。</p>
<h4>3.7 服务追踪 <a href="#scroller-34" id="scroller-34"></a></h4>
<p>服务追踪的原理主要包括下面两个关键点。</p>
<p>1、为了实现请求跟踪，当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的跟踪标识，同时在分布式系统内部流转的时候，框架始终保持传递该唯一标识，直到返回给请求方为止，这个唯一标识就是前文中提到的 Trace ID。</p>
<p>通过 Trace ID 的记录，我们就能将所有请求过程的日志关联起来。</p>
<p>2、为了统计各处理单元的时间延迟，当请求到达各个服务组件时，或是处理逻辑到达某个状态时，也通过一个唯一标识来标记它的开始、具体过程以及结束，该标识就是前文中提到的 Span ID。对于每个 Span 来说，它必须有开始和结束两个节点，</p>
<p>通过记录开始 Span 和结束 Span 的时间戳，就能统计出该 Span 的时间延迟，除了时间戳记录之外，它还可以包含一些其他元数据，比如事件名称、请求信息等。</p>
<p><img src="/images/blog/engineering/microservice-image_1_7.png" alt="image_1_7.png"></p>
<p>上图显示了Trace ID 和 Spand ID 在链路中的传输过程，它把服务调用的一个时序结构给展现出来了。</p>
<p>常见的服务链路追踪的技术有Zipkin、Pinpoint、SkyWalking 等。后面讲到Service Mesh的时候会详细说下Zipkin的x-b3 header头传递，以及流量染色的使用，非常给力。</p>
<h3>4 总结 <a href="#scroller-35" id="scroller-35"></a></h3>
<p>微服务架构提倡的单一应用程序划分成一组松散耦合的细粒度小型服务，辅助轻量级的协议，互相协调、互相配合，实现高效的应用价值，符合我们应用服务开发的发展趋势。</p>
<p>后续我们围绕它的核心模块：服务注册与发现、API 网关服务、分布式配置中心、服务通信、服务治理、分布式服务追踪与监控等，从原理到实践，一步步展开来研究。</p>
18:T148b,<p>关于服务拆分的切入点，我们先从MartinL.Abbott所著《架构即未来》中所介绍的AKF扩展立方体出发寻找一些灵感，然后给出本文中关于服务拆分的两大维度。</p>
<p>1. AKF扩展立方体</p>
<p>AKF扩展立方体（Scalability Cube）是一种可扩展模型，这个立方体有三个轴线，每个轴线描述扩展性的一个维度（见下图），分别是：</p>
<ul>
<li>X轴</li>
</ul>
<p>代表无差别的克隆服务和数据，工作可以很均匀的分散在不同的服务实例上</p>
<ul>
<li>Y轴</li>
</ul>
<p>关注应用中职责的划分，比如数据类型、交易执行类型的划分</p>
<ul>
<li>Z轴</li>
</ul>
<p>关注服务和数据的优先级划分，如分地域划</p>
<p><img src="/images/blog/engineering/microservice-image_5_1.png" alt="image_5_1.png"></p>
<p>以上X、Y和Z轴的划分可以概括为X 轴关注水平复制，Z 轴类似数据分区，而Y 轴则强调基于不同的业务拆分。理论上按照这三个扩展维度，可以将一个单体系统进行无限扩展。举例来说，比如用户预约挂号应用，一个集群撑不住时，分了多个集群，后来用户激增还是不够用，经过分析发现是用户和医生访问量很大，就将预约挂号应用拆成了患者服务、医生服务、支付服务等三个服务。三个服务的业务特点各不相同，独立维护，各自都可以再次按需扩展。</p>
<p>在上图中，Y轴就是我们所说的微服务的拆分模式，即基于不同的业务进行拆分。但在进行业务拆分过程中，我们发现业务往往与数据有较大耦合性，所以接下去我们把业务和数据结合起来对服务拆分的维度展开讨论。</p>
<p>2. 业务与数据</p>
<p>服务拆分存在两大维度，即业务与数据。业务体现在各种功能代码中，通过确定业务的边界，并使用领域与界限上下文、领域事件等技术手段可以实现拆分。而数据的拆分则体现在如何将集中式的中心化数据转变为各个微服务各自拥有的独立数据，这部分工作同样十分具有挑战性。</p>
<p>关于业务和数据谁应该先拆分的问题，可以是先数据库后业务代码，也可以是先业务代码后数据库。然而在拆分中遇到的最大挑战可能会是数据层的拆分，因为在数据库中，可能会存在各种跨表连接查询、跨库连接查询以及不同业务模块的代码与数据耦合得非常紧密的场景，这会导致服务的拆分非常的困难。因此在拆分步骤上我们更多的推荐数据库先行。数据模型能否彻底分开，很大程度上决定了微服务的边界功能是否彻底划清。</p>
<p>服务拆分的方法需要根据系统自身的特点和运行状态，通常分为绞杀者与修缮者两种模式。</p>
<p>1. 绞杀者模式</p>
<p>绞杀者模式（Strangler Pattern）最早由<a href="https://www.martinfowler.com/">Martin Fowler</a>提出，指的是在现有系统外围将新功能用新的方式构建为新的服务的策略，通过将新功能做成微服务方式，而不是直接修改原有系统，逐步的实现对老系统替换。采用这种策略，随着时间的推移，新的服务就会逐渐“绞杀”老的系统。对于那些规模很大而又难以对现有架构进行修改的遗留系统，推荐采用绞杀者模式。</p>
<p>绞杀者模式的示意图如下图所示，我们可以看到随着功能演进和时间的不断推移，老的遗留系统功能被逐步削弱，而采用微服务架构的新功能越积越多，最终会形成从量变到质变的过程。绞杀者模式在具体实施过程中，所需要把握的最主要一点原则就是对于任何需要开发的功能一定要完整的采用微服务架构，对于完全独立的新功能这点比较容易把握，而对于涉及到老业务变更的新功能则需要通过重构达到这一目标。</p>
<p><img src="/images/blog/engineering/microservice-image_5_2.png" alt="image_5_2.png"></p>
<p>2. 修缮者模式</p>
<p>修缮者模式就如修房或修路一样，将老旧待修缮的部分进行隔离，用新的方式对其进行单独修复。修复的同时，需保证与其他部分仍能协同功能。从这种思路出发，修缮者模式更多表现为一种重构技术。修缮者模式在具体实现上可以参考Martine Fowler的BranchByAbstraction重构方法，该重构方法的示意图如下图所示。</p>
<p><img src="/images/blog/engineering/microservice-image_5_3.png" alt="image_5_3.png"></p>
<p>从上图中，可以看到这种模式的实现方式可以分成三个主要步骤。</p>
<ul>
<li>抽象层提取</li>
</ul>
<p>首先通过识别内部的待拆分功能，对其增加抽象接口层，同时对原有代码进行改造，确保其同样实现该抽象层。这样在依赖关系上就添加了一个中间层。</p>
<ul>
<li>抽象层实现</li>
</ul>
<p>为抽象层提供新的实现，新的实现采用微服务方式。</p>
<ul>
<li>抽象层替换</li>
</ul>
<p>采用新的实现对原有的各个抽象层实现进行逐步替换，直至原有实现被完全废弃，从而完成新老实现方式之间的替换。</p>
19:T6ae1,<h1>架构设计模板</h1>
<p>架构设计文档的价值不在于文档本身，而在于写文档的过程——它迫使我们在动手之前系统性地思考。一份好的设计文档能回答三个问题：<strong>为什么要做、怎么做、做到什么程度算完</strong>。</p>
<p>然而实际工作中，设计文档常见两类问题：要么太空——通篇架构图但缺乏落地细节；要么有遗漏——上线后才发现没考虑容灾、没定义回滚方案。根本原因是缺少一个结构化的思考框架。</p>
<p>本文提供一套经过实践验证的架构设计模板，包含 11 个维度。它的设计思路遵循一条主线：</p>
<blockquote>
<p><strong>问题驱动 → 方案设计 → 工程落地</strong></p>
<ul>
<li>问题驱动（第 1 章）：搞清楚为什么要做，边界在哪</li>
<li>方案设计（第 2-9 章）：从架构到细节，把方案想透</li>
<li>工程落地（第 10-11 章）：怎么部署、怎么分期交付</li>
</ul>
</blockquote>
<p>这 11 个维度既可以作为写设计文档的提纲，也可以当作评审时的 Checklist。每个维度给出<strong>要回答的关键问题</strong>和<strong>具体交付物</strong>，文末附可直接复用的 Markdown 模板。</p>
<hr>
<h3>1. 需求介绍</h3>
<p>需求介绍的核心任务是把「为什么要做」讲清楚。它不是产品需求文档（PRD）的复述，而是从技术视角回答：现状有什么问题、我们打算怎么解决、做到什么程度算成功。</p>
<p><strong>要回答的关键问题：</strong></p>
<ul>
<li><strong>现状与痛点</strong>：当前系统/流程存在什么问题？对业务造成了哪些可量化的影响（故障频率、延迟、人工成本等）？</li>
<li><strong>目标与范围</strong>：新方案要解决哪些问题？同样重要的是——不解决哪些问题？明确的边界能防止需求蔓延。</li>
<li><strong>核心场景</strong>：列出 3-5 个最重要的使用场景。场景是连接需求与设计的桥梁——拆得越细，后面的设计越不容易遗漏。</li>
<li><strong>干系人</strong>：谁是用户？谁会被改动影响？谁需要配合？</li>
<li><strong>约束条件</strong>：时间窗口、预算、技术栈限制、合规要求等。</li>
<li><strong>验收标准</strong>：用可量化的指标定义「做完了」，如 P99 延迟 &lt; 200ms、可用性 &gt; 99.95%、数据一致性延迟 &lt; 1s。</li>
</ul>
<p><strong>实践建议：</strong></p>
<p>用「场景走查」来验证需求完整性——把每个核心场景从头到尾走一遍，记录每一步涉及的系统、数据和人员。走查过程中自然会暴露出遗漏的约束和边界条件。</p>
<p><strong>交付物：</strong> 需求背景文档（含场景列表、干系人矩阵、约束条件、验收标准）</p>
<hr>
<h3>2. 架构总览</h3>
<p>架构总览是整个设计文档的「地图」。评审者和后续加入的开发人员，通常最先看的就是这一章。它需要回答：系统长什么样、分几块、各块之间怎么协作。</p>
<p><strong>多视角描述架构：</strong></p>
<p>业界常用 <a href="https://en.wikipedia.org/wiki/4%2B1_architectural_view_model">4+1 视图模型</a> 或 <a href="https://c4model.com/">C4 模型</a> 来组织架构描述。对于多数项目，以下三个视角已经够用：</p>
<ul>
<li><strong>概念模型</strong>：系统中有哪些核心领域概念？它们之间的关系是什么？概念模型是整个设计的骨架。看似简单的概念定义——比如「部署包 = 介质包 + 配置」——往往直接决定了后续的技术设计。建议用 UML 类图或 ER 图表达。</li>
<li><strong>逻辑架构图</strong>：系统分几层？每层有哪些模块？模块之间的依赖方向是什么？建议按能力分层（接入层 → 业务逻辑层 → 领域服务层 → 基础设施层），并标注每个模块的核心职责。</li>
<li><strong>系统上下文图</strong>（System Context）：聚焦系统边界——哪些能力自研，哪些依赖外部系统？与周边系统的交互协议和数据格式是什么？这张图对于跨团队协作尤其关键。</li>
</ul>
<p><strong>画图原则：</strong></p>
<p>架构图的唯一标准是<strong>易懂</strong>。一些实用建议：</p>
<ul>
<li>每张图只表达一个层次的信息，避免在同一张图中混合部署细节和业务逻辑</li>
<li>用颜色/形状区分不同类型的组件（自研服务、外部依赖、中间件、数据存储）</li>
<li>标注关键数据流的方向和协议</li>
<li>推荐工具：Excalidraw（轻量手绘风）、draw.io（标准流程图）、PlantUML（文本生成图）</li>
</ul>
<p><strong>实践建议：</strong></p>
<p>好的架构图是改出来的，不是一次画对的。建议在正式评审前做一次小范围宣讲，一是统一理解，二是通过反馈优化设计。</p>
<p><strong>交付物：</strong> 概念模型图、逻辑架构图、系统上下文图</p>
<hr>
<h3>3. 核心流程</h3>
<p>架构总览展示了系统的静态结构，核心流程则展示系统的动态行为——各组件如何协作完成具体业务场景。<strong>架构图 + 时序图是设计评审中最有价值的两张图</strong>，前者回答「是什么」，后者回答「怎么运转」。</p>
<p><strong>场景驱动的梳理方法：</strong></p>
<ol>
<li><strong>列出核心场景</strong>：从用户/调用方的视角，挑出最重要的 3-5 个场景（通常就是需求介绍中的核心场景）</li>
<li><strong>画出 Happy Path</strong>：每个场景走一遍完整调用链路，用时序图（Sequence Diagram）标注参与方、调用顺序、数据流向</li>
<li><strong>标注关键路径</strong>：在时序图上标记性能瓶颈点、状态变更点、数据持久化点</li>
<li><strong>补充异常流程</strong>：这是最容易被忽略但最重要的部分——下游超时怎么办？重试是否幂等？消息丢了怎么补偿？数据不一致怎么修复？</li>
</ol>
<p><strong>常见陷阱：</strong></p>
<p>很多设计文档只画了「晴天场景」，对异常路径一笔带过。但线上故障绝大多数发生在异常分支。建议对每个核心流程至少补充以下异常场景：</p>
<ul>
<li>依赖服务不可用</li>
<li>网络超时 / 部分失败</li>
<li>数据不一致（如消息乱序、重复投递）</li>
<li>资源耗尽（连接池满、磁盘满、内存 OOM）</li>
</ul>
<p><strong>交付物：</strong> 核心场景的时序图（含 Happy Path 和关键异常流程）</p>
<hr>
<h3>4. 详细设计</h3>
<p>详细设计是对架构中复杂组件的「放大镜」。不需要面面俱到，但对核心模块和高风险模块必须写清楚。</p>
<p><strong>通常涵盖以下几类：</strong></p>
<p><strong>数据模型</strong></p>
<ul>
<li>核心表结构设计（字段、类型、约束）</li>
<li>索引策略（查询模式决定索引设计，而非反过来）</li>
<li>数据生命周期：冷热分离策略、归档/清理规则、数据保留期限</li>
<li>数据量评估：初始数据量、增长速率、单表上限</li>
</ul>
<p><strong>接口契约</strong></p>
<ul>
<li>对外 API 定义：路径、方法、入参、出参、错误码、版本策略</li>
<li>如涉及多系统协作，还需定义 SPI（扩展点接口）——即「我提供框架，你来实现具体逻辑」的扩展机制</li>
<li>接口幂等性设计：哪些接口需要幂等？幂等 Key 怎么生成？</li>
<li>建议遵循 <a href="https://www.openapis.org/">OpenAPI</a> 规范，便于自动生成文档和客户端代码</li>
</ul>
<p><strong>状态机</strong></p>
<ul>
<li>如业务有复杂状态流转（订单、审批、工单等），一张状态机图比大段文字清晰得多</li>
<li>明确每个状态转换的触发条件、执行动作和失败回退</li>
</ul>
<p><strong>关键算法/策略</strong></p>
<ul>
<li>路由策略（一致性 Hash、权重轮询等）</li>
<li>调度算法（优先级队列、公平调度等）</li>
<li>限流算法（令牌桶、滑动窗口等）</li>
</ul>
<p><strong>实践建议：</strong></p>
<p>详细设计不必一次写完，可以在开发过程中迭代补充。但有两样东西必须在写代码之前定好：<strong>接口契约</strong>和<strong>数据模型</strong>——它们的变更成本最高，影响面最广。</p>
<p><strong>交付物：</strong> 数据模型设计、接口文档（API/SPI）、状态机图（如有）、关键算法说明</p>
<hr>
<h3>5. 高可用设计</h3>
<p>高可用设计回答一个核心问题：<strong>系统的某个部分挂了，整体还能不能用？</strong> 这是从「能跑」到「能扛」的关键一步。</p>
<p><strong>冗余与容灾</strong></p>
<ul>
<li>服务层：是否多实例部署？是否跨可用区（AZ）部署？单个 AZ 故障时服务是否仍然可用？</li>
<li>数据层：数据库是否有主从/多副本？故障切换是自动还是手动？RPO（数据丢失量）和 RTO（恢复时间）的目标是多少？</li>
<li>降级方案：核心链路和非核心链路是否隔离？当非核心依赖不可用时，核心功能是否能继续运行？降级是自动触发还是手动开关？</li>
</ul>
<p><strong>故障检测与自愈</strong></p>
<ul>
<li>健康检查：Liveness Probe（进程是否存活）和 Readiness Probe（是否可接收流量）分别怎么设计？</li>
<li>熔断策略：使用什么熔断器（如 Sentinel、Resilience4j）？熔断阈值和恢复策略如何配置？</li>
<li>限流策略：在哪一层限流（网关层 / 应用层）？限流粒度是什么（全局 / 租户 / 接口）？</li>
<li>隔离机制：线程池隔离、信号量隔离还是进程隔离？</li>
</ul>
<p><strong>数据一致性</strong></p>
<ul>
<li>一致性模型选择：强一致（CP）还是最终一致（AP）？在什么场景下可以接受最终一致？</li>
<li>跨服务一致性方案：Saga、TCC、本地消息表、事务消息等，各有适用场景。选择依据是什么？</li>
<li>补偿机制：当一致性被破坏时，如何检测和修复？是否需要对账任务？</li>
</ul>
<p><strong>可观测性</strong></p>
<ul>
<li>监控三支柱：Metrics（指标）、Logging（日志）、Tracing（链路追踪）各自的方案是什么？</li>
<li>关键监控指标按 <a href="https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services/">RED 方法</a> 分类：Rate（请求速率）、Errors（错误率）、Duration（延迟分布）</li>
<li>告警规则：分级（P0/P1/P2/P3）、阈值、通知渠道、响应 SLA</li>
<li>故障定位：如何从告警快速定位到根因？是否有 Runbook（故障手册）？</li>
</ul>
<p><strong>交付物：</strong> 高可用方案说明（含冗余策略、故障恢复流程、可观测性方案、告警清单）</p>
<hr>
<h3>6. 高性能设计</h3>
<p>高性能设计的核心原则是<strong>先定目标，再找瓶颈，最后谈优化</strong>。没有量化目标的优化是盲目的。</p>
<p><strong>性能目标</strong></p>
<ul>
<li>QPS/TPS 目标：峰值多少？日常多少？需要预留多少 Buffer？</li>
<li>延迟目标：P50、P95、P99 分别是多少？（只看平均值会掩盖长尾问题）</li>
<li>数据量级：当前数据量多大？未来 1-3 年的增长预期？</li>
</ul>
<p><strong>瓶颈分析</strong></p>
<ul>
<li>识别系统是 CPU 密集型还是 IO 密集型</li>
<li>找出关键路径上的瓶颈点：数据库查询、外部 API 调用、序列化/反序列化、锁竞争等</li>
<li>使用 <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl 定律</a> 评估优化收益——优化非瓶颈环节收效甚微</li>
</ul>
<p><strong>分层优化策略</strong></p>
<table>
<thead>
<tr>
<th>层次</th>
<th>常用手段</th>
</tr>
</thead>
<tbody><tr>
<td>接入层</td>
<td>CDN 加速、负载均衡、连接复用、协议优化（HTTP/2、gRPC）</td>
</tr>
<tr>
<td>应用层</td>
<td>本地缓存（Caffeine）、分布式缓存（Redis）、异步化（MQ）、批量合并、并行调用</td>
</tr>
<tr>
<td>数据层</td>
<td>读写分离、分库分表、索引优化、热点数据隔离、查询结果缓存</td>
</tr>
<tr>
<td>基础设施</td>
<td>水平扩容、弹性伸缩（HPA）、资源池化、JVM/Runtime 调优</td>
</tr>
</tbody></table>
<p><strong>压测验证</strong></p>
<ul>
<li>工具选择：JMeter（全功能）、wrk/hey（轻量 HTTP）、k6（脚本化场景）</li>
<li>压测策略：阶梯加压找出拐点，而非直接打满</li>
<li>压测环境与生产环境的差异要记录清楚（机器规格、数据量、网络拓扑）</li>
<li>压测报告要包含：吞吐量曲线、延迟分布、资源利用率、瓶颈定位</li>
</ul>
<p><strong>交付物：</strong> 性能目标定义、瓶颈分析、分层优化方案、压测计划</p>
<hr>
<h3>7. 可扩展性设计</h3>
<p>可扩展性回答两个问题：<strong>加功能容不容易（业务扩展性）<strong>和</strong>加机器扛不扛得住更多量（容量扩展性）</strong>。</p>
<p><strong>业务扩展性</strong></p>
<p>好的扩展性设计遵循 <a href="https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle">开闭原则</a>——对扩展开放，对修改关闭。具体评判标准：</p>
<blockquote>
<p>新增一类需求时，是加配置就行，还是要写代码？写代码的话，是新增代码就行，还是要改已有代码？越往前者靠，扩展性越好。</p>
</blockquote>
<p>常见的扩展性手段：</p>
<ul>
<li><strong>插件化 / SPI 机制</strong>：通过接口抽象 + 实现注册，新增场景只需新增实现类</li>
<li><strong>策略模式 + 配置驱动</strong>：将业务规则外化为配置，通过策略分发路由到不同处理逻辑</li>
<li><strong>事件驱动</strong>：核心流程产出事件，扩展功能订阅事件，彼此解耦</li>
<li><strong>合理的领域划分</strong>：按业务能力（而非技术层次）划分模块，模块间通过明确的接口通信</li>
</ul>
<p><strong>容量扩展性</strong></p>
<ul>
<li>服务层：是否无状态？能否直接水平扩容？如果有状态（如本地缓存、WebSocket 长连接），扩容时如何处理？</li>
<li>数据层：数据库如何扩展？是否预留了分片键？分片策略是什么？</li>
<li>消息队列：Partition 数量是否支持后续扩展？Consumer Group 的 Rebalance 策略是什么？</li>
<li>单点瓶颈：系统中是否存在不可水平扩展的单点？如何规避或缓解？</li>
</ul>
<p><strong>交付物：</strong> 扩展点清单、领域划分图、容量扩展方案</p>
<hr>
<h3>8. 安全设计</h3>
<p>安全设计即使当前没有明确需求，也应作为 Checklist 在评审中显式确认。写「经评估，本期暂不涉及」远好过完全不提——前者是有意识的决策，后者是遗漏。</p>
<p><strong>认证与授权</strong></p>
<ul>
<li>认证方案：JWT、OAuth 2.0、Session、OIDC？Token 的签发、刷新和吊销机制？</li>
<li>授权模型：RBAC（基于角色）、ABAC（基于属性）？权限粒度到什么级别（菜单/按钮/数据行）？</li>
<li>服务间认证：内部服务间调用是否需要认证？方案是什么（mTLS、服务账号、JWT 传递）？</li>
</ul>
<p><strong>数据安全</strong></p>
<ul>
<li>敏感数据识别：哪些字段属于 PII（个人可识别信息）？如密码、手机号、身份证号、银行卡号</li>
<li>存储加密：敏感字段是否加密存储？加密算法和密钥管理方案？</li>
<li>数据脱敏：日志、监控、非生产环境中的敏感数据是否脱敏？脱敏规则是什么？</li>
<li>数据合规：是否涉及 GDPR、个人信息保护法等合规要求？数据跨境传输策略？</li>
</ul>
<p><strong>传输安全</strong></p>
<ul>
<li>是否全链路 HTTPS？TLS 版本和加密套件？</li>
<li>内部服务通信是否加密（mTLS）？证书管理方案？</li>
</ul>
<p><strong>审计与防护</strong></p>
<ul>
<li>审计日志：哪些关键操作需要记录？日志包含哪些字段（who/when/what/where）？日志的保留期限？</li>
<li>防攻击：SQL 注入、XSS、CSRF、SSRF 的防护措施？是否使用 WAF？</li>
<li>限流防刷：敏感接口（登录、短信验证码、支付）是否有专门的限流策略？</li>
</ul>
<p><strong>交付物：</strong> 安全设计说明（含认证方案、数据分级与保护策略、审计要求）</p>
<hr>
<h3>9. 技术选型</h3>
<p>技术选型是影响最深远的决策之一——选错了，后续所有人都在还债。好的选型不追求「最先进」，而追求「最合适」。</p>
<p><strong>要回答的关键问题：</strong></p>
<ul>
<li>核心语言和框架的选择依据是什么？</li>
<li>中间件的选择（消息队列、缓存、数据库、搜索引擎等）基于什么考量？</li>
<li>是否做过技术预研或 PoC 验证？结论是什么？</li>
</ul>
<p><strong>选型的评估维度：</strong></p>
<table>
<thead>
<tr>
<th>维度</th>
<th>要点</th>
</tr>
</thead>
<tbody><tr>
<td>功能匹配度</td>
<td>能否满足当前和可预见的未来需求？</td>
</tr>
<tr>
<td>生产成熟度</td>
<td>是否有大规模生产验证？社区活跃度和生态完善度？</td>
</tr>
<tr>
<td>团队匹配度</td>
<td>团队是否熟悉？学习曲线和上手成本？——技术再好，团队用不起来也白搭</td>
</tr>
<tr>
<td>运维成本</td>
<td>部署复杂度、监控支持、故障排查难度、升级迁移成本</td>
</tr>
<tr>
<td>许可证合规</td>
<td>开源许可证是否满足商业需求（注意 AGPL、SSPL 等传染性许可证）？</td>
</tr>
</tbody></table>
<p><strong>实践建议：</strong></p>
<ul>
<li>用 <a href="https://adr.github.io/">ADR（Architecture Decision Records）</a> 记录每个关键技术决策的上下文、选项、决策和后果，方便后续团队理解「当初为什么这么选」</li>
<li>如有多个候选方案，列对比表时不要超过 5 个维度，聚焦最关键的差异点</li>
<li>团队编码规范、Git 工作流、Code Review 流程等工程规范也可以写在这一节</li>
</ul>
<p><strong>交付物：</strong> 技术栈清单、关键选型对比表（或 ADR）、工程规范说明</p>
<hr>
<h3>10. 部署方案</h3>
<p>部署方案不只是「怎么把服务跑起来」，更要回答：怎么安全地发布变更、出了问题怎么快速回滚。</p>
<p><strong>环境规划</strong></p>
<ul>
<li>环境定义：开发（Dev）→ 测试（Test/QA）→ 预发（Staging）→ 生产（Production）</li>
<li>环境隔离：各环境之间如何隔离（独立集群 / Namespace 隔离 / 标签路由）？</li>
<li>配置管理：配置与代码是否分离？环境差异（副本数、资源配额、域名、Feature Flag）通过什么机制管理？推荐 ConfigMap + 密钥管理服务（如 Vault）</li>
</ul>
<p><strong>发布策略</strong></p>
<ul>
<li>滚动更新（Rolling Update）：适合大多数无状态服务，K8s 原生支持</li>
<li>蓝绿部署（Blue-Green）：适合需要快速切换和回滚的场景，需双倍资源</li>
<li>灰度发布（Canary）：适合风险较高的变更，按流量比例 / 用户标签 / 地域逐步放量</li>
<li>发布过程中的健康检查（Readiness Gate）和自动回滚（基于错误率 / 延迟的 Rollback 策略）</li>
</ul>
<p><strong>回滚方案</strong></p>
<ul>
<li>代码回滚流程：谁触发？如何执行？回滚后是否需要通知下游？</li>
<li>数据库回滚：Schema 变更是否向下兼容？是否准备了回滚脚本？建议采用 Expand-Contract 模式处理不兼容变更</li>
<li>配置回滚：配置变更是否有版本化和快速回滚能力？</li>
</ul>
<p><strong>资源规划</strong></p>
<ul>
<li>每个服务的 CPU / 内存 Request 和 Limit 如何设定？建议基于压测数据而非经验估算</li>
<li>是否需要 HPA（Horizontal Pod Autoscaler）？扩缩容的指标和阈值？</li>
<li>存储方案：云盘（持久化）、对象存储（文件/图片）、本地盘（临时缓存）分别用在哪里？</li>
</ul>
<p><strong>交付物：</strong> 部署架构图（物理视图）、环境配置清单、发布策略说明、回滚 Runbook</p>
<hr>
<h3>11. 架构演进规划</h3>
<p>大型项目不可能一步到位，分阶段交付是常态。架构演进规划的目标是让团队在每个阶段都知道做什么、为什么先做这个、后面还要做什么。</p>
<p><strong>MVP 定义</strong></p>
<ul>
<li>最小可用版本的范围是什么？用<strong>场景</strong>定义 MVP——用户能跑通哪些核心场景，就是 MVP</li>
<li>建议在 MVP 之前做一次<strong>架构原型验证</strong>（Walking Skeleton）：用最小的端到端场景跑通整个架构，验证核心技术方案的可行性。这一步能在早期暴露架构层面的问题，避免后期大面积返工</li>
</ul>
<p><strong>里程碑规划</strong></p>
<ul>
<li>按阶段拆分：每期交付什么功能？交付标准是什么？</li>
<li>阶段间的技术依赖：前一期没完成是否会阻塞后一期？有没有可以并行的工作？</li>
<li>建议用甘特图或里程碑表格可视化，让进度一目了然</li>
</ul>
<p><strong>技术债务管理</strong></p>
<ul>
<li>当前设计中有哪些已知的妥协和 TODO？为什么现在不做？</li>
<li>每笔技术债务的「利息」是什么——不偿还会导致什么后果？</li>
<li>计划在什么时间点偿还？建议将技术债务纳入迭代计划，而非无限期搁置</li>
</ul>
<p><strong>团队分工</strong></p>
<ul>
<li>各模块由谁负责？模块间的接口由谁定义、谁联调、谁验收？</li>
<li>团队能力与分工是否匹配？是否需要安排技术预研或培训？</li>
<li>再好的架构，如果不考虑团队的实际能力，也未必落得了地</li>
</ul>
<p><strong>交付物：</strong> MVP 范围定义、里程碑计划表、技术债务台账、团队分工矩阵</p>
<hr>
<h2>附：可复用的架构设计文档模板</h2>
<p>以下模板可直接复制使用，按实际情况填写或删除不需要的章节。</p>
<pre><code class="language-markdown"># [系统名称] 架构设计文档

&gt; 作者：xxx | 日期：yyyy-MM-dd | 版本：v1.0 | 状态：Draft / In Review / Approved

---

## 1. 需求介绍

### 1.1 现状与痛点
&lt;!-- 当前系统存在什么问题？可量化的业务影响？ --&gt;

### 1.2 目标与范围
&lt;!-- 要解决什么？不解决什么（明确边界）？ --&gt;

### 1.3 核心场景
| # | 场景名称 | 场景描述 | 优先级 |
|---|----------|----------|--------|
| 1 |          |          |        |

### 1.4 干系人
| 角色 | 人员 | 职责 |
|------|------|------|
|      |      |      |

### 1.5 约束条件
&lt;!-- 时间、预算、技术栈、合规等 --&gt;

### 1.6 验收标准
| 指标 | 目标值 | 度量方式 |
|------|--------|----------|
|      |        |          |

---

## 2. 架构总览

### 2.1 概念模型
&lt;!-- 核心领域概念及其关系（附图） --&gt;

### 2.2 逻辑架构图
&lt;!-- 系统分层、模块划分、依赖关系（附图） --&gt;

### 2.3 系统上下文
&lt;!-- 与周边系统的交互：协议、数据格式、调用方向（附图） --&gt;

---

## 3. 核心流程

### 3.1 场景一：[场景名称]

**Happy Path：**
&lt;!-- 时序图 --&gt;

**异常流程：**
&lt;!-- 超时 / 下游不可用 / 数据不一致 的处理方式 --&gt;

### 3.2 场景二：[场景名称]
&lt;!-- 同上 --&gt;

---

## 4. 详细设计

### 4.1 数据模型
&lt;!-- 核心表结构、索引策略、数据生命周期 --&gt;

### 4.2 接口契约
&lt;!-- API / SPI 定义：路径、方法、入参、出参、错误码 --&gt;

### 4.3 状态机
&lt;!-- 状态流转图（如有） --&gt;

### 4.4 关键算法
&lt;!-- 核心算法/策略的描述 --&gt;

---

## 5. 高可用设计

### 5.1 冗余与容灾
&lt;!-- 多实例 / 跨 AZ / 主从切换 / 降级方案 --&gt;

### 5.2 故障检测与自愈
&lt;!-- 健康检查 / 熔断 / 限流 / 隔离 --&gt;

### 5.3 数据一致性
&lt;!-- CP vs AP 选择 / 跨服务一致性方案 / 补偿机制 --&gt;

### 5.4 可观测性
| 类型 | 指标/工具 | 告警阈值 | 响应 SLA |
|------|-----------|----------|----------|
| Metrics |        |          |          |
| Logging |        |          |          |
| Tracing |        |          |          |

---

## 6. 高性能设计

### 6.1 性能目标
| 指标 | 目标值 |
|------|--------|
| QPS  |        |
| P99  |        |
| 数据量级 |    |

### 6.2 瓶颈分析
&lt;!-- 关键路径上的瓶颈点及根因分析 --&gt;

### 6.3 优化方案
&lt;!-- 按接入层 / 应用层 / 数据层 / 基础设施分层说明 --&gt;

### 6.4 压测计划
&lt;!-- 工具、场景、环境差异、通过标准 --&gt;

---

## 7. 可扩展性设计

### 7.1 业务扩展性
&lt;!-- 扩展点清单 / SPI 机制 / 领域划分 --&gt;

### 7.2 容量扩展性
&lt;!-- 无状态服务扩容 / 有状态组件扩展 / 单点瓶颈规避 --&gt;

---

## 8. 安全设计

- **认证与授权**：
- **数据安全**：
- **传输安全**：
- **审计日志**：
- **防攻击**：

&lt;!-- 如本期不涉及，请注明「经评估，本期暂不涉及」并说明原因 --&gt;

---

## 9. 技术选型

| 类别 | 选型 | 备选方案 | 选择依据 |
|------|------|----------|----------|
|      |      |          |          |

### 关键决策记录（ADR）
&lt;!-- 对于有争议的选型，记录上下文、选项、决策和后果 --&gt;

---

## 10. 部署方案

### 10.1 环境规划
| 环境 | 集群/NS | 副本数 | 资源配额 | 域名 |
|------|---------|--------|----------|------|
| Dev  |         |        |          |      |
| Test |         |        |          |      |
| Staging |      |        |          |      |
| Prod |         |        |          |      |

### 10.2 发布策略
&lt;!-- 滚动更新 / 蓝绿 / 灰度，以及健康检查和自动回滚机制 --&gt;

### 10.3 回滚方案
&lt;!-- 代码回滚流程 / 数据库兼容性 / 配置回滚 --&gt;

---

## 11. 架构演进规划

### 11.1 MVP 定义
&lt;!-- 第一个版本的最小可用范围（用场景定义） --&gt;

### 11.2 里程碑
| 阶段 | 时间 | 交付内容 | 验收标准 | 依赖 |
|------|------|----------|----------|------|
|      |      |          |          |      |

### 11.3 技术债务
| 债务 | 产生原因 | 影响（利息） | 计划偿还时间 |
|------|----------|--------------|--------------|
|      |          |              |              |

### 11.4 团队分工
| 模块 | 负责人/团队 | 上下游依赖 |
|------|-------------|------------|
|      |             |            |

---

## 附录

### 术语表
| 术语 | 定义 |
|------|------|
|      |      |

### 参考文档
&lt;!-- 相关 PRD、技术预研报告、竞品分析等 --&gt;

### 变更记录
| 版本 | 日期 | 变更人 | 变更内容 |
|------|------|--------|----------|
| v1.0 |      |        | 初稿     |
</code></pre>
1a:T5070,<h2>1 微服务的注册与发现 <a href="#scroller-1" id="scroller-1"></a></h2>
<p>我们前面在全景架构中对服务注册与发现做了大致的说明，本章我们着重详细说明微服务下注册与发现的这个能力。</p>
<p>微服务注册与发现类似于生活中的&quot;电话通讯录&quot;的概念，它记录了通讯录服务和电话的映射关系。在分布式架构中，服务会注册进去，当服务需要调用其它服务时，就这里找到服务的地址，进行调用。</p>
<p>步骤如下：</p>
<p>1、你先要把&quot;好友某某&quot;记录在通讯录中。</p>
<p>2、拨打电话的时候通过通讯录中找到&quot;好友某某&quot;，并拨通回电话。</p>
<p>3、当好友某某电话号码更新的时候，需要通知到你，并修改通讯录服务中的号码。</p>
<p>从这个过程中我们看到了一些特点：</p>
<p>1、把 &quot;好友某某&quot; 的电话号码写入通讯录中，统一在通讯录中维护，后续号码变更也是更新到通讯录中，这个过程就是服务注册的过程。</p>
<p>2、后续我们通过&quot;好友某某&quot;就可以定位到通讯录中的电话号码，并拨通电话，这个过程理解为服务发现的过程。</p>
<p>而我们微服务架构中的服务注册与发现结构如下图所示：</p>
<p><img src="/images/blog/engineering/microservice-image_6_1.png" alt="image_6_1.png"></p>
<p>图片中是一个典型的微服务架构，这个结构中主要涉及到三大角色：</p>
<p>provider - 服务提供者</p>
<p>consumer - 服务消费者</p>
<p>register center - 注册中心</p>
<p>它们之间的关系大致如下：</p>
<p>1、每个微服务在启动时，将自己的网络地址等信息（微服务的ServiceName、IP、Port、MetaData等）注册到注册中心，注册中心存储这些数据。</p>
<p>2、服务消费者从注册中心查询服务提供者的地址，并通过该地址调用服务提供者的接口。</p>
<p>3、各个微服务与注册中心使用一定机制（例如心跳）通信。如果注册中心与某微服务长时间无法通信，就会注销该实例。</p>
<p>优点如下：</p>
<p>1、解耦：服务消费者跟服务提供者解耦，各自变化，不互相影响</p>
<p>2、扩展：服务消费者和服务提供者增加和删除新的服务，对于双方没有任何影响</p>
<p>3、中介者设计模式：用一个中介对象来封装一系列的对象交互，这是一种多对多关系的中介者模式。</p>
<p>从功能上拆开主要有三块：服务注册、服务发现，和注册中心。我们一个一个来看。</p>
<h3>1.1 服务注册 <a href="#scroller-2" id="scroller-2"></a></h3>
<p>如图中，为Register注册中心注册一个服务信息，会将服务的信息：ServiceName、IP、Port以及服务实例MetaData元数据信息写入到注册中心。当服务发生变化的时候，也可以更新到注册中心。</p>
<p><img src="/images/blog/engineering/microservice-image_6_2.png" alt="image_6_2.png"></p>
<p>服务提供者（服务实例） 的服务注册模型是一种简单、容易理解、流行的服务注册模型，其在多种技术生态中都有所体现：</p>
<p>1、在K8S生态中，通过 K8S Service服务信息，和Pod的 endpoint（用来记录service对应的pod的访问地址）来进行注册。</p>
<p>2、在Spring Cloud生态中，应用名 对应 服务Service，实例 IP + Port 对应 Instance实例。比较典型的就是A服务，后面对应有多个实例做负载均衡。</p>
<p>3、在其他的注册组件中，比如 Eureka、Consul，服务模型也都是 服务→ 服务实例。</p>
<p>可以认为服务实例是一个真正的实体的载体，服务是对这些相同能力或者相同功能服务实例的一个抽象。</p>
<p><img src="/images/blog/engineering/microservice-image_6_3.png" alt="image_6_3.png"></p>
<h3>1.2 服务发现 <a href="#scroller-3" id="scroller-3"></a></h3>
<p>服务发现实际就是我们查询已经注册好的服务提供者，比如 p-&gt;p.queryService(serviceName)，通过服务名称查询某个服务是否存在，如果存在，</p>
<p>返回它的所有实例信息，即一组包含ip 、 port 、metadata元数据信息的endpoints信息。</p>
<p>这一组endpoints信息一般会被缓存在本地，如果注册中心挂掉，可保证段时间内依旧可用，这是去中心化的做法。对于单个 Service 后面有多个 Instance的情况（如上图），做 load balance。</p>
<p>服务发现的方式一般有两种：</p>
<p>1、拉取的方式：服务消费方（Consumer）主动向注册中心发起服务查询的请求。</p>
<p>2、推送的方式：服务订阅/通知变更（下发）：服务消费方（Consumer）主动向注册中心订阅某个服务，当注册中心中该服务信息发生变更时，注册中心主动通知消费者。</p>
<h3>1.3 注册中心 <a href="#scroller-4" id="scroller-4"></a></h3>
<p>注册中心提供的基本能力包括：提供服务注册、服务发现 以及 健康检查。</p>
<p>服务注册跟服务发现上面已经详细介绍了， 健康检查指的是指注册中心能够感知到微服务实例的健康状况，便于上游微服务实例及时发现下游微服务实例的健康状况。采取必备的访问措施，如避免访问不健康的实例。</p>
<p>主要的检查方式包括：</p>
<p>1、服务Provider 进行 TTL 健康汇报（Time To Live，微服务Provider定期向注册中心汇报健康状态）。</p>
<p>2、注册中心主动检查服务Provider接口。</p>
<p>综合我们前面的内容，可以总结下注册中心有如下几种能力：</p>
<p>1、高可用</p>
<p>这个主要体现在两个方面。一个方面是，注册中心本身作为基础设施层，具备高可用；第二种是就是前面我们说到的去中心化，极端情况下的故障，短时间内是不影响微服务应用的调用的</p>
<p>2、可视化操作</p>
<p>常用的注册中心，类似 Eureka、Consul 都有比较丰富的管理界面，对配置、服务注册、服务发现进行可视化管理。</p>
<p>3、高效运维</p>
<p>注册中心的文档丰富，对运维的支持比较好，并且对于服务的注册是动态感知获取的，方便动态扩容。</p>
<p>4、权限控制</p>
<p>数据是具有敏感性，无论是服务信息注册或服务是调用，需要具备权限控制能力，避免侵入或越权请求</p>
<p>5、服务注册推、拉能力</p>
<p>这个前面说过了，微服务应用程序（服务的Consumer），能够快速感知到服务实例的变化情况，使用拉取或者注册中心下发的方式进行处理。</p>
<p><img src="/images/blog/engineering/microservice-image_6_4.png" alt="image_6_4.png"></p>
<h2>2 现下的主流注册中心 <a href="#scroller-5" id="scroller-5"></a></h2>
<h3>2.1 Eureka <a href="#scroller-6" id="scroller-6"></a></h3>
<h4>2.1.1 介绍 <a href="#scroller-7" id="scroller-7"></a></h4>
<p>Eureka是Netflix OSS套件中关于服务注册和发现的解决方案。因为Spring Cloud 在它的微服务解决方案中对Eureka进行了集成，并作为优先推荐方案进行宣传，所以早期有用 Spring Cloud 来建设微服务系统的同学会比较熟悉。</p>
<p>目前大量公司的微服务系统中依旧使用Eureka作为注册中心，它的核心设计思想也被后续大量注册中心产品借鉴。但目前 <a href="https://github.com/Netflix/eureka/wiki">Eureka 2.0已经停止维护</a>，所以新的微服务架构设计中，不再建议使用。</p>
<p>Spring Cloud Netflix主要分为两个部分：</p>
<p>1、Eureka Server： 作为注册中心Server端，向微服务应用程序提供服务注册、发现、健康检查等能力。</p>
<p>2、Eureka Client： 微服务应用程序Client端，用以和Eureka Server进行通信。</p>
<p><img src="/images/blog/engineering/microservice-image_6_5.png" alt="image_6_5.png"></p>
<p>Eureka有比较友好的管理界面，如上图所示：</p>
<p>1、System Status：显示当前Eureka Server信息。</p>
<p>2、Instances Current registered with Eureka：在Eureka Server当前注册的数据，在Spring Cloud生态中，被注册的服务可以呗发现并罗列在这个地方。</p>
<p>3、General Info：基本信息，如cpu、内存、环境等。</p>
<h4>2.1.2 整体架构 <a href="#scroller-8" id="scroller-8"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_6_6.png" alt="image_6_6.png"></p>
<p>Eureka Server可以运行多个实例来构建集群，解决单点问题，但不同于ZooKeeper的选举leader的过程，Eureka Server采用的是Peer to Peer对等通信。</p>
<p>所以他有如下特点：</p>
<p>1、去中心化的架构：无master/slave区分，每一个Peer都是对等的。在这种架构中，节点通过彼此互相注册来提高可用性，每个节点需要添加一个或多个有效的serviceUrl指向其他节点。每个节点都可被视为其他节点的副本。</p>
<p>2、故障转移/故障恢复：如果某台Eureka Server宕机，Eureka Client的请求会自动切换到新的Eureka Server节点，当宕机的服务器重新恢复后，Eureka会再次将其纳入到服务器集群管理之中。</p>
<p>3、节点复制：当节点开始接受客户端请求时，所有的操作都会进行replicateToPeer（节点间复制）操作，将请求复制到其他Eureka Server当前所知的所有节点中。</p>
<p>同理，一个新的Eureka Server节点启动后，会首先尝试从邻近节点获取所有实例注册表信息，完成初始化。</p>
<p>4、CAP模式：复制算法非强一致性算法，而是当有数据写入时，Eureka Server将数据同步给其他的节点，因此Eureka在CAP提系统（一致性、可用性、分区容错性）是典型的AP系统。</p>
<h4>2.1.3 接入Spring Cloud <a href="#scroller-9" id="scroller-9"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_6_7.png" alt="image_6_7.png"></p>
<p>如上图所示：</p>
<p>1、Provider 服务提供者：服务向注册中心注册服务信息，即 服务 -&gt; 服务实例 数据模型， 同时定时向注册中心汇报健康检查，如果一定时间内（一般90s）没有进行心跳汇报，则会被注册中心剔除。</p>
<p>所以这边注意，注册中心感知到应用下线并进行剔除这个过程可能比较长。</p>
<p>2、Consumer 服务消费者：服务向注册中心获取所需服务对应的服务实例信息。这边需要注意，Eureka不支持订阅，因此在Spring Cloud生态中，通过定时拉取方式从注册中心中获取所需的服务实例信息。</p>
<p>3、Remote Call 远程调用：Consumer从注册中心获取的Provider的实例信息，通过 Load Balance的策略，确定一个实际的实例，发起远程调用。</p>
<h3>2.2 ZooKeeper <a href="#scroller-10" id="scroller-10"></a></h3>
<h4>2.2.1 介绍 <a href="#scroller-11" id="scroller-11"></a></h4>
<p>作为一个分布式的、开源的协调服务，ZooKeeper实现了一系列基础功能，包括简单易用的接口。</p>
<p>这些接口被用来实现服务的注册与发现功能。并实现一些高级功能，如数据同步、分布式锁、配置中心、集群选举、命名服务等。</p>
<p><img src="/images/blog/engineering/microservice-image_6_8.png" alt="image_6_8.png"></p>
<p>在数据模型上，类似于传统的文件系统，节点类型分为：</p>
<p>1、持久节点：节点创建后，就一直存在，除非执行删除操作，主动删掉这个节点。</p>
<p>2、临时节点（注册中心场景下的主要实现机制）：临时节点的生命周期和客户端会话绑定。也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。</p>
<p>在实际场景下，微服务启动的时候，会创建一个服务临时节点，等把服务停止，短时间后节点就没有了。</p>
<p><img src="/images/blog/engineering/microservice-image_6_9.png" alt="image_6_9.png"></p>
<p>Zookeeper有如下特点：</p>
<p>1、最终一致性：为客户端展示同一视图，这是zookeeper最重要的功能。2、可靠性：如果消息被到一台服务器接受，那么它将被所有的服务器接受。3、实时性：Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。4、等待无关（wait-free）：慢的或者失效的client不干预快速的client的请求。5、原子性：更新只能成功或者失败，没有中间状态。6、顺序性：所有Server，同一消息发布顺序一致。</p>
<h4>2.2.2 整体架构 <a href="#scroller-12" id="scroller-12"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_6_10.png" alt="image_6_10.png"></p>
<p>上图是Zookeeper 的服务架构，他有如下流程：</p>
<p>1、 多个节点组成分布式架构，每个Server在内存中存储一份数据；</p>
<p>2、通过选举产生leader，通过 Paxos(帕克索斯)强一致性算法 进行保证，是典型的CP结构。</p>
<p>3、Leader负责处理数据更新等操作（Zab协议）；</p>
<h4>2.2.3 接入Dubbo生态 <a href="#scroller-13" id="scroller-13"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_6_11.png" alt="image_6_11.png"></p>
<p>上图中的角色如下：</p>
<p>Provider：提供者,服务发布方</p>
<p>Consumer：消费者, 调用服务方</p>
<p>Container：Dubbo容器.依赖于Spring容器</p>
<p>Registry：注册中心，当Container启动时把所有可以提供的服务列表上Registry中进行注册，告诉Consumer提供了什么服务，以及服务方的位置</p>
<p>Monitor:监听器</p>
<p>说明：ZooKeeper在注册中心方面对Dubbo生态支持的比较好。服务提供者Providerzai Container启动时主动向注册中心Registry ZooKeeper中注册信息。</p>
<p>服务消费者Consumer启动时向注册中心Registry ZooKeeper中订阅注册中心，当Provider的信息发生变化时，注册中心ZooKeeper会主动向Consumer进行推送通知变更。</p>
<p>这边注意与Eureka的区别，这是主动推送通知，是注册中心下发的操作。</p>
<h3>2.3 Consul <a href="#scroller-14" id="scroller-14"></a></h3>
<h4>2.3.1 介绍 <a href="#scroller-15" id="scroller-15"></a></h4>
<p>Consul是HashiCorp推出的一款软件，是一个Service Mesh解决方案，提供了功能丰富的控制面功能：</p>
<p>1、Service Discovery（服务发现）</p>
<p>2、Configuration（配置化）</p>
<p>3、Segmentation Functionality</p>
<p>这些功能可以根据需要独立使用，或者将它们一起使用用来构建完整的Service Mesh。</p>
<p>Consul提供的关键功能如下：</p>
<p>1、Service Discovery：服务注册/发现功能。</p>
<p>2、Health Checking：健康检查，丰富的健康检查方式；</p>
<p>3、KV Store：KV存储功能，可应用多种场景，如动态配置存储，分布式协调、leader选举等。</p>
<p>4、Multi DataCenter：多数据中心。</p>
<h4>2.3.2 整体架构 <a href="#scroller-16" id="scroller-16"></a></h4>
<p><img src="/images/blog/engineering/microservice-image_6_12.png" alt="image_6_12.png"></p>
<p>如上图为Consul的架构，这边对技术点做一下说明：</p>
<p>1、Raft: 一种分布式一致性算法，Consul使用该算法保持强一致性，所以也是典型的CP模式</p>
<p>2、Client：Client是一种agent，其将会重定向所有的RPC 请求到Server。Client是无状态的，其主要参与LAN Gossip协议池。其占用很少的资源，并且消耗很少的网络带宽。</p>
<p>3、Server：Server是一种agent，其包含了一系列的责任包括：参与Raft协议写半数（Raft Quorum）、维护集群状态、响应RPC响应、和其他Datacenter通过WAN gossip交换信息和重定向查询请求至leader或者远端Datacenter。</p>
<p>4、Datacenter: Datacenter其是私有的、低延迟、高带宽的网络环境，去除了在公共网络上的网络交互。</p>
<p>5、Consensus: Consensus一致性在leader 选举、顺序执行transaction 上。当这些事务已经提交至有限状态机（finite-state machine）中，Consul定义consensus作为复制状态机的一致性。本质上使用实现了Raft协议，对于具体实现细节可参考 Consensus Protocol。</p>
<p>6、Gossip：Consul使用了Serf，其提供了Gossip协议多种用途，Serf提供成员关系、失败检查和事件广播。</p>
<p>7、LAN Gossip: Local Area Network Gossip其包含在同一个网络环境或Datacenter的节点。</p>
<p>8、WAN Gossip: Wide Area Network Gossip 其只包含Server节点，这些server分布在不同的datacenter中，其主要通过因特网或广域网相互交流。</p>
<p>9、RPC: 远程过程调用，用于服务之间的通信。</p>
<p>10、CAP抉择：在高可用方面，Consul使用Raft协议作为其分布式一致性协议，本身对故障节点有一定的容忍性，在单个DataCenter中Consul集群中节点的数量控制在2*n + 1个节点，其中n为可容忍的宕机个数，通常为3个节点。</p>
<p>所以是典型的CP模式。</p>
<p><img src="/images/blog/engineering/microservice-image_6_13.png" alt="image_6_13.png"></p>
<p>根据Consul 的选举机制和服务原理，我们有两个注意点 ：</p>
<p>1、部署Consul Service 节点应该奇数为宜，因为+1的偶数节点和奇数节点可容忍的故障数是一样的，比如上图3和4，另一方面，偶数个节点在选主节点的时候可能会出现二分选票的情况，还得重新选举。</p>
<p>2、Consul Service 节点数不是越多越好，虽然Server数量越多可容忍的故障数越多，但是Raft进行日志复制也是很耗时间的，而且Server数量越多，性能越低，所以结合实际场景，一般建议Server部署3个即可。</p>
<p>有兴趣的同学可以去Consul官网看看它的选举机制，还可以对比下Redis中Sentinel模式。</p>
<h4>2.3.3 生态对接 <a href="#scroller-17" id="scroller-17"></a></h4>
<p><strong>对接Spring Cloud生态</strong></p>
<p><img src="/images/blog/engineering/microservice-image_6_14.png" alt="image_6_14.png"></p>
<p>Consul作为注册中心，集成在Spring Cloud生态。可以看出，跟Eureka对接到Spring Cloud 生态的过程很像。</p>
<p>但是这边的健康检查更丰富，可以有多种不同的的Check方式：</p>
<ul>
<li>Script check（Script+ Interval）</li>
<li>基于HTTP请求</li>
<li>基于tcp请求</li>
<li>基于grpc请求</li>
</ul>
<h3>2.4 总结对比 <a href="#scroller-19" id="scroller-19"></a></h3>
<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>Eureka</strong></th>
<th><strong>Zookeeper</strong></th>
<th><strong>Consul</strong></th>
<th><strong>Etcd</strong></th>
</tr>
</thead>
<tbody><tr>
<td>一致性协议</td>
<td>AP</td>
<td>CP（Paxos算法）</td>
<td>CP（Raft算法）</td>
<td>CP（Raft算法）</td>
</tr>
<tr>
<td>健康检查</td>
<td>TTL(Time To Live)</td>
<td>TCP Keep Alive</td>
<td>TTL\HTTP\TCP\Script</td>
<td>Lease TTL KeepAlive</td>
</tr>
<tr>
<td>watch/long polling</td>
<td>不支持</td>
<td>watch</td>
<td>long polling</td>
<td>watch</td>
</tr>
<tr>
<td>雪崩保护</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr>
<td>安全与权限</td>
<td>不支持</td>
<td>ACL</td>
<td>ACL</td>
<td>RBAC</td>
</tr>
<tr>
<td>是否支持多数据中心</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>是否有管理界面</td>
<td>是</td>
<td>否（可用第三方ZkTools）</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>Spring Cloud 集成</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>Dubbo 集成</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>K8S 集成</td>
<td>不支持</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody></table>
<p>这边是对业内4种注册中心各纬度上的对比，Eureka是典型的AP类型，Zookeeper和Consul是典型的CP类型。如何选择取决你的业务是倾向A：高可用性 还是 C：强一致性。</p>
<p>当然，业务是复杂的，在真正的技术选型时，还是要根据自己的实际业务现状来判断。有一些倾向，比如你的系统是Spring Cloud体系下，那优先选择Eureka、Consul。</p>
<p>如果业务会更多向云原生对齐，则Consul、Etcd会是比较优先的选择。</p>
5:["$","article",null,{"className":"min-h-screen","children":["$","div",null,{"className":"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8","children":["$","div",null,{"className":"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12","children":[["$","header",null,{"className":"mb-8","children":[["$","nav",null,{"className":"flex items-center gap-1 text-sm mb-4","children":[["$","$L13",null,{"href":"/blog/page/1","className":"text-gray-500 hover:text-blue-600 transition-colors","children":"博客"}],["$","span",null,{"className":"text-gray-300","children":"/"}],["$","$L13",null,{"href":"/blog/category/engineering/page/1","className":"text-gray-500 hover:text-blue-600 transition-colors","children":"Engineering"}],[["$","span",null,{"className":"text-gray-300","children":"/"}],["$","$L13",null,{"href":"/blog/category/engineering/architecture/page/1","className":"text-blue-600 hover:text-blue-700 transition-colors","children":"架构设计"}]]]}],["$","div",null,{"className":"flex items-center mb-6","children":["$","div",null,{"className":"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal","children":[["$","svg",null,{"className":"w-4 h-4 mr-2 text-gray-400","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"}]}],["$","time",null,{"dateTime":"2024-03-21","children":"2024年03月21日"}]]}]}],["$","h1",null,{"className":"text-4xl font-bold text-gray-900 mb-6 text-center","children":"微服务拆分策略"}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-6 justify-center","children":[["$","$L13","微服务",{"href":"/blog/tag/%E5%BE%AE%E6%9C%8D%E5%8A%A1/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"微服务"}],["$","$L13","服务拆分",{"href":"/blog/tag/%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"服务拆分"}],["$","$L13","架构设计",{"href":"/blog/tag/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/page/1/","className":"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors","children":"架构设计"}]]}]]}],["$","div",null,{"className":"max-w-5xl mx-auto","children":["$","$L14",null,{"content":"$15"}]}],["$","$10",null,{"fallback":["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":"加载导航中..."}],"children":["$","$L16",null,{"globalNav":{"prev":{"slug":"engineering/architecture/微服务全景架构","title":"微服务全景架构","description":"微服务架构提倡的单一应用程序划分成一组松散耦合的细粒度小型服务，辅助轻量级的协议，互相协调、互相配合，实现高效的应用价值，符合我们应用服务开发的发展趋势。","pubDate":"2024-03-20","tags":["微服务","全景架构","分布式系统"],"heroImage":"$undefined","content":"$17"},"next":{"slug":"engineering/architecture/微服务拆分策略（附加篇）","title":"微服务拆分策略（附加篇）","description":"关于服务拆分的切入点，我们先从MartinL.Abbott所著《架构即未来》中所介绍的AKF扩展立方体出发寻找一些灵感，然后给出本文中关于服务拆分的两大维度。 1. AKF扩展立方体 AKF扩展立方体（Scalability Cube）是一种可扩展模型，这个立方体有三个轴线，每个轴线描述扩展性的一...","pubDate":"2024-03-22","tags":["微服务","服务拆分","领域驱动"],"heroImage":"$undefined","content":"$18"}},"tagNav":{"微服务":{"prev":"$5:props:children:props:children:props:children:2:props:children:props:globalNav:prev","next":"$5:props:children:props:children:props:children:2:props:children:props:globalNav:next"},"服务拆分":{"prev":null,"next":"$5:props:children:props:children:props:children:2:props:children:props:globalNav:next"},"架构设计":{"prev":{"slug":"engineering/architecture/架构设计模板","title":"架构设计模板","description":"一套可落地的架构设计文档模板，涵盖需求分析、架构总览、核心流程、详细设计等 11 个关键维度，附可直接复用的 Markdown 模板。","pubDate":"2024-03-16","tags":["架构设计","设计模板","方法论"],"heroImage":"$undefined","content":"$19"},"next":{"slug":"engineering/architecture/服务注册与发现","title":"服务注册与发现","description":"我们前面在全景架构中对服务注册与发现做了大致的说明，本章我们着重详细说明微服务下注册与发现的这个能力。微服务注册与发现类似于生活中的电话通讯录的概念，它记录了通讯录服务和电话的映射关系。","pubDate":"2024-03-23","tags":["微服务","服务发现","架构设计"],"heroImage":"$undefined","content":"$1a"}}}}]}],["$","$L1b",null,{}]]}]}]}]
8:null
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
a:{"metadata":[["$","title","0",{"children":"微服务拆分策略 - Skyfalling Blog"}],["$","meta","1",{"name":"description","content":"前面我们学习了微服务的全景架构，了解到相对于传统单体架构，微服务的优势，以及系统服务化的发展趋势。 对于新启动的项目，我们在权衡之后可以大方的使用微服务架构。但其实大部分情况下，我们还要去维护一些以前研发的单体系统，这些系统可能因为访问流量的膨胀、功能的扩张而显得非常臃肿不堪，急需要向微服务架构迁移..."}],["$","meta","2",{"property":"og:title","content":"微服务拆分策略"}],["$","meta","3",{"property":"og:description","content":"前面我们学习了微服务的全景架构，了解到相对于传统单体架构，微服务的优势，以及系统服务化的发展趋势。 对于新启动的项目，我们在权衡之后可以大方的使用微服务架构。但其实大部分情况下，我们还要去维护一些以前研发的单体系统，这些系统可能因为访问流量的膨胀、功能的扩张而显得非常臃肿不堪，急需要向微服务架构迁移..."}],["$","meta","4",{"property":"og:type","content":"article"}],["$","meta","5",{"property":"article:published_time","content":"2024-03-21"}],["$","meta","6",{"property":"article:author","content":"Skyfalling"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"微服务拆分策略"}],["$","meta","9",{"name":"twitter:description","content":"前面我们学习了微服务的全景架构，了解到相对于传统单体架构，微服务的优势，以及系统服务化的发展趋势。 对于新启动的项目，我们在权衡之后可以大方的使用微服务架构。但其实大部分情况下，我们还要去维护一些以前研发的单体系统，这些系统可能因为访问流量的膨胀、功能的扩张而显得非常臃肿不堪，急需要向微服务架构迁移..."}],["$","link","10",{"rel":"shortcut icon","href":"/favicon.png"}],["$","link","11",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","link","12",{"rel":"icon","href":"/favicon.png"}],["$","link","13",{"rel":"apple-touch-icon","href":"/favicon.png"}]],"error":null,"digest":"$undefined"}
12:{"metadata":"$a:metadata","error":null,"digest":"$undefined"}
