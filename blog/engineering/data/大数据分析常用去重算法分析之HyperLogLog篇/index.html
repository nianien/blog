<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/7fd1f07c30a72cee.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42d55485b4428e47.js"/><script src="/_next/static/chunks/4bd1b696-8ec333fca6b38e39.js" async=""></script><script src="/_next/static/chunks/1684-a2aac8a674e5d38c.js" async=""></script><script src="/_next/static/chunks/main-app-2791dc86ed05573e.js" async=""></script><script src="/_next/static/chunks/6874-7791217feaf05c17.js" async=""></script><script src="/_next/static/chunks/app/layout-51baccc14cf1da9e.js" async=""></script><script src="/_next/static/chunks/968-d7155a2506e36f1d.js" async=""></script><script src="/_next/static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js" async=""></script><meta name="next-size-adjust" content=""/><title>大数据分析常用去重算法分析之HyperLogLog篇 - Skyfalling Blog</title><meta name="description" content="上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 "/><meta property="og:title" content="大数据分析常用去重算法分析之HyperLogLog篇"/><meta property="og:description" content="上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 "/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-03-25"/><meta property="article:author" content="Skyfalling"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="大数据分析常用去重算法分析之HyperLogLog篇"/><meta name="twitter:description" content="上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 "/><link rel="shortcut icon" href="/favicon.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/favicon.png"/><link rel="apple-touch-icon" href="/favicon.png"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen flex flex-col"><header class="bg-[var(--background)]"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a class="-m-1.5 p-1.5" href="/"><span class="sr-only">Skyfalling Blog</span><span class="text-2xl font-bold text-gray-900">Skyfalling</span></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">打开主菜单</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/">首页</a><a class="text-base font-semibold leading-6 transition-colors text-blue-600 border-b-2 border-blue-600 pb-1" href="/blog/">博客</a><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/about/">关于</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"><a class="text-base font-semibold leading-6 transition-colors text-gray-900 hover:text-blue-600" href="/contact/">联系 <span aria-hidden="true">→</span></a></div></nav></header><main class="flex-1"><article class="min-h-screen"><div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8"><div class="rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12"><header class="mb-8"><nav class="flex items-center gap-1 text-sm mb-4"><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/page/1/">博客</a><span class="text-gray-300">/</span><a class="text-gray-500 hover:text-blue-600 transition-colors" href="/blog/category/engineering/page/1/">Engineering</a><span class="text-gray-300">/</span><a class="text-blue-600 hover:text-blue-700 transition-colors" href="/blog/category/engineering/data/page/1/">数据工程</a></nav><div class="flex items-center mb-6"><div class="inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal"><svg class="w-4 h-4 mr-2 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path></svg><time dateTime="2025-03-25">2025年03月25日</time></div></div><h1 class="text-4xl font-bold text-gray-900 mb-6 text-center">大数据分析常用去重算法分析之HyperLogLog篇</h1><div class="flex flex-wrap gap-2 mb-6 justify-center"><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/%E5%A4%A7%E6%95%B0%E6%8D%AE/page/1/">大数据</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/%E5%8E%BB%E9%87%8D%E7%AE%97%E6%B3%95/page/1/">去重算法</a><a class="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors" href="/blog/tag/HyperLogLog/page/1/">HyperLogLog</a></div></header><div class="max-w-5xl mx-auto"><div class="prose prose-lg prose-gray mx-auto max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-p:text-gray-700 prose-p:leading-relaxed prose-a:text-blue-600 prose-a:no-underline hover:prose-a:text-blue-700 prose-strong:text-gray-900 prose-strong:font-semibold prose-li:text-gray-700 prose-hr:border-gray-300"><p>上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。</p>
<p><img src="/images/blog/engineering/bigdata-image_2_1.png" alt="image_2_1.png"></p>
<p>HLL 算法需要完整遍历所有元素一次，而非多次或采样；该算法只能计算集合中有多少个不重复的元素，不能给出每个元素的出现次数或是判断一个元素是否之前出现过；多个使用 HLL 统计出的基数值可以融合。</p>
<p><img src="/images/blog/engineering/bigdata-image_2_2.png" alt="image_2_2.png"></p>
<p><img src="/images/blog/engineering/bigdata-image_2_3.png" alt="image_2_3.png"></p>
<p>HLL 算法有着非常优异的空间复杂度，可以看到它的空间占用随着基数值的增长并没有变化。HLL 后面不同的数字代表着不同的精度，数字越大，精度越高，占用的空间也越大，可以认为 HLL 的空间占用只和精度成正相关。</p>
<p><strong>HLL算法原理感性认知</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_4.png" alt="image_2_4.png"></p>
<p>HLL 算法的原理会涉及到比较多的数学知识，这边对这些数学原理和证明不会展开。举一个生活中的例子来帮助大家理解HLL算法的原理：比如你在进行一个实验，内容是不停地抛硬币，记录你连续抛到正面的次数（这是数学中的伯努利过程，感兴趣同学可以自行研究下）；如果你最多的连抛正面记录是3次，那可以想象你并没有做这个实验太多次，如果你最长的连抛正面记录是 20 次，那你可能进行了这个实验上千次。</p>
<p>一种理论上存在的情况是，你非常幸运，第一次进行这个实验就连抛了 20 次正面，我们也会认为你进行了很多次这个实验才得到了这个记录，这就会导致错误的预估；改进的方式是请 10 位同学进行这项实验，这样就可以观察到更多的样本数据，降低出现上述情况的概率。这就是 HLL 算法的核心思想。</p>
<p><strong>HLL算法具体实现</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_5.png" alt="image_2_5.png"></p>
<p>HLL 会通过一个 hash 函数来求出集合中所有元素的 hash 值（二进制表示的 hash 值，就可以理解为一串抛硬币正反面结果的序列），得到一个 hash 值的集合，然后找出该 hash 值集合中，第一个 1 出现的最晚的位置。例如有集合为 [010, 100, 001], 集合中元素的第一个 1 出现的位置分别为 2, 1, 3，可以得到里面最大的值为 3，故该集合中第一个1出现的最晚的位置为 3。因为每个位置上出现1的概率都是 1/2，所以我们可以做一个简单的推断，该集合中有 8 个不重复的元素。</p>
<p>可以看到这种简单的推断计算出来集合的基数值是有较大的偏差的，那如何来减少偏差呢？正如我上面的例子里说的一样，HLL 通过多次的进行试验来减少误差。那它是如何进行多次的实验的呢？这里 HLL 使用了分桶的思想，上文中我们一直有提到一个精度的概念，比如说 HLL(10)，这个 10 代表的就是取该元素对应 Hash 值二进制的后 10 位，计算出记录对应的桶，桶中会记录一个数字，代表对应到该桶的 hash 值的第一个 1 出现的最晚的位置。如上图，该 hash 值的后 10 位的 hash 值是 0000001001，转成 10 进制是 9，对应第 9 号桶，而该 hash 值第一个 1 出现的位置是第 6 位，比原先 9 号桶中的数字大，故把 9 号桶中的数字更新为 6。可以看到桶的个数越多，HLL 算法的精度就越高，HLL(10) 有 1024(210) 个桶，HLL(16)有 65536(216) 个桶。同样的，桶的个数越多，所占用的空间也会越大。</p>
<p><img src="/images/blog/engineering/bigdata-image_2_6.png" alt="image_2_6.png"></p>
<p>刚才的例子我们省略了一些细节，为了让大家不至于迷失在细节中而忽视了重点，真实的 HLL 算法的完整描述见上图，这边的重点是计算桶中平均数时使用调和平均数。调和平均数的优点是可以过滤掉不健康的统计值，使用算术平均值容易受到极值的影响（想想你和马云的平均工资），而调和平均数的结果会倾向于集合中比较小的元素。HLL 论文中还有更多的细节和参数，这边就不一一细举，感兴趣的同学可以自己阅读下论文。</p>
<p><strong>HLL评估</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_7.png" alt="image_2_7.png"></p>
<p>HLL 的误差分布服从正态分布，它的空间复杂度: O(m log2log2N), Ｎ 为基数, m 为桶个数。这边给大家推导一下它的空间复杂度，我有 264 个的不重复元素(Long. MAX_VALUE)，表达为二进制一个数是 64 位，这是第一重 log2, 那么第一个1最晚可能出现在第 64 位。64 需要 6 个 bit (26=64) 就可以存储，这是第二重 log2。如果精度为 10，则会有 1024 个桶，所以最外面还要乘以桶的个数。由于需要完整的遍历元素一遍，所以它的时间复杂度是一个线性的时间复杂度。</p>
<p><strong>在Kylin中的应用</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_8.png" alt="image_2_8.png"></p>
<p>在 Kylin 中使用 HLL 非常简单，在编辑度量的页面选择 COUNT DISTINCT，Return Type 选为非 Precisely 的其他选项，大家根据自己的需求选择不同的精度就可以愉快地使用了。</p>
<p><strong>总结</strong></p>
<p><img src="/images/blog/engineering/bigdata-image_2_9.png" alt="image_2_9.png"></p>
<p>我们回到最开始的去重场景，看看使用了 Bitmap 和 HLL 会给我们带来什么增益：无优化 case 下，每个 item 对应的 user_id 就可以看成存储原始值的一个集合；在使用 Bitmap 优化的case 下，每个 item 对应的 user_id 就可以看成一个 Bitmap 实例，同理 HLL就是一个 HLL 的实例，Bitmap/HLL 实例占用的空间都会比直接存储原始值的集合要小，这就达到了我们开始提的减少 shuffle 数据量的需求。</p>
<p><strong>Q&amp;A</strong></p>
<p>Q：您好，问一下关于精确去重的问题， 我选择了非精确去重，最后的误差率有时候会比界面上提示的值要高一些，这是为什么？</p>
<p>A：首先 HLL 的误差分布服从正态分布，也就是说是在99%的情况下是这个误差，同时 HLL 对于基数比较低的情况，误差会偏高。如果你的基数比较低的话，我推荐使用精确去重。</p>
<p>Q：我想要了解一下 Bitmap 在 Kylin 中，它最终落盘在 HBase 里面是什么样子的？</p>
<p>A：在 HBase 中存储的当然都是 Bytes。这个问题其实就是 Bitmap 的序列化的形式，Roaring Bitmap提供了序列化和反序列化的实现，你也可以写自己的序列化/反序列化的实现。</p>
<p>Q：Roaring Bitmap 里这些 container 要我们自己手动的指定吗。</p>
<p>A：不需要，Roaring Bitmap 会自动选择使用哪个 Container。</p>
</div></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div class="mt-12 pt-8 border-t border-gray-200">加载导航中...</div><!--/$--><div class="mt-16 border-t border-gray-200 pt-8"><div class="mx-auto max-w-3xl"><h3 class="text-2xl font-bold text-gray-900 mb-8">评论</h3></div></div></div></div></article><!--$--><!--/$--></main><footer class="bg-[var(--background)]"><div class="mx-auto max-w-7xl px-6 py-12 md:flex md:items-center md:justify-between lg:px-8"><div class="flex justify-center space-x-6 md:order-2"><a class="text-gray-600 hover:text-gray-800" href="/about/">关于</a><a class="text-gray-600 hover:text-gray-800" href="/blog/">博客</a><a class="text-gray-600 hover:text-gray-800" href="/contact/">联系</a></div><div class="mt-8 md:order-1 md:mt-0"><p class="text-center text-xs leading-5 text-gray-600">© <!-- -->2026<!-- --> Skyfalling Blog. All rights reserved.</p></div></div></footer></div><script src="/_next/static/chunks/webpack-42d55485b4428e47.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[10616,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"7177\",\"static/chunks/app/layout-51baccc14cf1da9e.js\"],\"default\"]\n3:I[87555,[],\"\"]\n4:I[31295,[],\"\"]\n5:I[6874,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"\"]\n7:I[59665,[],\"OutletBoundary\"]\na:I[74911,[],\"AsyncMetadataOutlet\"]\nc:I[59665,[],\"ViewportBoundary\"]\ne:I[59665,[],\"MetadataBoundary\"]\n10:I[26614,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/7fd1f07c30a72cee.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"9RQYaybRr2vNaUZfuFRUM\",\"p\":\"\",\"c\":[\"\",\"blog\",\"engineering\",\"data\",\"%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%8E%BB%E9%87%8D%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B9%8BHyperLogLog%E7%AF%87\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"engineering/data/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%8E%BB%E9%87%8D%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B9%8BHyperLogLog%E7%AF%87\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/7fd1f07c30a72cee.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"bg-[var(--background)]\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-6 py-12 md:flex md:items-center md:justify-between lg:px-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex justify-center space-x-6 md:order-2\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/about\",\"className\":\"text-gray-600 hover:text-gray-800\",\"children\":\"关于\"}],[\"$\",\"$L5\",null,{\"href\":\"/blog\",\"className\":\"text-gray-600 hover:text-gray-800\",\"children\":\"博客\"}],[\"$\",\"$L5\",null,{\"href\":\"/contact\",\"className\":\"text-gray-600 hover:text-gray-800\",\"children\":\"联系\"}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 md:order-1 md:mt-0\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs leading-5 text-gray-600\",\"children\":[\"© \",2026,\" Skyfalling Blog. All rights reserved.\"]}]}]]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"engineering/data/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B8%B8%E7%94%A8%E5%8E%BB%E9%87%8D%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B9%8BHyperLogLog%E7%AF%87\",\"c\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L6\",null,[\"$\",\"$L7\",null,{\"children\":[\"$L8\",\"$L9\",[\"$\",\"$La\",null,{\"promise\":\"$@b\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"RaAMc4bkFG7vnUoqQXD6Cv\",{\"children\":[[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Le\",null,{\"children\":\"$Lf\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$10\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"11:\"$Sreact.suspense\"\n12:I[74911,[],\"AsyncMetadata\"]\n14:I[32923,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n16:I[40780,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\n19:I[85300,[\"6874\",\"static/chunks/6874-7791217feaf05c17.js\",\"968\",\"static/chunks/968-d7155a2506e36f1d.js\",\"6909\",\"static/chunks/app/blog/%5B...slug%5D/page-3137b04d8f9ed325.js\"],\"default\"]\nf:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$11\",null,{\"fallback\":null,\"children\":[\"$\",\"$L12\",null,{\"promise\":\"$@13\"}]}]}]\n15:T1ce1,"])</script><script>self.__next_f.push([1,"\u003cp\u003e上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_1.png\" alt=\"image_2_1.png\"\u003e\u003c/p\u003e\n\u003cp\u003eHLL 算法需要完整遍历所有元素一次，而非多次或采样；该算法只能计算集合中有多少个不重复的元素，不能给出每个元素的出现次数或是判断一个元素是否之前出现过；多个使用 HLL 统计出的基数值可以融合。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_2.png\" alt=\"image_2_2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_3.png\" alt=\"image_2_3.png\"\u003e\u003c/p\u003e\n\u003cp\u003eHLL 算法有着非常优异的空间复杂度，可以看到它的空间占用随着基数值的增长并没有变化。HLL 后面不同的数字代表着不同的精度，数字越大，精度越高，占用的空间也越大，可以认为 HLL 的空间占用只和精度成正相关。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHLL算法原理感性认知\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_4.png\" alt=\"image_2_4.png\"\u003e\u003c/p\u003e\n\u003cp\u003eHLL 算法的原理会涉及到比较多的数学知识，这边对这些数学原理和证明不会展开。举一个生活中的例子来帮助大家理解HLL算法的原理：比如你在进行一个实验，内容是不停地抛硬币，记录你连续抛到正面的次数（这是数学中的伯努利过程，感兴趣同学可以自行研究下）；如果你最多的连抛正面记录是3次，那可以想象你并没有做这个实验太多次，如果你最长的连抛正面记录是 20 次，那你可能进行了这个实验上千次。\u003c/p\u003e\n\u003cp\u003e一种理论上存在的情况是，你非常幸运，第一次进行这个实验就连抛了 20 次正面，我们也会认为你进行了很多次这个实验才得到了这个记录，这就会导致错误的预估；改进的方式是请 10 位同学进行这项实验，这样就可以观察到更多的样本数据，降低出现上述情况的概率。这就是 HLL 算法的核心思想。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHLL算法具体实现\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_5.png\" alt=\"image_2_5.png\"\u003e\u003c/p\u003e\n\u003cp\u003eHLL 会通过一个 hash 函数来求出集合中所有元素的 hash 值（二进制表示的 hash 值，就可以理解为一串抛硬币正反面结果的序列），得到一个 hash 值的集合，然后找出该 hash 值集合中，第一个 1 出现的最晚的位置。例如有集合为 [010, 100, 001], 集合中元素的第一个 1 出现的位置分别为 2, 1, 3，可以得到里面最大的值为 3，故该集合中第一个1出现的最晚的位置为 3。因为每个位置上出现1的概率都是 1/2，所以我们可以做一个简单的推断，该集合中有 8 个不重复的元素。\u003c/p\u003e\n\u003cp\u003e可以看到这种简单的推断计算出来集合的基数值是有较大的偏差的，那如何来减少偏差呢？正如我上面的例子里说的一样，HLL 通过多次的进行试验来减少误差。那它是如何进行多次的实验的呢？这里 HLL 使用了分桶的思想，上文中我们一直有提到一个精度的概念，比如说 HLL(10)，这个 10 代表的就是取该元素对应 Hash 值二进制的后 10 位，计算出记录对应的桶，桶中会记录一个数字，代表对应到该桶的 hash 值的第一个 1 出现的最晚的位置。如上图，该 hash 值的后 10 位的 hash 值是 0000001001，转成 10 进制是 9，对应第 9 号桶，而该 hash 值第一个 1 出现的位置是第 6 位，比原先 9 号桶中的数字大，故把 9 号桶中的数字更新为 6。可以看到桶的个数越多，HLL 算法的精度就越高，HLL(10) 有 1024(210) 个桶，HLL(16)有 65536(216) 个桶。同样的，桶的个数越多，所占用的空间也会越大。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_6.png\" alt=\"image_2_6.png\"\u003e\u003c/p\u003e\n\u003cp\u003e刚才的例子我们省略了一些细节，为了让大家不至于迷失在细节中而忽视了重点，真实的 HLL 算法的完整描述见上图，这边的重点是计算桶中平均数时使用调和平均数。调和平均数的优点是可以过滤掉不健康的统计值，使用算术平均值容易受到极值的影响（想想你和马云的平均工资），而调和平均数的结果会倾向于集合中比较小的元素。HLL 论文中还有更多的细节和参数，这边就不一一细举，感兴趣的同学可以自己阅读下论文。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHLL评估\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_7.png\" alt=\"image_2_7.png\"\u003e\u003c/p\u003e\n\u003cp\u003eHLL 的误差分布服从正态分布，它的空间复杂度: O(m log2log2N), Ｎ 为基数, m 为桶个数。这边给大家推导一下它的空间复杂度，我有 264 个的不重复元素(Long. MAX_VALUE)，表达为二进制一个数是 64 位，这是第一重 log2, 那么第一个1最晚可能出现在第 64 位。64 需要 6 个 bit (26=64) 就可以存储，这是第二重 log2。如果精度为 10，则会有 1024 个桶，所以最外面还要乘以桶的个数。由于需要完整的遍历元素一遍，所以它的时间复杂度是一个线性的时间复杂度。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e在Kylin中的应用\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_8.png\" alt=\"image_2_8.png\"\u003e\u003c/p\u003e\n\u003cp\u003e在 Kylin 中使用 HLL 非常简单，在编辑度量的页面选择 COUNT DISTINCT，Return Type 选为非 Precisely 的其他选项，大家根据自己的需求选择不同的精度就可以愉快地使用了。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e总结\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_2_9.png\" alt=\"image_2_9.png\"\u003e\u003c/p\u003e\n\u003cp\u003e我们回到最开始的去重场景，看看使用了 Bitmap 和 HLL 会给我们带来什么增益：无优化 case 下，每个 item 对应的 user_id 就可以看成存储原始值的一个集合；在使用 Bitmap 优化的case 下，每个 item 对应的 user_id 就可以看成一个 Bitmap 实例，同理 HLL就是一个 HLL 的实例，Bitmap/HLL 实例占用的空间都会比直接存储原始值的集合要小，这就达到了我们开始提的减少 shuffle 数据量的需求。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eQ\u0026amp;A\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eQ：您好，问一下关于精确去重的问题， 我选择了非精确去重，最后的误差率有时候会比界面上提示的值要高一些，这是为什么？\u003c/p\u003e\n\u003cp\u003eA：首先 HLL 的误差分布服从正态分布，也就是说是在99%的情况下是这个误差，同时 HLL 对于基数比较低的情况，误差会偏高。如果你的基数比较低的话，我推荐使用精确去重。\u003c/p\u003e\n\u003cp\u003eQ：我想要了解一下 Bitmap 在 Kylin 中，它最终落盘在 HBase 里面是什么样子的？\u003c/p\u003e\n\u003cp\u003eA：在 HBase 中存储的当然都是 Bytes。这个问题其实就是 Bitmap 的序列化的形式，Roaring Bitmap提供了序列化和反序列化的实现，你也可以写自己的序列化/反序列化的实现。\u003c/p\u003e\n\u003cp\u003eQ：Roaring Bitmap 里这些 container 要我们自己手动的指定吗。\u003c/p\u003e\n\u003cp\u003eA：不需要，Roaring Bitmap 会自动选择使用哪个 Container。\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"17:T214d,"])</script><script>self.__next_f.push([1,"\u003ch2\u003e一、AI 正在发生什么：从“更大”到“更能干”\u003c/h2\u003e\n\u003ch3\u003e1）大模型走向“世界建模”\u003c/h3\u003e\n\u003cp\u003e以 GPT 系列、Claude、Gemini、通义等为代表的通用模型，已从语言理解扩展到视觉、语音、视频与动作控制，形成“多模态 +\u003cbr\u003e代理（agentic）”的新范式。斯坦福 HAI《AI Index 2025》指出：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e性能跃升\u003c/strong\u003e：2024 年模型在复杂推理与编程任务中的表现较 2023 年提升 50% 以上；SWE-bench 可解比例从 4.4% 提升至 71.7%。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e开源追平\u003c/strong\u003e：开源与闭源模型性能差距从 8% 缩小至 2%，AI 正从“巨头独占”走向“开源共享”。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e成本坍缩\u003c/strong\u003e：达到 GPT-3.5 水平的模型推理成本两年下降 280 倍。AI 的使用门槛正被迅速拉低。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2）科学计算的“AI 第一性”\u003c/h3\u003e\n\u003cp\u003eAlphaFold3、DeepMind 的 GNoME 以及 Earth-2 等项目，标志着 AI 已进入科学研究核心环节。AI\u003cbr\u003e不再仅仅识别模式，而是参与规律发现。生物学、气候模拟、材料科学正经历“生成—推理—验证”范式革命。\u003c/p\u003e\n\u003ch3\u003e3）从“工具”到“基础设施”\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e投资规模\u003c/strong\u003e：2024 年全球 AI 私营投资超 1000 亿美元，其中生成式 AI 占比 30%。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e使用扩散\u003c/strong\u003e：企业采用 AI 的比例已达 78%，其中 65% 经常性使用生成式 AI。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e现实落地\u003c/strong\u003e：Waymo 每周执行 15 万次无人驾驶任务，AI 已成为社会运行基础的一部分。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e二、为什么重要：效率红利、产业结构与科学范式\u003c/h2\u003e\n\u003ch3\u003e1）效率红利：从“人效提升”到“组织再造”\u003c/h3\u003e\n\u003cp\u003e多项研究显示生成式 AI 对知识工作者生产率提升 15%–40%。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e客服实验表明，新手员工在 AI 辅助下解决率提升 35%。\u003c/li\u003e\n\u003cli\u003e开发者使用代码助手后任务完成速度提升 25%。\u003cbr\u003e这种提升不仅体现在个体效率，更在于组织结构的重塑：未来企业将从“分工协作”进化为“人机协作”。AI 成为企业内部“第二大脑”，承担分析、生成与验证任务。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2）产业结构：从“软件吞噬世界”到“智能重写行业”\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e医疗\u003c/strong\u003e：AI 影像识别准确率已超专家平均水平；药物研发周期可缩短 40%。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e制造\u003c/strong\u003e：AI 驱动的质量检测与预测性维护提升生产良率 15%。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e金融\u003c/strong\u003e：AI 在风险建模与客服中广泛部署，节省运营成本 30%。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e交通\u003c/strong\u003e：智能调度与自动驾驶结合，城市拥堵时间下降 20%。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAI 不再是“应用层创新”，而是推动整个产业链价值重新分配的“中枢技术”。\u003c/p\u003e\n\u003ch3\u003e3）科学范式：AI 成为“假设生成器”\u003c/h3\u003e\n\u003cp\u003e过去的科研范式是“假设—实验—验证”，AI 让科学进入“生成—推理—验证”阶段。它能从数据中发现潜在规律，提前模拟实验结果，再由人类科学家进行验证。AI\u003cbr\u003e正成为科学家的共创者。\u003c/p\u003e\n\u003ch2\u003e三、挑战并非“副作用”，而是“主战场”\u003c/h2\u003e\n\u003ch3\u003e1）就业与能力结构的再平衡\u003c/h3\u003e\n\u003cp\u003eAI 替代的不是人，而是重复性脑力劳动。自动化趋势导致职业结构重塑：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e单一技能岗位萎缩；跨学科与创造型岗位上升。\u003c/li\u003e\n\u003cli\u003e教育体系需从“知识传授”转向“思维训练”与“人机协作能力培养”。\u003cbr\u003e未来社会将形成“人机共生”的劳动力生态。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2）伦理与可靠性：从“黑箱能力”到“可验证智能”\u003c/h3\u003e\n\u003cp\u003e算法偏见、虚假内容（Deepfake）与隐私泄露成为公众焦虑源。伦理治理的核心是三点：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e可解释性\u003c/strong\u003e：模型需能说明其决策逻辑。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e公平性\u003c/strong\u003e：避免因训练数据导致歧视。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e隐私保护\u003c/strong\u003e：确保数据使用安全、可控、可追踪。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAI 必须从“能用”迈向“可信”。负责任 AI（Responsible AI）将成为行业标准。\u003c/p\u003e\n\u003ch3\u003e3）技术安全与失控风险\u003c/h3\u003e\n\u003cp\u003eAI 的失真（hallucination）问题在决策系统中风险极高。自主代理（Agent）可能因目标偏差造成不可预期行为。\u003cbr\u003e防范思路：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e训练阶段强化“人类反馈对齐（RLHF）”；\u003c/li\u003e\n\u003cli\u003e推理阶段嵌入安全策略与审计机制；\u003c/li\u003e\n\u003cli\u003e对外接口增加人类在环（Human-in-the-loop）。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e四、如何落地：面向企业的 8 条实践路线\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e用例优先，分层推进\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e增产层：客服、文案、数据整理等快速落地；\u003c/li\u003e\n\u003cli\u003e提质层：代码助手、策略优化、运维自动化；\u003c/li\u003e\n\u003cli\u003e创新层：Agent 工厂与自主决策系统。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e三层模型栈设计\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e任务层：小模型 + 本地推理；\u003c/li\u003e\n\u003cli\u003e通用层：API 调用闭源大模型；\u003c/li\u003e\n\u003cli\u003e中间件层：记忆、RAG、工作流编排。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e数据治理前置\u003c/strong\u003e：统一数据契约、提示语标准化、评测数据资产化。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e安全与合规即设计约束\u003c/strong\u003e：遵循隐私最小化与可追溯原则，将治理要求前置到架构设计。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e工程化评测体系\u003c/strong\u003e：建立功能、安全、成本三维评测框架，持续 A/B 测试与安全红队化。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eAgent 权限与审计机制\u003c/strong\u003e：限制外部调用权限，提供日志可追踪与回滚机制。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003e组织与人才升级\u003c/strong\u003e：新角色包括 AI 产品经理、数据提示工程师、RAI 审核官。跨职能小队成为创新主力。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eROI 量化与节奏控制\u003c/strong\u003e：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e短期衡量节省工时与质量提升；\u003c/li\u003e\n\u003cli\u003e中期衡量转化率与延迟优化；\u003c/li\u003e\n\u003cli\u003e长期关注新收入占比与边际成本下降。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e五、政策与社会：从原则到制度化共识\u003c/h2\u003e\n\u003cp\u003eAI 治理正从理念走向法规：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e**欧盟《AI 法案》**确立风险分级监管体系，高风险场景强制审查；2027 年前全面实施。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e美国 AI 行政令\u003c/strong\u003e强调透明、安全与版权保护，但更新迭代频繁，治理仍在探索中。\u003c/li\u003e\n\u003cli\u003e**中国《生成式 AI 暂行办法》**聚焦安全、合规与社会责任，强化模型备案与输出审查。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e未来治理方向是 \u003cstrong\u003e全球互认 + 本地差异化实施\u003c/strong\u003e。企业合规体系需同时满足多法域要求。\u003c/p\u003e\n\u003ch2\u003e六、反常识与纠偏\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eAI 提效不是万能药\u003c/strong\u003e：若流程与组织不变，AI 只会加重管理负担。流程再造是关键。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e小模型 + 工具链更具性价比\u003c/strong\u003e：多数结构化任务无需大模型；RAG + 检索即够用。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e安全是创新的前提\u003c/strong\u003e：早期建立安全闸门反而能加快迭代，减少上线风险。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e七、面向 2030 的三种情景\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eA：智能官能化（Augmented Intelligence）\u003c/strong\u003e\u003cbr\u003e小模型普及，AI 成为每个岗位的“副驾驶”。组织形态重构，人均产出翻倍。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eB：代理自治化（Agentic Automation）\u003c/strong\u003e\u003cbr\u003eAgent 网络接管企业内部流程，人类负责规则与异常决策。对齐与审计成为关键能力。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eC：科学范式跃迁（AI-native Science）\u003c/strong\u003e\u003cbr\u003e世界模型成为科学研究新实验室，药物与气候研究周期缩短数倍。AI 成为基础设施。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e现实将是 A→B→C 的递进演化。每个阶段都需新的治理模式与社会契约。\u003c/p\u003e\n\u003ch2\u003e八、结语：让 AI 成为“可复利的社会能力”\u003c/h2\u003e\n\u003cp\u003eAI 的未来，不是取代人类，而是\u003cstrong\u003e重塑人类能力边界\u003c/strong\u003e。\u003cbr\u003e真正的关键，不在于模型多强，而在于我们能否：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e以真实问题驱动；\u003c/li\u003e\n\u003cli\u003e以安全和伦理兜底；\u003c/li\u003e\n\u003cli\u003e以工程化与制度化保证复利。\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当人类学会以“结构化理性”驾驭智能，AI 将从风口变成文明底座。\u003cbr\u003e它既是工具，更是镜子——照见我们对智慧与秩序的共同追求。\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"18:T2bf1,"])</script><script>self.__next_f.push([1,"\u003cp\u003e去重分析在企业日常分析中的使用频率非常高，如何在大数据场景下快速地进行去重分析一直是一大难点。在近期的 Apache Kylin Meetup 北京站上，我们邀请到 Kyligence 大数据研发工程师陶加涛为大家揭开了大数据分析常用去重算法的神秘面纱。\u003c/p\u003e\n\u003cp\u003eApache Kylin 作为目前唯一一个同时支持精确与非精确去重查询的 OLAP 引擎，非常好地覆盖了大数据上的去重需求。本次分享讲解了 Kylin 这两种去重方式背后用到的算法，希望能让大家从源头上理解为什么 Kylin 的去重查询有着如此优异的性能。此次分享的回顾将分为两期，本篇首先为大家介绍精确去重算法 Bitmap 。\u003c/p\u003e\n\u003cp\u003e首先，请大家思考一个问题：在大数据处理领域中，什么环节是你最不希望见到的？以我的观点来看，shuffle 是我最不愿意见到的环节，因为一旦出现了非常多的 shuffle，就会占用大量的磁盘和网络 IO，从而导致任务进行得非常缓慢。而今天我们所讨论的去重分析，就是一个会产生非常多 shuffle 的场景，先来看以下场景：\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_1.png\" alt=\"image_1_1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e我们有一张商品访问表，表上有 item 和 user_id 两个列，我们希望求商品的 UV，这是去重非常典型的一个场景。我们的数据是存储在分布式平台上的，分别在数据节点 1 和 2 上。\u003c/p\u003e\n\u003cp\u003e我们从物理执行层面上想一下这句 SQL 背后会发生什么故事：首先分布式计算框架启动任务, 从两个节点上去拿数据, 因为 SQL group by 了 item 列, 所以需要以 item 为 key 对两个表中的原始数据进行一次 shuffle。我们来看看需要 shuffle 哪些数据：因为 select/group by了 item，所以 item 需要 shuffle 。但是，user_id 我们只需要它的一个统计值，能不能不 shuffle 整个 user_id 的原始值呢？\u003c/p\u003e\n\u003cp\u003e如果只是简单的求 count 的话, 每个数据节点分别求出对应 item 的 user_id 的 count, 然后只要 shuffle 这个 count 就行了，因为count 只是一个数字, 所以 shuffle 的量非常小。但是由于分析的指标是 count distinct，我们不能简单相加两个节点user_id 的 count distinct 值，我们只有得到一个 key 对应的所有 user_id 才能统计出正确的 count distinct值，而这些值原先可能分布在不同的节点上，所以我们只能通过 shuffle 把这些值收集到同一个节点上再做去重。而当 user_id 这一列的数据量非常大的时候，需要 shuffle 的数据量也会非常大。我们其实最后只需要一个 count 值，那么有办法可以不 shuffle 整个列的原始值吗？我下面要介绍的两种算法就提供了这样的一种思路，使用更少的信息位，同样能够求出该列不重复元素的个数（基数）。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e精确算法: Bitmap\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_2.png\" alt=\"image_1_2.png\"\u003e\u003c/p\u003e\n\u003cp\u003e第一种要介绍的算法是一种精确的去重算法，主要利用了 Bitmap 的原理。Bitmap 也称之为 Bitset，它本质上是定义了一个很大的 bit 数组，每个元素对应到 bit 数组的其中一位。例如有一个集合［2，3，5，8］对应的 Bitmap 数组是［001101001］，集合中的 2 对应到数组 index 为 2 的位置，3 对应到 index 为 3 的位置，下同，得到的这样一个数组，我们就称之为 Bitmap。很直观的，数组中 1 的数量就是集合的基数。追本溯源，我们的目的是用更小的存储去表示更多的信息，而在计算机最小的信息单位是 bit，如果能够用一个 bit 来表示集合中的一个元素，比起原始元素，可以节省非常多的存储。\u003c/p\u003e\n\u003cp\u003e这就是最基础的 Bitmap，我们可以把 Bitmap 想象成一个容器，我们知道一个 Integer 是32位的，如果一个 Bitmap 可以存放最多 Integer.MAX_VALUE 个值，那么这个 Bitmap 最少需要 32 的长度。一个 32 位长度的 Bitmap 占用的空间是512 M （2^32/8/1024/1024），这种 Bitmap 存在着非常明显的问题：这种 Bitmap 中不论只有 1 个元素或者有 40 亿个元素，它都需要占据 512 M 的空间。回到刚才求 UV 的场景，不是每一个商品都会有那么多的访问，一些爆款可能会有上亿的访问，但是一些比较冷门的商品可能只有几个用户浏览，如果都用这种 Bitmap，它们占用的空间都是一样大的，这显然是不可接受的。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e升级版 Bitmap: Roaring Bitmap\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_3.png\" alt=\"image_1_3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e对于上节说的问题，有一种设计的非常的精巧 Bitmap，叫做 Roaring Bitmap，能够很好地解决上面说的这个问题。我们还是以存放 Integer 值的 Bitmap 来举例，Roaring Bitmap 把一个 32 位的 Integer 划分为高 16 位和低 16 位，取高 16 位找到该条数据所对应的 key，每个 key 都有自己的一个 Container。我们把剩余的低 16 位放入该 Container 中。依据不同的场景，有 3 种不同的 Container，分别是 Array Container、Bitmap Container 和 Run Container，下文将一一介绍。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_4.png\" alt=\"image_1_4.png\"\u003e\u003c/p\u003e\n\u003cp\u003e首先第一种，是 Roaring Bitmap 初始化时默认的 Container，叫做 Array Container。Array Container 适合存放稀疏的数据，Array Container 内部的数据结构是一个 short array，这个 array 是有序的，方便查找。数组初始容量为 4，数组最大容量为 4096。超过最大容量 4096 时，会转换为 Bitmap Container。这边举例来说明数据放入一个 Array Container 的过程：有 0xFFFF0000 和 0xFFFF0001 两个数需要放到 Bitmap 中, 它们的前 16 位都是 FFFF，所以他们是同一个 key，它们的后 16 位存放在同一个 Container 中; 它们的后 16 位分别是 0 和 1, 在 Array Container 的数组中分别保存 0 和 1 就可以了，相较于原始的 Bitmap 需要占用 512M 内存来存储这两个数，这种存放实际只占用了 2+4=6 个字节（key 占 2 Bytes，两个 value 占 4 Bytes，不考虑数组的初始容量）。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_5.png\" alt=\"image_1_5.png\"\u003e\u003c/p\u003e\n\u003cp\u003e第二种 Container 是 Bitmap Container，其原理就是上文说的 Bitmap。它的数据结构是一个 long 的数组，数组容量固定为 1024，和上文的 Array Container 不同，Array Container 是一个动态扩容的数组。这边推导下 1024 这个值：由于每个 Container 还需处理剩余的后 16 位数据，使用 Bitmap 来存储需要 8192 Bytes（2^16/8）, 而一个 long 值占 8 个 Bytes，所以一共需要 1024（8192/8）个 long 值。所以一个 Bitmap container 固定占用内存 8 KB（1024 * 8 Byte）。当 Array Container 中元素到 4096 个时，也恰好占用 8 k（4096*2Bytes）的空间，正好等于 Bitmap 所占用的 8 KB。而当你存放的元素个数超过 4096 的时候，Array Container 的大小占用还是会线性的增长，但是 Bitmap Container 的内存空间并不会增长，始终还是占用 8 K，所以当 Array Container 超过最大容量（DEFAULT_MAX_SIZE）会转换为 Bitmap Container。\u003c/p\u003e\n\u003cp\u003e我们自己在 Kylin 中实践使用 Roaring Bitmap 时，我们发现 Array Container 随着数据量的增加会不停地 resize 自己的数组，而 Java 数组的 resize 其实非常消耗性能，因为它会不停地申请新的内存，同时老的内存在复制完成前也不会释放，导致内存占用变高，所以我们建议把 DEFAULT_MAX_SIZE 调得低一点，调成 1024 或者 2048，减少 Array Container 后期 reszie 数组的次数和开销。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_6.png\" alt=\"image_1_6.png\"\u003e\u003c/p\u003e\n\u003cp\u003e最后一种 Container 叫做Run Container，这种 Container 适用于存放连续的数据。比如说 1 到 100，一共 100 个数，这种类型的数据称为连续的数据。这边的Run指的是Run Length Encoding（RLE），它对连续数据有比较好的压缩效果。原理是对于连续出现的数字, 只记录初始数字和后续数量。例如: 对于 [11, 12, 13, 14, 15, 21, 22]，会被记录为 11, 4, 21, 1。很显然，该 Container 的存储占用与数据的分布紧密相关。最好情况是如果数据是连续分布的，就算是存放 65536 个元素，也只会占用 2 个 short。而最坏的情况就是当数据全部不连续的时候，会占用 128 KB 内存。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_7.png\" alt=\"image_1_7.png\"\u003e\u003c/p\u003e\n\u003cp\u003e总结：用一张图来总结3种 Container 所占的存储空间，可以看到元素个数达到 4096 之前，选用 Array Container 的收益是最好的，当元素个数超过了 4096 时，Array Container 所占用的空间还是线性的增长，而 Bitmap Container 的存储占用则与数据量无关，这个时候 Bitmap Container 的收益就会更好。而 Run Container 占用的存储大小完全看数据的连续性, 因此只能画出一个上下限范围 [4 Bytes, 128 KB]。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e在 Kylin 中的应用\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_8.png\" alt=\"image_1_8.png\"\u003e\u003c/p\u003e\n\u003cp\u003e我们再来看一下Bitmap 在 Kylin 中的应用，Kylin 中编辑 measure 的时候，可以选择 Count Distinct，且Return Type 选为 Precisely，点保存就可以了。但是事情没有那么简单，刚才上文在讲 Bitmap 时，一直都有一个前提，放入的值都是数值类型，但是如果不是数值类型的值，它们不能够直接放入 Bitmap，这时需要构建一个全区字典，做一个值到数值的映射，然后再放入 Bitmap 中。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_9.png\" alt=\"image_1_9.png\"\u003e\u003c/p\u003e\n\u003cp\u003e在 Kylin 中构建全局字典，当列的基数非常高的时候，全局字典会成为一个性能的瓶颈。针对这种情况，社区也一直在努力做优化，这边简单介绍几种优化的策略，更详细的优化策略可以见文末的参考链接。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_10.png\" alt=\"image_1_10.png\"\u003e\u003c/p\u003e\n\u003cp\u003e1）当一个列的值完全被另外一个列包含，而另一个列有全局字典，可以复用另一个列的全局字典。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_11.png\" alt=\"image_1_11.png\"\u003e\u003c/p\u003e\n\u003cp\u003e2）当精确去重指标不需要跨 Segment 聚合的时候，可以使用这个列的 Segment 字典代替（这个列需要字典编码）。在 Kylin 中，Segment 就相当于时间分片的概念。当不会发生跨 Segments 的分析时，这个列的 Segment 字典就可以代替这个全局字典。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/blog/engineering/bigdata-image_1_12.png\" alt=\"image_1_12.png\"\u003e\u003c/p\u003e\n\u003cp\u003e3）如果你的 cube 包含很多的精确去重指标，可以考虑将这些指标放到不同的列族上。不止是精确去重，像一些复杂 measure，我们都建议使用多个列族去存储，可以提升查询的性能。\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"article\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"rounded-2xl shadow-2xl border border-gray-200 hover:shadow-3xl transition-all duration-300 p-8 sm:p-12\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"flex items-center gap-1 text-sm mb-4\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/blog/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"博客\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L5\",null,{\"href\":\"/blog/category/engineering/page/1\",\"className\":\"text-gray-500 hover:text-blue-600 transition-colors\",\"children\":\"Engineering\"}],[[\"$\",\"span\",null,{\"className\":\"text-gray-300\",\"children\":\"/\"}],[\"$\",\"$L5\",null,{\"href\":\"/blog/category/engineering/data/page/1\",\"className\":\"text-blue-600 hover:text-blue-700 transition-colors\",\"children\":\"数据工程\"}]]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center mb-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center px-3 py-1.5 bg-gray-50 text-gray-600 rounded-md text-sm font-normal\",\"children\":[[\"$\",\"svg\",null,{\"className\":\"w-4 h-4 mr-2 text-gray-400\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"viewBox\":\"0 0 24 24\",\"children\":[\"$\",\"path\",null,{\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"strokeWidth\":2,\"d\":\"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z\"}]}],[\"$\",\"time\",null,{\"dateTime\":\"2025-03-25\",\"children\":\"2025年03月25日\"}]]}]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-6 text-center\",\"children\":\"大数据分析常用去重算法分析之HyperLogLog篇\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6 justify-center\",\"children\":[[\"$\",\"$L5\",\"大数据\",{\"href\":\"/blog/tag/%E5%A4%A7%E6%95%B0%E6%8D%AE/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"大数据\"}],[\"$\",\"$L5\",\"去重算法\",{\"href\":\"/blog/tag/%E5%8E%BB%E9%87%8D%E7%AE%97%E6%B3%95/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"去重算法\"}],[\"$\",\"$L5\",\"HyperLogLog\",{\"href\":\"/blog/tag/HyperLogLog/page/1/\",\"className\":\"inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-gray-200 text-gray-800 hover:bg-gray-300 hover:text-gray-900 transition-colors\",\"children\":\"HyperLogLog\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"max-w-5xl mx-auto\",\"children\":[\"$\",\"$L14\",null,{\"content\":\"$15\"}]}],[\"$\",\"$11\",null,{\"fallback\":[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":\"加载导航中...\"}],\"children\":[\"$\",\"$L16\",null,{\"globalNav\":{\"prev\":{\"slug\":\"insights/technology/人工智能的未来—机遇与挑战\",\"title\":\"人工智能的未来：机遇、挑战与行动路线图\",\"description\":\"过去十年，AI 从“可用”走向“有用”，从“模型演示”走向“生产系统”。2024—2025 年尤为关键：多模态大模型跃迁、开源权重追平、产业投资破纪录、治理规则成型。今天谈AI，不再只是技术叙事，而是战略、制度与社会协同的综合工程。\",\"pubDate\":\"2025-1-29\",\"tags\":[\"人工智能\",\"大语言模型\",\"技术趋势\"],\"heroImage\":\"$undefined\",\"content\":\"$17\"},\"next\":{\"slug\":\"engineering/data/大数据分析常用去重算法分析之Bitmap篇\",\"title\":\"大数据分析常用去重算法分析之Bitmap篇\",\"description\":\"去重分析在企业日常分析中的使用频率非常高，如何在大数据场景下快速地进行去重分析一直是一大难点。在近期的 Apache Kylin Meetup 北京站上，我们邀请到 Kyligence 大数据研发工程师陶加涛为大家揭开了大数据分析常用去重算法的神秘面纱。 Apache Kylin 作为目前唯一一个同...\",\"pubDate\":\"2025-03-26\",\"tags\":[\"大数据\",\"去重算法\",\"Bitmap\"],\"heroImage\":\"$undefined\",\"content\":\"$18\"}},\"tagNav\":{\"大数据\":{\"prev\":null,\"next\":\"$6:props:children:props:children:props:children:2:props:children:props:globalNav:next\"},\"去重算法\":{\"prev\":null,\"next\":\"$6:props:children:props:children:props:children:2:props:children:props:globalNav:next\"},\"HyperLogLog\":{\"prev\":null,\"next\":null}}}]}],[\"$\",\"$L19\",null,{}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"9:null\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n8:null\n"])</script><script>self.__next_f.push([1,"b:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"大数据分析常用去重算法分析之HyperLogLog篇 - Skyfalling Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 \"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"大数据分析常用去重算法分析之HyperLogLog篇\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 \"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"5\",{\"property\":\"article:published_time\",\"content\":\"2025-03-25\"}],[\"$\",\"meta\",\"6\",{\"property\":\"article:author\",\"content\":\"Skyfalling\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"大数据分析常用去重算法分析之HyperLogLog篇\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"上篇介绍了利用 Roaring Bitmap 来进行精确去重。虽然这种算法能大大地减少存储开销，但是随着数据量的增大，它依然面临着存储上的压力。在本篇推送中将要介绍的 HyperLogLog（下称 HLL）是一种非精确的去重算法，它的特点是具有非常优异的空间复杂度（几乎可以达到常数级别）。 \"}],[\"$\",\"link\",\"10\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"12\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"link\",\"13\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.png\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"13:{\"metadata\":\"$b:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>