---
title: "广告系统的数据基建：从用户识别到智能定向"
description: "系统阐述广告系统数据基础设施的核心架构，涵盖用户身份体系、Cookie Mapping、DMP 平台、定向策略、CTR/CVR 预估模型、数据埋点体系及归因模型，并分析隐私合规浪潮对广告数据基建的深层冲击与重构路径。"
pubDate: "2025-07-20"
tags: ["广告系统", "DMP", "用户定向", "数据基建"]
---

> 广告系统的本质，是一个以数据为燃料的实时决策引擎。数据的质量、丰度与时效性，直接决定了广告系统识别用户、理解用户、触达用户的能力上限。本文作为系列第三篇，将聚焦广告系统的数据技术基础设施，从用户身份体系、DMP 数据管理平台、定向策略设计、CTR/CVR 预估模型、数据埋点体系到隐私合规的冲击与应对，系统性地展开广告数据基建的全景图。

## 数据在广告系统中的核心地位

### 广告系统是数据驱动的决策系统

在互联网广告的语境下，每一次广告的展示都是一次实时决策。当用户打开一个网页或 App，广告位向广告系统发起请求时，系统需要在 100 毫秒以内完成一系列复杂的判断：这个用户是谁？他可能对什么感兴趣？当前有哪些广告主在竞价？哪条广告展示给他效果最好？这条广告的出价是多少？这一切判断的根基，都是数据。

从宏观视角看，广告系统的数据链路可以概括为一条闭环：

**用户行为 → 数据采集 → 特征提取 → 模型预估 → 广告决策 → 效果反馈 → 模型迭代**

这条链路中，每个环节都依赖于前一个环节产生的数据，而最终的效果反馈又会回流到数据采集层，形成不断优化的循环。数据的缺失或质量问题在链路中的任何一个节点出现，都会像管道中的堵塞一样影响整个系统的输出效率。

"Data is the new oil"这句话在广告领域有着最为直接的验证。对于搜索引擎、社交平台、电商平台等流量巨头而言，其广告业务的变现效率差异，本质上是数据能力的差异。拥有更丰富用户数据的平台，能够更精准地识别和理解用户，从而将广告展示给最可能产生价值的人，进而提升广告主的投放回报率（ROI），吸引更多广告预算。

### 广告系统对数据的三个核心需求

广告系统对数据的需求可以抽象为三个层面：

| 层面 | 核心问题 | 对应技术能力 | 数据基建支撑 |
|------|---------|-------------|-------------|
| 识别用户（Who） | 这是谁？这个人在另一个设备上还是同一个人吗？ | 身份识别、跨设备匹配 | 用户 ID 体系、Cookie Mapping、Identity Graph |
| 理解用户（What） | 他的年龄、性别、兴趣、消费能力如何？ | 用户画像、标签体系 | DMP、特征工程、标签平台 |
| 触达用户（How） | 用什么方式、在什么时间、展示什么内容最有效？ | 定向策略、预估模型 | CTR/CVR 模型、定向系统、归因体系 |

这三个层面构成了广告数据基建的核心骨架。识别用户是基础，理解用户是核心，触达用户是目标。接下来的内容将围绕这三个层面逐一展开。

### 数据质量对变现效率的直接影响

在广告系统中，变现效率有一个经典的拆解公式：

**Revenue = PV × PVR × ASN × CTR × ACP**

其中：

- **PV（Page View）**：页面访问量，代表流量规模
- **PVR（PV Request Rate）**：广告请求率，即有多少 PV 发起了广告请求
- **ASN（Average Show Number）**：平均广告展示条数
- **CTR（Click-Through Rate）**：点击率
- **ACP（Average Click Price）**：平均点击价格

在这个公式中，PV 主要取决于产品本身的流量能力，ASN 取决于广告位设计，而 CTR 和 ACP 则直接受数据质量的影响。更精准的用户识别使得广告能够投放给对的人，从而提升 CTR；更深入的用户理解使得广告主愿意为高价值用户出更高的价格，从而提升 ACP。数据质量的改善，往往能在不增加流量的情况下显著提升整体收入。

除了上述公式外，广告系统还需要关注以下几个核心变现指标：

| 指标 | 全称 | 含义 | 与数据的关系 |
|------|------|------|-------------|
| CPM | Cost Per Mille | 每千次展示成本 | 数据越好，广告主愿意支付的 CPM 越高 |
| eCPM | Effective CPM | 等效千次展示收入 | 受 CTR 和出价双重影响，是衡量变现效率的核心 |
| CTR | Click-Through Rate | 点击率 | 预估精度直接决定 eCPM 排序质量 |
| CVR | Conversion Rate | 转化率 | 深度优化依赖于转化数据的回传 |
| ARPU | Average Revenue Per User | 每用户平均收入 | 综合反映用户数据利用效率 |

## 用户身份体系：跨平台识别的挑战

在广告系统中，"识别用户"是一切的起点。只有知道"这是谁"，才能进一步了解"他想要什么"。然而，用户身份的识别远比想象中复杂——同一个用户可能使用不同的浏览器、不同的设备、不同的 App，在不同的平台上留下分散的行为痕迹。将这些碎片化的身份信息拼接为完整的用户画像，是广告数据基建的首要挑战。

### Web 时代的身份标识：Cookie

Cookie 是浏览器端存储的一小段文本数据，由服务器设置并在后续请求中自动附带。在互联网广告的早期发展中，Cookie 是用户身份识别的基石。

**第一方 Cookie 与第三方 Cookie 的区别**

理解 Cookie 在广告系统中的作用，首先需要区分第一方 Cookie 和第三方 Cookie：

- **第一方 Cookie（First-Party Cookie）**：由用户当前访问的网站域名设置。例如，用户访问 example.com 时，example.com 设置的 Cookie 就是第一方 Cookie。它主要用于网站自身的功能，如保存登录状态、记录用户偏好等。
- **第三方 Cookie（Third-Party Cookie）**：由非当前访问域名的第三方设置。例如，用户访问 example.com 时，页面中嵌入了 ad-network.com 的广告代码，ad-network.com 设置的 Cookie 就是第三方 Cookie。它的核心用途是跨站追踪——当用户后续访问另一个同样嵌入了 ad-network.com 代码的网站 another-site.com 时，ad-network.com 能通过这个 Cookie 识别出"这是同一个用户"，从而实现跨网站的用户行为追踪。

第三方 Cookie 是整个程序化广告生态的底层支撑。没有它，广告网络无法跨站识别用户，也无法进行再营销（Retargeting）、频次控制（Frequency Capping）和跨站归因分析。

**第三方 Cookie 的消亡**

然而，第三方 Cookie 的跨站追踪能力引发了严重的用户隐私担忧，推动了浏览器厂商和监管机构的反制行动：

- **Safari ITP（Intelligent Tracking Prevention）**：苹果从 2017 年开始在 Safari 中逐步收紧对第三方 Cookie 的限制。ITP 2.0 直接阻止了所有第三方 Cookie 的设置，ITP 2.3 进一步限制了第一方 Cookie 的有效期。Safari 用户在广告网络的视角中变成了"匿名人群"。
- **Firefox ETP（Enhanced Tracking Protection）**：Mozilla 在 2019 年默认启用了增强型追踪保护，阻止已知追踪器的第三方 Cookie。
- **Chrome 的隐私沙盒计划（Privacy Sandbox）**：作为全球市场份额最大的浏览器，Chrome 在 2020 年宣布将分阶段淘汰第三方 Cookie，并提出 Privacy Sandbox 作为替代方案。尽管这一时间表多次推迟，但方向是明确的——第三方 Cookie 最终将退出历史舞台。

**Cookie 的固有局限性**

即使在第三方 Cookie 尚未完全消亡的今天，它也存在多重固有局限：

- **跨浏览器无法打通**：用户在 Chrome 和 Safari 中的 Cookie 完全独立，无法关联。
- **用户可清除**：用户主动清除 Cookie 后，之前积累的行为数据全部丧失。
- **移动端不适用**：App 内的流量不使用浏览器 Cookie 机制，而移动端已经占据了超过 70% 的互联网流量。
- **有效期有限**：即使不被用户清除，Cookie 也有过期时间（通常 30 天到 1 年不等），过期后需要重新生成。

这些局限意味着，仅依赖 Cookie 构建的用户身份体系是脆弱且不完整的。

### Cookie Mapping：跨平台身份匹配

在 RTB（Real-Time Bidding，实时竞价）生态中，参与方众多——有 SSP（供给侧平台）、Ad Exchange（广告交易平台）、DSP（需求侧平台）、DMP（数据管理平台）等。每个平台都有自己的用户 ID 体系，彼此之间互不相通。Cookie Mapping（Cookie 映射）就是解决这个问题的关键技术。

**核心问题**

Ad Exchange 通过自己的 Cookie 识别用户，生成一个内部 User ID（例如 AE_User_123）。DSP 也通过自己的 Cookie 识别用户，生成另一个内部 User ID（例如 DSP_User_456）。当 Ad Exchange 向 DSP 发送竞价请求（Bid Request）时，携带的是 AE_User_123。DSP 需要知道 AE_User_123 在自己的数据库中对应的是 DSP_User_456，才能基于自己积累的用户数据进行判断和出价。

如果 DSP 无法完成这个映射，那么它看到的就是一个"陌生人"，既不知道这个用户的历史行为，也无法进行再营销投放，只能依靠极其有限的上下文信息进行粗放的出价。

**Cookie Mapping 的工作机制**

Cookie Mapping 的核心原理是利用浏览器的 HTTP 请求机制，让两个不同的平台在用户的浏览器中"交换"各自的 User ID。具体流程如下：

1. **像素标签（Pixel Tag）植入**：DSP 在广告主的网站或合作媒体页面中植入一个 1×1 像素的透明图片标签（Pixel Tag），该图片的请求指向 DSP 的服务器。
2. **DSP Cookie 写入**：当用户访问该页面时，浏览器向 DSP 服务器请求这个像素图片，DSP 在响应中设置自己的 Cookie（包含 DSP_User_456）。
3. **302 重定向到 Ad Exchange**：DSP 在响应中返回一个 302 重定向，将请求导向 Ad Exchange 的同步接口，URL 中携带 DSP_User_456 作为参数。
4. **映射关系存储**：Ad Exchange 收到请求后，从自己的 Cookie 中读取 AE_User_123，同时从 URL 参数中获取 DSP_User_456，将这两个 ID 的映射关系存储在自己的数据库中。
5. **后续竞价中使用**：当 Ad Exchange 后续向 DSP 发送竞价请求时，不仅携带 AE_User_123，还会携带映射后的 DSP_User_456，使 DSP 能够识别用户。

以 Google 的 Cookie 匹配流程为例，Google Ad Exchange（AdX）的做法更为精细：AdX 在竞价请求中为 DSP 分配一个加密的 USERID'（即 google_user_id 的加密版本）。DSP 需要预先通过像素标签或重定向的方式完成 Cookie 映射。映射成功后，AdX 在 Bid Request 中携带的 google_user_id 字段，DSP 可以通过查询映射表找到对应的自有 User ID。Google 的映射中还涉及 base64 编码、匹配标记（match tag）等细节，以确保映射过程的安全性和准确性。

**匹配率问题**

Cookie Mapping 的匹配率是一个关键指标。在实践中，典型的匹配率在 60%~80% 之间，这意味着 20%~40% 的用户无法被 DSP 识别。匹配率受多种因素影响：

- **Cookie 有效期**：Cookie 过期后映射关系失效，需要重新建立。
- **用户清除 Cookie**：一旦用户清除了 Cookie，之前的映射全部失效。
- **浏览器限制**：Safari 和 Firefox 对第三方 Cookie 的限制导致映射无法完成。
- **同步频率**：Cookie Mapping 需要用户"路过"同步页面才能建立，首次接触的用户通常尚未完成映射。

未匹配的用户对 DSP 而言是"盲区"——DSP 要么选择不竞价（流失潜在机会），要么按照通用策略出一个保守的价格。这直接影响了 DSP 的竞争力和广告主的投放效果。

**Cookie Mapping 对 Retargeting 的支撑**

Cookie Mapping 是再营销（Retargeting）的技术前提。再营销的核心逻辑是"对访问过广告主网站或 App 的用户进行二次广告触达"。这就要求 DSP 能够在用户浏览其他网站时识别出"这个用户曾经访问过我的广告主的网站"。

具体流程为：用户访问广告主网站 → 广告主网站上的 DSP 像素标签被触发 → DSP 记录"DSP_User_456 访问了广告主 A 的网站"→ 用户后续浏览其他媒体网站 → Ad Exchange 发起竞价 → DSP 通过 Cookie Mapping 识别出该用户是 DSP_User_456 → DSP 发现该用户在广告主 A 的再营销列表中 → DSP 为广告主 A 出高价竞拍。

没有 Cookie Mapping，这条链路就断裂了。DSP 无法将 Ad Exchange 传来的用户 ID 与自己记录的再营销列表关联，再营销也就无从谈起。

### 移动时代的身份标识

随着移动互联网的崛起，用户的主要上网行为从 PC 端转移到了手机和平板。在移动端，Cookie 机制不再是主流的身份识别方式，取而代之的是设备标识符（Device Identifier）和设备指纹（Device Fingerprint）。

**设备标识符**

设备标识符是由操作系统分配的唯一标识，用于在 App 环境中识别设备（进而识别用户）。主流的设备标识符包括：

| 标识符 | 平台 | 说明 | 当前状态 |
|--------|------|------|---------|
| IDFA（Identifier for Advertisers） | iOS | 苹果为广告追踪分配的设备级唯一标识 | 需用户主动授权（iOS 14.5+） |
| GAID（Google Advertising ID） | Android（海外） | Google 为广告追踪分配的设备级标识 | 用户可重置或关闭个性化广告 |
| OAID（Open Anonymous Device Identifier） | Android（国内） | 移动安全联盟（MSA）推出的匿名设备标识 | 国内主流安卓手机支持 |
| IMEI | 所有手机 | 设备硬件级唯一标识 | 因隐私问题，Android 10+ 禁止 App 获取 |

在隐私政策收紧之前，IDFA 和 GAID 是移动广告生态的基石。广告网络通过 IDFA/GAID 在不同 App 之间追踪用户行为，实现跨 App 的用户画像构建和广告定向。其作用相当于 PC 端的第三方 Cookie。

**苹果 ATT 框架的冲击**

2021 年，苹果推出 ATT（App Tracking Transparency）框架，要求 App 在访问 IDFA 之前必须弹窗征询用户的明确授权。这一政策的实施带来了剧烈的行业震荡：

- **IDFA 获取率骤降**：在 ATT 生效前，广告平台通常可以获取 70% 以上 iOS 设备的 IDFA；ATT 生效后，全球范围内的授权率迅速降至 20% 以下，部分地区甚至低于 15%。
- **定向能力大幅削弱**：没有 IDFA，广告平台无法在不同 App 间关联用户身份，跨 App 的行为定向和再营销能力严重受损。
- **归因精度下降**：没有 IDFA 作为唯一标识，广告效果的归因（判断用户的转化是由哪条广告带来的）变得困难。
- **中小广告主受影响更大**：大平台（如 Meta、Google）拥有丰富的登录态第一方数据，受冲击相对较小；而中小广告主和第三方广告网络的定向和归因能力受到毁灭性打击。

**替代方案的探索**

面对 IDFA 受限和第三方 Cookie 淘汰的双重压力，行业提出了多种替代方案：

- **SKAdNetwork（SKAN）**：苹果提供的隐私保护归因框架。它不暴露用户级数据，而是以聚合和延迟的方式提供转化数据。SKAN 的数据粒度较粗、延迟较高（24~48 小时），且转化值（Conversion Value）的位数有限（早期版本仅 6 位），限制了广告主对转化效果的精细分析。SKAN 4.0 引入了分层归因（粗粒度/细粒度根据广告投放量级动态调整），在一定程度上缓解了数据颗粒度不足的问题。
- **Google Privacy Sandbox（Android 版）**：Google 在 Android 端推出的隐私沙盒计划，与 Chrome 的 Privacy Sandbox 理念一致，试图在不依赖设备标识符的情况下支持广告的基本功能。核心组件包括 Topics API（基于用户近期使用的 App 推断兴趣类别）和 Attribution Reporting API（隐私保护的归因报告）。
- **统一 ID 方案（Unified ID Solutions）**：行业组织和广告技术公司提出的基于第一方数据的 ID 解决方案。代表性方案包括：
  - **UID 2.0（Unified ID 2.0）**：由 The Trade Desk 主导，基于用户的邮箱地址生成加密且可轮换的 ID。用户可以在统一的门户中管理自己的隐私偏好。
  - **RampID**：由 LiveRamp 推出，通过确定性的 ID 解析将线上线下数据打通。
  - **ID5**：欧洲市场常用的通用 ID 方案，基于第一方 Cookie 和发布者数据生成。

这些方案各有优劣。SKAdNetwork 由平台强制推行但数据粒度有限，统一 ID 方案依赖于行业的广泛采纳。没有哪一个方案能够完全替代 IDFA/Cookie 提供的用户级追踪能力，行业正在从"精确追踪个体"转向"概率性推断+聚合分析"的新范式。

**设备指纹**

设备指纹（Device Fingerprint）是一种不依赖标识符的用户识别技术。它通过收集设备的多维特征信息（如屏幕分辨率、操作系统版本、系统语言、时区、安装的字体列表、GPU 型号、电池状态等），将这些特征组合计算出一个"准唯一"的标识。

设备指纹的优势在于不需要存储任何标识符，不受用户清除 Cookie 或重置 IDFA 的影响。但它的问题也很明显：

- **唯一性不足**：不同设备可能生成相同的指纹（碰撞），尤其在设备型号和系统版本趋同的情况下。
- **稳定性不够**：系统升级、App 更新等都可能导致指纹变化。
- **合规性存疑**：苹果和 Google 都明确禁止 App 通过设备指纹进行用户追踪，将其视为对隐私政策的规避行为。

因此，设备指纹通常作为辅助手段使用，用于反作弊和补充识别，而非作为主要的用户身份识别方案。

### 跨设备身份图谱（Identity Graph）

在现实场景中，一个用户通常拥有多台设备：手机用于通勤和碎片化浏览，平板用于休闲娱乐，PC 用于工作和深度浏览。如果广告系统将同一用户在不同设备上的行为视为不同用户，不仅会导致用户画像的碎片化，还会造成广告的过度曝光（同一用户在多设备上重复看到同一广告）和归因错误。

跨设备身份图谱（Identity Graph）正是为了解决这一问题而构建的数据基础设施。它将同一用户在不同设备、不同平台上的身份标识关联为一个统一的用户档案。

**确定性匹配（Deterministic Matching）**

确定性匹配基于明确的登录行为进行身份关联。当同一用户在手机 App 和 PC 浏览器上使用相同的账号登录某个服务（如 Google 账号、Facebook 账号、微信号）时，平台可以确定性地将该用户在不同设备上的身份关联起来。

确定性匹配的优势在于准确率极高（接近 100%），劣势在于覆盖率有限——只有拥有大规模登录态的平台（Google、Meta、亚马逊、字节跳动等）才具备这一能力。对于没有登录体系的中小平台和第三方广告网络来说，确定性匹配几乎不可用。

**概率性匹配（Probabilistic Matching）**

概率性匹配通过分析设备间的行为相似性来推断它们是否属于同一用户。常用的信号包括：

- **IP 地址**：同一 WiFi 网络下的设备共享相同的出口 IP。
- **地理位置**：两台设备长期出现在相同的位置（如家和办公室）。
- **浏览行为模式**：访问相同或高度相似的网站/App。
- **时间模式**：两台设备的活跃时段互补（如 PC 白天活跃、手机晚上活跃）。

概率性匹配的覆盖面广但准确率较低（通常在 60%~85% 之间）。误匹配（将不同用户的设备关联在一起）会导致用户画像污染，进而影响定向精度。因此，实践中通常会设定较高的置信度阈值，只有当多维信号高度一致时才建立关联。

**身份图谱的业务价值**

身份图谱在广告系统中承载着多重业务价值：

- **频次控制（Frequency Capping）**：没有跨设备身份图谱，广告系统对每台设备独立计数。一个用户在手机上看到广告 3 次、平板上看到 3 次、PC 上看到 3 次，总共被同一广告轰炸了 9 次。身份图谱使得系统可以在用户维度而非设备维度进行频次控制。
- **归因分析**：用户可能在手机上看到广告（展示），但在 PC 上完成购买（转化）。没有身份图谱，这次展示和转化无法关联，广告效果被低估。
- **完整画像构建**：将用户在不同设备上的行为汇聚到统一的用户档案中，构建更全面的兴趣和意图画像。

**隐私合规下身份图谱的边界**

身份图谱的构建本质上是对用户行为的跨平台关联，这与用户隐私保护存在天然的张力。在 GDPR 和 CCPA 等法规框架下，身份图谱需要严格遵循以下原则：

- **明确告知与用户授权**：数据的收集和关联需要获得用户的明确同意。
- **数据最小化**：仅收集业务必需的数据，不过度关联。
- **用户可控**：用户有权查看、修改和删除自己的身份图谱数据。
- **匿名化处理**：在可能的情况下，对 ID 进行加密和匿名化，避免直接存储可识别个人身份的原始信息。

从行业趋势来看，基于登录态第一方数据的确定性匹配将越来越成为身份图谱的主流构建方式，而基于第三方数据的概率性匹配将逐步受到更多限制。

## DMP：广告数据的中枢神经

### DMP 的定位与核心能力

DMP（Data Management Platform，数据管理平台）是广告数据基建中的核心组件，它在广告生态中扮演着"中枢神经"的角色——汇聚来自各方的数据，加工为可用的标签和人群包，输出给投放系统用于定向和优化。

从功能定义来看，DMP 是一个集中管理和激活第一方、第二方、第三方数据的平台。它的核心使命是回答一个问题：**DMP 告诉 DSP 要找哪些人、什么样的人应该看什么广告。** 在广告投放决策链路中，DMP 存储流量和受众的特征信息，为 DSP 的竞价决策提供数据支撑。

DMP 的核心能力可以概括为一条数据处理链路：

**数据接入 → 清洗去重 → 标签体系构建 → 人群包管理 → 定向输出**

- **数据接入**：将各类数据源（广告主 CRM、App SDK 埋点、网站像素、第三方数据供应商等）的数据统一接入 DMP。
- **清洗去重**：对接入的数据进行格式标准化、异常值剔除、重复数据合并等处理，确保数据质量。
- **标签体系构建**：基于原始数据生成结构化的用户标签（如"25-30 岁""高消费""电商兴趣"等）。
- **人群包管理**：根据标签组合条件筛选出特定的用户集合（人群包），供投放系统使用。
- **定向输出**：将人群包以 API 或文件的方式输出给 DSP 等投放系统，用于广告定向。

**DMP 在广告生态中的位置**

从系统架构的视角来看，DMP 位于数据源和投放系统之间，是连接两者的桥梁：

- **上游（数据源）**：广告主的第一方数据（CRM、App、网站）、第三方数据供应商、媒体平台的第二方数据。
- **下游（投放系统）**：DSP（需求侧平台）、程序化投放引擎、广告主的自有投放系统。

在大型广告平台（如 Google、Meta、字节跳动）中，DMP 的能力通常被集成在平台内部，与投放引擎紧密耦合。而在开放的程序化广告生态中，DMP 可以是独立的第三方平台（如 Oracle Data Cloud、Lotame、Adobe Audience Manager），为多个广告主和投放系统提供数据服务。

值得注意的是，不同视角下的 DMP 定位有所不同：

- **媒体端 DMP**：侧重于管理自有流量的用户数据，为程序化变现提供受众数据支撑。
- **广告主端 DMP**：侧重于管理广告主的第一方数据（CRM、交易数据等），并与投放平台对接，实现精准定向。
- **第三方 DMP**：侧重于整合多方数据源，提供跨平台的受众数据服务。

### 数据源的分类与价值

DMP 管理的数据按来源可分为三类，每类数据在精准度、覆盖面和获取成本上各有特点：

| 数据类型 | 来源 | 典型示例 | 精准度 | 覆盖面 | 获取成本 | 合规风险 |
|---------|------|---------|--------|--------|---------|---------|
| 第一方数据 | 广告主自有 | CRM 数据、App 内行为、交易记录、会员数据 | 最高 | 有限（仅覆盖已知用户） | 低（自有数据） | 低 |
| 第二方数据 | 合作伙伴 | 媒体共享的用户画像、战略合作方的用户数据 | 较高 | 中等 | 中（需要合作关系） | 中 |
| 第三方数据 | 数据供应商 | 运营商数据、征信数据、SDK 采集的跨 App 行为数据 | 存疑 | 广（可覆盖全量互联网用户） | 高（付费购买） | 高 |

**第一方数据**

第一方数据是广告主自己收集的用户数据，包括用户在广告主网站和 App 上的浏览行为、搜索行为、购物车操作、交易记录、注册信息、客服互动记录等。这类数据的精准度最高——它直接来源于用户与广告主的真实交互，不存在推断和猜测的成分。

然而，第一方数据的覆盖面有限，只包含已经与广告主产生过交互的用户。对于需要拓展新客群的广告主来说，仅依赖第一方数据是不够的。

在隐私合规趋势下，第一方数据的战略价值被显著提升。它是广告主在"后 Cookie 时代"仍然可以合法使用的核心数据资产。越来越多的品牌开始投资建设自己的第一方数据平台（CDP，Customer Data Platform），将 DMP 和 CRM 的能力融合，构建以第一方数据为核心的营销数据基础设施。

**第二方数据**

第二方数据本质上是另一家公司的第一方数据，通过合作关系获取。例如，一个电商平台与一个航旅平台达成数据合作协议，电商平台可以使用航旅平台的用户出行偏好数据来优化自己的广告定向。

第二方数据的价值在于，它既保持了较高的精准度（直接来源于合作方的真实交互数据），又能在一定程度上扩展数据的覆盖面（触达广告主自身未覆盖到的用户）。其挑战在于：需要建立信任关系的合作伙伴、数据使用权限的界定、以及数据安全的保障。

**第三方数据**

第三方数据来源于专业的数据供应商，通常是通过 SDK 嵌入大量 App 采集的跨应用行为数据、运营商的网络使用数据、征信机构的消费能力数据等。第三方数据的覆盖面最广，理论上可以为广告主提供全网用户的画像信息。

然而，第三方数据的质量一直备受质疑：

- **精准度问题**：数据经过多次转手和推断，与用户真实状态的偏差可能很大。一项业界研究表明，部分第三方数据供应商提供的年龄标签准确率不足 50%。
- **时效性问题**：第三方数据的更新频率通常不如第一方数据，标签可能已过时。
- **合规风险**：在 GDPR 和 CCPA 等法规下，第三方数据的收集和使用面临严格的合规审查。用户未必知道自己的数据被收集并出售给了广告网络。

因此，行业趋势是第三方数据的使用逐步萎缩，第一方数据的重要性持续上升。DMP 的价值也在从"整合外部数据"转向"激活自有数据"。

### 标签体系设计

标签体系是 DMP 的核心产出。原始数据经过采集、清洗和加工后，最终以"标签"的形式附着在用户身上，供投放系统进行定向筛选。标签体系的设计质量直接决定了 DMP 的可用性。

**标签的层级结构**

一个设计良好的标签体系应当具有清晰的层级结构，从粗到细逐级细化：

| 层级 | 含义 | 示例 |
|------|------|------|
| 一级分类 | 标签的大类别 | 人口属性、兴趣偏好、消费能力、行为特征 |
| 二级分类 | 大类下的子维度 | 年龄段、性别、行业兴趣、品牌偏好 |
| 三级标签 | 具体的标签值 | 25-30 岁、男性、电商-数码-手机、偏好苹果品牌 |

以一个实际的标签体系为例：

- **人口属性**
  - 年龄段：18 岁以下 / 18-24 岁 / 25-30 岁 / 31-40 岁 / 41-50 岁 / 50 岁以上
  - 性别：男 / 女
  - 学历：大专以下 / 大专 / 本科 / 硕士及以上
  - 婚姻状态：未婚 / 已婚 / 已婚有子女
- **兴趣偏好**
  - 电商兴趣：数码3C / 服饰鞋包 / 美妆个护 / 食品饮料 / 家居日用
  - 内容兴趣：科技 / 财经 / 体育 / 娱乐 / 游戏 / 教育
  - 出行偏好：商务出行 / 休闲旅游 / 自驾游 / 海外旅行
- **消费能力**
  - 消费水平：低 / 中 / 高 / 高端奢侈
  - 消费场景：线上消费为主 / 线下消费为主 / 全渠道
- **行为特征**
  - 活跃度：高频活跃 / 中频活跃 / 低频活跃 / 沉默用户
  - 生命周期：新用户 / 成长期 / 成熟期 / 衰退期 / 流失用户

**标签的生成方式**

标签按生成方式可分为两大类：

**规则标签**：基于明确的条件定义生成。例如，"过去 30 天内在电商 App 中浏览手机品类页面超过 5 次"的用户被打上"手机购买意向"标签。规则标签的优势在于逻辑清晰、可解释性强、生成成本低；劣势在于规则的制定依赖人工经验，难以覆盖复杂的用户行为模式。

**模型标签**：基于机器学习模型预测生成。例如，通过训练一个分类模型，输入用户的多维行为特征，预测用户的性别（当性别信息未直接获取时）。模型标签的优势在于能够捕捉人工规则难以覆盖的复杂模式；劣势在于模型本身存在误差，标签的精准度受模型质量影响，且可解释性较弱。

在实践中，两种方式通常结合使用。对于有明确数据支撑的标签（如"过去 7 天有购买行为"），使用规则方式；对于需要推断的标签（如"消费能力等级"），使用模型方式。

**标签的时效性管理**

不同类型的标签对时效性的要求差异巨大：

| 时效性类型 | 更新频率 | 适用标签 | 技术实现 |
|-----------|---------|---------|---------|
| 实时标签 | 秒级~分钟级 | 当前浏览内容、实时搜索关键词、当前位置 | 流式计算（Flink/Kafka Streams） |
| 近实时标签 | 小时级 | 今日浏览类目偏好、今日搜索意图 | 微批处理 |
| 离线标签 | 天级~周级 | 长期兴趣偏好、消费能力、人口属性 | 批处理（Spark/Hive） |

实时标签的价值在于捕捉用户的即时意图。例如，用户当前正在搜索"机票 北京到上海"，这一实时搜索行为所反映的出行意图，其价值远高于一个月前的搜索历史。但实时标签的计算和存储成本也显著高于离线标签，需要流式计算框架和低延迟的存储系统支撑。

**标签覆盖率与精准度的权衡**

标签体系设计中存在一个核心矛盾：**覆盖率与精准度的权衡**。

覆盖率指标签可用于多少用户。精准度指标签与用户真实属性的匹配程度。两者往往呈负相关——为了提高覆盖率，标签生成的规则或模型阈值需要放宽，这会引入更多误判，降低精准度；反之，严格的阈值可以保证精准度，但覆盖率会下降。

例如，一个"高消费能力"标签：

- **严格定义**：过去 3 个月累计消费金额超过 10000 元的用户。精准度高，但可能只覆盖 5% 的用户。
- **宽松定义**：模型预测消费能力得分 top 30% 的用户。覆盖率提升到 30%，但其中可能包含不少实际消费能力并不高的用户。

在广告投放场景中，需要根据广告主的具体需求来平衡这一矛盾：品牌广告通常更看重覆盖面，可以容忍一定的精准度损失；效果广告则对精准度要求更高，宁可牺牲覆盖面。

### 人群包管理

人群包（Audience Segment）是 DMP 输出给投放系统的最终产物，它是基于标签组合条件筛选出的用户集合。人群包管理是 DMP 日常运营中最高频的操作。

**人群包的定义与创建**

人群包通过标签的布尔组合来定义。例如：

- **目标人群 A**：年龄 25-35 岁 AND 性别为女 AND 兴趣包含"美妆个护" AND 过去 30 天有电商浏览行为
- **目标人群 B**：地域为一线城市 AND 消费能力为高 AND NOT 过去 90 天已购买过广告主商品

标签之间支持 AND（交集）、OR（并集）、NOT（排除）等逻辑操作。复杂的人群包可能涉及数十个标签条件的组合。

**Lookalike（相似人群扩展）**

Lookalike 是 DMP 中一项极为重要的能力。其核心逻辑是：广告主提供一组"种子用户"（通常是已转化或高价值的用户），DMP 在全量用户中寻找与种子用户特征相似的用户群体，用于拓展投放范围。

Lookalike 的典型实现流程：

1. **种子用户分析**：提取种子用户的多维特征分布（年龄分布、兴趣分布、行为模式等）。
2. **特征权重计算**：分析哪些特征最能区分种子用户与非种子用户（使用信息增益、TF-IDF 等方法）。
3. **相似度计算**：在全量用户中计算每个用户与种子用户特征分布的相似度。
4. **阈值筛选**：根据广告主需要的规模，设定相似度阈值，筛选出目标人群包。

Lookalike 的关键参数是**扩展倍数**（即目标人群规模与种子用户规模的比值）。扩展倍数越大，覆盖面越广但精准度越低。通常建议的扩展倍数在 5~20 倍之间，具体取决于种子用户的规模和质量。

**排除逻辑**

排除逻辑是人群包管理中容易被忽视但至关重要的环节：

- **已转化用户排除**：对于以获取新客为目标的广告活动，应当排除已经完成转化的用户，避免将广告预算浪费在已有客户身上。
- **竞品用户排除**：某些场景下，广告主不希望向竞品的忠实用户展示广告（因为转化概率低）。
- **员工排除**：排除公司内部员工，避免展示和点击数据被内部流量污染。
- **黑名单排除**：排除已被标记为无效流量或恶意点击的用户/设备。

**人群包的规模估算**

在创建人群包时，需要估算其规模（即包含多少用户）。规模估算需要注意以下几点：

- **标签覆盖率的叠加衰减**：多个标签条件取交集后，实际覆盖的用户数通常远小于单个标签的覆盖数。如果 3 个标签各覆盖 50% 的用户，交集后可能只有 10%~15%（取决于标签间的相关性）。
- **可触达量与实际规模的差异**：人群包中的用户并不一定都能被广告触达。部分用户可能不活跃（在投放周期内不产生广告请求），部分用户的 ID 可能已失效（Cookie 过期、设备 ID 被重置）。实际可触达量通常只有人群包名义规模的 30%~60%。
- **日活 vs 月活的差异**：人群包基于历史行为定义的用户总量通常是月活级别的，而广告投放的触达发生在每天的实时请求中。日活用户数通常只有月活的 1/5 到 1/3。

理解这些差异对于广告投放策略的制定至关重要——避免因为高估可触达量而设定过于激进的投放目标。

## 广告定向：从粗放到精准的演进

### 定向维度体系

广告定向（Ad Targeting）是指根据特定条件筛选目标受众的过程，其目的是将广告展示给最可能对其感兴趣的用户群体。定向能力是广告系统的核心竞争力之一——定向越精准，广告对用户的相关性越高，点击率和转化率也就越高。

广告定向的维度可以从粗到细、从静态到动态进行分类：

| 定向类型 | 维度示例 | 精准度 | 覆盖面 | 数据依赖 |
|---------|---------|--------|--------|---------|
| 地理定向 | 国家、省份、城市、区县、商圈、LBS（基于位置服务） | 中 | 大 | GPS/IP 地址 |
| 人口定向 | 年龄、性别、学历、收入水平、婚姻状态 | 中 | 大 | 用户画像标签 |
| 兴趣定向 | 电商兴趣、游戏兴趣、旅游兴趣、美食兴趣 | 中高 | 中 | 历史行为聚合 |
| 行为定向 | 近期搜索行为、浏览行为、购买行为、App 安装行为 | 高 | 小 | 近期行为数据 |
| 重定向（Retargeting） | 访问过广告主网站/App 的用户 | 极高 | 极小 | Cookie/设备 ID 匹配 |
| 上下文定向 | 当前浏览内容的主题、关键词、页面类别 | 中 | 大 | 内容分析/NLP |
| 设备定向 | 操作系统、设备品牌、网络类型、运营商 | 低 | 大 | 设备信息 |

**各定向维度的深入分析**

**地理定向**是最基础的定向维度之一。它可以细化到多个层级：国家级定向适用于跨国投放的品牌广告，城市级定向适用于区域性商家，商圈级和 LBS 定向则适用于本地生活类广告（如餐厅、超市、门店引流）。LBS 定向的精度取决于位置数据的来源——GPS 数据精度最高（误差在几十米以内），WiFi 定位次之，IP 定位最粗（只能定位到城市级别）。在隐私合规框架下，精确位置数据的获取越来越受限，IP 地理定位的重要性在回升。

**人口定向**依赖于用户画像标签的质量。在大型平台中，用户注册时填写的年龄、性别等信息可以直接使用；在缺乏注册数据的场景中，这些标签需要通过模型推断。推断的精准度因平台而异——拥有丰富用户行为数据的平台，模型推断的性别准确率可以达到 90% 以上；而数据有限的平台，推断精度可能不足 70%。

**兴趣定向**是通过聚合用户的历史行为来推断其长期兴趣偏好。与行为定向不同的是，兴趣定向反映的是用户的"泛化偏好"而非"即时意图"。例如，一个用户在过去 3 个月中频繁浏览数码产品的评测内容，即使今天没有相关浏览行为，系统仍然会认为他对数码产品有兴趣。兴趣定向的优势在于覆盖面较广，适合品牌广告和拉新场景。

**行为定向**关注的是用户近期的具体行为，反映的是较强的即时意图。例如，"过去 3 天搜索过'空气净化器'的用户"比"对家居用品感兴趣的用户"意图要明确得多。行为定向的精准度更高，但覆盖面更小，适合效果类广告主。行为定向的关键在于行为事件的选择和时间窗口的设定——太远的行为失去了意图信号，太近的行为可能已经被满足。

**上下文定向**不依赖于用户的身份和历史行为，而是根据用户当前浏览内容的主题和语义进行定向。例如，用户正在阅读一篇关于新能源汽车的文章时，展示汽车广告。上下文定向在隐私合规时代正在"复兴"——它不需要追踪用户身份，天然符合隐私保护的要求。但其局限在于，用户浏览的内容不一定反映其购买意图（阅读一篇关于战争的新闻不代表用户想购买武器）。现代的上下文定向已经从关键词匹配升级到基于深度语义理解的内容分析，包括主题分类、情感分析、品牌安全检测等。

### 定向策略的设计方法论

定向不是孤立的技术操作，而是需要与广告投放目标、预算和创意策略协同设计的系统性工程。

**漏斗模型：从拉新到召回的分层策略**

借鉴营销漏斗的概念，定向策略可以按用户所处的漏斗阶段进行分层设计：

| 漏斗阶段 | 用户状态 | 定向策略 | 广告目标 | 衡量指标 |
|---------|---------|---------|---------|---------|
| 认知层 | 不了解品牌 | 宽定向（人口+兴趣） | 品牌曝光 | 曝光量、覆盖人数 |
| 兴趣层 | 对品类有兴趣 | 兴趣定向+上下文定向 | 引起关注 | CTR、视频完播率 |
| 意向层 | 有购买意图 | 行为定向（搜索/浏览行为） | 促进互动 | 点击率、详情页浏览 |
| 转化层 | 即将购买 | 重定向（加购/浏览未购买） | 促成转化 | CVR、CPA |
| 忠诚层 | 已购买用户 | 重定向（复购/交叉销售） | 提升 LTV | 复购率、ARPU |

每个阶段使用不同的定向策略和创意内容，形成完整的投放链路。上层漏斗侧重覆盖面（宽定向），下层漏斗侧重精准度（窄定向），不同阶段的预算分配也应有所侧重。

**定向的"宽窄"权衡**

定向的"宽"与"窄"之间存在一个经典的权衡：

- **过窄的问题**：当定向条件过于严格时，符合条件的用户太少，广告曝光量不足，预算消耗不出去。极端情况下，过窄的定向可能导致"出价再高也买不到量"的困境。同时，过窄的定向也限制了模型学习的样本量，不利于模型优化。
- **过宽的问题**：当定向条件过于宽泛时，大量广告展示给了对产品不感兴趣的用户，点击率和转化率下降，广告主的 ROI 下降。

实践中的最佳做法是：初期使用较宽的定向进行投放测试（Exploration），通过积累数据让模型学习到高价值用户的特征；然后逐步收紧定向（Exploitation），将预算集中在效果最好的人群上。这实质上是一个 Explore-Exploit 的经典博弈问题。

**自动定向（Auto Targeting）的兴起**

随着机器学习技术在广告系统中的深入应用，越来越多的平台开始推行"自动定向"或"智能定向"——广告主不再需要手动选择定向条件，而是将定向决策交给平台的算法模型。

自动定向的核心思路是：平台的 CTR/CVR 预估模型已经隐式地学习了"哪些用户更可能对这条广告感兴趣"，因此可以直接由模型来决定将广告展示给谁，而不需要广告主通过人工规则来限定受众。

自动定向的优势包括：

- **释放广告主的运营成本**：广告主不需要花费大量时间研究定向策略。
- **充分利用平台数据**：平台拥有的数据维度和粒度远超广告主的认知，模型能捕捉到人工规则难以发现的高价值信号。
- **动态优化**：模型可以实时调整定向策略，快速响应用户行为的变化。

但自动定向也面临一些挑战：

- **可控性下降**：广告主失去了对投放受众的直接控制能力，"黑盒"决策可能导致广告出现在不符合品牌调性的场景中。
- **冷启动问题**：新广告缺乏历史数据时，模型的自动定向效果较差。
- **透明度不足**：广告主难以理解"为什么广告展示给了这些人"，不利于策略优化和经验积累。

目前行业的主流做法是"半自动"模式——广告主设定大方向的定向约束（如地域限制、排除条件），在约束范围内交给平台模型进行细粒度的受众选择。

### Retargeting（再营销）的原理与实践

再营销是广告定向体系中最具代表性的策略之一，也是转化率最高的定向方式。其核心逻辑简洁而有力：**对已经与品牌有过交互的用户进行二次广告触达**。

**为什么再营销有效？**

从消费者行为学的角度看，用户的购买决策通常不是一次完成的，尤其是对于高客单价或高决策成本的商品。用户可能在第一次接触时浏览了商品详情页，但因为价格犹豫、对比竞品、等待时机等原因未能立即购买。再营销的价值在于，在用户购买意图尚未消退时，通过广告"提醒"用户，将其拉回决策路径。

数据显示，再营销广告的 CTR 通常是普通展示广告的 2~5 倍，CVR 更可高出 3~10 倍。这使得再营销成为效果类广告主的必备策略。

**再营销的技术实现**

再营销的技术链路包括以下环节：

1. **用户行为采集**：在广告主的网站/App 中植入追踪代码（如 JavaScript SDK、像素标签），采集用户的关键行为事件（浏览商品、加入购物车、开始结算等）。
2. **用户标记**：将发生过上述行为的用户的 Cookie 或设备 ID 记录到 DSP 的再营销列表中。
3. **广告请求匹配**：当该用户后续访问接入了 DSP 的媒体网站/App 时，DSP 通过 Cookie Mapping 或设备 ID 匹配识别出该用户。
4. **竞价与投放**：DSP 为该用户出价竞拍广告位，通常出价高于普通用户（因为再营销用户的预期转化率更高）。
5. **广告展示**：向该用户展示与其之前浏览行为相关的广告内容（如之前浏览过的商品图片）。

**再营销的分层策略**

精细的再营销不是"一刀切"地将所有接触过品牌的用户等同对待，而是根据用户的行为深度进行分层，对不同层级的用户采用不同的策略：

| 行为层级 | 用户描述 | 再营销策略 | 出价策略 |
|---------|---------|-----------|---------|
| 浏览未深入 | 仅浏览了首页或列表页 | 品牌提醒广告 | 低出价 |
| 浏览了商品详情 | 查看了具体商品的详情页 | 展示该商品的广告 | 中出价 |
| 加购未支付 | 将商品加入了购物车但未完成支付 | 展示商品+优惠信息 | 高出价 |
| 购买后复购 | 已购买过某商品 | 推荐互补/升级商品 | 中出价 |

这种分层策略背后的逻辑是：行为深度越深，购买意图越强，预期转化率越高，因此值得投入更高的出价。

**频次控制的重要性**

再营销的一个重要原则是**适度**。过度的再营销不仅浪费广告预算，还会导致严重的负面用户体验。用户在多个网站上反复看到同一商品的广告，会产生"被跟踪"和"被打扰"的感觉，可能对品牌产生反感。

频次控制（Frequency Capping）的常见策略包括：

- **时间维度**：同一用户每天最多看到同一广告 3 次、每周最多 7 次。
- **行为事件驱动**：一旦用户完成了转化（如购买了该商品），立即停止该商品的再营销。
- **衰减策略**：距离用户最后一次访问的时间越长，再营销的出价和频次逐步降低（因为意图在消退）。
- **跨渠道协同**：在搜索、展示、社交等多个渠道之间协调频次，避免用户在每个渠道都被轰炸。

## CTR/CVR 预估：广告系统的"大脑"

### 预估模型的重要性

如果说数据是广告系统的"燃料"，定向是"方向盘"，那么 CTR/CVR 预估模型就是广告系统的"大脑"——它决定了系统如何评估每条广告对每个用户的价值，进而影响广告的排序和展示。

**CTR 预估**预测的是：给定一个用户、一条广告和一个上下文（时间、位置、设备等），用户看到这条广告后点击的概率是多少。

**CVR 预估**预测的是：在用户点击了广告之后，完成目标转化行为（如下载、注册、购买）的概率是多少。

预估模型的输出直接用于 eCPM 排序。在 CPC（按点击付费）模式下，eCPM = 出价 × pCTR；在 CPA（按转化付费）模式下，eCPM = 出价 × pCTR × pCVR。排序结果决定了哪条广告获得展示机会，因此预估模型的精度直接影响：

- **平台收入**：预估偏高的广告排到前面但实际不被点击，浪费了展示机会；预估偏低的高质量广告被排到后面，错失了展示机会。
- **广告主 ROI**：预估不准导致广告展示给不对的用户，广告主的投放效果下降，最终减少预算投入。
- **用户体验**：精准的预估意味着用户看到的广告与自己的兴趣更相关，减少了对无关广告的干扰。

在大型广告平台中，预估精度 1% 的提升可能带来数亿乃至数十亿级别的年收入增长。这使得 CTR/CVR 预估成为广告技术领域投入最大、竞争最激烈的研究方向。

### 模型演进路径

广告预估模型的发展经历了从简单到复杂、从手工特征工程到自动特征学习的演进过程：

| 阶段 | 代表方法 | 核心特点 | 优势 | 局限 | 代表性应用 |
|------|---------|---------|------|------|-----------|
| 第一代 | 逻辑回归（LR） | 线性模型，手工特征交叉 | 可解释性强、训练效率高、工程部署简单 | 无法自动学习特征交互，依赖特征工程 | Google 早期广告系统 |
| 第二代 | GBDT + LR | GBDT 自动产生特征交叉，输出作为 LR 的输入 | 自动化特征交叉能力 | 特征交叉仍受限于树的深度 | Facebook 2014 |
| 第三代 | 深度学习（DNN/Wide&Deep/DCN/DeepFM） | 深度神经网络自动学习高阶特征交互 | 强大的特征交互学习能力 | 训练和推理成本高、可解释性弱 | 各大广告平台 |
| 第四代 | 多任务学习（MMOE/PLE/ESMM） | 同时预估 CTR 和 CVR，共享底层特征表示 | 解决 CVR 的样本稀疏问题，多目标协同优化 | 任务间可能存在负迁移 | 字节跳动、阿里巴巴 |

**逻辑回归（LR）阶段**

逻辑回归是广告 CTR 预估的起点。它的核心优势在于简单、高效、可解释。在大规模广告系统中，每秒需要进行数百万次的 CTR 预估，LR 模型的低推理延迟使其在工程上非常友好。Google 在 2013 年发表的论文《Ad Click Prediction: a View from the Trenches》详细描述了其基于 LR 的大规模 CTR 预估系统，使用了 FTRL（Follow-the-Regularized-Leader）在线学习算法，可以实时更新模型参数。

LR 的核心局限在于它是一个线性模型，无法自动捕捉特征之间的交互关系。例如，"用户年龄为 25 岁"和"广告类型为游戏"这两个特征单独看可能信号不强，但组合起来则是一个强特征。在 LR 框架下，这种交叉特征需要人工手动构造，成本极高。

**GBDT + LR 阶段**

2014 年，Facebook 提出了 GBDT + LR 的组合方案。核心思路是：先用 GBDT（梯度提升决策树）对原始特征进行非线性变换，将 GBDT 每棵树的叶子节点作为新的特征输入 LR 模型。GBDT 的分支结构天然地实现了特征交叉——每个叶子节点代表一组特征条件的组合。

这一方案在当时取得了显著的效果提升，因为它在保持 LR 工程友好性的同时，自动化了特征交叉的过程。但 GBDT 的特征交叉能力仍然受限于树的深度和棵数，对于高阶、复杂的特征交互学习能力有限。

**深度学习阶段**

随着深度学习技术的成熟，DNN（深度神经网络）开始应用于广告 CTR 预估。相比 LR 和 GBDT，DNN 的核心优势在于能够自动学习高阶特征交互，不需要人工构造交叉特征。

这一阶段涌现出多种经典的模型架构：

- **Wide & Deep（Google, 2016）**：将 LR（Wide 部分）和 DNN（Deep 部分）结合，Wide 部分负责记忆（Memorization），Deep 部分负责泛化（Generalization）。
- **DeepFM（华为, 2017）**：将 FM（因子分解机）与 DNN 结合，FM 部分高效地学习二阶特征交互，DNN 部分学习高阶交互。
- **DCN（Deep & Cross Network, Google, 2017）**：引入 Cross Network 层，显式地建模有界阶的特征交叉。
- **DIN（Deep Interest Network, 阿里, 2018）**：引入注意力机制，对用户的历史行为序列进行加权，使模型能够关注与当前广告最相关的历史行为。

**多任务学习阶段**

在实际广告系统中，不仅需要预估 CTR，还需要预估 CVR、甚至更深层的转化指标（如付费、留存）。传统做法是为每个指标独立训练一个模型，但这会面临两个问题：

1. **CVR 的样本稀疏问题**：CVR 的正样本（转化用户）数量远少于 CTR 的正样本（点击用户），导致 CVR 模型的训练数据严重不足。
2. **多目标间的信息孤立**：独立训练的模型无法共享底层特征表示，造成信息浪费。

多任务学习（Multi-Task Learning）方案通过让多个预估任务共享底层网络结构来解决这些问题。代表性架构包括：

- **ESMM（Entire Space Multi-Task Model, 阿里, 2018）**：利用 pCVR = pCTCVR / pCTR 的关系，在全样本空间（展示样本）上训练 CVR 模型，避免了样本选择偏差问题。
- **MMOE（Multi-gate Mixture-of-Experts, Google, 2018）**：通过多个 Expert 网络和门控（Gate）机制，让不同任务可以选择性地共享或独享底层特征表示。
- **PLE（Progressive Layered Extraction, 腾讯, 2020）**：在 MMOE 基础上引入任务专属 Expert 和渐进式提取机制，进一步缓解任务间的负迁移问题。

### 特征工程的核心维度

无论使用什么模型架构，特征的质量始终是预估效果的关键。广告 CTR/CVR 预估中的特征可以从三个维度来组织：

**用户侧特征**

用户侧特征描述的是"这个用户是什么样的人"和"他最近做了什么"。具体包括：

- **静态画像特征**：年龄、性别、地域、设备类型、操作系统等。这类特征变化缓慢，通常从用户画像标签中获取。
- **统计类特征**：过去 N 天的广告点击率、转化率、广告交互频次等。这类特征反映用户对广告的整体态度。
- **历史行为序列**：用户最近浏览/点击/购买的商品列表、搜索关键词列表、观看的视频列表等。行为序列是当前预估模型中最重要的特征之一，DIN、DIEN（Deep Interest Evolution Network）等模型专门为建模行为序列而设计。
- **实时行为特征**：用户在当前 session 内的行为，如刚刚搜索了什么、正在浏览什么内容。实时特征反映最即时的用户意图，价值极高但计算成本也最高。

**广告侧特征**

广告侧特征描述的是"这条广告是什么样的"和"它的历史表现如何"。具体包括：

- **基础属性**：广告 ID、广告主 ID、行业分类、投放目标（品牌/效果）。
- **创意特征**：广告创意类型（图片/视频/文字）、创意尺寸、标题关键词、落地页类型。
- **历史效果**：广告的历史 CTR、CVR、展示量、点击量。新广告缺乏历史数据时，可以使用同广告主或同行业的平均数据作为冷启动特征。
- **出价信息**：广告的出价金额、出价方式（CPC/CPM/CPA）。

**上下文特征**

上下文特征描述的是"广告展示的环境是什么样的"。具体包括：

- **时间特征**：当前时间（小时、星期几、是否节假日）。不同时间段用户的点击行为模式可能有显著差异。
- **设备与网络**：设备类型（手机/平板/PC）、操作系统、屏幕尺寸、网络类型（WiFi/4G/5G）。
- **广告位特征**：广告位 ID、位置（页面顶部/中部/底部）、广告位类型（信息流/开屏/Banner）。
- **内容上下文**：当前页面的内容类别、关键词。在信息流场景中，广告前后的内容也会影响用户对广告的感知。

**交叉特征**

交叉特征是将上述三类特征进行组合，以捕捉特征间的交互效应。例如：

- **用户×广告**：该用户对该广告主的历史互动次数、该用户对该商品类目的偏好度。
- **用户×上下文**：该用户在当前时间段的历史点击率、该用户在当前设备类型上的历史行为。
- **广告×上下文**：该广告在当前广告位上的历史 CTR、该行业在当前时间段的平均转化率。

在深度学习模型中，低阶交叉特征（如用户年龄×广告类目）可以通过 FM 或 Cross Network 显式建模，高阶交叉特征由 DNN 隐式学习。

### 样本与标签的设计考量

预估模型的训练依赖于高质量的样本数据。样本和标签的设计看似简单，实则包含诸多工程细节和统计学考量。

**正负样本的定义**

对于 CTR 预估：正样本是用户点击了广告的展示（Impression），负样本是用户看到但未点击的展示。定义清晰，但需要注意"有效展示"的界定——广告是否真的展示在了用户的可视区域内？如果广告加载了但用户未滚动到该位置就离开了页面，这种"展示"是否应该作为负样本？过于宽松的展示定义会引入大量低质量负样本，影响模型的学习效果。

对于 CVR 预估：正样本是用户点击广告后完成了转化行为，负样本是点击后未转化。CVR 的正样本通常非常稀少（转化率可能只有 1%~5%），正负样本比例严重失衡，需要使用下采样（Down Sampling）、加权等技术进行处理。

**样本偏差问题**

广告系统中的样本数据天然存在偏差——用户看到的广告并不是随机的，而是经过系统排序和筛选后展示的。这意味着：

- **位置偏差（Position Bias）**：排在前面的广告获得更多的点击，不是因为它"更好"，而仅仅因为它排在前面。模型在这样的数据上训练会错误地学到"位置"的影响，而非广告本身的吸引力。
- **选择偏差（Selection Bias）**：模型只在被展示的广告上有观测数据，未被展示的广告（被模型排到后面的）没有数据。模型的训练数据是其自身预测结果的筛选，形成了反馈循环。

应对样本偏差的常见方法包括：

- 在模型中显式建模位置特征，但在推理时消除位置的影响。
- 使用 Inverse Propensity Weighting（IPW）对样本进行加权，修正选择偏差。
- 通过 Exploration（探索）机制，随机展示部分广告以获取无偏样本。

**延迟转化问题**

CVR 预估面临一个独特的挑战：转化反馈的延迟。用户点击广告后，可能过了数小时甚至数天才完成转化。例如，用户今天点击了一个 App 下载广告，但下载完毕并首次打开可能在明天，而完成注册和激活可能在后天。

如果模型在转化数据回传之前就使用这些样本进行训练，那么部分实际会转化的用户会被错误地标记为负样本，导致模型低估 CVR。

常见的解决方案包括：

- **等待窗口**：设定一个固定的等待时间（如 72 小时），等待足够长的时间后再使用样本进行训练。这种方法简单但牺牲了模型的时效性。
- **延迟建模**：在模型中显式建模转化延迟的分布，将"已过 T 小时仍未转化"的信息作为特征输入。
- **数据回补**：先使用不完整的标签进行训练，当转化数据回传后再更新样本标签并增量更新模型。

**样本量级与训练基础设施**

大型广告平台每天产生的广告展示和点击事件达到数十亿条。如此大规模的训练数据对模型训练基础设施提出了极高的要求：

- **分布式训练**：单机无法处理这种规模的数据，需要使用参数服务器（Parameter Server）或分布式数据并行方案。
- **增量更新**：每天重新从头训练模型不现实，需要支持增量训练（Incremental Training）或在线学习（Online Learning），使模型能够持续吸收最新的数据。
- **特征存储**：数十亿用户的实时特征需要低延迟的分布式存储系统（如 Redis 集群、自研 KV 存储）支撑。

## 数据埋点体系：广告效果的度量基础

### 广告链路的完整埋点

数据埋点是广告系统数据基建的"毛细血管"——如果没有准确、完整、及时的埋点数据，前面讨论的用户识别、标签体系、预估模型都将成为"无源之水"。

广告从请求到转化的完整链路中，每个关键节点都需要对应的埋点事件：

| 埋点事件 | 触发时机 | 记录的关键信息 | 用途 |
|---------|---------|-------------|------|
| Ad Request（广告请求） | 客户端/服务端向广告系统发起广告请求 | 请求 ID、用户 ID、广告位 ID、设备信息、时间戳 | 统计填充率、分析流量特征 |
| Ad Fill（广告填充） | 广告系统返回了广告素材 | 请求 ID、广告 ID、出价信息、排序位置 | 统计填充率、分析竞价情况 |
| Ad Impression（广告展示） | 广告素材真实展示在用户的可视区域 | 请求 ID、广告 ID、展示时间、可见性信息 | CTR 分母、计费基础（CPM）、频次统计 |
| Ad Click（广告点击） | 用户点击了广告 | 请求 ID、广告 ID、点击坐标、跳转目标 | CTR 分子、CPC 计费基础 |
| Conversion（转化） | 用户完成了目标行为 | 点击 ID、转化类型、转化价值、转化时间 | CVR 计算、ROAS 计算、模型训练标签 |

**展示埋点的特殊性**

在上述埋点中，展示埋点（Impression）的定义和实现最为复杂。从技术角度看，"广告被展示"可以有多种定义：

- **广告素材开始加载**：最宽松的定义，但广告可能加载了却未出现在用户的视野中（如在信息流的底部）。
- **广告素材加载完成**：比开始加载更严格，但仍不保证用户"看到了"广告。
- **广告进入可视区域（Viewable Impression）**：IAB（Interactive Advertising Bureau）和 MRC（Media Rating Council）定义的标准：展示广告至少 50% 的面积在可视区域中持续至少 1 秒，视频广告至少 50% 的面积在可视区域中持续至少 2 秒。

可见性（Viewability）标准的引入，是为了解决"无效展示"的问题——广告主不应为用户未真正看到的广告付费。但可见性的检测本身也存在技术挑战，不同检测技术（如 JavaScript 监测、IntersectionObserver API、Moat/IAS 等第三方验证）的结果可能不一致。

**转化埋点的实现方式**

转化埋点的实现取决于转化发生的位置：

- **Web 端转化**：在广告主的网站中植入转化像素（Conversion Pixel），当用户完成目标行为（如提交订单）时触发像素请求，将转化数据回传给广告平台。
- **App 端转化**：通过集成第三方归因 SDK（如 AppsFlyer、Adjust、Branch）或平台自有 SDK，在 App 内采集安装、注册、购买等转化事件，并回传给广告平台。
- **线下转化**：通过上传 CRM 数据（如门店购买记录），与广告曝光/点击数据进行匹配，实现线下转化的归因。
- **服务端转化回传（S2S）**：广告主的后端服务器直接向广告平台的 API 发送转化事件。这种方式更可靠（不受客户端环境限制），也更符合隐私合规要求（Meta 的 Conversions API、Google 的 Enhanced Conversions 都是基于此方式）。

### 埋点质量的关键指标

埋点数据的质量直接影响模型训练效果和计费准确性。衡量埋点质量的核心指标包括：

**上报率**

上报率 = 实际上报的埋点事件数 / 理论应上报的埋点事件数。理想情况下上报率应为 100%，但实际中会因以下原因导致部分事件丢失：

- 网络问题：弱网环境下客户端埋点请求发送失败。
- 客户端异常：App 崩溃导致未来得及发送的埋点数据丢失。
- 采样丢失：部分系统为了降低数据量，对埋点事件进行了采样。

上报率低于 95% 时，应当排查并解决丢失原因。常用的保障手段包括：本地缓存+重试、批量上报、关键埋点服务端补发等。

**去重**

同一次广告展示或点击，可能因为页面刷新、网络重试、SDK bug 等原因被重复上报。重复的埋点事件如果不被过滤，会导致：

- CTR 被高估（展示重复计数导致分母偏大，但如果点击也重复则影响不确定）。
- 计费不准确（广告主被多收费）。
- 模型训练数据被污染。

去重的常见方法是为每次事件生成唯一的 Request ID 或 Impression ID，在数据处理层按 ID 去重。

**时效性**

埋点数据从产生到入库的延迟（Data Latency）直接影响两个方面：

- **实时报表的准确性**：广告主需要近实时地了解投放效果（展示量、点击量、花费），数据延迟过高会影响广告主的决策和体验。
- **模型训练的时效性**：在线学习模型需要近实时的训练数据输入。如果展示和点击数据延迟到达，模型无法及时学习最新的用户行为模式。

大型广告平台通常要求关键埋点数据的端到端延迟在分钟级以内，这对数据管道的实时性提出了很高的要求（需要使用 Kafka、Flink 等流式处理基础设施）。

**口径一致性**

口径一致性指不同数据源对同一指标的统计结果应当一致。在广告系统中，常见的口径不一致问题包括：

- **前后端口径差异**：前端 SDK 上报的展示数和后端日志记录的广告返回数不一致。前端展示可能因为广告未渲染完成就被用户滑走而少于后端返回数；也可能因为客户端缓存导致同一广告被多次展示而多于后端返回数。
- **广告主与平台的数据差异**：广告主的第三方监测工具（如 DV、MOAT）统计的展示数与平台统计的展示数不一致，导致计费争议。
- **实时数据与离线报表的差异**：实时数据管道和离线数据管道的处理逻辑（去重规则、过滤条件）不完全一致，导致实时看板与次日报表的数据有差异。

口径一致性问题需要通过统一数据定义文档、对齐计算逻辑、定期进行数据审计来解决。

### 归因模型

归因（Attribution）是广告效果度量中最复杂也最具争议性的话题之一。它要回答的核心问题是：**用户最终的转化行为，应该归功于哪次广告触达？**

在简单的场景中（用户看到一条广告 → 点击 → 立即购买），归因不是问题。但在现实中，用户的转化路径通常是复杂的多触点过程：

用户可能先在 YouTube 看到品牌视频广告 → 后来在 Google 搜索品牌关键词并点击搜索广告 → 又在购物网站看到 Banner 再营销广告 → 最终直接访问品牌官网完成购买。在这个链路中，视频广告、搜索广告和再营销广告都起到了一定的作用，如何分配"功劳"？

**主流归因模型**

| 归因模型 | 逻辑 | 优势 | 局限 |
|---------|------|------|------|
| 最后点击归因（Last Click） | 最后一次被用户点击的广告获得 100% 的功劳 | 简单、确定性强 | 忽略了上层漏斗广告的贡献 |
| 最后触达归因（Last Touch） | 最后一次展示或点击的广告获得全部功劳 | 包含了展示的价值 | 仍然忽视了之前触点的作用 |
| 首次触达归因（First Touch） | 第一次触达的广告获得全部功劳 | 强调了"获客"的价值 | 忽略了后续触点在转化中的推动作用 |
| 线性归因（Linear） | 所有触点平均分配功劳 | 承认了所有触点的贡献 | 没有区分不同触点的重要性差异 |
| 时间衰减归因（Time Decay） | 越接近转化的触点获得越多的功劳 | 反映了"临门一脚"的重要性 | 衰减函数的选择缺乏客观依据 |
| 位置归因（Position-based / U-shaped） | 首次和最后一次触点各获得 40%，中间触点分享 20% | 兼顾了获客和转化的价值 | 40/20/40 的比例是人为设定的 |
| 数据驱动归因（Data-Driven Attribution） | 基于模型计算每个触点的真实边际贡献 | 最接近真实的功劳分配 | 需要大量数据，计算复杂 |

**最后点击归因**长期以来是行业的默认标准，因为它简单、确定性强、易于实施。但它系统性地低估了品牌广告和上层漏斗广告的价值——这些广告可能在用户心中种下了品牌认知的种子，但因为不是"最后一次点击"而被归因模型忽略。

**数据驱动归因**是目前最先进的归因方法，它通过机器学习模型（如 Shapley Value、Markov Chain 等）分析大量转化路径数据，计算每个触点的真实边际贡献。Google Ads 和 Meta Ads 都已经将数据驱动归因作为默认或推荐的归因模型。但数据驱动归因需要足够大的样本量（通常要求数千次转化），对于数据量不足的中小广告主来说可能不适用。

**归因窗口**

归因窗口（Attribution Window）定义了"转化行为在多长时间内可以被归因给之前的广告触达"。常见的行业惯例：

| 触达类型 | 归因窗口 | 说明 |
|---------|---------|------|
| 点击归因 | 7 天 / 28 天 | 用户点击广告后 7 天内的转化归因给该广告 |
| 展示归因 | 1 天 | 用户看到广告后 1 天内的转化归因给该广告 |

归因窗口的设定是一个平衡性问题：

- **窗口太长**：可能将与广告无关的自然转化错误地归因给广告，导致广告效果被高估。
- **窗口太短**：可能忽略了广告的延迟影响效应，导致广告效果被低估。

不同行业的合理归因窗口差异很大。快消品的购买决策周期短，7 天点击归因通常足够；汽车、房产等高客单价行业的决策周期长达数月，28 天甚至更长的归因窗口可能更合适。

**跨渠道归因的挑战**

在实际投放中，广告主通常在多个渠道（搜索、社交、展示、视频等）同时投放广告。跨渠道归因的核心难题是**数据的割裂**——每个广告平台只能看到自己渠道内的触点数据，无法看到用户在其他渠道的触达历史。

这导致了一个普遍的现象：每个平台都倾向于将转化归因给自己的广告触达（因为它只能看到自己的数据），所有平台声称带来的转化加起来往往远超实际总转化数。这就是所谓的"归因膨胀"问题。

解决跨渠道归因问题的方法包括：

- **第三方归因平台**：使用独立的第三方归因平台（如 AppsFlyer、Adjust 在移动端，Google Analytics 在 Web 端）作为"裁判"，统一收集各渠道的触点数据，进行去重和归因。
- **Marketing Mix Modeling（MMM）**：使用宏观经济学方法，通过分析广告预算变化与总体转化的相关性来评估各渠道的贡献。MMM 不依赖于用户级数据，天然适合隐私合规环境，但粒度较粗、时效性较低。
- **增量测试（Incrementality Test）**：通过 A/B 测试的方式，对比"投放广告"和"不投放广告"两组用户的转化差异，直接测量广告带来的增量效果。这是衡量广告真实价值的"金标准"，但成本较高（需要牺牲一部分流量作为对照组）。

## 隐私合规对广告数据基建的冲击与重构

### 全球隐私监管的加速收紧

过去几年，全球范围内的隐私保护法规和平台政策正在深刻重塑广告数据基建的游戏规则。这不仅是法律层面的合规要求，更是对广告技术底层架构的根本性挑战。

**GDPR（General Data Protection Regulation，通用数据保护条例）**

2018 年生效的欧盟 GDPR 是全球最严格的数据保护法规，其核心原则包括：

- **合法性基础**：数据的收集和处理必须有合法依据，最常用的是"用户同意"（Consent）。
- **数据最小化**：只能收集达成目的所必需的最少数据。
- **目的限制**：数据只能用于收集时明确告知的目的。
- **用户权利**：用户有权访问、更正、删除自己的数据（"被遗忘权"）。
- **数据可移植性**：用户有权将自己的数据以通用格式导出并转移到其他服务。

GDPR 对广告系统的影响是深远的。在用户未授权的情况下，广告系统不能使用 Cookie、设备 ID 等方式追踪用户行为。违规的处罚极其严厉——最高可达全球年营业额的 4% 或 2000 万欧元（取较高者）。Google 因 GDPR 相关违规已被法国数据保护机构 CNIL 处以 1.5 亿欧元的罚款。

**CCPA（California Consumer Privacy Act，加利福尼亚消费者隐私法案）**

2020 年生效的 CCPA 是美国最具影响力的隐私法规，赋予了加州消费者以下权利：

- **知情权**：消费者有权知道企业收集了哪些个人数据。
- **删除权**：消费者有权要求企业删除其个人数据。
- **退出权**：消费者有权拒绝企业出售其个人数据（"Do Not Sell My Personal Information"）。
- **非歧视权**：企业不得因消费者行使隐私权利而对其进行歧视。

**苹果 ATT 框架**

如前文所述，ATT 框架要求 App 在追踪用户之前获得明确授权。其影响已经在前文的移动端身份标识章节中详细讨论。这里需要补充的是，ATT 不仅影响了 IDFA 的获取，还间接改变了整个移动广告生态的数据流通方式——没有 IDFA，第三方广告网络无法在不同 App 之间进行用户级别的数据交换。

**Google Privacy Sandbox**

Google 的 Privacy Sandbox 计划旨在为 Chrome 浏览器和 Android 系统提供一套替代第三方 Cookie 和设备标识符的隐私保护技术方案。核心组件包括：

- **Topics API**：取代第三方 Cookie 的兴趣定向能力。浏览器根据用户近期的浏览历史推断出若干兴趣主题（如"运动"、"旅游"），在用户访问参与了 Topics API 的网站时，将这些主题（而非详细的浏览历史）分享给广告网络。主题的粒度较粗（约 350 个类别），且每个主题包含 5% 的随机噪声以增强隐私保护。
- **Attribution Reporting API**：取代传统的像素级归因方式。该 API 在浏览器本地完成归因计算，仅向广告平台发送聚合化的归因报告，不暴露用户级的点击-转化关联。报告分为事件级报告（有一定的噪声和延迟）和汇总报告（高度聚合化），广告平台需要适应这种低粒度的归因数据。
- **Protected Audience API（原 FLEDGE）**：取代再营销中的用户列表机制。广告竞价在用户的浏览器本地进行，而非在远程服务器上，用户的兴趣组信息不离开设备。
- **Private Aggregation API**：提供隐私保护的数据聚合能力，使广告平台可以在不获取个体用户数据的前提下进行统计分析。

### 隐私合规对广告系统的具体影响

隐私法规和平台政策的收紧，对广告系统的影响可以从以下几个维度来分析：

**定向能力下降**

第三方 Cookie 的淘汰和 IDFA 的受限，使得广告系统的跨站/跨 App 用户追踪能力大幅削弱。具体表现包括：

- 基于第三方 Cookie 的兴趣定向和行为定向受到限制（尤其在 Safari 和 Firefox 中已经完全失效）。
- 跨 App 的再营销列表覆盖率下降（未授权 ATT 的 iOS 用户无法进入再营销列表）。
- Lookalike 人群扩展的精准度下降（种子用户与全量用户的关联能力减弱）。

根据行业测算，第三方 Cookie 完全淘汰后，仅依赖传统定向手段的广告平台，其定向精准度可能下降 30%~50%，对应的广告收入可能下降 20%~30%。

**归因精度降低**

传统的归因依赖于用户级的跨站追踪——广告平台需要知道"用户 A 在网站 X 看到了广告，然后在网站 Y 完成了购买"。没有第三方 Cookie 和 IDFA，这种用户级的跨站归因变得不可能（或至少不准确）。

SKAdNetwork 等隐私保护归因框架虽然提供了替代方案，但数据的粒度、时效性和准确性都大幅下降：

- **粒度下降**：从用户级归因变为广告活动级归因，无法分析单个用户的转化路径。
- **时效性下降**：归因数据从实时/近实时变为延迟 24~48 小时。
- **准确性下降**：引入噪声和随机化机制，单条归因数据的准确性降低。

**对第一方数据的依赖加强**

在第三方数据获取受限的环境下，广告主和平台对第一方数据的依赖显著增强。这推动了以下趋势：

- **CDP（Customer Data Platform）建设热潮**：广告主纷纷投资建设自己的第一方数据平台，将 CRM、网站行为、App 行为、线下交易等数据统一管理和激活。
- **"围墙花园"效应加剧**：拥有大规模登录态第一方数据的平台（Google、Meta、Amazon、字节跳动等）在隐私合规环境中的竞争优势进一步扩大，因为它们不依赖第三方数据也能实现精准定向。
- **第一方数据的交换与合作**：广告主与媒体平台通过"数据清洁室"（Data Clean Room）等隐私保护技术进行第一方数据的匹配和分析，在不共享原始用户数据的前提下实现联合洞察。

### 应对策略：广告数据基建的重构方向

面对隐私合规的冲击，广告行业正在从多个维度进行数据基建的重构：

**第一方数据战略**

第一方数据战略不仅是"收集更多的第一方数据"，还包括：

- **数据资产化**：将分散在各业务系统中的第一方数据统一整合、标准化，使其成为可被投放系统直接使用的数据资产。
- **价值交换**：通过提供优质的产品体验和个性化服务，激励用户主动分享数据（如注册会员、订阅推送、填写偏好调查）。
- **全链路追踪**：建设从广告展示到最终转化的全链路第一方追踪能力（服务端归因、Conversion API 等），减少对第三方 Cookie 的依赖。

**上下文定向的回归**

上下文定向不依赖于用户身份追踪，天然符合隐私保护要求。在第三方 Cookie 和 IDFA 受限的环境下，上下文定向正在经历"文艺复兴"：

- **语义理解升级**：传统的上下文定向基于关键词匹配，精度有限。现代的上下文定向使用自然语言处理（NLP）技术，对页面内容进行深层语义分析，理解文章的主题、情感、品牌安全性等。
- **品牌安全**：上下文定向可以确保广告不出现在品牌不希望关联的内容（如暴力、政治争议等）旁边。
- **页面级信号**：不仅分析文本内容，还可以分析页面中的图片、视频等多媒体元素，构建更丰富的上下文特征。

值得注意的是，上下文定向的精准度通常不如基于用户行为的定向，它更适合品牌广告和上层漏斗投放，而非效果类投放。

**隐私计算技术**

隐私计算技术旨在实现"数据可用不可见"——在不暴露原始数据的前提下，完成数据的分析和建模。在广告领域，主要的隐私计算技术包括：

- **联邦学习（Federated Learning）**：模型训练在各参与方本地进行，只交换模型参数（梯度）而非原始数据。Google 已经在 Chrome 的 Privacy Sandbox 中使用联邦学习技术进行广告相关性建模。在广告场景中，联邦学习可以使广告主和媒体平台在不共享用户级数据的前提下联合训练预估模型。
- **差分隐私（Differential Privacy）**：在数据查询或模型训练过程中注入统计噪声，使得无法从输出中推断出单个用户的信息。苹果的 SKAdNetwork 和 Google 的 Attribution Reporting API 都使用了差分隐私技术来保护用户隐私。差分隐私的挑战在于噪声的引入会降低数据的实用性，需要在隐私保护程度和数据精度之间找到平衡。
- **安全多方计算（Secure Multi-Party Computation, MPC）**：多个参与方在不暴露各自数据的情况下，共同计算一个函数的结果。例如，广告主和媒体平台可以通过 MPC 计算两方数据的交集用户数量（用于人群匹配率估算），而不暴露具体的用户 ID 列表。
- **数据清洁室（Data Clean Room）**：一种受控的数据协作环境，多方将各自的数据导入一个安全的隔离环境中进行联合分析，分析结果以聚合化的形式输出，原始数据不离开清洁室。Google Ads Data Hub、Meta Advanced Analytics 和 Amazon Marketing Cloud 都是典型的数据清洁室产品。

**服务端转化追踪**

传统的转化追踪依赖于客户端（浏览器/App）发送的像素请求，受到浏览器隐私策略和广告拦截器的影响越来越大。服务端转化追踪（Server-Side Conversion Tracking）提供了一种更可靠的替代方案：

- 转化事件由广告主的后端服务器发送给广告平台的 API（如 Meta Conversions API、Google Enhanced Conversions、TikTok Events API）。
- 服务端追踪不受浏览器 Cookie 限制和广告拦截器的影响，数据传输更可靠。
- 广告主可以在服务端对数据进行预处理（如哈希化个人信息）后再发送，更好地控制数据隐私。
- 服务端追踪可以传递更丰富的转化数据（如订单金额、产品类别等），支持广告平台进行更精细的优化。

服务端转化追踪正在成为行业的标准实践。Meta 的数据显示，同时使用 Conversions API 和像素的广告主，转化事件的捕获率比仅使用像素的广告主高出 20%~30%。

### 数据基建的演进方向

综合以上分析，广告数据基建正在经历一场深刻的范式转变：

| 维度 | 旧范式 | 新范式 |
|------|--------|--------|
| 用户识别 | 第三方 Cookie / IDFA | 第一方登录态 + 统一 ID + 概率性匹配 |
| 数据来源 | 重度依赖第三方数据 | 以第一方数据为核心 |
| 定向策略 | 基于用户级追踪的行为定向 | 上下文定向 + 群组级定向 + 模型自动定向 |
| 归因模型 | 用户级、实时、确定性归因 | 聚合化、延迟、概率性归因 + 增量测试 |
| 数据协作 | 原始数据交换 | 隐私计算（联邦学习、MPC、数据清洁室） |
| 转化追踪 | 客户端像素 | 服务端 API + 客户端像素双重追踪 |
| 效果度量 | 点击归因为主 | 多触点归因 + MMM + 增量测试的组合 |

这场转变的本质是：广告行业正在从"以追踪个体用户为中心"的数据范式，转向"以隐私保护为前提的智能推断"范式。在这个过程中，数据基建的技术复杂度大幅增加，但也在推动行业朝着更可持续、更尊重用户的方向发展。

## 全文总结

广告系统的数据基建是一个庞大而精密的工程体系。从用户身份识别的基础层开始，经过 DMP 的数据管理与标签化处理，到定向策略的设计与实施，再到 CTR/CVR 预估模型的核心决策引擎，最后通过数据埋点体系完成效果度量与反馈闭环——每个环节都紧密咬合，共同构成了广告系统的数据运转链路。

回顾全文讨论的核心主题：

- **用户身份体系**是数据基建的地基。Cookie、设备标识符、Cookie Mapping、身份图谱等技术手段，共同支撑起了广告系统识别用户的能力。但随着第三方 Cookie 淘汰和 IDFA 受限，这一地基正在经历重建。
- **DMP** 是数据的中枢神经，负责将原始数据转化为可用的标签和人群包。标签体系的设计质量、人群包的管理精度、Lookalike 的扩展效果，直接决定了定向的上限。
- **广告定向**是连接数据与投放的桥梁。从粗放的地理/人口定向到精准的行为定向和再营销，定向策略的演进反映了数据能力的升级。自动定向的兴起则标志着机器学习正在接管越来越多的人工决策。
- **CTR/CVR 预估模型**是广告系统的价值评估引擎。从逻辑回归到深度学习再到多任务学习，模型的演进背后是对数据规模和特征交互建模能力的持续追求。
- **数据埋点与归因**是效果度量的基础。埋点质量直接影响模型训练和计费准确性，归因模型的选择则影响广告主对各渠道价值的判断。
- **隐私合规**正在重塑整个数据基建的范式。第一方数据战略、上下文定向回归、隐私计算技术和服务端追踪，共同构成了新时代广告数据基建的技术方向。

对于广告系统的建设者和从业者而言，理解数据基建的全貌——不仅是各个组件的技术原理，更是它们之间的关联关系和整体运作逻辑——是设计和优化广告系统的前提。数据质量的提升、预估精度的改善、隐私合规的适配，这些工作都不是孤立的技术优化，而是需要在系统层面统筹考虑的系统性工程。
